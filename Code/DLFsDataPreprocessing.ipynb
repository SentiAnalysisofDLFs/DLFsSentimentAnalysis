{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf57444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import mysql.connector\n",
    "import mysql.connector\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74edbbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_mysql(database):\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"123456\",\n",
    "        database=database\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "# 从MySQL中检索数据\n",
    "def fetch_data_from_mysql(conn, table_name, *columns):\n",
    "    columns_str = ', '.join(columns)\n",
    "    query = \"SELECT {} FROM `{}`\".format(columns_str, table_name)\n",
    "    df = pd.read_sql(query, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0806ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(comment):\n",
    "    if pd.isna(comment) or comment.strip() == '':\n",
    "        return None  # 返回 None 如果字符串为空或为 NaN\n",
    "    try:\n",
    "        return json.loads(comment)  # 尝试解析 JSON\n",
    "    except json.JSONDecodeError:\n",
    "        return None  # 如果不是有效的 JSON，返回 None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a56aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入一段字符串 输出这段字符串包含的文件是否涉及多语言\n",
    "def dulge_ifMpl(a):\n",
    "    str1 = ''.join(str(i) for i in a)\n",
    "    flag = 0\n",
    "    c = 0\n",
    "    py = 0\n",
    "    lua1 = 0\n",
    "    java = 0\n",
    "    ruby = 0\n",
    "    cuda = 0\n",
    "    js = 0\n",
    "    cp1 = 0\n",
    "    cx = 0\n",
    "    go1 = 0\n",
    "    ts = 0\n",
    "    swift = 0\n",
    "    Haskell1 = 0\n",
    "    erl = 0\n",
    "    kt = 0\n",
    "    lsp = 0\n",
    "    rs = 0\n",
    "    vue = 0\n",
    "    groovy = 0\n",
    "    scala = 0\n",
    "    CoffeeScript = 0\n",
    "    perl = 0\n",
    "    Clojure = 0\n",
    "    F1 = 0\n",
    "    PHP = 0\n",
    "    cp2 = 0\n",
    "    expect = 0\n",
    "    sh = 0\n",
    "    glsl = 0\n",
    "    j2 = 0\n",
    "    if any(ext in str1 for ext in [\".cpp'\", \".h'\", \".c'\", \".hpp'\", \".cc'\", \".hxx'\", \".cxx'\", \".hh'\"]):\n",
    "        c = 1\n",
    "    if any(ext in str1 for ext in [\".cuh'\", \".cu'\"]):\n",
    "        cuda = 1\n",
    "    if (\".py'\" in str1):\n",
    "        py = 1\n",
    "    if (\".lua'\" in str1):\n",
    "        lua1 = 1\n",
    "    if any(ext in str1 for ext in [\".java'\", \".jav'\"]):\n",
    "        java = 1\n",
    "    if (\".rb'\" in str1):\n",
    "        ruby = 1\n",
    "    if (\".js'\" in str1):\n",
    "        js = 1\n",
    "    if (\".m'\" in str1):\n",
    "        cp1 = 1  # Objective-C\n",
    "    if (\".mm'\" in str1):\n",
    "        cp2 = 1  # Objective-C++\n",
    "    if (\".cs'\" in str1):\n",
    "        cx = 1  # C#\n",
    "    if (\".go'\" in str1):\n",
    "        go1 = 1\n",
    "    if (\".ts'\" in str1):\n",
    "        ts = 1  # TypeScript\n",
    "    if (\".swift'\" in str1):\n",
    "        swift = 1\n",
    "    if (\".hs'\" in str1):\n",
    "        Haskell1 = 1\n",
    "    if (\".erl'\" in str1):\n",
    "        erl = 1  # Erlang\n",
    "    if (\".kt'\" in str1):\n",
    "        kt = 1  # Kotlin\n",
    "    if (\".lsp'\" in str1):\n",
    "        lsp = 1  # LISP\n",
    "    if (\".rs'\" in str1):\n",
    "        rs = 1  # Rust\n",
    "    if (\".vue'\" in str1):\n",
    "        vue = 1  # vue\n",
    "    if (\".groovy'\" in str1):\n",
    "        groovy = 1  # groovy\n",
    "    if any(ext in str1 for ext in [\".sc'\", \".scala'\"]):\n",
    "        scala = 1  # Scala\n",
    "    if any(ext in str1 for ext in [\".coffee'\", \".litcoffee'\"]):\n",
    "        CoffeeScript = 1  # CoffeeScript\n",
    "    if any(ext in str1 for ext in [\".pl'\", \".prl'\", \".pm'\", \".perl'\"]):\n",
    "        perl = 1  # perl\n",
    "    if any(ext in str1 for ext in [\".clj'\", \".cljs'\", \".cljc'\", \".edn'\"]):\n",
    "        Clojure = 1  # Clojure\n",
    "    if any(ext in str1 for ext in [\".fs'\", \".fsi'\", \".fsx'\", \".fsscript'\"]):\n",
    "        F1 = 1  # F#\n",
    "    if any(ext in str1 for ext in [\".php'\", \".php3'\", \".php4'\", \".php5'\", \".php7'\"]):\n",
    "        PHP = 1  # PHP\n",
    "    if (\".expect'\" in str1):\n",
    "        expect = 1\n",
    "    if (\".sh'\" in str1):\n",
    "        sh = 1\n",
    "    if (\".glsl'\" in str1):\n",
    "        glsl = 1\n",
    "    if (\".j2'\" in str1):\n",
    "        j2 = 1\n",
    "    if ((c + py + lua1 + java + ruby + cuda + js + cp1 + cp2 + cx + go1 + ts + swift + Haskell1 + erl + kt + lsp + rs + vue + groovy + scala + CoffeeScript + perl + Clojure + F1 + PHP + expect + sh + glsl + j2) >= 2):\n",
    "        flag = 1\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cb0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_issueData_to_sentimentAnalysis(df_issue_content, df_pr_data, df_issue_data, list_sentiAnalysis):\n",
    "    \"\"\"\n",
    "    将issue的comments转化为情感分析DataFrame。\n",
    "\n",
    "    参数:\n",
    "    df_issue_content: 包含IssueContent的DataFrame。\n",
    "    df_pr_data: 包含Issue是否为多语言issue的DataFrame。\n",
    "    df_issue_data: 包含Issue类别的DataFrame。\n",
    "    list_sentiAnalysis: 用于存储新行数据的列表。\n",
    "\n",
    "    返回:\n",
    "    None。\n",
    "    \"\"\"\n",
    "    # 遍历 df_issue_content 并将数据添加到 new_rows 列表\n",
    "    for index, row in df_issue_content.iterrows():\n",
    "        relatedPrID = df_issue_data.loc[df_issue_data['IssueID'] == row['IssueID'], 'RelatedPrId'].values[0]\n",
    "        issueCategory = df_issue_data.loc[df_issue_data['IssueID'] == row['IssueID'], 'Category'].values[0]\n",
    "        isMPLF = df_pr_data.loc[df_pr_data['PrRelatedIssueId'] == row['IssueID'], 'IsMPLF'].values[0]\n",
    "#         new_row = {\n",
    "#             'TextContent': row['IssueContent'],\n",
    "#             'TextType': 'IssueBody',\n",
    "#             'url': row['url'],\n",
    "#             'Creator': row['IssueCreator'],\n",
    "#             'CreatedAt': row['IssueCreatedAt'],\n",
    "#             'IssueID': row['IssueID'],\n",
    "#             'RelatedPrID': relatedPrID,\n",
    "#             'IssueCategory': issueCategory,\n",
    "#             'IsMPLF': isMPLF\n",
    "#         }\n",
    "#         # 将新行字典添加到新行列表\n",
    "#         list_sentiAnalysis.append(new_row)\n",
    "        \n",
    "         # 处理 files 列，当其不为空\n",
    "        if row['IssueComments']:\n",
    "            comments = row['IssueComments']\n",
    "            for comment in comments:\n",
    "                comment_row = {\n",
    "                    'TextContent': comment['body'],\n",
    "                    'TextType': 'IssueComment',\n",
    "                    'url': comment['url'],\n",
    "                    'Creator': comment['creator'],\n",
    "                    'CreatedAt': datetime.datetime.strptime(comment['createdAt'], '%Y-%m-%dT%H:%M:%SZ'),\n",
    "                    'IssueID': row['IssueID'],\n",
    "                    'RelatedPrID': relatedPrID,\n",
    "                    'IssueCategory': issueCategory,\n",
    "                    'IsMPLF': isMPLF\n",
    "                }\n",
    "                list_sentiAnalysis.append(comment_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a972dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_prData_to_sentimentAnalysis(df_pr_content, df_pr_data, df_issue_data, list_sentiAnalysis):\n",
    "    \"\"\"\n",
    "    将issue的content和comments转化为情感分析DataFrame。\n",
    "\n",
    "    参数:\n",
    "    df_issue_content: 包含IssueContent和Comments的DataFrame。\n",
    "    df_pr_data: 包含Issue是否为多语言issue的DataFrame\n",
    "    df_issue_data: 包含Issue类别的DataFrame\n",
    "    list_sentiAnalysis: 用于存储新行数据的列表。\n",
    "\n",
    "    返回:\n",
    "    None: 直接修改提供的新行列表。\n",
    "    \"\"\"\n",
    "    # 遍历 df_issue_content 并将数据添加到 new_rows 列表\n",
    "    for index, row in df_pr_content.iterrows():\n",
    "        issueID = df_pr_data.loc[df_pr_data['PrID'] == row['PrID'], 'PrRelatedIssueId'].values[0]\n",
    "        # 判断该pull request对应的issue在不在已分类的issues中，不在则过滤掉\n",
    "        if(issueID not in df_issue_data['IssueID'].values):\n",
    "            continue\n",
    "        \n",
    "        issueCategory = df_issue_data.loc[df_issue_data['IssueID'] == issueID, 'Category'].values[0]\n",
    "        isMPLF = df_pr_data.loc[df_pr_data['PrRelatedIssueId'] == issueID, 'IsMPLF'].values[0]\n",
    "#         new_row = {\n",
    "#             'TextContent': row['PrContent'],\n",
    "#             'TextType': 'PrBody',\n",
    "#             'url': row['url'],\n",
    "#             'Creator': row['PrCreator'],\n",
    "#             'CreatedAt': row['PrCreatedAt'],\n",
    "#             'IssueID': issueID,\n",
    "#             'RelatedPrID': row['PrID'],\n",
    "#             'IssueCategory': issueCategory,\n",
    "#             'IsMPLF': isMPLF\n",
    "#         }\n",
    "#         # 将新行字典添加到新行列表\n",
    "#         list_sentiAnalysis.append(new_row)\n",
    "        \n",
    "         # 处理 files 列，当其不为空\n",
    "        if row['PrComments']:\n",
    "            comments = row['PrComments']\n",
    "            for comment in comments:\n",
    "                comment_row = {\n",
    "                    'TextContent': comment['body'],\n",
    "                    'TextType': 'PrComment',\n",
    "                    'url': comment['url'],\n",
    "                    'Creator': comment['creator'],\n",
    "                    'CreatedAt': datetime.datetime.strptime(comment['createdAt'], '%Y-%m-%dT%H:%M:%SZ'),\n",
    "                    'IssueID': issueID,\n",
    "                    'RelatedPrID': row['PrID'],\n",
    "                    'IssueCategory': issueCategory,\n",
    "                    'IsMPLF': isMPLF\n",
    "                }\n",
    "                list_sentiAnalysis.append(comment_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94020a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # 替换 URL、filePath、电子邮件、代码片段等为特定标记\n",
    "    def replace_patterns(text):\n",
    "        url_pattern = re.compile(r'(?:https?://|www\\.)(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        email_pattern = re.compile(r'\\b[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\\b')\n",
    "        code_pattern = re.compile(r'`[^`]+`')  # Markdown inline code\n",
    "        \n",
    "        text = url_pattern.sub(\"[url]\", text)\n",
    "        text = email_pattern.sub(\"[email]\", text)\n",
    "        text = code_pattern.sub(\"[code]\", text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    # 从文本中识别并替换标记\n",
    "    text = replace_patterns(text)\n",
    "    \n",
    "    # 去除特殊字符和非字母数字表情字符\n",
    "    pattern = r'[^a-zA-Z0-9\\s.,!?;:\\[\\] \\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FAFF]'\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    \n",
    "    # 去除多余空格：替换多个空格为一个空格，并去掉文本开头和结尾的空格\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b0702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shone\\AppData\\Local\\Temp\\ipykernel_20208\\4263502064.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据条数： 190\n",
      "数据条数： 259\n",
      "数据条数： 190\n",
      "数据条数： 244\n",
      "1113\n"
     ]
    }
   ],
   "source": [
    "conn = connect_to_mysql('deep_learning')\n",
    "df_incubator_mxnet_issue_data = fetch_data_from_mysql(conn, 'incubator-mxnet_issue_data', 'IssueID', 'RelatedPrId', 'Category')\n",
    "df_incubator_mxnet_pr_data = fetch_data_from_mysql(conn, 'incubator-mxnet_pr_data', 'PrID', 'PrRelatedIssueId', 'Files')\n",
    "df_issue_content_mx = fetch_data_from_mysql(conn, 'issue_content_mx', 'IssueID', 'IssueContent', 'url', 'IssueCreator', 'IssueCreatedAt', 'IssueCommentsNum', 'IssueComments')\n",
    "df_pr_content_mx = fetch_data_from_mysql(conn, 'pr_content_mx', 'PrID', 'PrContent', 'url', 'PrCreator', 'PrCreatedAt', 'PrCommentsNum', 'PrComments')\n",
    "conn.close()\n",
    "\n",
    "df_incubator_mxnet_issue_data.drop_duplicates(inplace=True)\n",
    "df_incubator_mxnet_pr_data.drop_duplicates(inplace=True)\n",
    "df_issue_content_mx.drop_duplicates(inplace=True)\n",
    "df_pr_content_mx.drop_duplicates(inplace=True)\n",
    "\n",
    "print('数据条数：', df_incubator_mxnet_issue_data.shape[0])\n",
    "print('数据条数：', df_incubator_mxnet_pr_data.shape[0])\n",
    "print('数据条数：', df_issue_content_mx.shape[0])\n",
    "print('数据条数：', df_pr_content_mx.shape[0])\n",
    "\n",
    "df_issue_content_mx['IssueComments'] = df_issue_content_mx.IssueComments.apply(load_json)\n",
    "df_pr_content_mx['PrComments'] = df_pr_content_mx.PrComments.apply(load_json)\n",
    "df_incubator_mxnet_pr_data['IsMPLF'] = df_incubator_mxnet_pr_data.Files.apply(dulge_ifMpl)\n",
    "\n",
    "# 创建 sentiment_analysis 列表\n",
    "sentiment_analysis_mx = []\n",
    "\n",
    "# 调用函数以转换数据并填充 new_rows\n",
    "convert_issueData_to_sentimentAnalysis(df_issue_content_mx, df_incubator_mxnet_pr_data, df_incubator_mxnet_issue_data, sentiment_analysis_mx)\n",
    "convert_prData_to_sentimentAnalysis(df_pr_content_mx, df_incubator_mxnet_pr_data, df_incubator_mxnet_issue_data, sentiment_analysis_mx)\n",
    "# 将收集的行列表转换为 DataFrame\n",
    "df_sentiment_analysis_mx = pd.DataFrame(sentiment_analysis_mx)\n",
    "print(df_sentiment_analysis_mx.shape[0])\n",
    "\n",
    "df_sentiment_analysis_mx['CleanedTextContent'] = df_sentiment_analysis_mx.TextContent.apply(preprocess_text)\n",
    "df_sentiment_analysis_mx.to_csv('./processing_sentiment_analysis_mxComments_v1.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54cbd8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shone\\AppData\\Local\\Temp\\ipykernel_20208\\4263502064.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据条数： 927\n",
      "数据条数： 1068\n",
      "数据条数： 927\n",
      "数据条数： 1068\n",
      "7166\n"
     ]
    }
   ],
   "source": [
    "conn = connect_to_mysql('deep_learning')\n",
    "df_pytorch_issue_data = fetch_data_from_mysql(conn, 'pytorch_issue_data', 'IssueID', 'RelatedPrId', 'Category')\n",
    "df_pytorch_pr_data = fetch_data_from_mysql(conn, 'pytorch_pr_data', 'PrID', 'PrRelatedIssueId', 'PrFiles')\n",
    "df_issue_content_py = fetch_data_from_mysql(conn, 'issue_content_py', 'IssueID', 'IssueContent', 'url', 'IssueCreator', 'IssueCreatedAt', 'IssueCommentsNum', 'IssueComments')\n",
    "df_pr_content_py = fetch_data_from_mysql(conn, 'pr_content_py', 'PrID', 'PrContent', 'url', 'PrCreator', 'PrCreatedAt', 'PrCommentsNum', 'PrComments')\n",
    "conn.close()\n",
    "\n",
    "df_pytorch_issue_data.drop_duplicates(inplace=True)\n",
    "df_pytorch_pr_data.drop_duplicates(inplace=True)\n",
    "df_issue_content_py.drop_duplicates(inplace=True)\n",
    "df_pr_content_py.drop_duplicates(inplace=True)\n",
    "\n",
    "print('数据条数：', df_pytorch_issue_data.shape[0])\n",
    "print('数据条数：', df_pytorch_pr_data.shape[0])\n",
    "print('数据条数：', df_issue_content_py.shape[0])\n",
    "print('数据条数：', df_pr_content_py.shape[0])\n",
    "\n",
    "df_issue_content_py['IssueComments'] = df_issue_content_py.IssueComments.apply(load_json)\n",
    "df_pr_content_py['PrComments'] = df_pr_content_py.PrComments.apply(load_json)\n",
    "df_pytorch_pr_data['IsMPLF'] = df_pytorch_pr_data.PrFiles.apply(dulge_ifMpl)\n",
    "\n",
    "# 创建 sentiment_analysis 列表\n",
    "sentiment_analysis_py = []\n",
    "\n",
    "# 调用函数以转换数据并填充 new_rows\n",
    "convert_issueData_to_sentimentAnalysis(df_issue_content_py, df_pytorch_pr_data, df_pytorch_issue_data, sentiment_analysis_py)\n",
    "convert_prData_to_sentimentAnalysis(df_pr_content_py, df_pytorch_pr_data, df_pytorch_issue_data, sentiment_analysis_py)\n",
    "# 将收集的行列表转换为 DataFrame\n",
    "df_sentiment_analysis_py = pd.DataFrame(sentiment_analysis_py)\n",
    "print(df_sentiment_analysis_py.shape[0])\n",
    "\n",
    "df_sentiment_analysis_py['CleanedTextContent'] = df_sentiment_analysis_py.TextContent.apply(preprocess_text)\n",
    "df_sentiment_analysis_py.to_csv('./processing_sentiment_analysis_pyComments_v1.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "833d02c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shone\\AppData\\Local\\Temp\\ipykernel_20208\\4263502064.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据条数： 381\n",
      "数据条数： 443\n",
      "数据条数： 381\n",
      "数据条数： 432\n",
      "2348\n"
     ]
    }
   ],
   "source": [
    "conn = connect_to_mysql('deep_learning')\n",
    "df_tensorflow_issue_data = fetch_data_from_mysql(conn, 'tensorflow_issue_data', 'IssueID', 'RelatedPrId', 'Category')\n",
    "df_tensorflow_pr_data = fetch_data_from_mysql(conn, 'tensorflow_pr_data', 'PrID', 'PrRelatedIssueId', 'PrFiles')\n",
    "df_issue_content_tf = fetch_data_from_mysql(conn, 'issue_content_tf', 'IssueID', 'IssueContent', 'url', 'IssueCreator', 'IssueCreatedAt', 'IssueCommentsNum', 'IssueComments')\n",
    "df_pr_content_tf = fetch_data_from_mysql(conn, 'pr_content_tf', 'PrID', 'PrContent', 'url', 'PrCreator', 'PrCreatedAt', 'PrCommentsNum', 'PrComments')\n",
    "conn.close()\n",
    "\n",
    "df_tensorflow_issue_data.drop_duplicates(inplace=True)\n",
    "df_tensorflow_pr_data.drop_duplicates(inplace=True)\n",
    "df_issue_content_tf.drop_duplicates(inplace=True)\n",
    "df_pr_content_tf.drop_duplicates(inplace=True)\n",
    "\n",
    "print('数据条数：', df_tensorflow_issue_data.shape[0])\n",
    "print('数据条数：', df_tensorflow_pr_data.shape[0])\n",
    "print('数据条数：', df_issue_content_tf.shape[0])\n",
    "print('数据条数：', df_pr_content_tf.shape[0])\n",
    "\n",
    "df_issue_content_tf['IssueComments'] = df_issue_content_tf.IssueComments.apply(load_json)\n",
    "df_pr_content_tf['PrComments'] = df_pr_content_tf.PrComments.apply(load_json)\n",
    "\n",
    "df_tensorflow_pr_data['IsMPLF'] = df_tensorflow_pr_data.PrFiles.apply(dulge_ifMpl)\n",
    "\n",
    "# 创建 sentiment_analysis 列表 调用函数以转换数据并填充 new_rows\n",
    "sentiment_analysis_tf = []\n",
    "convert_issueData_to_sentimentAnalysis(df_issue_content_tf, df_tensorflow_pr_data, df_tensorflow_issue_data, sentiment_analysis_tf)\n",
    "convert_prData_to_sentimentAnalysis(df_pr_content_tf, df_tensorflow_pr_data, df_tensorflow_issue_data, sentiment_analysis_tf)\n",
    "\n",
    "# 将收集的行列表转换为 DataFrame\n",
    "df_sentiment_analysis_tf = pd.DataFrame(sentiment_analysis_tf)\n",
    "print(df_sentiment_analysis_tf.shape[0])\n",
    "\n",
    "df_sentiment_analysis_tf['CleanedTextContent'] = df_sentiment_analysis_tf.TextContent.apply(preprocess_text)\n",
    "df_sentiment_analysis_tf.to_csv('./processing_sentiment_analysis_tfComments_v1.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc42d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
