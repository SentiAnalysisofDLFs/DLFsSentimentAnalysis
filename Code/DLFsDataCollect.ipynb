{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92446b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import mysql.connector\n",
    "import requests\n",
    "import mysql.connector\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dcfa074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your GitHub personal access token \n",
    "# Set request header information, including authorization token\n",
    "load_dotenv()\n",
    "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = {'Authorization': 'Bearer ' + github_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eafeebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_mysql(database):\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"123456\",\n",
    "        database=database\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "# Retrieve data from MySQL\n",
    "def fetch_data_from_mysql(conn, table_name, *columns):\n",
    "    columns_str = ', '.join(columns)\n",
    "    query = \"SELECT {} FROM {}\".format(columns_str, table_name)\n",
    "    df = pd.read_sql(query, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d67831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the creator, creation time, closure time, and number of comments for the issue\n",
    "def get_github_issues(owner, repo, id_list, headers, tableName):\n",
    "    j = 0\n",
    "    while j < len(id_list):\n",
    "        i = j\n",
    "        j = j + 200\n",
    "        all_issues = []\n",
    "        # Loop through each submitted ID\n",
    "        while i < j and i < len(id_list):\n",
    "            url = f\"https://api.github.com/repos/{owner}/{repo}/issues/{id_list[i]}\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                issue = response.json()\n",
    "                all_issues.append(issue)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve issue information for id {id_list[i]}. Status code:\", response.status_code)\n",
    "            i = i + 1\n",
    "        time.sleep(3)\n",
    "#         print('Now the i-value is: ', i)\n",
    "\n",
    "        conn = connect_to_mysql('deep_learning')\n",
    "        cursor = conn.cursor()\n",
    "        for issue_info in all_issues:\n",
    "            issueId = issue_info['number']\n",
    "            creator = issue_info['user']['login']\n",
    "            createdAt = datetime.datetime.strptime(issue_info['created_at'], '%Y-%m-%dT%H:%M:%SZ') if issue_info['created_at'] else None\n",
    "            closedAt = datetime.datetime.strptime(issue_info['closed_at'], '%Y-%m-%dT%H:%M:%SZ') if issue_info['closed_at'] else None\n",
    "            commentCount = issue_info['comments']\n",
    "\n",
    "            insert_query = f\"UPDATE {tableName} SET IssueCreator = %s, IssueCreatedAt = %s, IssueClosedAt = %s, IssueCommentsNum = %s WHERE IssueID = %s\"\n",
    "            try:\n",
    "                cursor.execute(insert_query, (creator, createdAt, closedAt, commentCount, issueId))\n",
    "                conn.commit()\n",
    "            except:\n",
    "                print(\"Insert error\"+ str(i) + \" issueid:\" + str(issueId))\n",
    "                conn.rollback()\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d859bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve comments on the issue and return JSON data\n",
    "def get_github_issues_comments(owner, repo, id_list, headers, tableName):\n",
    "    j = 0\n",
    "    while j < len(id_list):\n",
    "        i = j\n",
    "        j = j + 200\n",
    "        all_comments = []\n",
    "        while i < j and i < len(id_list):\n",
    "            url = f\"https://api.github.com/repos/{owner}/{repo}/issues/{id_list[i]}/comments\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                comment = response.json()\n",
    "                all_comments.append(comment)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve issue comments information for id {id_list[i]}. Status code:\", response.status_code)\n",
    "            i = i + 1\n",
    "        time.sleep(3)\n",
    "#         print('Now the i-value is: ', i)\n",
    "\n",
    "        conn = connect_to_mysql('deep_learning')\n",
    "        cursor = conn.cursor()\n",
    "        for issue_info in all_comments:\n",
    "            if not issue_info:\n",
    "                continue\n",
    "            issueId = issue_info[0]['issue_url'].split('/')[-1]\n",
    "            comments = json.dumps([{'id': dic['id'], 'url': dic['html_url'], 'creator': dic['user']['login'], 'createdAt': dic['created_at'], 'body': dic['body']} for dic in issue_info])\n",
    "\n",
    "            insert_query = f\"UPDATE {tableName} SET IssueComments = %s WHERE IssueID = %s\"\n",
    "            try:\n",
    "                cursor.execute(insert_query, (comments, issueId))\n",
    "                conn.commit()\n",
    "            except:\n",
    "                print(\"Insert error\"+ str(i) + \" issueid:\" + str(issueId))\n",
    "                conn.rollback()\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c140952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get issue comments for MXNet\n",
    "owner = 'apache'\n",
    "repo = 'mxnet'\n",
    "\n",
    "conn = connect_to_mysql('deep_learning')\n",
    "df_issues_mx = fetch_data_from_mysql(conn, 'issue_content_mx', 'IssueID')\n",
    "conn.close()\n",
    "# print('Number of data entries: ', df_issues_mx.shape[0])\n",
    "\n",
    "id_list_mx = df_issues_mx['IssueID'].tolist()\n",
    "\n",
    "get_apache_issues(owner, repo, id_list_mx, headers, 'issue_content_mx')\n",
    "get_apache_issues_comments(owner, repo, id_list_mx, headers, 'issue_content_mx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ccc9267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get issue comments for pytorch\n",
    "owner = 'pytorch'\n",
    "repo = 'pytorch'\n",
    "\n",
    "conn = connect_to_mysql('deep_learning')\n",
    "df_issues_py = fetch_data_from_mysql(conn, 'issue_content_py', 'IssueID')\n",
    "conn.close()\n",
    "# print('Number of data entries: ', df_issues_py.shape[0])\n",
    "\n",
    "id_list_py = df_issues_py['IssueID'].tolist()\n",
    "\n",
    "get_github_issues(owner, repo, id_list_py, headers, 'issue_content_py')\n",
    "get_github_issues_comments(owner, repo, id_list_py, headers, 'issue_content_py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1c3b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get issue comments for tensorflow\n",
    "owner = 'tensorflow'\n",
    "repo = 'tensorflow'\n",
    "\n",
    "conn = connect_to_mysql('deep_learning')\n",
    "df_issues_tf = fetch_data_from_mysql(conn, 'issue_content_tf', 'IssueID')\n",
    "conn.close()\n",
    "# print('Number of data entries: ', df_issues_tf.shape[0])\n",
    "\n",
    "id_list_tf = df_issues_tf['IssueID'].tolist()\n",
    "\n",
    "get_apache_issues(owner, repo, id_list_tf, headers, 'issue_content_tf')\n",
    "get_apache_issues_comments(owner, repo, id_list_tf, headers, 'issue_content_tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "433adde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the creator, creation time, closure time, and number of comments for the pull request\n",
    "def get_apache_pulls(owner, repo, id_list, headers, tableName):\n",
    "    j = 0\n",
    "    while j < len(id_list):\n",
    "        i = j\n",
    "        j = j + 200\n",
    "        all_pulls = []\n",
    "        while i < j and i < len(id_list):\n",
    "            url = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{id_list[i]}\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                pull = response.json()\n",
    "                all_pulls.append(pull)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve pull information for id {id_list[i]}. Status code:\", response.status_code)\n",
    "            i = i + 1\n",
    "        time.sleep(3)\n",
    "#         print('At this point, the value of i is:', i)\n",
    "\n",
    "        conn = connect_to_mysql('deep_learning')\n",
    "        cursor = conn.cursor()\n",
    "        for pull_info in all_pulls:\n",
    "            prId = pull_info['number']\n",
    "            creator = pull_info['user']['login']\n",
    "            createdAt = datetime.datetime.strptime(pull_info['created_at'], '%Y-%m-%dT%H:%M:%SZ') if pull_info['created_at'] else None\n",
    "            closedAt = datetime.datetime.strptime(pull_info['closed_at'], '%Y-%m-%dT%H:%M:%SZ') if pull_info['closed_at'] else None\n",
    "            commentCount = pull_info['review_comments']\n",
    "\n",
    "            insert_query = f\"UPDATE {tableName} SET PrCreator = %s, PrCreatedAt = %s, PrClosedAt = %s, PrCommentsNum = %s WHERE PrID = %s\"\n",
    "            try:\n",
    "                cursor.execute(insert_query, (creator, createdAt, closedAt, commentCount, prId))\n",
    "                conn.commit()\n",
    "            except:\n",
    "                print(\"insert error\"+ str(i) + \" prid:\" + str(prId))\n",
    "                conn.rollback()\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e2e5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve comments on the pull request and return JSON data\n",
    "def get_apache_pulls_comments(owner, repo, id_list, headers, tableName):\n",
    "    j = 0\n",
    "    while j < len(id_list):\n",
    "        i = j\n",
    "        j = j + 200\n",
    "        all_comments = []\n",
    "        while i < j and i < len(id_list):\n",
    "            url = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{id_list[i]}/comments\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                comment = response.json()\n",
    "                all_comments.append(comment)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve pull comments information for id {id_list[i]}. Status code:\", response.status_code)\n",
    "            i = i + 1\n",
    "        time.sleep(3)\n",
    "#         print('At this point, the value of i is:', i)\n",
    "\n",
    "        conn = connect_to_mysql('deep_learning')\n",
    "        cursor = conn.cursor()\n",
    "        for pr_info in all_comments:\n",
    "            if not pr_info:\n",
    "                continue\n",
    "            prId = pr_info[0]['pull_request_url'].split('/')[-1]\n",
    "            comments = json.dumps([{'id': dic['id'], 'url': dic['html_url'], 'creator': dic['user']['login'], 'createdAt': dic['created_at'], 'body': dic['body']} for dic in pr_info])\n",
    "\n",
    "            insert_query = f\"UPDATE {tableName} SET PrComments = %s WHERE PrID = %s\"\n",
    "            try:\n",
    "                cursor.execute(insert_query, (comments, prId))\n",
    "                conn.commit()\n",
    "            except:\n",
    "                print(\"insert error\"+ str(i) + \" prid:\" + str(prId))\n",
    "                conn.rollback()\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ac24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pull request comments for mxnet\n",
    "owner = 'apache'\n",
    "repo = 'mxnet'\n",
    "\n",
    "conn = connect_to_mysql('deep_learning')\n",
    "df_pull_mx = fetch_data_from_mysql(conn, 'pr_content_mx', 'PrID')\n",
    "conn.close()\n",
    "# print('Number of data entries: ', df_pull_mx.shape[0])\n",
    "\n",
    "id_list_mx = df_pull_mx['PrID'].tolist()\n",
    "\n",
    "get_apache_pulls(owner, repo, id_list_mx, headers, 'pr_content_mx')\n",
    "get_apache_pulls_comments(owner, repo, id_list_mx, headers, 'pr_content_mx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf7d253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pull request comments for pytorch\n",
    "owner = 'pytorch'\n",
    "repo = 'pytorch'\n",
    "\n",
    "conn = connect_to_mysql('deep_learning')\n",
    "df_pull_py = fetch_data_from_mysql(conn, 'pr_content_py', 'PrID')\n",
    "conn.close()\n",
    "# print('Number of data entries: ', df_pull_py.shape[0])\n",
    "\n",
    "id_list_py = df_pull_py['PrID'].tolist()\n",
    "\n",
    "get_apache_pulls(owner, repo, id_list_py, headers, 'pr_content_py')\n",
    "get_apache_pulls_comments(owner, repo, id_list_py, headers, 'pr_content_py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "964f8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pull request comments for tensorflow\n",
    "owner = 'tensorflow'\n",
    "repo = 'tensorflow'\n",
    "\n",
    "conn = connect_to_mysql('deep_learning')\n",
    "df_pull_tf = fetch_data_from_mysql(conn, 'pr_content_tf', 'PrID')\n",
    "conn.close()\n",
    "# print('Number of data entries: ', df_pull_tf.shape[0])\n",
    "\n",
    "id_list_tf = df_pull_tf['PrID'].tolist()\n",
    "\n",
    "get_apache_pulls(owner, repo, id_list_tf, headers, 'pr_content_tf')\n",
    "get_apache_pulls_comments(owner, repo, id_list_tf, headers, 'pr_content_tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
