TextContent,TextType,url,Creator,CreatedAt,IssueID,RelatedPrID,IssueCategory,IsMPLF,CleanedTextContent,SentimentScore
"This seems like reasonable behavior to preserve, since we're unlikely to ever add any kind of checking to these ops (doing so is problematic due to numerical error) and we're unlikely to normalize due to speed.  Documentation contributions welcome!
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1234#issuecomment-193538287,girving,2016-03-08 01:07:33,1234,[1580],Documentation bug,0,"This seems like reasonable behavior to preserve, since we're unlikely to ever add any kind of checking to these ops (doing so is problematic due to numerical error) and we're unlikely to normalize due to speed. Documentation contributions welcome!",2
"The described convenient behavior has changed somewhere between versions 0.9 and 0.10.
The snippet with `sparse_softmax_cross_entropy_with_logits` now results in:

```
[array([ nan], dtype=float32), array([ nan], dtype=float32)]
```

Cross entropy for padding logits became `nan` instead of `0.0`. Looks like a breaking change: in my case forward pass is still okay (with masking), but gradients are now stuffed with `nan`s . It took some time to realize that new behavior is version dependent.

Versions with ""0"" behavior:
[linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl)

Versions with ""nan"" behavior:
[linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl)
[linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl)

Should we open a new issue or is this new behavior by design?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1234#issuecomment-246196752,ivan-aksamentov,2016-09-11 18:48:27,1234,[1580],Documentation bug,0,"The described convenient behavior has changed somewhere between versions 0.9 and 0.10. The snippet with [code] now results in: ``[code]`[code]nan[code]0.0[code]nan`s . It took some time to realize that new behavior is version dependent. Versions with ""0"" behavior: [linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl]([url] Versions with ""nan"" behavior: [linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl]([url] [linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl]([url] Should we open a new issue or is this new behavior by design?",0
"Can you open a new bug for this, explaining what behavior you think is correct?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1234#issuecomment-246254204,ebrevdo,2016-09-12 05:39:04,1234,[1580],Documentation bug,0,"Can you open a new bug for this, explaining what behavior you think is correct?",0
"I let ivan create the bug issue but I confirm that the new behavior can cause some troubles. I am using `sparse_softmax_cross_entropy_with_logits` and, in my opinion, the best behavior would be to return a loss of _0.0_ and null gradients when the label is not in the range _[0, num_classes)_; never return _nan_.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1234#issuecomment-247547726,JulienB-78,2016-09-16 08:36:08,1234,[1580],Documentation bug,0,"I let ivan create the bug issue but I confirm that the new behavior can cause some troubles. I am using [code] and, in my opinion, the best behavior would be to return a loss of _0.0_ and null gradients when the label is not in the range _[0, num_classes)_; never return _nan_.",-2
"This is only going to get more strict.  Passing labels that are out of range is a sign of a hidden bug; one that may have model builders searching for a long time before figuring out the true problem.  Starting in a few days, this op will raise exceptions when passed invalid labels on CPU.  On GPU it will continue to return NaNs because we can't easily pass error flags back from the GPU.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1234#issuecomment-248783238,ebrevdo,2016-09-22 00:45:06,1234,[1580],Documentation bug,0,"This is only going to get more strict. Passing labels that are out of range is a sign of a hidden bug; one that may have model builders searching for a long time before figuring out the true problem. Starting in a few days, this op will raise exceptions when passed invalid labels on CPU. On GPU it will continue to return NaNs because we can't easily pass error flags back from the GPU.",-3
"This is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag.""
",IssueComment,https://github.com/tensorflow/tensorflow/issues/4358#issuecomment-246829263,andydavis1,2016-09-13 21:23:27,4358,[4421],Documentation bug,0,"This is a question better suited for StackOverflow. Please ask it there and tag it with the [code] tag.""",0
"@andydavis1 Are you sure? I'm mainly pointing at a ""bug"" in the docs. I'm not asking for anything, my question was just to suggest a way of improving the docs.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/4358#issuecomment-246835094,danijar,2016-09-13 21:44:44,4358,[4421],Documentation bug,0,"@andydavis1 Are you sure? I'm mainly pointing at a ""bug"" in the docs. I'm not asking for anything, my question was just to suggest a way of improving the docs.",0
"Ah ok. I took that last sentence you wrote "" Do we have a better example illustrating preprocessing steps like data normalization, distorting images, etc?"". As a general question.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/4358#issuecomment-246838764,andydavis1,2016-09-13 21:58:14,4358,[4421],Documentation bug,0,"Ah ok. I took that last sentence you wrote "" Do we have a better example illustrating preprocessing steps like data normalization, distorting images, etc?"". As a general question.",0
"The folder holding the file referenced in the docs has, e.g. https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/models/image/cifar10/cifar10_input.py, which does contain a `distorted_inputs` routine, is this what you're looking for? If so, then the easiest fix is just to change the link in the docs to point to the cifar10_input.py file instead of the cifar10.py file that imports it (line 47)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/4358#issuecomment-247389137,ghost,2016-09-15 17:06:39,4358,[4421],Documentation bug,0,"The folder holding the file referenced in the docs has, e.g. [url] which does contain a [code] routine, is this what you're looking for? If so, then the easiest fix is just to change the link in the docs to point to the cifar10_input.py file instead of the cifar10.py file that imports it (line 47)",0
"Thanks. Yes, I think that would be suitable. Do you want to create a pull request? Otherwise, I can do that.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/4358#issuecomment-247448027,danijar,2016-09-15 20:37:31,4358,[4421],Documentation bug,0,"Thanks. Yes, I think that would be suitable. Do you want to create a pull request? Otherwise, I can do that.",3
"You can go ahead.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/4358#issuecomment-247686656,ghost,2016-09-16 19:29:16,4358,[4421],Documentation bug,0,You can go ahead.,2
It looks the code meant to have `_interactive = False` before the [block](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/tf_logging.py#L40). Would you be willing to file a PR?,IssueComment,https://github.com/tensorflow/tensorflow/issues/8401#issuecomment-286629880,drpngx,2017-03-15 03:20:45,8401,[8420],Visualization bug,0,It looks the code meant to have [code] before the [block]([url]#L40). Would you be willing to file a PR?,1
Sure thing!,IssueComment,https://github.com/tensorflow/tensorflow/issues/8401#issuecomment-286632454,nsriram13,2017-03-15 03:41:31,8401,[8420],Visualization bug,0,Sure thing!,3
"Great, thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/8401#issuecomment-286775244,drpngx,2017-03-15 15:19:39,8401,[8420],Visualization bug,0,"Great, thanks!",3
"I had the same issue when I was trying to get the max indices.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-212215166,xiongkun,2016-04-20 02:23:18,1793,[8930],Algorithm design bug,0,I had the same issue when I was trying to get the max indices.,0
"this is a bit of a hack, but copying the gradient for maxpool and registering it for max_pool_with_argmax works. The function signature has an additional arg (presumably this has to do with the argmax). Also the op doesn't have a data_format, so that is left default (NHWC).

``` python
from tensorflow.python.framework import ops
from tensorflow.python.ops import gen_nn_ops
@ops.RegisterGradient(""MaxPoolWithArgmax"")
def _MaxPoolWithArgmaxGrad(op, grad, some_other_arg):
  return gen_nn_ops._max_pool_grad(op.inputs[0],
                                   op.outputs[0],
                                   grad,
                                   op.get_attr(""ksize""),
                                   op.get_attr(""strides""),
                                   padding=op.get_attr(""padding""),
                                   data_format='NHWC')
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-221447775,mwalton,2016-05-25 01:14:30,1793,[8930],Algorithm design bug,0,"this is a bit of a hack, but copying the gradient for maxpool and registering it for max_pool_with_argmax works. The function signature has an additional arg (presumably this has to do with the argmax). Also the op doesn't have a data_format, so that is left default (NHWC). ``[code]``",0
"@mwalton: `some_other_arg` should be called `unused_argmax_grad`, but otherwise that's basically it.  Would you be interesting it submitting your change as a PR?  We'd have to add tests if so (mirroring those for the gradient of the normal max_pool.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-224131073,girving,2016-06-07 00:44:45,1793,[8930],Algorithm design bug,0,"@mwalton: [code] should be called [code], but otherwise that's basically it. Would you be interesting it submitting your change as a PR? We'd have to add tests if so (mirroring those for the gradient of the normal max_pool.",2
"@girving  Sure! Should I go ahead and put in the PR; or implement the tests first?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-224321589,mwalton,2016-06-07 15:40:52,1793,[8930],Algorithm design bug,0,@girving Sure! Should I go ahead and put in the PR; or implement the tests first?,2
"@mwalton: The tests should go in the same PR.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-224322513,girving,2016-06-07 15:43:54,1793,[8930],Algorithm design bug,0,@mwalton: The tests should go in the same PR.,0
"@mwalton Not sure if you've made any progress on this, but I believe the correct change would be the following:

``` python
@ops.RegisterGradient(""MaxPoolWithArgmax"")
def _MaxPoolGradWithArgmax(op, grad, unused_argmax_grad):
  return gen_nn_ops._max_pool_grad_with_argmax(op.inputs[0],
                                               grad,
                                               op.outputs[1],
                                               op.get_attr(""ksize""),
                                               op.get_attr(""strides""),
                                               padding=op.get_attr(""padding""))
```

Seems to be working on a model I'm training. Haven't had time to write tests for it yet, nor do I know how/what tests are needed for registering an existing op (that appears to have **some** test coverage, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/pooling_ops_test.py#L521). 

@girving If you can provide some direction on what tests I'd need to add for this change, I can try to pull together a PR. 
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-234070576,bcaine,2016-07-20 20:24:03,1793,[8930],Algorithm design bug,0,"@mwalton Not sure if you've made any progress on this, but I believe the correct change would be the following: ``[code]`` Seems to be working on a model I'm training. Haven't had time to write tests for it yet, nor do I know how/what tests are needed for registering an existing op (that appears to have **some** test coverage, see [url]#L521). @girving If you can provide some direction on what tests I'd need to add for this change, I can try to pull together a PR.",1
"@bcaine Awesome!  Tests for gradients are pretty easy: just use `tf.test.compute_gradient_error` and verify that the error is small (1e-4 or 1e-3, typically, due to numerical differences).  You can look at other `compute_gradient_error` examples and mimic.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-234071826,girving,2016-07-20 20:28:27,1793,[8930],Algorithm design bug,0,"@bcaine Awesome! Tests for gradients are pretty easy: just use [code] and verify that the error is small (1e-4 or 1e-3, typically, due to numerical differences). You can look at other [code] examples and mimic.",4
"Are there any updates on this issue? It seems that adding this gradient was attempted in #4014, but not taken place due to commit conflicts. Should I cherry-pick commit dc3d4782cbdf2d98b into a PR?",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-291206249,Enet4,2017-04-03 17:02:00,1793,[8930],Algorithm design bug,0,"Are there any updates on this issue? It seems that adding this gradient was attempted in #4014, but not taken place due to commit conflicts. Should I cherry-pick commit dc3d4782cbdf2d98b into a PR?",0
"@Enet4 Definitely looks stagnated, so feel free to take over.",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-291207778,girving,2017-04-03 17:06:56,1793,[8930],Algorithm design bug,0,"@Enet4 Definitely looks stagnated, so feel free to take over.",-1
"Hi. I trained a network with @bcaine register ops solution in python. Now I exported my graph using freeze_graph.py to use my network in C++. But there, this gradient is not registered.
Can anyone help how this can be for C++/ source?",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-302686807,eflavio,2017-05-19 12:14:00,1793,[8930],Algorithm design bug,0,"Hi. I trained a network with @bcaine register ops solution in python. Now I exported my graph using freeze_graph.py to use my network in C++. But there, this gradient is not registered. Can anyone help how this can be for C++/ source?",0
"Hey, is anyone doing anything about the lack of gradient?",IssueComment,https://github.com/tensorflow/tensorflow/issues/1793#issuecomment-303909054,will-hang,2017-05-25 02:58:14,1793,[8930],Algorithm design bug,0,"Hey, is anyone doing anything about the lack of gradient?",-1
"It's typically an error in the MD format, like missing spaces in front the bullet.",IssueComment,https://github.com/tensorflow/tensorflow/issues/9313#issuecomment-295343293,drpngx,2017-04-19 16:55:13,9313,[10423],Documentation bug,0,"It's typically an error in the MD format, like missing spaces in front the bullet.",0
"Where are the instructions on how to generate the docs?

I could make this fix here and in multiple other places if I can just generate the docs to check that my changes fix things like this.",IssueComment,https://github.com/tensorflow/tensorflow/issues/9313#issuecomment-296825550,dmonopoly,2017-04-24 21:20:04,9313,[10423],Documentation bug,0,Where are the instructions on how to generate the docs? I could make this fix here and in multiple other places if I can just generate the docs to check that my changes fix things like this.,1
Nm found it here via #1574  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/community/documentation.md,IssueComment,https://github.com/tensorflow/tensorflow/issues/9313#issuecomment-298067116,dmonopoly,2017-04-28 18:04:51,9313,[10423],Documentation bug,0,Nm found it here via #1574 [url],0
I think the issue is the extra line in `metrics:` args description in python code. PR #10423 ,IssueComment,https://github.com/tensorflow/tensorflow/issues/9313#issuecomment-306005731,yongtang,2017-06-03 22:41:45,9313,[10423],Documentation bug,0,I think the issue is the extra line in [code] args description in python code. PR #10423,0
Could you fix or delegate this @wolffg?,IssueComment,https://github.com/tensorflow/tensorflow/issues/8718#issuecomment-289881536,aselle,2017-03-28 19:40:20,8718,[10658],Documentation bug,0,Could you fix or delegate this @wolffg?,0
Added a PR #10658 for that.,IssueComment,https://github.com/tensorflow/tensorflow/issues/8718#issuecomment-307891796,yongtang,2017-06-12 19:17:20,8718,[10658],Documentation bug,0,Added a PR #10658 for that.,0
Maybe @mrry can comment on what might be an issue with the `tf.sparse_placeholder` shape API.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6749#issuecomment-271765776,jart,2017-01-11 03:06:59,6749,[11153],Version compatibility bug,0,Maybe @mrry can comment on what might be an issue with the [code] shape API.,0
"Looks like the problem is in `array_ops._normalize_sparse_shape()`. It converts its argument to a tensor, which for a list of Python `int` values will result in a `tf.int32` tensor. I suspect the correct answer is to add a `dtype=dtypes.int64` to the `ops.convert_to_tensor()` call, but since there doesn't appear to be any unit test for this I'll defer to @ilblackdragon, who originally added that function.",IssueComment,https://github.com/tensorflow/tensorflow/issues/6749#issuecomment-271934860,mrry,2017-01-11 17:30:56,6749,[11153],Version compatibility bug,0,"Looks like the problem is in [code]. It converts its argument to a tensor, which for a list of Python [code] values will result in a [code] tensor. I suspect the correct answer is to add a [code] to the [code] call, but since there doesn't appear to be any unit test for this I'll defer to @ilblackdragon, who originally added that function.",0
"simple workaround:

`shape = [1, 3]`
`shape = np.array(shape, dtype=np.int64)`
`tf.sparse_placeholder(tf.int32, shape=shape)`",IssueComment,https://github.com/tensorflow/tensorflow/issues/6749#issuecomment-272385201,kilianyp,2017-01-13 08:12:05,6749,[11153],Version compatibility bug,0,simple workaround: [code] [code] [code],0
"Any update on this issue? @ilblackdragon 
In my experience the workaround does __not__ work because then it complains about:

`ValueError: Tensor Tensor(""Input_2/shape_1:0"", shape=(2,), dtype=int64) may not be fed.`

In other words: it doesn't want to do Tensor conversion itself, but it also doesn't accept to be fed with the `int64` shape Tensor.",IssueComment,https://github.com/tensorflow/tensorflow/issues/6749#issuecomment-286632439,michaelosthege,2017-03-15 03:41:26,6749,[11153],Version compatibility bug,0,"Any update on this issue? @ilblackdragon In my experience the workaround does __not__ work because then it complains about: [code] In other words: it doesn't want to do Tensor conversion itself, but it also doesn't accept to be fed with the [code] shape Tensor.",-3
I also seem to be having the same problem.  Has there been any progress on this issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/6749#issuecomment-295020413,rolfe,2017-04-19 00:00:41,6749,[11153],Version compatibility bug,0,I also seem to be having the same problem. Has there been any progress on this issue?,0
"The workaround is all well and good

```
>> foo = tf.sparse_placeholder(tf.float32, shape=np.array([10, 47], dtype=np.int64))
>> foo.get_shape()
TensorShape([Dimension(10), Dimension(47)])
```

.... until you want a variable dimension

```
>> bar = tf.sparse_placeholder(tf.float32, shape=[None, 47])
>> bar.get_shape()
TensorShape(None)
>> bar2 = tf.sparse_placeholder(tf.float32, shape=np.array([None, 47], dtype=np.int64))
TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/6749#issuecomment-297891681,meereeum,2017-04-28 02:36:44,6749,[11153],Version compatibility bug,0,The workaround is all well and good ``[code]`[code]`[code]``,0
Marking this as contributions welcome. @ilblackdragon please let me know if you plan to fix this.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6749#issuecomment-309139901,skye,2017-06-16 21:37:05,6749,[11153],Version compatibility bug,0,Marking this as contributions welcome. @ilblackdragon please let me know if you plan to fix this.,0
Added a PR #11153 with test cases.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6749#issuecomment-312127183,yongtang,2017-06-29 22:36:30,6749,[11153],Version compatibility bug,0,Added a PR #11153 with test cases.,3
"@martinwicke, @josh11b , this seems to come from the attribute specifier only allowing a >= optionally and not ==. 
i.e.
```
REGISTER_OP(""AvgPool"")
    .Input(""value: T"")
    .Output(""output: T"")
    .Attr(""ksize: list(int) >= 4"")
    .Attr(""strides: list(int) >= 4"")
    .Attr(GetPaddingAttrString())
    .Attr(GetConvnetDataFormatAttrString())
    .Attr(""T: {half, float, double}"")
    .SetShapeFn(shape_inference::AvgPoolShape)
    .Doc(R""doc(
```
We can't make it list(int) == 4, because the op registration class doesn't support that for Attr. However, since the attribute constraint gets auto placed in the docs i.e. here:
https://www.tensorflow.org/api_docs/python/tf/nn/max_pool

It is confusing, maybe we should

1. not  include the list constraints in auto-generated documentation.
2. augment list constraints to allow == as well as >=.

",IssueComment,https://github.com/tensorflow/tensorflow/issues/10729#issuecomment-308895222,aselle,2017-06-15 23:48:21,10729,[11925],Documentation bug,0,"@martinwicke, @josh11b , this seems to come from the attribute specifier only allowing a >= optionally and not ==. i.e. ``[code]`` We can't make it list(int) == 4, because the op registration class doesn't support that for Attr. However, since the attribute constraint gets auto placed in the docs i.e. here: [url] It is confusing, maybe we should 1. not include the list constraints in auto-generated documentation. 2. augment list constraints to allow == as well as >=.",0
"Two things we can do: support more constraint types (good, but work), and add support for = at the beginning of the doc string for attrs suppressing the generated prefix (which currently works for tensor inputs).",IssueComment,https://github.com/tensorflow/tensorflow/issues/10729#issuecomment-308899336,josh11b,2017-06-16 00:19:45,10729,[11925],Documentation bug,0,"Two things we can do: support more constraint types (good, but work), and add support for = at the beginning of the doc string for attrs suppressing the generated prefix (which currently works for tensor inputs).",1
"If you are accepting PRs for this and could point me to some resources to study how this works in detail (like the op registration class for one), I'd be happy to do one.",IssueComment,https://github.com/tensorflow/tensorflow/issues/10729#issuecomment-308900566,jkschin,2017-06-16 00:29:32,10729,[11925],Documentation bug,0,"If you are accepting PRs for this and could point me to some resources to study how this works in detail (like the op registration class for one), I'd be happy to do one.",5
"If you want to fix the >= / = / == parsing issue, the code that processes that lives here in tensorflow/core/framework/op_def_builder.cc line 221ff. You could allow == as a token, and then we could use that in the Op registrations. There's no documentation for this, just the code.

We would love a PR for that.",IssueComment,https://github.com/tensorflow/tensorflow/issues/10729#issuecomment-309112348,martinwicke,2017-06-16 19:18:48,10729,[11925],Documentation bug,0,"If you want to fix the >= / = / == parsing issue, the code that processes that lives here in tensorflow/core/framework/op_def_builder.cc line 221ff. You could allow == as a token, and then we could use that in the Op registrations. There's no documentation for this, just the code. We would love a PR for that.",2
"Josh also suggested there is a := syntax that lets you remove the constraint part in the docs and provide your own text completely.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/10729#issuecomment-309133461,aselle,2017-06-16 21:02:22,10729,[11925],Documentation bug,0,Josh also suggested there is a := syntax that lets you remove the constraint part in the docs and provide your own text completely.,0
"Added PR #11925 for the fix. As both `max_pool` and `avg_pool` are wrapped in the python code, the fix only changes the docstring in tensorflow/python/ops/nn_ops.py.",IssueComment,https://github.com/tensorflow/tensorflow/issues/10729#issuecomment-319246820,yongtang,2017-08-01 02:04:00,10729,[11925],Documentation bug,0,"Added PR #11925 for the fix. As both [code] and [code] are wrapped in the python code, the fix only changes the docstring in tensorflow/python/ops/nn_ops.py.",0
@martinwicke can you comment or redirect? Thanks.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12249#issuecomment-322219024,skye,2017-08-14 15:17:04,12249,[12276],Version compatibility bug,0,@martinwicke can you comment or redirect? Thanks.,0
"Yes, we're using getargspec, which doesn't support type annotations. This is worthwhile to fix. If someone wants to take it on, the code should be relatively isolated in a single function which is checking arguments. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/12249#issuecomment-322243326,martinwicke,2017-08-14 16:46:52,12249,[12276],Version compatibility bug,0,"Yes, we're using getargspec, which doesn't support type annotations. This is worthwhile to fix. If someone wants to take it on, the code should be relatively isolated in a single function which is checking arguments.",2
Added a PR #12276 for this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12249#issuecomment-322280659,yongtang,2017-08-14 19:08:12,12249,[12276],Version compatibility bug,0,Added a PR #12276 for this issue.,0
I think `optimize` flag should be respected. Added a PR #12459 for it.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12436#issuecomment-323862399,yongtang,2017-08-21 21:50:52,12436,[12459],Algorithm design bug,0,I think [code] flag should be respected. Added a PR #12459 for it.,2
"@benoitsteiner, could you please update this issue upon concluding review of #12459? Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/12436#issuecomment-325258541,ali01,2017-08-28 04:40:04,12436,[12459],Algorithm design bug,0,"@benoitsteiner, could you please update this issue upon concluding review of #12459? Thanks",1
Created a PR #12658 for that.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-325474788,yongtang,2017-08-28 20:40:29,12641,[12658],Memory bug,0,Created a PR #12658 for that.,0
"Slurping the whole file into memory and writing it back out isn't exactly optimal. Streaming would be great. What would be even better is the [`sendfile`](http://man7.org/linux/man-pages/man2/sendfile.2.html) system call, which does it entirely in kernel space. If would be terrific if @rohan100jain was able to implement that when src and dst are Unix FS, and do streaming otherwise.",IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-326123868,jart,2017-08-30 21:25:41,12641,[12658],Memory bug,0,"Slurping the whole file into memory and writing it back out isn't exactly optimal. Streaming would be great. What would be even better is the [[code]]([url] system call, which does it entirely in kernel space. If would be terrific if @rohan100jain was able to implement that when src and dst are Unix FS, and do streaming otherwise.",2
The implementation of CopyFile in PR #12658 has been updated with calling `sendfile` in Linux for posix file systems. Please take a look.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-326179771,yongtang,2017-08-31 03:31:17,12641,[12658],Memory bug,0,The implementation of CopyFile in PR #12658 has been updated with calling [code] in Linux for posix file systems. Please take a look.,0
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-352936418,tensorflowbutler,2017-12-20 01:18:55,12641,[12658],Memory bug,0,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-355099387,tensorflowbutler,2018-01-03 19:11:44,12641,[12658],Memory bug,0,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-358751313,tensorflowbutler,2018-01-18 19:13:55,12641,[12658],Memory bug,0,Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-363337091,tensorflowbutler,2018-02-06 07:42:08,12641,[12658],Memory bug,0,Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
"There's a PR somewhere adding in-kernel sendfile copy support I spent a lot of time helping to review a while back. I don't know what the status of that is, but I hope the author is generous enough to bring it to completion, because it'd be a great notch in his belt because this isn't an easy problem to solve.",IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-363464831,jart,2018-02-06 15:49:13,12641,[12658],Memory bug,0,"There's a PR somewhere adding in-kernel sendfile copy support I spent a lot of time helping to review a while back. I don't know what the status of that is, but I hope the author is generous enough to bring it to completion, because it'd be a great notch in his belt because this isn't an easy problem to solve.",2
It's the PR cited above - #12658 ,IssueComment,https://github.com/tensorflow/tensorflow/issues/12641#issuecomment-363470177,quaeler,2018-02-06 16:04:32,12641,[12658],Memory bug,0,It's the PR cited above - #12658,0
"@MarkDaoust we should update the pre-requisites.

Thank for reporting this, @eaperz! If you want to send a PR, that's also great.",IssueComment,https://github.com/tensorflow/tensorflow/issues/12821#issuecomment-327250758,drpngx,2017-09-05 17:40:30,12821,[12839],Code bug,0,"@MarkDaoust we should update the pre-requisites. Thank for reporting this, @eaperz! If you want to send a PR, that's also great.",3
Is it good to check whether `patch` is installed before it is invoked [here](https://github.com/tensorflow/tensorflow/blob/12a628a623a5dae81b8fc699792eaf414e6ace41/tensorflow/workspace.bzl#L110)?,IssueComment,https://github.com/tensorflow/tensorflow/issues/12821#issuecomment-327377723,facaiy,2017-09-06 05:21:09,12821,[12839],Code bug,0,Is it good to check whether [code] is installed before it is invoked [here]([url]#L110)?,0
"I think it should be checked in a pre-requisite stage, along with all other pre-requisites to build. Unfortunately it's my first contact with tensorflow and I have no idea where in the code is this verification done.",IssueComment,https://github.com/tensorflow/tensorflow/issues/12821#issuecomment-327382384,boared,2017-09-06 05:54:05,12821,[12839],Code bug,0,"I think it should be checked in a pre-requisite stage, along with all other pre-requisites to build. Unfortunately it's my first contact with tensorflow and I have no idea where in the code is this verification done.",0
"@eaperz  I agree with you. Since I'm not familiar with bazel, I don't know how to do pre-check yet.",IssueComment,https://github.com/tensorflow/tensorflow/issues/12821#issuecomment-327383234,facaiy,2017-09-06 05:59:49,12821,[12839],Code bug,0,"@eaperz I agree with you. Since I'm not familiar with bazel, I don't know how to do pre-check yet.",0
Best place would probably be in the `configure`(https://github.com/tensorflow/tensorflow/blob/master/configure.py) script.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12821#issuecomment-327602275,drpngx,2017-09-06 20:23:17,12821,[12839],Code bug,0,Best place would probably be in the [code]([url] script.,0
"This means modifying UNARY_GRADIENT_COMPLEX macro and changing x to y and y to dy for every op that uses it, are you sure that wouldn't break things/contradict documentation for those other ops? BTW, you can press ""y"" in github to generate a permanent link with line number reference",IssueComment,https://github.com/tensorflow/tensorflow/issues/12902#issuecomment-328376465,yaroslavvb,2017-09-10 22:22:21,12902,[13212],Documentation bug,0,"This means modifying UNARY_GRADIENT_COMPLEX macro and changing x to y and y to dy for every op that uses it, are you sure that wouldn't break things/contradict documentation for those other ops? BTW, you can press ""y"" in github to generate a permanent link with line number reference",0
" @yaroslavvb, it doesn't contradict documentation for other operations which use UNARY_GRADIENT_COMPLEX macros, because the other ops use 'y' and 'dy' names in docs.

Thanks for your suggestion, I updated the issue with permanent links.",IssueComment,https://github.com/tensorflow/tensorflow/issues/12902#issuecomment-328442194,Dorokhov,2017-09-11 07:29:56,12902,[13212],Documentation bug,0,"@yaroslavvb, it doesn't contradict documentation for other operations which use UNARY_GRADIENT_COMPLEX macros, because the other ops use 'y' and 'dy' names in docs. Thanks for your suggestion, I updated the issue with permanent links.",2
"@Dorokhov do you want to do a PR to fix it? If you do, make sure to run the tests locally first",IssueComment,https://github.com/tensorflow/tensorflow/issues/12902#issuecomment-328574223,yaroslavvb,2017-09-11 15:55:57,12902,[13212],Documentation bug,0,"@Dorokhov do you want to do a PR to fix it? If you do, make sure to run the tests locally first",0
"@yaroslavvb right, I will do",IssueComment,https://github.com/tensorflow/tensorflow/issues/12902#issuecomment-328593344,Dorokhov,2017-09-11 17:02:42,12902,[13212],Documentation bug,0,"@yaroslavvb right, I will do",2
"this is bad, it shouldn't crash Python even if type is wrong",IssueComment,https://github.com/tensorflow/tensorflow/issues/13506#issuecomment-334602876,yaroslavvb,2017-10-05 21:54:21,13506,[13517],Data bug,1,"this is bad, it shouldn't crash Python even if type is wrong",-4
"The crash is caused by the fact that int64 was never registered in the kernel of `tf.image.pad_to_bounding_box`. Instead, the `int64` of the `Tpadding` is directly used as `int32` without appropriate processing.

A PR #13517 has been created to address the crash.",IssueComment,https://github.com/tensorflow/tensorflow/issues/13506#issuecomment-334661264,yongtang,2017-10-06 05:23:31,13506,[13517],Data bug,1,"The crash is caused by the fact that int64 was never registered in the kernel of [code]. Instead, the [code] of the [code] is directly used as [code] without appropriate processing. A PR #13517 has been created to address the crash.",0
"Thanks for debugging and the PR @yongtang !

Marking as ""Contributions Welcome"", though it seems the contribution has already been sent :)",IssueComment,https://github.com/tensorflow/tensorflow/issues/13506#issuecomment-335082297,asimshankar,2017-10-09 07:26:04,13506,[13517],Data bug,1,"Thanks for debugging and the PR @yongtang ! Marking as ""Contributions Welcome"", though it seems the contribution has already been sent :)",3
"It looks like this is due to the fact that TF_TensorData returns nil if no data is allocated. Assuming this is correct behavior and nil needs to be checked for on the go side then the following patch fixes the problem:
```
diff --git a/tensorflow/go/tensor.go b/tensorflow/go/tensor.go
index e8fa21a..6cbf759 100644
--- a/tensorflow/go/tensor.go
+++ b/tensorflow/go/tensor.go
@@ -205,6 +205,9 @@ func (t *Tensor) WriteContentsTo(w io.Writer) (int64, error) {
 func tensorData(c *C.TF_Tensor) []byte {
        // See: https://github.com/golang/go/wiki/cgo#turning-c-arrays-into-go-slices
        cbytes := C.TF_TensorData(c)
+       if cbytes == nil {
+               return nil
+       }
        length := int(C.TF_TensorByteSize(c))
        slice := (*[1 << 30]byte)(unsafe.Pointer(cbytes))[:length:length]
        return slice
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/13764#issuecomment-337083514,vishvananda,2017-10-17 00:40:19,13764,[14082],Test bug,0,It looks like this is due to the fact that TF_TensorData returns nil if no data is allocated. Assuming this is correct behavior and nil needs to be checked for on the go side then the following patch fixes the problem: ``[code]``,0
"Thanks for the report @vishvananda. I'm unable to reproduce the problem using the [1.3.0 release binary](""https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-1.3.0.tar.gz""), or [1.4.0-rc0 release binary](https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-1.3.0.tar.gz) (will try rebuilding from source using the exact flags you're using). Do you see the same problem when using the release binaries of the C API?

Which version of `go` are you using? Also, is it possible that `LD_LIBRARY_PATH` is somehow bringing in an older version of the C API libraries that your go program ends up using?

It should be okay for `TF_TensorData` to return `nil`.

Any additional information in reproducing the environment will be helpful. (I'll try to dig into this a bit more by rebuilding from source using the command you provided above)",IssueComment,https://github.com/tensorflow/tensorflow/issues/13764#issuecomment-337091767,asimshankar,2017-10-17 01:38:26,13764,[14082],Test bug,0,"Thanks for the report @vishvananda. I'm unable to reproduce the problem using the [1.3.0 release binary](""[url]""), or [1.4.0-rc0 release binary]([url] (will try rebuilding from source using the exact flags you're using). Do you see the same problem when using the release binaries of the C API? Which version of [code] are you using? Also, is it possible that [code] is somehow bringing in an older version of the C API libraries that your go program ends up using? It should be okay for [code] to return [code]. Any additional information in reproducing the environment will be helpful. (I'll try to dig into this a bit more by rebuilding from source using the command you provided above)",0
"Fascinating, both the 1.3.0 and the 1.4.0-rc0 release binary return zero length from TF_TensorData but they return a pointer to an actual buffer instead of nil. I'm attempting my flags on the 1.3 branch to see if it is the flags that are causing it to return nil. Next, I'll try removing the extra flags one at a time to see if I can narrow it down. I suspect AllocateTensor ends up with a nil buffer in certain cases. In the successful versions I don't see this error message:
```
2017-10-16 21:31:57.797656: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes
2017-10-16 21:31:57.797690: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes
```
In any case the nil check is probably good to have anyway.",IssueComment,https://github.com/tensorflow/tensorflow/issues/13764#issuecomment-337115998,vishvananda,2017-10-17 04:41:14,13764,[14082],Test bug,0,"Fascinating, both the 1.3.0 and the 1.4.0-rc0 release binary return zero length from TF_TensorData but they return a pointer to an actual buffer instead of nil. I'm attempting my flags on the 1.3 branch to see if it is the flags that are causing it to return nil. Next, I'll try removing the extra flags one at a time to see if I can narrow it down. I suspect AllocateTensor ends up with a nil buffer in certain cases. In the successful versions I don't see this error message: ``[code]`` In any case the nil check is probably good to have anyway.",1
"Ok, I think I've tracked down the issue to building with MKL. If I build without `--config=mkl` the tests pass fine. The issue is that building with MKL uses the bfc_allocator to allocate memory. That allocator explicitly returns nil when an allocation of zero bytes is performed (As a side note, this probably should not be an error or warning if we expect it to happen when we request a zero length tensor). In the case of running without MKL, the allocation eventually calls malloc (or jemalloc or alloc_aligned). The man tells me that malloc(0) is implementation defined and our version returns a non-nil pointer so the code does not throw a null-pointer exception. I suggest using something like the patch I included above for the go side, and maybe downgrading the error and warning messages in bfc_allocator.cc and allocator_retry.cc to something a bit less scary (maybe Info?).",IssueComment,https://github.com/tensorflow/tensorflow/issues/13764#issuecomment-337123785,vishvananda,2017-10-17 05:42:38,13764,[14082],Test bug,0,"Ok, I think I've tracked down the issue to building with MKL. If I build without [code] the tests pass fine. The issue is that building with MKL uses the bfc_allocator to allocate memory. That allocator explicitly returns nil when an allocation of zero bytes is performed (As a side note, this probably should not be an error or warning if we expect it to happen when we request a zero length tensor). In the case of running without MKL, the allocation eventually calls malloc (or jemalloc or alloc_aligned). The man tells me that malloc(0) is implementation defined and our version returns a non-nil pointer so the code does not throw a null-pointer exception. I suggest using something like the patch I included above for the go side, and maybe downgrading the error and warning messages in bfc_allocator.cc and allocator_retry.cc to something a bit less scary (maybe Info?).",0
"Thanks for the detailed trackdown @vishvananda, much appreciated.

Yes, what you said makes sense. For the Go side, would you like to contribute a pull request to make the fix? If not, let me know and I'm happy to make the change as well.

Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/13764#issuecomment-337127649,asimshankar,2017-10-17 06:07:44,13764,[14082],Test bug,0,"Thanks for the detailed trackdown @vishvananda, much appreciated. Yes, what you said makes sense. For the Go side, would you like to contribute a pull request to make the fix? If not, let me know and I'm happy to make the change as well. Thanks!",4
`model_to_dot()` does not work since commit  3599fd4. A minor fix seems works.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14542#issuecomment-344303287,qmick,2017-11-14 15:54:12,14542,[14553],Deployment bug,0,[code] does not work since commit 3599fd4. A minor fix seems works.,0
"Could you edit your post and wrap code in three backticks (Markdown code highlighting), please?

```cpp
int main() {
  // This is easier to read.
}
```

![image](https://user-images.githubusercontent.com/1595907/33139045-6ca77b38-cfac-11e7-8a29-233e0918a72d.png)",IssueComment,https://github.com/tensorflow/tensorflow/issues/14800#issuecomment-346406818,carlthome,2017-11-22 16:42:05,14800,[14816],Memory bug,0,"Could you edit your post and wrap code in three backticks (Markdown code highlighting), please? ``[code]`` ![image]([url]",0
"Or better yet, paste links to the relevant lines and GitHub will insert code snippets for you:
https://github.com/tensorflow/tensorflow/blob/6c95675492aa8d25619f5e4ce1674582c051a7fe/tensorflow/c/c_api.cc#L580-L583",IssueComment,https://github.com/tensorflow/tensorflow/issues/14800#issuecomment-346407628,carlthome,2017-11-22 16:44:50,14800,[14816],Memory bug,0,"Or better yet, paste links to the relevant lines and GitHub will insert code snippets for you: [url]#L580-L583",0
"@carlthome, thanks for the tip. Now I updated the description.",IssueComment,https://github.com/tensorflow/tensorflow/issues/14800#issuecomment-346481595,orpillar,2017-11-22 21:45:47,14800,[14816],Memory bug,0,"@carlthome, thanks for the tip. Now I updated the description.",3
"@orpillar I think those issues are true.  In `snappy_outputbuffer.cc`, ~`unique_ptr` probably could be used.~ Update: Actually there are only 4 bytes so it could be placed into the stack instead.

Would you like to create a PR for that? Otherwise I could help create a PR for you.",IssueComment,https://github.com/tensorflow/tensorflow/issues/14800#issuecomment-346495208,yongtang,2017-11-22 22:57:43,14800,[14816],Memory bug,0,"@orpillar I think those issues are true. In [code], ~[code] probably could be used.~ Update: Actually there are only 4 bytes so it could be placed into the stack instead. Would you like to create a PR for that? Otherwise I could help create a PR for you.",2
"@yongtang, thanks for looking into the issues. You are right about snappy_outputbuffer.cc.
I am new to open source community, just want to see there is any easy things I could contribute.
Please feel free to help create a PR. Thanks,",IssueComment,https://github.com/tensorflow/tensorflow/issues/14800#issuecomment-346517268,orpillar,2017-11-23 01:59:37,14800,[14816],Memory bug,0,"@yongtang, thanks for looking into the issues. You are right about snappy_outputbuffer.cc. I am new to open source community, just want to see there is any easy things I could contribute. Please feel free to help create a PR. Thanks,",3
@orpillar Created PR #14816 for the fix. Thanks for your contribution to TensorFlow community! ðŸ‘  ,IssueComment,https://github.com/tensorflow/tensorflow/issues/14800#issuecomment-346520065,yongtang,2017-11-23 02:30:10,14800,[14816],Memory bug,0,@orpillar Created PR #14816 for the fix. Thanks for your contribution to TensorFlow community! ðŸ‘,5
@yongtang. Thanks for the PR. It looks the sanity build had time out.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14800#issuecomment-346985300,orpillar,2017-11-26 05:21:07,14800,[14816],Memory bug,0,@yongtang. Thanks for the PR. It looks the sanity build had time out.,0
@orpillar bumped the build. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/14800#issuecomment-347060931,yongtang,2017-11-27 02:10:14,14800,[14816],Memory bug,0,@orpillar bumped the build. Thanks!,3
"Sounds like a mistake, cc @fchollet 

https://github.com/tensorflow/tensorflow/blob/ab0fcaceda001825654424bf18e8a8e0f8d39df2/tensorflow/python/keras/_impl/keras/layers/core.py#L107-L113",IssueComment,https://github.com/tensorflow/tensorflow/issues/14819#issuecomment-346546411,facaiy,2017-11-23 07:29:21,14819,[14831],Algorithm design bug,0,"Sounds like a mistake, cc @fchollet [url]#L107-L113",-1
"Correct, that's a bug, `self.supports_masking = True` should be after the call to the parent's constructor.",IssueComment,https://github.com/tensorflow/tensorflow/issues/14819#issuecomment-346547610,fchollet,2017-11-23 07:38:19,14819,[14831],Algorithm design bug,0,"Correct, that's a bug, [code] should be after the call to the parent's constructor.",-1
I can work on it. I'll fix it later.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14819#issuecomment-346548169,ZhengshengWei,2017-11-23 07:42:37,14819,[14831],Algorithm design bug,0,I can work on it. I'll fix it later.,2
"Fine. It would be better if you can add a corresponding test case here:

https://github.com/tensorflow/tensorflow/blob/ab0fcaceda001825654424bf18e8a8e0f8d39df2/tensorflow/python/keras/_impl/keras/layers/core_test.py#L38",IssueComment,https://github.com/tensorflow/tensorflow/issues/14819#issuecomment-346548808,facaiy,2017-11-23 07:47:19,14819,[14831],Algorithm design bug,0,Fine. It would be better if you can add a corresponding test case here: [url]#L38,0
okay,IssueComment,https://github.com/tensorflow/tensorflow/issues/14819#issuecomment-346548908,ZhengshengWei,2017-11-23 07:48:09,14819,[14831],Algorithm design bug,0,okay,0
@facaiy please check if unit test added is valid. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/14819#issuecomment-346579579,ZhengshengWei,2017-11-23 10:22:43,14819,[14831],Algorithm design bug,0,@facaiy please check if unit test added is valid. Thanks!,1
Added a PR #14872 for DT_HALF support on GPU.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14871#issuecomment-346914862,yongtang,2017-11-25 02:57:28,14871,[14872],Processor bug,1,Added a PR #14872 for DT_HALF support on GPU.,3
@ebrevdo Any idea what would be happening here?  Do while loop gradients depend on unserialized information?,IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-278995160,girving,2017-02-10 16:43:52,7404,[18052],Documentation bug,0,@ebrevdo Any idea what would be happening here? Do while loop gradients depend on unserialized information?,0
"Yes, though I thought Yuan and Sherry had added the appropriate serialization to the metagraph.  Is this on master branch of tf?",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-279127308,ebrevdo,2017-02-11 07:22:35,7404,[18052],Documentation bug,0,"Yes, though I thought Yuan and Sherry had added the appropriate serialization to the metagraph. Is this on master branch of tf?",0
"Ya, this is master.",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-279141724,malmaud,2017-02-11 12:46:43,7404,[18052],Documentation bug,0,"Ya, this is master.",0
"OK, I see if I save and restore the metagraph (via `tf.train.export_meta_graph` and `tf.train.import_meta_graph`, then I can take the gradient in the restored session. So it's just a problem if you try serializing and importing the `GraphDef` itself. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-279160667,malmaud,2017-02-11 17:14:36,7404,[18052],Documentation bug,0,"OK, I see if I save and restore the metagraph (via [code] and [code], then I can take the gradient in the restored session. So it's just a problem if you try serializing and importing the [code] itself.",0
"@ebrevdo Is there an easy way to produce a nicer error message here, so that users don't have to guess the graph vs. metagraph issue?",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-279431704,girving,2017-02-13 15:50:44,7404,[18052],Documentation bug,0,"@ebrevdo Is there an easy way to produce a nicer error message here, so that users don't have to guess the graph vs. metagraph issue?",0
"Yes; I believe that the forward_ctxt object here:

forward_ctxt.outer_context

should have a @property outer_context; and if no such internal object is
set, it can raise a ValueError/InternalError that maybe you're trying to
call gradients on a while loop without properly serializing your graph via
MetaGraphDef.

On Mon, Feb 13, 2017 at 7:51 AM, Geoffrey Irving <notifications@github.com>
wrote:

> @ebrevdo <https://github.com/ebrevdo> Is there an easy way to produce a
> nicer error message here, so that users don't have to guess the graph vs.
> metagraph issue?
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-279431704>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABtimxlSpTQAQlztIVyjpp6fmXDWkZ60ks5rcHvvgaJpZM4L89DK>
> .
>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-279453375,ebrevdo,2017-02-13 17:00:39,7404,[18052],Documentation bug,0,"Yes; I believe that the forward_ctxt object here: forward_ctxt.outer_context should have a @property outer_context; and if no such internal object is set, it can raise a ValueError/InternalError that maybe you're trying to call gradients on a while loop without properly serializing your graph via MetaGraphDef. On Mon, Feb 13, 2017 at 7:51 AM, Geoffrey Irving <[email]> wrote: > @ebrevdo <[url] Is there an easy way to produce a > nicer error message here, so that users don't have to guess the graph vs. > metagraph issue? > > â€” > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub > <[url]#issuecomment-279431704>, > or mute the thread > <[url] > . >",0
"Hi @ebrevdo , is there any update on this issue? Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-343528096,kejiashi,2017-11-10 16:58:13,7404,[18052],Documentation bug,0,"Hi @ebrevdo , is there any update on this issue? Thanks!",1
"@ebrevdo, any update on this issue or any workaround? Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-344156455,posenhuang,2017-11-14 06:10:20,7404,[18052],Documentation bug,0,"@ebrevdo, any update on this issue or any workaround? Thanks!",1
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-353159633,tensorflowbutler,2017-12-20 19:27:54,7404,[18052],Documentation bug,0,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-355373162,tensorflowbutler,2018-01-04 19:18:55,7404,[18052],Documentation bug,0,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-360130004,tensorflowbutler,2018-01-24 13:18:44,7404,[18052],Documentation bug,0,Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-3
@ebrevdo should we mark this contributions welcome?,IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-363965038,gunan,2018-02-08 00:52:28,7404,[18052],Documentation bug,0,@ebrevdo should we mark this contributions welcome?,0
Yes,IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-363981991,ebrevdo,2018-02-08 02:26:46,7404,[18052],Documentation bug,0,Yes,0
Created a PR #18052 to fix this.,IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-376929140,imsheridan,2018-03-28 15:29:35,7404,[18052],Documentation bug,0,Created a PR #18052 to fix this.,3
"Hello, I came up with the same issue when I use **tf.import_graph_def**:
AttributeError: 'NoneType' object has no attribute 'outer_context'

Following the instructions above I switched to **import_meta_graph** like this:

`
def _make_model_and_ops(self, patch_val):
        start = time.time()
        
        self.image_input_ = tf.placeholder(tf.float32, shape=(None, None, None, 3), name='image_input')
        saver = tf.train.import_meta_graph(PATH_TO_CKPT + '.meta',
                                           import_scope=""detection"",
                                           input_map={
                                               'ToFloat_3': self.image_input_
                                           })
        saver.restore(self.sess, PATH_TO_CKPT)
        self.graph = self.sess.graph
        
        with self.sess.graph.as_default():
            tf.set_random_seed(1234)
            
            # Tensors are post-fixed with an underscore!
            #self.image_input_shape_ = tf.placeholder(tf.int32, shape=(1,3), name=""image_input_shape"")
            
            self.eps_ = tf.placeholder(tf.float32, shape=(1), name='eps')
            
            # The following commented part is the original code using import_graph_def
            '''
            detection_graph_def = tf.GraphDef()
            with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:
                serialized_graph = fid.read()
                detection_graph_def.ParseFromString(serialized_graph)
                tf.import_graph_def(detection_graph_def, name='detection',
                                    input_map={
                                               'Preprocessor/map/TensorArrayStack/TensorArrayGatherV3': self.image_input_,
                                               'Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3': self.image_input_shape_
                                              })
            '''
            
            # Second-stage Class Loss
            self.second_stage_cls_scores_ = self.graph.get_tensor_by_name('detection/SecondStagePostprocessor/convert_scores:0')
            second_stage_cls_logits_ = self.graph.get_tensor_by_name('detection/SecondStagePostprocessor/scale_logits:0')
            self.second_stage_cls_labels_ = tf.placeholder(tf.float32, shape=second_stage_cls_logits_.shape, name='second_stage_cls_labels')
            
            self.second_stage_cls_losses_ = tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.reshape(self.second_stage_cls_labels_, (-1, self.second_stage_cls_labels_.shape[2])),
                                                                                       logits=tf.reshape(second_stage_cls_logits_, (-1, second_stage_cls_logits_.shape[2]))) 
           
            # Second-stage bounding boxes
            self.second_stage_loc_bboxes_ = self.graph.get_tensor_by_name('detection/SecondStagePostprocessor/Reshape_4:0')
            
            grads = tf.gradients(self.second_stage_cls_losses_, [self.image_input_])
            print(grads)
            self.unclipped_adv_images_ = self.image_input_ + self.eps_ * tf.sign(grads)
            self.adv_images_ = tf.clip_by_value(self.unclipped_adv_images_, clip_value_min=0, clip_value_max=255)
    
    
        elapsed = time.time() - start
        print(""Finished loading the model, took {:.0f}s"".format(elapsed))           
`

But the problem still exist.
Does this mean that the information required for tf.gradients does not appear in the check point? If so, what else can I do?

Thanks, and sorry for my poor English....",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-443428187,ProjectDimlight,2018-12-01 13:58:02,7404,[18052],Documentation bug,0,"Hello, I came up with the same issue when I use **tf.import_graph_def**: AttributeError: 'NoneType' object has no attribute 'outer_context' Following the instructions above I switched to **import_meta_graph** like this: [code] But the problem still exist. Does this mean that the information required for tf.gradients does not appear in the check point? If so, what else can I do? Thanks, and sorry for my poor English....",0
"Having the same problem as @ProjectDimlight, tried the suggestions above with no luck. Any updates on this?",IssueComment,https://github.com/tensorflow/tensorflow/issues/7404#issuecomment-599016109,SilverKnightVGM,2020-03-14 05:59:09,7404,[18052],Documentation bug,0,"Having the same problem as @ProjectDimlight, tried the suggestions above with no luck. Any updates on this?",-2
Added a PR #14939 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14932#issuecomment-347525789,yongtang,2017-11-28 13:38:30,14932,[14939],Data bug,1,Added a PR #14939 for the fix.,3
"@jhseu, do you think we should support both and just fallback or just document it?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/14951#issuecomment-347694540,aselle,2017-11-28 23:06:22,14951,[14984],Documentation bug,0,"@jhseu, do you think we should support both and just fallback or just document it?",0
"Yeah, if there's a common practice here, we should use that and deprecate the other environment variable in TF 2.0.",IssueComment,https://github.com/tensorflow/tensorflow/issues/14951#issuecomment-347699146,jhseu,2017-11-28 23:27:27,14951,[14984],Documentation bug,0,"Yeah, if there's a common practice here, we should use that and deprecate the other environment variable in TF 2.0.",1
The S3_REGION was introduced in PR #11089. Sorry about the confusion on AWS_REGION vs. S3_REGION.  I will create a PR to add AWS_REGION support shortly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14951#issuecomment-348075450,yongtang,2017-11-30 03:54:29,14951,[14984],Documentation bug,0,The S3_REGION was introduced in PR #11089. Sorry about the confusion on AWS_REGION vs. S3_REGION. I will create a PR to add AWS_REGION support shortly.,2
Added a PR #14984 for the fix. Please take a look.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14951#issuecomment-348076292,yongtang,2017-11-30 04:01:27,14951,[14984],Documentation bug,0,Added a PR #14984 for the fix. Please take a look.,2
@rmlarsen Do you mind fixing this?,IssueComment,https://github.com/tensorflow/tensorflow/issues/9827#issuecomment-300904786,girving,2017-05-11 20:16:21,9827,[15394],Documentation bug,0,@rmlarsen Do you mind fixing this?,0
"BTW- I would be happy to regularly make PRs for various documentation fixes.  However, I'm a little confused by the code.  I can grep for some of the descriptions to find current docs in the code, but I find that there is quite a bit of duplicate documentation.   Is this because there is separate documentation for the C++ and python code?  

Since I assume you want the same behavior in both, could this be changed to use \copydoc from doxygen to avoid having to put the docs in two places?

Otherwise, If I were to make a change, do I change all the places or is some of it generated and I only need to change one?

So that I can be a contributing citizen, generally, what is the rule for where to change things when fixing documentation?",IssueComment,https://github.com/tensorflow/tensorflow/issues/9827#issuecomment-300977059,ddurham2,2017-05-12 03:51:18,9827,[15394],Documentation bug,0,"BTW- I would be happy to regularly make PRs for various documentation fixes. However, I'm a little confused by the code. I can grep for some of the descriptions to find current docs in the code, but I find that there is quite a bit of duplicate documentation. Is this because there is separate documentation for the C++ and python code? Since I assume you want the same behavior in both, could this be changed to use \copydoc from doxygen to avoid having to put the docs in two places? Otherwise, If I were to make a change, do I change all the places or is some of it generated and I only need to change one? So that I can be a contributing citizen, generally, what is the rule for where to change things when fixing documentation?",2
"@ddurham2 (cc @martinwicke): I don't think we have a good story for avoid code duplication between C++ and Python for ops with wrappers.  In this case (and many others) I don't think there's a good substitute for a human merging the docs, since they're different ops at the C++ level (though they probably shouldn't be).

@ddurham2 Did I interpret correctly that you're volunteering to send a PR?  If so, thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/9827#issuecomment-301112007,girving,2017-05-12 15:42:16,9827,[15394],Documentation bug,0,"@ddurham2 (cc @martinwicke): I don't think we have a good story for avoid code duplication between C++ and Python for ops with wrappers. In this case (and many others) I don't think there's a good substitute for a human merging the docs, since they're different ops at the C++ level (though they probably shouldn't be). @ddurham2 Did I interpret correctly that you're volunteering to send a PR? If so, thank you!",1
Sure.. I'll give it a whirl. Could you give me a pointer on how to build and view the documentation (HTML or otherwise) to make sure my changes would look presentable?,IssueComment,https://github.com/tensorflow/tensorflow/issues/9827#issuecomment-301283377,ddurham2,2017-05-14 00:44:30,9827,[15394],Documentation bug,0,Sure.. I'll give it a whirl. Could you give me a pointer on how to build and view the documentation (HTML or otherwise) to make sure my changes would look presentable?,3
"The documentation on documentation is here. If you have questions or if something doesn't work as expected, please ask. Note that the doc generator currently only works for Python 2.7.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/community/documentation.md",IssueComment,https://github.com/tensorflow/tensorflow/issues/9827#issuecomment-301288504,martinwicke,2017-05-14 03:24:28,9827,[15394],Documentation bug,0,"The documentation on documentation is here. If you have questions or if something doesn't work as expected, please ask. Note that the doc generator currently only works for Python 2.7. [url]",0
@zheng-xq Here's a GPU memory alloc issue. Reported both here and on Stack Overflow: http://stackoverflow.com/questions/41530966/memory-error-with-eigenallocator,IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-271779658,jart,2017-01-11 05:10:08,6766,[16051],Memory bug,1,@zheng-xq Here's a GPU memory alloc issue. Reported both here and on Stack Overflow: [url],0
"Hi, @jrosti 
Have this problem been solved?
I met the same problem in `r1.01`",IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-292775048,CharlesShang,2017-04-09 09:34:00,6766,[16051],Memory bug,1,"Hi, @jrosti Have this problem been solved? I met the same problem in [code]",0
I still have this problem which seems to arise when using tensorflow fold.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-295353061,leconteur,2017-04-19 17:20:12,6766,[16051],Memory bug,1,I still have this problem which seems to arise when using tensorflow fold.,-2
"Still getting this issue, as of 06/02/2017 when using tf.gather_nd(...) and softmax_cross_entropy_with_logits(...) together.",IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-305683981,yycho0108,2017-06-02 04:06:18,6766,[16051],Memory bug,1,"Still getting this issue, as of 06/02/2017 when using tf.gather_nd(...) and softmax_cross_entropy_with_logits(...) together.",-2
"Anyone looking into this? I'm also experiencing this issue using TensorFlow 1.2.0 (v1.2.0-rc2-21-g12f033d). In my case, a `tf.while_loop` is being used (in conjunction with `tf.TensorArray`); however, the same error occurs if I swap out the `tf.while_loop` for a `while` statement.

**Backtrace** (abbr):
```
2017-06-24 05:42:28.894580: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes
2017-06-24 05:42:28.894638: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes
2017-06-24 05:42:28.894647: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes
2017-06-24 05:42:28.894657: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes
2017-06-24 05:42:28.895314: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr
2017-06-24 05:42:28.895406: E tensorflow/core/common_runtime/bfc_allocator.cc:378] tried to deallocate nullptr
2017-06-24 05:42:28.896185: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for
         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](while/Reshape, while/Reshape_1)]]
2017-06-24 05:42:28.896209: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for
         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](while/Reshape, while/Reshape_1)]]
.
.
.
2017-06-24 05:42:28.905449: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for
         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](while/Reshape, while/Reshape_1)]]
2017-06-24 05:42:28.905669: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: Ran out of GPU memory when allocating 0 bytes for
         [[Node: while/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](while/Reshape, while/Reshape_1)]]
```

A bit further down,
```
Caused by op 'while/SoftmaxCrossEntropyWithLogits', defined at:
  ...
  File ""scripts/gpu_experiment.py"", line 400, in build_backend
    backend['o'] = build_outputs(config, backend.get('o', None))
  File ""scripts/gpu_experiment.py"", line 363, in build_outputs
    loop_vars = tf.while_loop(loop_cond, _build_outputs, loop_vars)
    ...
    cross_ent = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-310870817,j-wilson,2017-06-24 23:02:07,6766,[16051],Memory bug,1,"Anyone looking into this? I'm also experiencing this issue using TensorFlow 1.2.0 (v1.2.0-rc2-21-g12f033d). In my case, a [code] is being used (in conjunction with [code]); however, the same error occurs if I swap out the [code] for a [code] statement. **Backtrace** (abbr): ``[code]`[code]`[code]``",0
I'm also experiencing this issue and error message is same as  @j-wilson   . I am fine tuning object detction api on faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017 model.ckpt.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-317678587,gmvidooly,2017-07-25 09:14:01,6766,[16051],Memory bug,1,I'm also experiencing this issue and error message is same as @j-wilson . I am fine tuning object detction api on faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017 model.ckpt.,0
Also having the same problem in tf 1.3. Would be great if it threw a more descriptive exception.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-324608838,JulienSiems,2017-08-24 11:27:15,6766,[16051],Memory bug,1,Also having the same problem in tf 1.3. Would be great if it threw a more descriptive exception.,1
"I hit this issue.  After some investigating I realized I was feeding in an empty tensor.  Not sure if that is the only thing that can cause it, but that was my problem at least.

It was easy to fix, but it certainly would be nice if it threw a more descriptive error.",IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-330064751,metachi,2017-09-17 17:38:02,6766,[16051],Memory bug,1,"I hit this issue. After some investigating I realized I was feeding in an empty tensor. Not sure if that is the only thing that can cause it, but that was my problem at least. It was easy to fix, but it certainly would be nice if it threw a more descriptive error.",1
Massive thanks. Empty tensor is the cause of my problem too. @metachi ,IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-341400564,enfeizhan,2017-11-02 12:02:43,6766,[16051],Memory bug,1,Massive thanks. Empty tensor is the cause of my problem too. @metachi,5
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-353159133,tensorflowbutler,2017-12-20 19:25:48,6766,[16051],Memory bug,1,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-355372976,tensorflowbutler,2018-01-04 19:18:11,6766,[16051],Memory bug,1,It has been 14 days with no activity and the [code] label was assigned. Please update the label and/or status accordingly.,0
"I'm facing same problem even checking if tensor is empty or not:
```

 loss = K.switch(tf.size(y_true) > 0,
                    tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true, dim=1),
                    tf.constant(0.0))
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-356691761,filipetrocadoferreira,2018-01-10 18:25:03,6766,[16051],Memory bug,1,I'm facing same problem even checking if tensor is empty or not: ``[code]``,-2
"@filipetrocadoferreira Have you tried to wrap the conditional branches into lambda functions? 
```
loss = K.switch(tf.size(y_true) > 0,
                    lambda: tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true, dim=1),
                    lambda: tf.constant(0.0))
```
This should allow a lazy execution of the branches. (see [tf.cond](https://www.tensorflow.org/api_docs/python/tf/cond))",IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-356697028,marcocannici,2018-01-10 18:43:20,6766,[16051],Memory bug,1,@filipetrocadoferreira Have you tried to wrap the conditional branches into lambda functions? ``[code]`` This should allow a lazy execution of the branches. (see [tf.cond]([url],1
"wow, this seems to work. Can you link to an explanation?",IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-356874068,filipetrocadoferreira,2018-01-11 09:19:23,6766,[16051],Memory bug,1,"wow, this seems to work. Can you link to an explanation?",2
Added PR #16051 for a fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-357065999,yongtang,2018-01-11 21:24:41,6766,[16051],Memory bug,1,Added PR #16051 for a fix.,0
"@filipetrocadoferreira I canâ€™t find any link with an extensive explanation (I tought it was explained in tf.cond â€™s documentation but actually it is not). In short, if you donâ€™t define the branches as functions, they will be both executed regardless of the condition. This explains why you still had the problem despite checking the tensorâ€™s size.",IssueComment,https://github.com/tensorflow/tensorflow/issues/6766#issuecomment-357085664,marcocannici,2018-01-11 22:42:24,6766,[16051],Memory bug,1,"@filipetrocadoferreira I canâ€™t find any link with an extensive explanation (I tought it was explained in tf.cond â€™s documentation but actually it is not). In short, if you donâ€™t define the branches as functions, they will be both executed regardless of the condition. This explains why you still had the problem despite checking the tensorâ€™s size.",-1
"Could you provide a reproducible test case of what exactly you tried to do? Generally speaking, I think a lot of the tooling after training requires NHWC, as that was the only format when those were written. If you could provide a reproducible test case, we could work to improve it. @petewarden, do you have any other comments?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/15034#issuecomment-348561433,aselle,2017-12-01 17:47:50,15034,[16075],Algorithm design bug,0,"Could you provide a reproducible test case of what exactly you tried to do? Generally speaking, I think a lot of the tooling after training requires NHWC, as that was the only format when those were written. If you could provide a reproducible test case, we could work to improve it. @petewarden, do you have any other comments?",0
"I tried:

```
python tensorflow/python/tools/optimize_for_inference.py \
--input ./ckpt/frozen_model.pb \
--output ./ckpt/optimized_model.pb \
--frozen_graph true \
--input_names Placeholder \
--output_names policy_head/softmax,value_head/value/Tanh
```

and

```
tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph='./ckpt/frozen_model.pb' \
--out_graph='./ckpt/transformed_model.pb' \
--inputs='Placeholder' \
--outputs='policy_head/softmax,value_head/value/Tanh' \
--transforms='
fold_constants(ignore_errors=true)
fold_batch_norms
fold_old_batch_norms
fuse_pad_and_conv
fuse_resize_and_conv
fuse_resize_pad_and_conv
'
```

In both cases, the error occurred in fused batchnorm. The frozen model worked well, but the optimized model and transformed model emitted error.",IssueComment,https://github.com/tensorflow/tensorflow/issues/15034#issuecomment-348849210,khanrc,2017-12-04 03:04:48,15034,[16075],Algorithm design bug,0,"I tried: ``[code]`[code]`[code]`` In both cases, the error occurred in fused batchnorm. The frozen model worked well, but the optimized model and transformed model emitted error.",-2
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/15034#issuecomment-353540243,tensorflowbutler,2017-12-22 07:34:33,15034,[16075],Algorithm design bug,0,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/15034#issuecomment-355638719,tensorflowbutler,2018-01-05 19:08:07,15034,[16075],Algorithm design bug,0,Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/15034#issuecomment-360129386,tensorflowbutler,2018-01-24 13:17:05,15034,[16075],Algorithm design bug,0,Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
"@wolffg, could you look at fixing this?",IssueComment,https://github.com/tensorflow/tensorflow/issues/16263#issuecomment-359320047,aselle,2018-01-22 04:08:54,16263,[17443],Documentation bug,0,"@wolffg, could you look at fixing this?",0
Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16263#issuecomment-363336179,tensorflowbutler,2018-02-06 07:37:24,16263,[17443],Documentation bug,0,Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16263#issuecomment-367093343,tensorflowbutler,2018-02-20 19:35:48,16263,[17443],Documentation bug,0,Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Added a PR #17443 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16263#issuecomment-370502614,yongtang,2018-03-05 17:45:54,16263,[17443],Documentation bug,0,Added a PR #17443 for the fix.,0
Nagging Assignee @wolffg: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16263#issuecomment-374545431,tensorflowbutler,2018-03-20 10:20:31,16263,[17443],Documentation bug,0,Nagging Assignee @wolffg: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Nagging Assignee @wolffg: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16263#issuecomment-378772096,tensorflowbutler,2018-04-04 23:03:48,16263,[17443],Documentation bug,0,Nagging Assignee @wolffg: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
"Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Have I written custom code
OS Platform and Distribution
TensorFlow installed from
TensorFlow version
Bazel version
CUDA/cuDNN version
GPU model and memory
Exact command to reproduce",IssueComment,https://github.com/tensorflow/tensorflow/issues/17614#issuecomment-372061796,tensorflowbutler,2018-03-10 20:08:00,17614,[17617],Documentation bug,0,"Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks. Have I written custom code OS Platform and Distribution TensorFlow installed from TensorFlow version Bazel version CUDA/cuDNN version GPU model and memory Exact command to reproduce",0
Added a PR #17614 for the doc fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/17614#issuecomment-372062274,yongtang,2018-03-10 20:13:38,17614,[17617],Documentation bug,0,Added a PR #17614 for the doc fix.,3
"I believe this was fixed by https://github.com/tensorflow/tensorflow/commit/f4e70be18b104fbb2efeefeb83bea190aec12727
but an update to the site hasn't been pushed since.

@MarkDaoust : Can we push an update?",IssueComment,https://github.com/tensorflow/tensorflow/issues/17614#issuecomment-372062742,asimshankar,2018-03-10 20:18:48,17614,[17617],Documentation bug,0,I believe this was fixed by [url] but an update to the site hasn't been pushed since. @MarkDaoust : Can we push an update?,0
"@asimshankar @MarkDaoust It looks like the issue was fixed by f4e70be, but later it has been overridden by 9dae88d. I created #17617 to get the fix back.",IssueComment,https://github.com/tensorflow/tensorflow/issues/17614#issuecomment-372064987,yongtang,2018-03-10 20:45:06,17614,[17617],Documentation bug,0,"@asimshankar @MarkDaoust It looks like the issue was fixed by f4e70be, but later it has been overridden by 9dae88d. I created #17617 to get the fix back.",0
This question seems suitable for StackOverFlow. ,IssueComment,https://github.com/tensorflow/tensorflow/issues/13288#issuecomment-331831902,ghost,2017-09-25 09:47:59,13288,[17863],Documentation bug,0,This question seems suitable for StackOverFlow.,0
This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/13288#issuecomment-334074103,asimshankar,2017-10-04 07:39:29,13288,[17863],Documentation bug,0,This question is better asked on [StackOverflow]([url] since it is not a bug or feature request. There is also a larger community that reads questions there. Thanks!,2
"@asimshankar Maybe my description is not very clear, but I was not asking a question. I am fairly sure this is a bug, because the codeâ€™s behavior is different than the documented behavior. I think either the implementation is wrong, or the documentation is wrong.

Consider the following two pieces of codes:

```python
import tensorflow as tf
from tensorflow.contrib import staging

staging.StagingArea(dtypes=[tf.int32]).put(tf.constant(1))
```

```python
import tensorflow as tf
from tensorflow.contrib import staging

staging.StagingArea(dtypes=[tf.int32]).put((tf.constant(1),))
```

The first one wonâ€™t work as I described, the second one works. If the documentation is correct, both ones should work, so I think this is a bug that need to be fixed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/13288#issuecomment-334080725,EFanZh,2017-10-04 08:08:57,13288,[17863],Documentation bug,0,"@asimshankar Maybe my description is not very clear, but I was not asking a question. I am fairly sure this is a bug, because the codeâ€™s behavior is different than the documented behavior. I think either the implementation is wrong, or the documentation is wrong. Consider the following two pieces of codes: ``[code]`[code]`[code]`` The first one wonâ€™t work as I described, the second one works. If the documentation is correct, both ones should work, so I think this is a bug that need to be fixed.",-2
"I see. Indeed it seems the documentation is incorrect.

Possible fixes include:

- Updating the documentation in [this line](https://github.com/tensorflow/tensorflow/blob/3dbe216/tensorflow/python/ops/data_flow_ops.py#L1676) to something like `A tuple or list of Tensors. The number of elements must match the length of the list provided to the dtypes argument when creating the StagingArea`.
- Updating the code to allow for a single Tensor by changing [this line](https://github.com/tensorflow/tensorflow/blob/3dbe216/tensorflow/python/ops/data_flow_ops.py#L1690) so that `indices` ends up as `[0]` instead of `None` when the argument is an instance of `Tensor`

PRs to fix these are welcome!

FYI @ekelsen ",IssueComment,https://github.com/tensorflow/tensorflow/issues/13288#issuecomment-334221798,asimshankar,2017-10-04 16:59:53,13288,[17863],Documentation bug,0,I see. Indeed it seems the documentation is incorrect. Possible fixes include: - Updating the documentation in [this line]([url]#L1676) to something like [code]. - Updating the code to allow for a single Tensor by changing [this line]([url]#L1690) so that [code] ends up as [code] instead of [code] when the argument is an instance of [code] PRs to fix these are welcome! FYI @ekelsen,1
"Thank you for outlining how to address this, @asimshankar, and for making it accessible for my first contribution. I've created a PR here: #13502 and tested it locally.",IssueComment,https://github.com/tensorflow/tensorflow/issues/13288#issuecomment-334371840,JackDanger,2017-10-05 06:34:12,13288,[17863],Documentation bug,0,"Thank you for outlining how to address this, @asimshankar, and for making it accessible for my first contribution. I've created a PR here: #13502 and tested it locally.",5
"Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Have I written custom code
OS Platform and Distribution
TensorFlow installed from
TensorFlow version
Bazel version
CUDA/cuDNN version
GPU model and memory
Exact command to reproduce",IssueComment,https://github.com/tensorflow/tensorflow/issues/17663#issuecomment-372703472,tensorflowbutler,2018-03-13 15:21:17,17663,[18022],Documentation bug,0,"Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks. Have I written custom code OS Platform and Distribution TensorFlow installed from TensorFlow version Bazel version CUDA/cuDNN version GPU model and memory Exact command to reproduce",0
@MarkDaoust ,IssueComment,https://github.com/tensorflow/tensorflow/issues/17663#issuecomment-375806071,skye,2018-03-23 21:41:41,17663,[18022],Documentation bug,0,@MarkDaoust,0
Created a PR #18022 to fix this math equation format issue,IssueComment,https://github.com/tensorflow/tensorflow/issues/17663#issuecomment-376612890,imsheridan,2018-03-27 17:42:57,17663,[18022],Documentation bug,0,Created a PR #18022 to fix this math equation format issue,2
"This does seem like a documentation bug.
@ekelsen  (it seems you authored it) and @wolffg could you take a look?",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-308172648,aselle,2017-06-13 16:26:32,10622,[18223],Documentation bug,0,This does seem like a documentation bug. @ekelsen (it seems you authored it) and @wolffg could you take a look?,0
"Mark, is this an issue with an unsealed library?",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-308184097,wolffg,2017-06-13 17:07:48,10622,[18223],Documentation bug,0,"Mark, is this an issue with an unsealed library?",0
"The opposite problem actually. It's over-sealed and the objects are not exposed.

It is removed by the `remove_undocumented` in [standard_ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/standard_ops.py).

Its neighbor, `RandomShuffleQueue`, is made visible by the `@@RandomShuffleQueue` in [io_ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/io_ops.py).

So if we want it exposed as `tf.RecordInput` we would just need to add `@@RecordInput` there. It's probably even better to move those `@@`s across to `data_flow_ops` where these things are defined. 

The same situation seems to apply to `Barrier` and `StagingArea`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-308205292,MarkDaoust,2017-06-13 18:23:45,10622,[18223],Documentation bug,0,"The opposite problem actually. It's over-sealed and the objects are not exposed. It is removed by the [code] in [standard_ops]([url] Its neighbor, [code], is made visible by the [code] in [io_ops]([url] So if we want it exposed as [code] we would just need to add [code] there. It's probably even better to move those [code]s across to [code] where these things are defined. The same situation seems to apply to [code] and [code].",0
@martinwicke can you comment on the intended API here? It look like these are meant to be public. Are they meant to go in the main `tf` namespace of is there another place for them.,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-308223430,MarkDaoust,2017-06-13 19:30:28,10622,[18223],Documentation bug,0,@martinwicke can you comment on the intended API here? It look like these are meant to be public. Are they meant to go in the main [code] namespace of is there another place for them.,0
"I'm pretty sure that Barrier and StagingArea are intentionally not exposed, so the same ma apply here. Can you ask the authors to make sure these are not intentionally private?",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-308233533,martinwicke,2017-06-13 20:09:48,10622,[18223],Documentation bug,0,"I'm pretty sure that Barrier and StagingArea are intentionally not exposed, so the same ma apply here. Can you ask the authors to make sure these are not intentionally private?",0
The current state is intentional.,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-308236413,ekelsen,2017-06-13 20:20:27,10622,[18223],Documentation bug,0,The current state is intentional.,0
"Why would it be intentional? Because the C++ backend _is_ open ([source](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/record-input)), and it's been described and recommended in the high performance models guide ([source](https://www.tensorflow.org/performance/performance_models)).",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-313849757,TimZaman,2017-07-08 11:13:39,10622,[18223],Documentation bug,0,Why would it be intentional? Because the C++ backend _is_ open ([source]([url] and it's been described and recommended in the high performance models guide ([source]([url],0
@TimZaman has a valid point,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-313889132,ahundt,2017-07-09 00:23:15,10622,[18223],Documentation bug,0,@TimZaman has a valid point,2
"If they are used, we should expose them through a public endpoint in contrib. We don't want to expose them directly since that would subject them to API stability guarantees, and they're not ready for that yet.",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-313900986,martinwicke,2017-07-09 05:56:49,10622,[18223],Documentation bug,0,"If they are used, we should expose them through a public endpoint in contrib. We don't want to expose them directly since that would subject them to API stability guarantees, and they're not ready for that yet.",0
"@martinwicke There are some other TF APIs that have been both documented and clearly marked as experimental and subject to change, which I think would work well here. I agree regarding relocating to contrib as well.  How does that sounds as an approach?",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-313936517,ahundt,2017-07-09 18:22:32,10622,[18223],Documentation bug,0,"@martinwicke There are some other TF APIs that have been both documented and clearly marked as experimental and subject to change, which I think would work well here. I agree regarding relocating to contrib as well. How does that sounds as an approach?",2
Considering recent discussion can this be reopened?,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-313936609,ahundt,2017-07-09 18:24:09,10622,[18223],Documentation bug,0,Considering recent discussion can this be reopened?,0
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-353156474,tensorflowbutler,2017-12-20 19:15:38,10622,[18223],Documentation bug,0,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
I think this is still valid for the python api version,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-353195612,ahundt,2017-12-20 22:03:15,10622,[18223],Documentation bug,0,I think this is still valid for the python api version,0
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-355373824,tensorflowbutler,2018-01-04 19:21:26,10622,[18223],Documentation bug,0,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
"@tfboyd, you seem to own the relevant docs. Is the recommendation to use `RecordInput` still up to date? I have the feeling that this been replaced by `tf.data`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-355389654,MarkDaoust,2018-01-04 20:26:57,10622,[18223],Documentation bug,0,"@tfboyd, you seem to own the relevant docs. Is the recommendation to use [code] still up to date? I have the feeling that this been replaced by [code].",0
"These can definitely be exposed as symbols in contrib. Please send a PR. Sorry for the endless delays. 

Exposing in contrib is (for now) our way of making as experimental.",IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-357322834,martinwicke,2018-01-12 18:52:56,10622,[18223],Documentation bug,0,These can definitely be exposed as symbols in contrib. Please send a PR. Sorry for the endless delays. Exposing in contrib is (for now) our way of making as experimental.,1
A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-359962726,tensorflowbutler,2018-01-23 23:07:38,10622,[18223],Documentation bug,0,A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.,0
Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-363773663,tensorflowbutler,2018-02-07 13:47:40,10622,[18223],Documentation bug,0,Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-3
Who should provide this PR?,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-363953296,wolffg,2018-02-07 23:55:23,10622,[18223],Documentation bug,0,Who should provide this PR?,0
Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-367675877,tensorflowbutler,2018-02-22 13:10:34,10622,[18223],Documentation bug,0,Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Added a PR #18223 to expose `RecordInput` symbol and docs in `tf.contrib.framework.RecordInput`.,IssueComment,https://github.com/tensorflow/tensorflow/issues/10622#issuecomment-378435479,yongtang,2018-04-03 23:53:10,10622,[18223],Documentation bug,0,Added a PR #18223 to expose [code] symbol and docs in [code].,0
"@annarev When I trace through this code in Python 3, it does indeed look like `tf.compat.as_str()` is mapped to this function:

https://github.com/tensorflow/tensorflow/blob/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8/tensorflow/python/util/compat.py#L48-L68

However, if I do `from tensorflow.python.util import compat`, `compat.as_str()` maps to `as_text()` via (presumably) this appropriate redirection:

https://github.com/tensorflow/tensorflow/blob/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8/tensorflow/python/util/compat.py#L93-L97

Is it possible that the `@tf_export()` decorator is rebinding the symbol incorrectly? From what I can tell, it has the correct behavior in Python 2, but should have different behavior in Python 3.",IssueComment,https://github.com/tensorflow/tensorflow/issues/18598#issuecomment-382007615,mrry,2018-04-17 14:13:24,18598,[18601],Version compatibility bug,0,"@annarev When I trace through this code in Python 3, it does indeed look like [code] is mapped to this function: [url]#L48-L68 However, if I do [code], [code] maps to [code] via (presumably) this appropriate redirection: [url]#L93-L97 Is it possible that the [code] decorator is rebinding the symbol incorrectly? From what I can tell, it has the correct behavior in Python 2, but should have different behavior in Python 3.",0
"@mrry @annarev I think the tf_export could be explicitly called based on python 2 or 3 to address the issue. The following diff might work:
```diff
diff --git a/tensorflow/python/util/compat.py b/tensorflow/python/util/compat.py
index 4163fca..738479c 100644
--- a/tensorflow/python/util/compat.py
+++ b/tensorflow/python/util/compat.py
@@ -45,7 +45,6 @@ from tensorflow.python.util.tf_export import tf_export
 from tensorflow.python.util.tf_export import tf_export
 
 
-@tf_export('compat.as_bytes', 'compat.as_str')
 def as_bytes(bytes_or_text, encoding='utf-8'):
   """"""Converts either bytes or unicode to `bytes`, using utf-8 encoding for text.
 
@@ -68,7 +67,6 @@ def as_bytes(bytes_or_text, encoding='utf-8'):
                     (bytes_or_text,))
 
 
-@tf_export('compat.as_text')
 def as_text(bytes_or_text, encoding='utf-8'):
   """"""Returns the given argument as a unicode string.
 
@@ -93,8 +91,12 @@ def as_text(bytes_or_text, encoding='utf-8'):
 # Convert an object to a `str` in both Python 2 and 3.
 if _six.PY2:
   as_str = as_bytes
+  tf_export('compat.as_bytes', 'compat.as_str')(as_bytes)
+  tf_export('compat.as_text')(as_text)
 else:
   as_str = as_text
+  tf_export('compat.as_bytes')(as_bytes)
+  tf_export('compat.as_text', 'compat.as_str')(as_text)
 
 
 @tf_export('compat.as_str_any')
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/18598#issuecomment-382048934,yongtang,2018-04-17 16:05:45,18598,[18601],Version compatibility bug,0,@mrry @annarev I think the tf_export could be explicitly called based on python 2 or 3 to address the issue. The following diff might work: ``[code]bytes[code]str[code]``,0
Added a PR #18601 for the fix. Please take a look to see if it fixes the issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/18598#issuecomment-382053350,yongtang,2018-04-17 16:19:32,18598,[18601],Version compatibility bug,0,Added a PR #18601 for the fix. Please take a look to see if it fixes the issue.,2
"Can we get this merged in 1.8? 

https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/util/compat.py",IssueComment,https://github.com/tensorflow/tensorflow/issues/18598#issuecomment-382430023,andresusanopinto,2018-04-18 15:34:50,18598,[18601],Version compatibility bug,0,Can we get this merged in 1.8? [url],0
"@andresusanopinto I added a PR #18662 against r1.8 to carry the fix. As 1.8.0 release is very close, not sure if the fix could be applied in time though.",IssueComment,https://github.com/tensorflow/tensorflow/issues/18598#issuecomment-382441788,yongtang,2018-04-18 16:09:49,18598,[18601],Version compatibility bug,0,"@andresusanopinto I added a PR #18662 against r1.8 to carry the fix. As 1.8.0 release is very close, not sure if the fix could be applied in time though.",0
Thanks @yongtang!,IssueComment,https://github.com/tensorflow/tensorflow/issues/18598#issuecomment-382643775,andresusanopinto,2018-04-19 07:50:59,18598,[18601],Version compatibility bug,0,Thanks @yongtang!,3
"@martinwicke, FYI
@frexvahi, thanks for reporting this. Would you be willing to submit a PR to fix this, since you already didd this in Keras?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-358052838,aselle,2018-01-16 18:08:01,16152,[19199],Code bug,0,"@martinwicke, FYI @frexvahi, thanks for reporting this. Would you be willing to submit a PR to fix this, since you already didd this in Keras?",2
"I could submit a PR, but getting someone to sign the corporate CLA would be harder.",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-358233321,frexvahi,2018-01-17 08:33:42,16152,[19199],Code bug,0,"I could submit a PR, but getting someone to sign the corporate CLA would be harder.",-2
The original poster has replied to this issue after the stat:awaiting response label was applied.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-359961763,tensorflowbutler,2018-01-23 23:03:23,16152,[19199],Code bug,0,The original poster has replied to this issue after the stat:awaiting response label was applied.,0
I fixed it on my end. I will try to submit a pull request today or tomorrow with the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-365798466,KarlJack47,2018-02-15 01:18:36,16152,[19199],Code bug,0,I fixed it on my end. I will try to submit a pull request today or tomorrow with the fix.,3
Just a quick update: I submitted a pull request that should fix the issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-365815285,KarlJack47,2018-02-15 03:20:32,16152,[19199],Code bug,0,Just a quick update: I submitted a pull request that should fix the issue.,3
"Can you say ""Fixes #16152"" in the description for your PR? That way this issue will be closed when your PR is submitted.",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-367469799,martinwicke,2018-02-21 20:58:16,16152,[19199],Code bug,0,"Can you say ""Fixes #16152"" in the description for your PR? That way this issue will be closed when your PR is submitted.",0
A quick update. I believe the issue has been fixed in r1.7 since ever since I started using it I haven't had any of the warnings.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-376997423,KarlJack47,2018-03-28 18:55:29,16152,[19199],Code bug,0,A quick update. I believe the issue has been fixed in r1.7 since ever since I started using it I haven't had any of the warnings.,4
Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-377755674,martinwicke,2018-04-01 05:33:34,16152,[19199],Code bug,0,Thanks!,2
"I'm still hitting this, Tensorflow 1.7.0 and 1.8.0-rc1. Python 3.6.5. Afraid I don't have an easy reproducer to hand, will update if I get one.",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-384907685,pwaller,2018-04-27 08:48:43,16152,[19199],Code bug,0,"I'm still hitting this, Tensorflow 1.7.0 and 1.8.0-rc1. Python 3.6.5. Afraid I don't have an easy reproducer to hand, will update if I get one.",-2
"Reproducer below tested on 1.8.0-rc1. Was hard to make a reproducer because the warning did not show up unless I had `warnings.filterwarnings('error')`, which I use to make it easier to find the sources of warnings.

```python3
import tensorflow as tf

import warnings
warnings.filterwarnings('error')

tf.reduce_sum(tf.placeholder(tf.float64))
```

Full stack trace below.

<details>

```.pytb
---------------------------------------------------------------------------
DeprecationWarning                        Traceback (most recent call last)
<ipython-input-1-1de048b23827> in <module>()
      4 warnings.filterwarnings('error')
      5 
----> 6 tf.reduce_sum(tf.placeholder(tf.float64))

~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    403       if is_in_graph_mode.IS_IN_GRAPH_MODE() and _PRINT_DEPRECATION_WARNINGS:
    404         invalid_args = []
--> 405         named_args = tf_inspect.getcallargs(func, *args, **kwargs)
    406         for arg_name, spec in iter(deprecated_positions.items()):
    407           if (spec.position < len(args) and

~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/util/tf_inspect.py in getcallargs(func, *positional, **named)
    107   argspec will be used.
    108   """"""
--> 109   argspec = getargspec(func)
    110   call_args = named.copy()
    111   this = getattr(func, 'im_self', None) or getattr(func, '__self__', None)

~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/util/tf_inspect.py in getargspec(object)
     53   decorators, target = tf_decorator.unwrap(object)
     54   return next((d.decorator_argspec for d in decorators
---> 55                if d.decorator_argspec is not None), _inspect.getargspec(target))
     56 
     57 

/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py in getargspec(func)
   1069     warnings.warn(""inspect.getargspec() is deprecated, ""
   1070                   ""use inspect.signature() or inspect.getfullargspec()"",
-> 1071                   DeprecationWarning, stacklevel=2)
   1072     args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann = \
   1073         getfullargspec(func)

DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
```

</details>",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-384924531,pwaller,2018-04-27 09:56:26,16152,[19199],Code bug,0,"Reproducer below tested on 1.8.0-rc1. Was hard to make a reproducer because the warning did not show up unless I had [code], which I use to make it easier to find the sources of warnings. ``[code]`[code]`[code]`` </details>",-1
"Tensorflow 1.9.0-dev20180427
```
import tensorflow as tf
miniconda3/envs/kaggle/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-386804874,CicoZhang,2018-05-05 13:13:42,16152,[19199],Code bug,0,Tensorflow 1.9.0-dev20180427 ``[code]float[code]np.floating[code]np.float64 == np.dtype(float).type[code]``,0
Added PR #19199 as an attempt for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-388071788,yongtang,2018-05-10 14:33:11,16152,[19199],Code bug,0,Added PR #19199 as an attempt for the fix.,0
"I am still hitting this warning with the following versions:
 * 1.8.0
 * 1.9.0
 * 1.10.0
 * 1.10.1
 * 1.11.0-rc2",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-424297579,sque,2018-09-25 10:55:25,16152,[19199],Code bug,0,I am still hitting this warning with the following versions: * 1.8.0 * 1.9.0 * 1.10.0 * 1.10.1 * 1.11.0-rc2,-2
Had so many of these on 1.8 that i could not longer see my test output. Updated to 1.10 and now i only have a few dozen of these warnings left.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-425012606,EelcoHoogendoorn,2018-09-27 08:53:38,16152,[19199],Code bug,0,Had so many of these on 1.8 that i could not longer see my test output. Updated to 1.10 and now i only have a few dozen of these warnings left.,2
"Yeah, still seeing this in 1.11.0-rc0:

```
/Users/josh/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  return _inspect.getargspec(target)
/Users/josh/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  return _inspect.getargspec(target)
...
```

Can we reopen?",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-425087742,joshburkart,2018-09-27 13:18:08,16152,[19199],Code bug,0,"Yeah, still seeing this in 1.11.0-rc0: ``[code]`` Can we reopen?",-1
any updates?,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-428867422,bwanglzu,2018-10-11 08:29:33,16152,[19199],Code bug,0,any updates?,0
I think the issue has been resolved in #22517 now.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-428996927,yongtang,2018-10-11 15:21:14,16152,[19199],Code bug,0,I think the issue has been resolved in #22517 now.,3
Still getting this issue with 1.11.0 and Python 3.6 ,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-431188870,NicoCoallier,2018-10-18 22:45:01,16152,[19199],Code bug,0,Still getting this issue with 1.11.0 and Python 3.6,-2
me too.,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-431281132,bwanglzu,2018-10-19 08:08:21,16152,[19199],Code bug,0,me too.,0
me too,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-438432861,HanxiSun,2018-11-13 20:54:21,16152,[19199],Code bug,0,me too,0
I see it in 1.12 too on Python 3.6,IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-439576488,Arvinds-ds,2018-11-17 01:34:41,16152,[19199],Code bug,0,I see it in 1.12 too on Python 3.6,0
"> I see it in 1.12 too on Python 3.6

the same to you",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-441140203,zqs01,2018-11-23 01:15:48,16152,[19199],Code bug,0,> I see it in 1.12 too on Python 3.6 the same to you,0
"Resolved in #22517, so I believe it will appear in the next release (TF 1.13 or 2.0).",IssueComment,https://github.com/tensorflow/tensorflow/issues/16152#issuecomment-455001389,wookayin,2019-01-17 00:55:34,16152,[19199],Code bug,0,"Resolved in #22517, so I believe it will appear in the next release (TF 1.13 or 2.0).",3
I can verify the issue. Created a PR #19307 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/19274#issuecomment-389337557,yongtang,2018-05-15 22:45:45,19274,[19307],Code bug,1,I can verify the issue. Created a PR #19307 for the fix.,3
@yongtang PR should address this issue. Will follow up on that.,IssueComment,https://github.com/tensorflow/tensorflow/issues/19274#issuecomment-411890664,rohan100jain,2018-08-09 20:43:55,19274,[19307],Code bug,1,@yongtang PR should address this issue. Will follow up on that.,0
"Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.",IssueComment,https://github.com/tensorflow/tensorflow/issues/19274#issuecomment-423838623,tensorflowbutler,2018-09-23 18:50:52,19274,[19307],Code bug,1,"Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the [code] label. Thank you.",1
"Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.",IssueComment,https://github.com/tensorflow/tensorflow/issues/19274#issuecomment-427819416,tensorflowbutler,2018-10-08 12:48:48,19274,[19307],Code bug,1,"Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the [code] label. Thank you.",1
"Update the code in the github try to fix it. Please check it.
https://github.com/raintung/TensorflowPatch/blob/master/v1.6/java/src/main/native/session_jni.cc",IssueComment,https://github.com/tensorflow/tensorflow/issues/17698#issuecomment-377777894,raintung,2018-04-01 10:39:38,17698,[20558],Memory bug,0,Update the code in the github try to fix it. Please check it. [url],0
Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/17698#issuecomment-381582821,tensorflowbutler,2018-04-16 12:31:26,17698,[20558],Memory bug,0,Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/17698#issuecomment-385751802,tensorflowbutler,2018-05-01 18:38:21,17698,[20558],Memory bug,0,Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Thank you for bringing this to our attention. That does appear to be a small memory leak. We'd welcome a pull request fixing it.,IssueComment,https://github.com/tensorflow/tensorflow/issues/17698#issuecomment-385783849,jart,2018-05-01 20:42:24,17698,[20558],Memory bug,0,Thank you for bringing this to our attention. That does appear to be a small memory leak. We'd welcome a pull request fixing it.,2
"@jart Can you please assign me this. I'm new might need help, but will submit a PR fixing this",IssueComment,https://github.com/tensorflow/tensorflow/issues/17698#issuecomment-398583543,meggamind,2018-06-20 00:08:39,17698,[20558],Memory bug,0,"@jart Can you please assign me this. I'm new might need help, but will submit a PR fixing this",3
Added a PR #21443 to fix the incorrect link.,IssueComment,https://github.com/tensorflow/tensorflow/issues/21434#issuecomment-411040618,yongtang,2018-08-07 12:35:34,21434,[21443],Visualization bug,0,Added a PR #21443 to fix the incorrect link.,3
"I've submitted a [PR](https://github.com/tensorflow/tensorflow/pull/21677) that fixes the issue.  The underlying problem is that the existing code expects the results of two different floating point computations to match exactly.  In AVX512 builds one of the computations uses an optimised  Eigen algorithm for computing the square roots of vectors of doubles and this algorithm can produce slightly different results from the unoptimised version.  These differences cause the exact match to fail.  The PR fixes the issue by modifying the test case so that the results of the two computations only need to be close to each other, rather than matching exactly.",IssueComment,https://github.com/tensorflow/tensorflow/issues/21676#issuecomment-413821383,markdryan,2018-08-17 10:12:34,21676,[21677],Test bug,0,"I've submitted a [PR]([url] that fixes the issue. The underlying problem is that the existing code expects the results of two different floating point computations to match exactly. In AVX512 builds one of the computations uses an optimised Eigen algorithm for computing the square roots of vectors of doubles and this algorithm can produce slightly different results from the unoptimised version. These differences cause the exact match to fail. The PR fixes the issue by modifying the test case so that the results of the two computations only need to be close to each other, rather than matching exactly.",2
Thanks! I will leave this as contributions welcome until the PR is merged.,IssueComment,https://github.com/tensorflow/tensorflow/issues/21676#issuecomment-413975300,michaelisard,2018-08-17 20:08:25,21676,[21677],Test bug,0,Thanks! I will leave this as contributions welcome until the PR is merged.,3
Note //tensorflow/python/kernel_tests:embedding_ops_test_gpu is now also failing on master on AVX512 builds.  This unit test along with //tensorflow/python/kernel_tests:embedding_ops_test_gpu can be fixed by merging #21677.,IssueComment,https://github.com/tensorflow/tensorflow/issues/21676#issuecomment-445186263,markdryan,2018-12-07 10:15:04,21676,[21677],Test bug,0,Note //tensorflow/python/kernel_tests:embedding_ops_test_gpu is now also failing on master on AVX512 builds. This unit test along with //tensorflow/python/kernel_tests:embedding_ops_test_gpu can be fixed by merging #21677.,1
"AFAIK, this is the last remaining AVX512 issue, now that #21265 has been merged.  It would be great to get this fixed for the next release.",IssueComment,https://github.com/tensorflow/tensorflow/issues/21676#issuecomment-445186977,markdryan,2018-12-07 10:17:46,21676,[21677],Test bug,0,"AFAIK, this is the last remaining AVX512 issue, now that #21265 has been merged. It would be great to get this fixed for the next release.",2
"@naoto0804 
Keras model training will update params in ```model._collected_trainable_weights``` which is produced at ```model.compile```.
When you call ```dis_model.trainable = False``` to freeze ```dis_model```, you don't compile ```dis_model```, so two things happens:
* ```dis_model._collected_trainable_weights``` still includes old trainable params.
* ```dis_model.trainable_weights``` will return null, as you set all params non-trainable.

When you call ```dis_model.train_on_batch```, the params in ```dis_model._collected_trainable_weights``` will be updated according gradient descent, so it meets your requirements. But Keras found ```dis_model._collected_trainable_weights``` and ```dis_model.trainable_weights``` are inconsistent, so print warning in case this is not by design.

When you call ```combined_model.compile```, ```combined_model._collected_trainable_weights``` will be generated, and it doesn't includes the params in ```dis_model``` as they are marked as non-trainable.

To sum up, this warning is to prevent misuse. In your case, you code makes sense. I think we just need to reduce log frequency in ```tf.keras``` to once only, to prevent it floods the screen. I sent #22296 to fix it. Thanks. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/22012#issuecomment-421694071,yanboliang,2018-09-16 04:52:53,22012,[22296],Build bug,0,"@naoto0804 Keras model training will update params in ``[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`` to once only, to prevent it floods the screen. I sent #22296 to fix it. Thanks.",2
I'm bit new to tf/keras. Thank you so much for clear explanation and PR!,IssueComment,https://github.com/tensorflow/tensorflow/issues/22012#issuecomment-421704267,naoto0804,2018-09-16 05:53:57,22012,[22296],Build bug,0,I'm bit new to tf/keras. Thank you so much for clear explanation and PR!,5
Note that you can also suppress the warning by setting back `dis_model.trainable = True` once you've compiled `combined_model`.,IssueComment,https://github.com/tensorflow/tensorflow/issues/22012#issuecomment-422177897,fchollet,2018-09-17 21:28:11,22012,[22296],Build bug,0,Note that you can also suppress the warning by setting back [code] once you've compiled [code].,0
"That's really cool and straightforward way, thank you for the suggestion!",IssueComment,https://github.com/tensorflow/tensorflow/issues/22012#issuecomment-424384901,naoto0804,2018-09-25 15:14:23,22012,[22296],Build bug,0,"That's really cool and straightforward way, thank you for the suggestion!",5
"> Note that you can also suppress the warning by setting back `dis_model.trainable = True` once you've compiled `combined_model`.

this does seem to work ",IssueComment,https://github.com/tensorflow/tensorflow/issues/22012#issuecomment-472936135,lzhengchun,2019-03-14 16:03:13,22012,[22296],Build bug,0,> Note that you can also suppress the warning by setting back [code] once you've compiled [code]. this does seem to work,0
Added a PR #22849 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/22793#issuecomment-428349635,yongtang,2018-10-09 20:58:37,22793,[22849],Algorithm design bug,0,Added a PR #22849 for the fix.,0
"Nagging Assignees @drpngx, @harshini-gadige: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.",IssueComment,https://github.com/tensorflow/tensorflow/issues/22793#issuecomment-435584428,tensorflowbutler,2018-11-03 12:33:30,22793,[22849],Algorithm design bug,0,"Nagging Assignees @drpngx, @harshini-gadige: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.",-2
Can you please help here?,IssueComment,https://github.com/tensorflow/tensorflow/issues/22217#issuecomment-425185771,bhagatindia,2018-09-27 17:55:48,22217,[23811],Code bug,1,Can you please help here?,0
"@bhagatindia I can reproduce this issue. It seems to be caused by the lack of `CancellationManager` in the while-loop related ops. I'm working on the fix. Will keep you updated. 

cc @skye @mrry Is my understanding right and any suggestions?",IssueComment,https://github.com/tensorflow/tensorflow/issues/22217#issuecomment-439289846,feihugis,2018-11-16 05:51:47,22217,[23811],Code bug,1,@bhagatindia I can reproduce this issue. It seems to be caused by the lack of [code] in the while-loop related ops. I'm working on the fix. Will keep you updated. cc @skye @mrry Is my understanding right and any suggestions?,1
PR #23811 is submitted to fix this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/22217#issuecomment-439569864,feihugis,2018-11-17 00:37:18,22217,[23811],Code bug,1,PR #23811 is submitted to fix this issue.,0
Nagging Assignee @skye: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/22217#issuecomment-443448467,tensorflowbutler,2018-12-01 18:43:55,22217,[23811],Code bug,1,Nagging Assignee @skye: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
"I think the feature request makes sense. Unfortunately, because SparseTensor.dense_shape is a Tensor, I'm afraid that we have to use session to calculate the value of shape, eg `sess.run(z.dense_shape)`",IssueComment,https://github.com/tensorflow/tensorflow/issues/21964#issuecomment-417265960,facaiy,2018-08-30 10:07:18,21964,[24018],Data bug,0,"I think the feature request makes sense. Unfortunately, because SparseTensor.dense_shape is a Tensor, I'm afraid that we have to use session to calculate the value of shape, eg [code]",0
"Thanks,

Currently, I did the following wrapping for a workaround

```python
def sparse_concat(values, axis, *args, **kwargs):
    shapes = [x.get_shape() for x in values]
    res = tf.sparse_concat(axis, values, *args, **kwargs)
    if all(x.is_fully_defined() for x in shapes):
        dense_shape = shapes[0].as_list()
        D = sum(x.as_list()[axis] for x in shapes)
        dense_shape[axis] = D
        res = tf.SparseTensor(indices=res.indices,
                              values=res.values,
                              dense_shape=dense_shape)

    return res

```",IssueComment,https://github.com/tensorflow/tensorflow/issues/21964#issuecomment-417329293,gongliyu,2018-08-30 13:58:49,21964,[24018],Data bug,0,"Thanks, Currently, I did the following wrapping for a workaround ``[code]``",2
"Sounds like a good idea for me. Would you like to create a Pull Request to fix the issue after:

https://github.com/tensorflow/tensorflow/blob/63be4a65a1ba37848d3bfbe72ea2b60184d9979e/tensorflow/python/ops/sparse_ops.py#L314-L315

cc @ebrevdo @aselle @drpngx How do you think?

",IssueComment,https://github.com/tensorflow/tensorflow/issues/21964#issuecomment-417346720,facaiy,2018-08-30 14:48:18,21964,[24018],Data bug,0,Sounds like a good idea for me. Would you like to create a Pull Request to fix the issue after: [url]#L314-L315 cc @ebrevdo @aselle @drpngx How do you think?,3
"I'm sorry I'm not familar with the tensorflow codebase, so I don't know which tests need to run and how to run them after the modification. If anyone thinks this issue makes sense, please create a pull request. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/21964#issuecomment-417355816,gongliyu,2018-08-30 15:13:07,21964,[24018],Data bug,0,"I'm sorry I'm not familar with the tensorflow codebase, so I don't know which tests need to run and how to run them after the modification. If anyone thinks this issue makes sense, please create a pull request. Thanks!",1
"@drpngx Hi, could you help here? Thanks.",IssueComment,https://github.com/tensorflow/tensorflow/issues/21964#issuecomment-419555668,facaiy,2018-09-07 20:23:54,21964,[24018],Data bug,0,"@drpngx Hi, could you help here? Thanks.",2
/CC @skye for shape inference. Unfortunately I'm out next week.,IssueComment,https://github.com/tensorflow/tensorflow/issues/21964#issuecomment-419645745,drpngx,2018-09-08 14:25:27,21964,[24018],Data bug,0,/CC @skye for shape inference. Unfortunately I'm out next week.,0
Added a PR #24018 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/21964#issuecomment-442502361,yongtang,2018-11-28 16:06:18,21964,[24018],Data bug,0,Added a PR #24018 for the fix.,0
Added a PR #24569 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/24567#issuecomment-449919856,yongtang,2018-12-26 07:23:54,24567,[24569],Build bug,0,Added a PR #24569 for the fix.,0
Added PR #24583 for a fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/24578#issuecomment-450020615,yongtang,2018-12-26 20:23:26,24578,[24583],Code bug,0,Added PR #24583 for a fix.,0
"@Alireza89 I think you are correct, do you want to create a PR for that?",IssueComment,https://github.com/tensorflow/tensorflow/issues/24601#issuecomment-450232944,yongtang,2018-12-27 21:18:39,24601,[24613],Test bug,0,"@Alireza89 I think you are correct, do you want to create a PR for that?",2
"@yongtang  Well I don't have a plan to create a PR for now but if it is actually a bug, I hope it gets corrected in the master branch in the future.",IssueComment,https://github.com/tensorflow/tensorflow/issues/24601#issuecomment-450296254,Alireza89,2018-12-28 06:02:16,24601,[24613],Test bug,0,"@yongtang Well I don't have a plan to create a PR for now but if it is actually a bug, I hope it gets corrected in the master branch in the future.",1
@Alireza89 I have created the PR #24613 for the fix. Thanks for your contribution!,IssueComment,https://github.com/tensorflow/tensorflow/issues/24601#issuecomment-450365267,yongtang,2018-12-28 14:13:35,24601,[24613],Test bug,0,@Alireza89 I have created the PR #24613 for the fix. Thanks for your contribution!,5
"Thanks for the fix! The PR has been reviewed, so closing this now.",IssueComment,https://github.com/tensorflow/tensorflow/issues/24601#issuecomment-466586164,petewarden,2019-02-22 23:39:44,24601,[24613],Test bug,0,"Thanks for the fix! The PR has been reviewed, so closing this now.",4
Added a PR #24629 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/24627#issuecomment-450550855,yongtang,2018-12-30 10:13:24,24627,[24629],Version compatibility bug,0,Added a PR #24629 for the fix.,0
"Thanks @yongtang , looks much better. ðŸ‘ ",IssueComment,https://github.com/tensorflow/tensorflow/issues/24627#issuecomment-450560676,ageron,2018-12-30 13:25:52,24627,[24629],Version compatibility bug,0,"Thanks @yongtang , looks much better. ðŸ‘",4
"It can be fixed temporary by changing the line 1394 in external/eigen_archive/Eigen/src/Core/productsGeneralBlockPanelKernel.h:

Change line 1394 from 
#if EIGEN_GNUC_AT_LEAST(6,0) 
to
#if EIGEN_GNUC_AT_LEAST(6,0) && NDEBUG

Basically disable EIGEN_GEBP_2PX4_SPILLING_WORKAROUND when compile debug version
",IssueComment,https://github.com/tensorflow/tensorflow/issues/24457#issuecomment-448799710,shengfuintel,2018-12-20 00:09:17,24457,[24647],Build bug,0,"It can be fixed temporary by changing the line 1394 in external/eigen_archive/Eigen/src/Core/productsGeneralBlockPanelKernel.h: Change line 1394 from #if EIGEN_GNUC_AT_LEAST(6,0) to #if EIGEN_GNUC_AT_LEAST(6,0) && NDEBUG Basically disable EIGEN_GEBP_2PX4_SPILLING_WORKAROUND when compile debug version",0
"Was this with Eigen 3.3.6? Does Eigen 3.3.5 work? If so, ~~please report back to upstream (see http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1651)~~ this is probably http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1643.",IssueComment,https://github.com/tensorflow/tensorflow/issues/24457#issuecomment-449870245,mwoehlke-kitware,2018-12-25 19:48:07,24457,[24647],Build bug,0,"Was this with Eigen 3.3.6? Does Eigen 3.3.5 work? If so, ~~please report back to upstream (see [url]~~ this is probably [url]",0
"Could you check if it works with Eigen 3.3.7? Otherwise, feel free to re-open http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1651 with more details.",IssueComment,https://github.com/tensorflow/tensorflow/issues/24457#issuecomment-449873498,chhtz,2018-12-25 20:59:44,24457,[24647],Build bug,0,"Could you check if it works with Eigen 3.3.7? Otherwise, feel free to re-open [url] with more details.",0
"The master branch of tensorflow still used 9f48e814419e of Eigen library which does not includes the fix (88fc23324517) yet.

Just created a PR #24647 that bumps Eigen to fix the issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/24457#issuecomment-450701303,yongtang,2019-01-01 00:24:59,24457,[24647],Build bug,0,The master branch of tensorflow still used 9f48e814419e of Eigen library which does not includes the fix (88fc23324517) yet. Just created a PR #24647 that bumps Eigen to fix the issue.,1
"Here is a simple workaround:

```python
for elem in r.to_list():
    print(elem)
```

However, it moves all the data to Python. To preserve Tensors and remain within TensorFlow:

```python
for row_index in tf.range(r.nrows()):
    print(r[row_index])
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/24679#issuecomment-451081626,ageron,2019-01-03 08:38:32,24679,[24723],Data bug,0,Here is a simple workaround: ``[code]`[code]`[code]``,0
"The issue was that, the `__getitem__` in RaggedTensor should throw out `IndexError` (vs. `InvalidArgumentError`) in order to allow python to process iteration correctly (translated to `StopIteration` in `next/__next__()`). 

Created a PR #24723 for the fix.

The fix will only work with eager mode as non-eager mode will not be able to find out the out-of-bound errors before session run.",IssueComment,https://github.com/tensorflow/tensorflow/issues/24679#issuecomment-451720879,yongtang,2019-01-06 07:10:28,24679,[24723],Data bug,0,"The issue was that, the [code] in RaggedTensor should throw out [code] (vs. [code]) in order to allow python to process iteration correctly (translated to [code] in [code]). Created a PR #24723 for the fix. The fix will only work with eager mode as non-eager mode will not be able to find out the out-of-bound errors before session run.",0
ValueError is a bit more standard/specific than OpError. Does seem like the docstring should be updated. Can you send a PR?,IssueComment,https://github.com/tensorflow/tensorflow/issues/24756#issuecomment-452479035,allenlavoie,2019-01-08 22:44:17,24756,[24786],Documentation bug,0,ValueError is a bit more standard/specific than OpError. Does seem like the docstring should be updated. Can you send a PR?,1
"Are there any other code paths in `tf.train.init_from_checkpoint` that could raise `tf.errors.OpError`? If so, simply updating the docstring doesn't seem like the right answer here. I'll also point out that making the doc change would make it harder to distinguish between two pretty distinct error modes: missing variables in graph vs. missing tensors in checkpoints.",IssueComment,https://github.com/tensorflow/tensorflow/issues/24756#issuecomment-452482821,sharvil,2019-01-08 22:59:39,24756,[24786],Documentation bug,0,"Are there any other code paths in [code] that could raise [code]? If so, simply updating the docstring doesn't seem like the right answer here. I'll also point out that making the doc change would make it harder to distinguish between two pretty distinct error modes: missing variables in graph vs. missing tensors in checkpoints.",-1
AFAICT the docstring was never correct. So unless there's a strong use-case for a different exception type I'd say it just needs a docstring update.,IssueComment,https://github.com/tensorflow/tensorflow/issues/24756#issuecomment-452486098,allenlavoie,2019-01-08 23:13:30,24756,[24786],Documentation bug,0,AFAICT the docstring was never correct. So unless there's a strong use-case for a different exception type I'd say it just needs a docstring update.,0
Good to know. I won't be able to make the docstring change but hopefully someone can take this on.,IssueComment,https://github.com/tensorflow/tensorflow/issues/24756#issuecomment-452541345,sharvil,2019-01-09 01:45:55,24756,[24786],Documentation bug,0,Good to know. I won't be able to make the docstring change but hopefully someone can take this on.,1
@sharvil Created a PR for that.,IssueComment,https://github.com/tensorflow/tensorflow/issues/24756#issuecomment-452545593,yongtang,2019-01-09 02:09:23,24756,[24786],Documentation bug,0,@sharvil Created a PR for that.,0
"Nice, thanks for the fix @yongtang!",IssueComment,https://github.com/tensorflow/tensorflow/issues/24756#issuecomment-452555538,sharvil,2019-01-09 03:06:10,24756,[24786],Documentation bug,0,"Nice, thanks for the fix @yongtang!",5
@jvishnuvardhan  Hiï¼ŒI want to know when this problem will be solved. Thank you,IssueComment,https://github.com/tensorflow/tensorflow/issues/24566#issuecomment-458437766,storm-rain,2019-01-29 07:39:07,24566,[24791],Algorithm design bug,1,@jvishnuvardhan Hiï¼ŒI want to know when this problem will be solved. Thank you,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=24566"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=24566"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/24566#issuecomment-498124605,tensorflow-bot[bot],2019-06-03 06:06:56,24566,[24791],Algorithm design bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #25048 to fix the warning.,IssueComment,https://github.com/tensorflow/tensorflow/issues/25043#issuecomment-455814700,yongtang,2019-01-19 20:59:33,25043,[25048],Code bug,0,Added a PR #25048 to fix the warning.,3
"@ymodak , can you please assist with this. Thanks.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25043#issuecomment-457351755,msymp,2019-01-24 20:51:44,25043,[25048],Code bug,0,"@ymodak , can you please assist with this. Thanks.",2
"Added a PR #25255, Will let the docker file maintainers to decide if it will be merged or not.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25247#issuecomment-458194366,yongtang,2019-01-28 16:12:51,25247,[25255],Build bug,0,"Added a PR #25255, Will let the docker file maintainers to decide if it will be merged or not.",0
"# Edit: updated for 2023, still works

Just wanted to follow up for anybody using the images with Colab, this is how I did it:

```
# create a home for your config and your notebooks on your host (these will be accessible to TF from the container)
$ mkdir - p ${HOME}/.config/jupyter ${HOME}/Development/Notebooks

# enable the extension in our mounted configuration folder
# this is required since we'll be running with a mounted configuration folder so any changes survive container restarts
$ docker run -ti --rm -u `id -u`:`id -g` -v ""${HOME}/.config/jupyter:/.jupyter"" tensorflow/tensorflow:nightly-gpu-py3-jupyter bash -c ""source /etc/bash.bashrc && jupyter serverextension enable --py jupyter_http_over_ws""

# run the container (will keep it running each time you restart the computer)
$ docker run --restart=always --detach --name jupyter --privileged --gpus all -u `id -u`:`id -g` -p 8888:8888 -v ""${HOME}/.config/jupyter:/.jupyter"" -v ""${HOME}/Development/Notebooks:/tf"" tensorflow/tensorflow:nightly-gpu-py3-jupyter bash -c ""source /etc/bash.bashrc && jupyter notebook --notebook-dir=/tf --ip 0.0.0.0 --no-browser --NotebookApp.allow_origin='https://colab.research.google.com'""

# check the token in Docker logs
$ docker logs jupyter
```

This will run the container as your current user (which needs to have permissions to run Docker) and will create a detached, always running process which will start with the Docker daemon, basically making it a ""service"".

Open http://localhost:8888/, login with the token to get the cookie stored in the browser. Once you do, open Colab and connect to your local runtime, it should work.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25247#issuecomment-459644861,dkarlovi,2019-02-01 08:28:26,25247,[25255],Build bug,0,"# Edit: updated for 2023, still works Just wanted to follow up for anybody using the images with Colab, this is how I did it: ``[code]id -u[code]id -g[code]id -u[code]id -g[code]`` This will run the container as your current user (which needs to have permissions to run Docker) and will create a detached, always running process which will start with the Docker daemon, basically making it a ""service"". Open [url] login with the token to get the cookie stored in the browser. Once you do, open Colab and connect to your local runtime, it should work.",3
Added a PR #25702 to remove the limitation.,IssueComment,https://github.com/tensorflow/tensorflow/issues/25701#issuecomment-462934636,yongtang,2019-02-12 21:06:08,25701,[25702],Data bug,0,Added a PR #25702 to remove the limitation.,0
Created a PR #25851 to address the different behavior between tf and h5.,IssueComment,https://github.com/tensorflow/tensorflow/issues/25835#issuecomment-464889169,yongtang,2019-02-18 21:38:25,25835,[25851],Deployment bug,0,Created a PR #25851 to address the different behavior between tf and h5.,0
"Hi Yutong,

That docstring is here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/linalg_ops.py#L337

Would you be able to make the contribution, please?",IssueComment,https://github.com/tensorflow/tensorflow/issues/24818#issuecomment-459569154,lamberta,2019-02-01 01:13:39,24818,[25941],Documentation bug,0,"Hi Yutong, That docstring is here: [url]#L337 Would you be able to make the contribution, please?",2
@Flowerfan Would you mind to provide one video samples that trigger the issue described?,IssueComment,https://github.com/tensorflow/tensorflow/issues/21549#issuecomment-412286412,yongtang,2018-08-11 16:36:22,21549,[26522],Version compatibility bug,0,@Flowerfan Would you mind to provide one video samples that trigger the issue described?,0
"
[VIRAT_S_000000_0023.avi.zip](https://github.com/tensorflow/tensorflow/files/2280711/VIRAT_S_000000_0023.avi.zip)
@yongtang  I uploaded the video.

Below is the video info using ffprobe
ffprobe version 2.8.14-0ubuntu0.16.04.1 Copyright (c) 2007-2018 the FFmpeg developers
  built with gcc 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.9) 20160609
  configuration: --prefix=/usr --extra-version=0ubuntu0.16.04.1 --build-suffix=-ffmpeg --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --cc=cc --cxx=g++ --enable-gpl --enable-shared --disable-stripping --disable-decoder=libopenjpeg --disable-decoder=libschroedinger --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxvid --enable-libzvbi --enable-openal --enable-opengl --enable-x11grab --enable-libdc1394 --enable-libiec61883 --enable-libzmq --enable-frei0r --enable-libx264 --enable-libopencv
  libavutil      54. 31.100 / 54. 31.100
  libavcodec     56. 60.100 / 56. 60.100
  libavformat    56. 40.101 / 56. 40.101
  libavdevice    56.  4.100 / 56.  4.100
  libavfilter     5. 40.101 /  5. 40.101
  libavresample   2.  1.  0 /  2.  1.  0
  libswscale      3.  1.101 /  3.  1.101
  libswresample   1.  2.101 /  1.  2.101
  libpostproc    53.  3.100 / 53.  3.100
Input #0, avi, from '/home/flowerfan/data/cubes/gt_train/VIRAT_S_000000/VIRAT_S_000000_0023.avi':
  Metadata:
    encoder         : Lavf56.40.101
  Duration: 00:00:13.00, start: 0.000000, bitrate: 1000 kb/s
    Stream #0:0: Video: h264 (High) (H264 / 0x34363248), yuv420p, 1360x608, 993 kb/s, 30 fps, 30 tbr, 30 tbn, 60 tbc
",IssueComment,https://github.com/tensorflow/tensorflow/issues/21549#issuecomment-412317464,Flowerfan,2018-08-12 04:12:50,21549,[26522],Version compatibility bug,0,"[VIRAT_S_000000_0023.avi.zip]([url] @yongtang I uploaded the video. Below is the video info using ffprobe ffprobe version 2.8.14-0ubuntu0.16.04.1 Copyright (c) 2007-2018 the FFmpeg developers built with gcc 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.9) 20160609 configuration: --prefix=/usr --extra-version=0ubuntu0.16.04.1 --build-suffix=-ffmpeg --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --cc=cc --cxx=g++ --enable-gpl --enable-shared --disable-stripping --disable-decoder=libopenjpeg --disable-decoder=libschroedinger --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxvid --enable-libzvbi --enable-openal --enable-opengl --enable-x11grab --enable-libdc1394 --enable-libiec61883 --enable-libzmq --enable-frei0r --enable-libx264 --enable-libopencv libavutil 54. 31.100 / 54. 31.100 libavcodec 56. 60.100 / 56. 60.100 libavformat 56. 40.101 / 56. 40.101 libavdevice 56. 4.100 / 56. 4.100 libavfilter 5. 40.101 / 5. 40.101 libavresample 2. 1. 0 / 2. 1. 0 libswscale 3. 1.101 / 3. 1.101 libswresample 1. 2.101 / 1. 2.101 libpostproc 53. 3.100 / 53. 3.100 Input #0, avi, from '/home/flowerfan/data/cubes/gt_train/VIRAT_S_000000/VIRAT_S_000000_0023.avi': Metadata: encoder : Lavf56.40.101 Duration: 00:00:13.00, start: 0.000000, bitrate: 1000 kb/s Stream #0:0: Video: h264 (High) (H264 / 0x34363248), yuv420p, 1360x608, 993 kb/s, 30 fps, 30 tbr, 30 tbn, 60 tbc",0
"@Flowerfan The tf.contrib.ffmpeg in tensorflow repo has been deprecated and will be removed in 2.0 (soon to be released). The video decoding functionality support is now in `tensorflow/io` repo:

https://github.com/tensorflow/io

Also google group discussion: https://groups.google.com/a/tensorflow.org/forum/#!forum/io

I tried your sample video with `tensorflow-io`, everything seems to be fine.

I will close this issue for now. But if you continue to encounter issues with the video clip when using `tensorflow-io`, you can create an issue in https://github.com/tensorflow/io",IssueComment,https://github.com/tensorflow/tensorflow/issues/21549#issuecomment-471237225,yongtang,2019-03-10 01:14:42,21549,[26522],Version compatibility bug,0,"@Flowerfan The tf.contrib.ffmpeg in tensorflow repo has been deprecated and will be removed in 2.0 (soon to be released). The video decoding functionality support is now in [code] repo: [url] Also google group discussion: [url]#!forum/io I tried your sample video with [code], everything seems to be fine. I will close this issue for now. But if you continue to encounter issues with the video clip when using [code], you can create an issue in [url]",2
Added PR #26770 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/26735#issuecomment-473455488,yongtang,2019-03-15 22:04:06,26735,[26770],Code bug,0,Added PR #26770 for the fix.,0
"Hi @smit-hinsu, would you please help to take a look? Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/26800#issuecomment-474602978,aaroey,2019-03-19 22:05:17,26800,[27072],Deployment bug,0,"Hi @smit-hinsu, would you please help to take a look? Thanks",2
"Thanks for the detailed report and also proposing a solution!

Pull requests should be sent to the `master` branch. You can refer to guidelines  for contributing code to TensorFlow at https://www.tensorflow.org/community/contribute/code. Let us know if you have any other questions!",IssueComment,https://github.com/tensorflow/tensorflow/issues/26800#issuecomment-475081378,smit-hinsu,2019-03-21 00:49:30,26800,[27072],Deployment bug,0,Thanks for the detailed report and also proposing a solution! Pull requests should be sent to the [code] branch. You can refer to guidelines for contributing code to TensorFlow at [url] Let us know if you have any other questions!,4
"@smit-hinsu thanks for the review, I'll update the Pull request later.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26800#issuecomment-475132745,monklof,2019-03-21 07:23:05,26800,[27072],Deployment bug,0,"@smit-hinsu thanks for the review, I'll update the Pull request later.",3
"@smit-hinsu Hi, I've updated the pull request.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26800#issuecomment-475939245,monklof,2019-03-24 08:36:27,26800,[27072],Deployment bug,0,"@smit-hinsu Hi, I've updated the pull request.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26800"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26800"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/26800#issuecomment-483903275,tensorflow-bot[bot],2019-04-17 01:33:33,26800,[27072],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I think the issue is that the first line `x: Input samples.` should be prefixed with 4 spaces (not 5). Created a PR #27596 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/27583#issuecomment-480553566,yongtang,2019-04-07 02:34:55,27583,[27596],Documentation bug,0,I think the issue is that the first line [code] should be prefixed with 4 spaces (not 5). Created a PR #27596 for the fix.,2
"@dynamicwebpaige  @margaretmz  Since you are experts, any idea why this PR didn't pass test ? It was just to fix some display issue of the Keras doc. I didn't do the PR but I see it didn't pass the test and it is not clear why. Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/27583#issuecomment-486086466,tarrade,2019-04-24 06:29:44,27583,[27596],Documentation bug,0,"@dynamicwebpaige @margaretmz Since you are experts, any idea why this PR didn't pass test ? It was just to fix some display issue of the Keras doc. I didn't do the PR but I see it didn't pass the test and it is not clear why. Thanks",0
"I don't know if it normally take 2 days to deploy the new version of the doc, but I still see the same issue in the doc:
![image](https://user-images.githubusercontent.com/12021701/57180374-4c867a80-6e88-11e9-97ee-1da60b9932bf.png)
Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/27583#issuecomment-489331218,tarrade,2019-05-04 14:20:28,27583,[27596],Documentation bug,0,"I don't know if it normally take 2 days to deploy the new version of the doc, but I still see the same issue in the doc: ![image]([url] Thanks",0
"The issue was not fixed with the PR, please reopen the ticket. Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/27583#issuecomment-490962659,tarrade,2019-05-09 15:56:02,27583,[27596],Documentation bug,0,"The issue was not fixed with the PR, please reopen the ticket. Thanks",-1
"@tarrade The page is pointing to 2.0.0alpha so it still use the docstring in 2.0.0 python. The PR #27596 fixes the issue in the master branch, it will show up in the next release of 2.0.0 (alpha or beta), then the web page will be re-rendered to capture the change.

I will re-open the issue for now, though I think once the next release of 2.0.0 (alpha or beta) is out the page will be updated and corrected automatically.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/27583#issuecomment-490969414,yongtang,2019-05-09 16:14:12,27583,[27596],Documentation bug,0,"@tarrade The page is pointing to 2.0.0alpha so it still use the docstring in 2.0.0 python. The PR #27596 fixes the issue in the master branch, it will show up in the next release of 2.0.0 (alpha or beta), then the web page will be re-rendered to capture the change. I will re-open the issue for now, though I think once the next release of 2.0.0 (alpha or beta) is out the page will be updated and corrected automatically.",1
"@yongtang ah ok got it. Since this was independend of a Tensorflow version (the format), I was think it will be probagated to the main branch and I could see the update on the main page. I am fine to have the ticket closed since the issue is really fixed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/27583#issuecomment-490983575,tarrade,2019-05-09 16:55:54,27583,[27596],Documentation bug,0,"@yongtang ah ok got it. Since this was independend of a Tensorflow version (the format), I was think it will be probagated to the main branch and I could see the update on the main page. I am fine to have the ticket closed since the issue is really fixed.",3
I am closing the issue as it was resolved. I have checked that the PR was merged already. It will reflect on the website soon. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/27583#issuecomment-490988554,jvishnuvardhan,2019-05-09 17:11:03,27583,[27596],Documentation bug,0,I am closing the issue as it was resolved. I have checked that the PR was merged already. It will reflect on the website soon. Thanks!,4
Created a PR #27699 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/27497#issuecomment-481492246,yongtang,2019-04-10 00:52:35,27497,[27699],Data bug,0,Created a PR #27699 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27497"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27497"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/27497#issuecomment-484506210,tensorflow-bot[bot],2019-04-18 13:23:07,27497,[27699],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"SELU was designed for standard feed-forward neural networks, I'd use a standard FNN for the SELU example instead of a CNN.",IssueComment,https://github.com/tensorflow/tensorflow/issues/27657#issuecomment-481164621,ekerazha,2019-04-09 08:56:35,27657,[27837],Documentation bug,0,"SELU was designed for standard feed-forward neural networks, I'd use a standard FNN for the SELU example instead of a CNN.",0
"@dynamicwebpaige can you help me with this i would love to work on this.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/27657#issuecomment-481246219,thealphacod3r,2019-04-09 13:14:44,27657,[27837],Documentation bug,0,@dynamicwebpaige can you help me with this i would love to work on this.,3
Added PR #27871 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/27848#issuecomment-483386127,yongtang,2019-04-15 19:29:28,27848,[27871],Code bug,0,Added PR #27871 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27848"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27848"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/27848#issuecomment-487901436,tensorflow-bot[bot],2019-04-30 10:25:15,27848,[27871],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added PR #28267 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28054#issuecomment-487692006,yongtang,2019-04-29 18:29:40,28054,[28267],Documentation bug,0,Added PR #28267 for the fix.,0
"@Ouwen The link is not accessible, could you post the code instead?",IssueComment,https://github.com/tensorflow/tensorflow/issues/28241#issuecomment-487450845,yongtang,2019-04-29 04:48:40,28241,[28274],Version compatibility bug,0,"@Ouwen The link is not accessible, could you post the code instead?",-1
"@yongtang my apologies, I've changed the settings on the colab notebook and posted the code above.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28241#issuecomment-487736423,Ouwen,2019-04-29 20:42:50,28241,[28274],Version compatibility bug,0,"@yongtang my apologies, I've changed the settings on the colab notebook and posted the code above.",2
I could reproduce the issue in TF2.0. I think either we need to update the code or update the doc saying the dtype of img should be a tensor. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/28241#issuecomment-487773100,jvishnuvardhan,2019-04-29 23:01:15,28241,[28274],Version compatibility bug,0,I could reproduce the issue in TF2.0. I think either we need to update the code or update the doc saying the dtype of img should be a tensor. Thanks!,1
Added a PR #28274 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28241#issuecomment-487795027,yongtang,2019-04-30 01:12:03,28241,[28274],Version compatibility bug,0,Added a PR #28274 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28241"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28241"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28241#issuecomment-488040678,tensorflow-bot[bot],2019-04-30 17:24:29,28241,[28274],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
The issue is the usage of `real_frames.shape[-1].value`. In TF 1.x `real_frames.shape` returns a list of `Dimensions` which does have the value. In TF 2.0 `real_frames.shape` returns int so `value` is not applicable any more. Created a PR #28461 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28444#issuecomment-489901671,yongtang,2019-05-07 04:18:54,28444,[28461],Version compatibility bug,0,The issue is the usage of [code]. In TF 1.x [code] returns a list of [code] which does have the value. In TF 2.0 [code] returns int so [code] is not applicable any more. Created a PR #28461 for the fix.,0
"Thanks for the report @timsainb, and thanks for the fix @yongtang. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/28444#issuecomment-492722368,rryan,2019-05-15 16:15:59,28444,[28461],Version compatibility bug,0,"Thanks for the report @timsainb, and thanks for the fix @yongtang.",5
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28444"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28444"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28444#issuecomment-492911496,tensorflow-bot[bot],2019-05-16 04:25:21,28444,[28461],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
CC @Joeper214 who found this issue,IssueComment,https://github.com/tensorflow/tensorflow/issues/28508#issuecomment-490384241,tsawada,2019-05-08 07:44:05,28508,[28510],Code bug,0,CC @Joeper214 who found this issue,0
"@tsawada From the above referenced issue, can see a PR was raised, Can you please check if this is resolved after this change got merged.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28508#issuecomment-490892601,muddham,2019-05-09 12:57:12,28508,[28510],Code bug,0,"@tsawada From the above referenced issue, can see a PR was raised, Can you please check if this is resolved after this change got merged.",0
"I built latest master `8a8a109e` and my `o_trunc` branch within `tensorflow/tensorflow:devel` docker container, and confirmed that the problem reproduces on the `master`, and not on `o_trunc`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28508#issuecomment-491173017,tsawada,2019-05-10 06:30:14,28508,[28510],Code bug,0,"I built latest master [code] and my [code] branch within [code] docker container, and confirmed that the problem reproduces on the [code], and not on [code].",0
"Oh, the PR fixing this hasn't been yet merged (due to my commit causing a merge conflict, sorry about that)",IssueComment,https://github.com/tensorflow/tensorflow/issues/28508#issuecomment-491349449,mihaimaruseac,2019-05-10 16:27:37,28508,[28510],Code bug,0,"Oh, the PR fixing this hasn't been yet merged (due to my commit causing a merge conflict, sorry about that)",-1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28508"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28508"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28508#issuecomment-491899426,tensorflow-bot[bot],2019-05-13 16:45:39,28508,[28510],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"An easy fix is to skip building `hwloc`. With https://github.com/tensorflow/tensorflow/pull/25471 and some minor additional changes (https://github.com/freedomtan/tensorflow/commit/ffd86f605bfdbe6f209c1fa707089d6010f0b719), I can build tensorflow master on FreeBSD.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-487239876,freedomtan,2019-04-27 00:42:57,28113,[28689],Build bug,0,An easy fix is to skip building [code]. With [url] and some minor additional changes ([url] I can build tensorflow master on FreeBSD.,3
Ping @gunan; this might not on your radar but in case we have contributors you could offer some advice.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-487250074,byronyi,2019-04-27 03:14:50,28113,[28689],Build bug,0,Ping @gunan; this might not on your radar but in case we have contributors you could offer some advice.,1
"I managed to build TF 2.0.0-alpha with hwloc enabled, however I had to apply a [handful of hacks](http://arrowd.name/tf.patch). All of them a pretty simple, it would be great if someone push them upstream.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-487272966,arrowd,2019-04-27 10:05:30,28113,[28689],Build bug,0,"I managed to build TF 2.0.0-alpha with hwloc enabled, however I had to apply a [handful of hacks]([url] All of them a pretty simple, it would be great if someone push them upstream.",2
"@arrowd clean up your patches and send pull request then. But I think some of the hacks are in #25471, so you may wanna check it first.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-487329470,freedomtan,2019-04-28 00:18:07,28113,[28689],Build bug,0,"@arrowd clean up your patches and send pull request then. But I think some of the hacks are in #25471, so you may wanna check it first.",0
@arrowd : Did you get the chance to look into @freedomtan's suggestion ? Is this still an issue. Please let us know. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-488562910,achandraa,2019-05-02 06:12:15,28113,[28689],Build bug,0,@arrowd : Did you get the chance to look into @freedomtan's suggestion ? Is this still an issue. Please let us know. Thanks!,1
@freedomtan 's branch contains namy changes that I also have. I'll merge them with my patches and create a new pull request.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-489719204,arrowd,2019-05-06 18:11:23,28113,[28689],Build bug,0,@freedomtan 's branch contains namy changes that I also have. I'll merge them with my patches and create a new pull request.,1
That's great. Shall be looking forward to it. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-489909627,achandraa,2019-05-07 05:05:03,28113,[28689],Build bug,0,That's great. Shall be looking forward to it. Thanks!,5
I got blocked by TF not supporting Bazel 0.25. Is there plans to allow building using new Bazel version?,IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-489959478,arrowd,2019-05-07 07:02:47,28113,[28689],Build bug,0,I got blocked by TF not supporting Bazel 0.25. Is there plans to allow building using new Bazel version?,-2
"It is funny that I get both these errors:

>You have bazel 0.23.0 installed.
>Please upgrade your bazel installation to version 0.24.1 or higher to build TensorFlow!

>You have bazel 0.25.0 installed.
>Please downgrade your bazel installation to version 0.24.1 or lower to build TensorFlow!",IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-489959853,arrowd,2019-05-07 07:04:13,28113,[28689],Build bug,0,It is funny that I get both these errors: >You have bazel 0.23.0 installed. >Please upgrade your bazel installation to version 0.24.1 or higher to build TensorFlow! >You have bazel 0.25.0 installed. >Please downgrade your bazel installation to version 0.24.1 or lower to build TensorFlow!,-2
"I need some help with Bazel. How do I implement following changes without braking Linux case?

```
--- third_party/hwloc/BUILD.bazel.orig	2019-04-25 07:56:49 UTC
+++ third_party/hwloc/BUILD.bazel
@@ -36,7 +36,6 @@ template_rule(
         ""#undef HWLOC_VERSION_RELEASE"": ""#define HWLOC_VERSION_RELEASE 3"",
         ""#undef HWLOC_VERSION_GREEK"": ""#define HWLOC_VERSION_GREEK \""\"""",
         ""#undef HWLOC_VERSION"": ""#define HWLOC_VERSION \""2.0.3\"""",
-        ""#undef HWLOC_LINUX_SYS"": ""#define HWLOC_LINUX_SYS 1"",
         ""#undef hwloc_pid_t"": ""#define hwloc_pid_t pid_t"",
         ""#undef hwloc_thread_t"": ""#define hwloc_thread_t pthread_t"",
         ""#  undef HWLOC_HAVE_STDINT_H"": ""#  define HWLOC_HAVE_STDINT_H 1 "",
@@ -86,7 +85,6 @@ _INCLUDE_PRIVATE_HWLOC_AUTOIGEN_CONFIG_H_COMMON_SUBS =
     ""#undef HAVE_NL_LANGINFO"": ""#define HAVE_NL_LANGINFO 1"",
     ""#undef HAVE_OPENAT"": ""#define HAVE_OPENAT 1"",
     ""#undef HAVE_POSIX_MEMALIGN"": ""#define HAVE_POSIX_MEMALIGN 1"",
-    ""#undef HAVE_PROGRAM_INVOCATION_NAME"": ""#define HAVE_PROGRAM_INVOCATION_NAME 1"",
     ""#undef HAVE_PTHREAD_T"": ""#define HAVE_PTHREAD_T 1"",
     ""#undef HAVE_PUTWC"": ""#define HAVE_PUTWC 1"",
     ""#undef HAVE_SETLOCALE"": ""#define HAVE_SETLOCALE 1"",
@@ -149,7 +147,6 @@ _INCLUDE_PRIVATE_HWLOC_AUTOIGEN_CONFIG_H_COMMON_SUBS =
     ""#undef HWLOC_HAVE_SYSCALL"": ""#define HWLOC_HAVE_SYSCALL 1"",
     ""#undef HWLOC_HAVE_X11_KEYSYM"": ""#define HWLOC_HAVE_X11_KEYSYM 1"",
     ""#undef HWLOC_HAVE_X86_CPUID"": ""#define HWLOC_HAVE_X86_CPUID 1"",
-    ""#undef HWLOC_LINUX_SYS"": ""#define HWLOC_LINUX_SYS 1"",
     ""#undef HWLOC_SIZEOF_UNSIGNED_INT"": ""#define HWLOC_SIZEOF_UNSIGNED_INT 4"",
     ""#undef HWLOC_SIZEOF_UNSIGNED_LONG"": ""#define HWLOC_SIZEOF_UNSIGNED_LONG 8"",
     ""#undef HWLOC_SYM_PREFIX"": ""#define HWLOC_SYM_PREFIX hwloc_"",
@@ -224,13 +221,12 @@ cc_library(
         ""hwloc/static-components.h"",
         ""hwloc/topology.c"",
         ""hwloc/topology-hardwired.c"",
-        ""hwloc/topology-linux.c"",
+        ""hwloc/topology-freebsd.c"",
         ""hwloc/topology-noos.c"",
         ""hwloc/topology-synthetic.c"",
         ""hwloc/topology-xml.c"",
         ""hwloc/topology-xml-nolibxml.c"",
         ""hwloc/traversal.c"",
-        ""include/hwloc/linux.h"",
         ""include/hwloc/plugins.h"",
         ""include/hwloc/shmem.h"",
         ""include/private/autogen/config.h"",
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-490056667,arrowd,2019-05-07 12:22:27,28113,[28689],Build bug,0,I need some help with Bazel. How do I implement following changes without braking Linux case? ``[code]``,0
@arrowd : Can we open a new issue (bug/feature) if it is not related to the issue at hand. We would be happy to help on that and also it would be very easy for us to track. Meanwhile can we close this since it is resolved. Let us know. Thanks!   ,IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-490806336,achandraa,2019-05-09 08:20:46,28113,[28689],Build bug,0,@arrowd : Can we open a new issue (bug/feature) if it is not related to the issue at hand. We would be happy to help on that and also it would be very easy for us to track. Meanwhile can we close this since it is resolved. Let us know. Thanks!,3
"@arrowd if you haven't figured out how to do it yet, check bazel's [select](https://docs.bazel.build/versions/master/be/functions.html#select). See TensorFlow's [BUILD.bazel](https://github.com/tensorflow/tensorflow/blob/master/third_party/aws/BUILD.bazel) of AWS SDK for example usage of `select`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-491556528,freedomtan,2019-05-12 01:22:33,28113,[28689],Build bug,0,"@arrowd if you haven't figured out how to do it yet, check bazel's [select]([url]#select). See TensorFlow's [BUILD.bazel]([url] of AWS SDK for example usage of [code].",0
@arrowd :  Let us know if that helps. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-491686517,achandraa,2019-05-13 06:00:30,28113,[28689],Build bug,0,@arrowd : Let us know if that helps. Thanks!,3
This is mostly fixed by https://github.com/tensorflow/tensorflow/pull/28689,IssueComment,https://github.com/tensorflow/tensorflow/issues/28113#issuecomment-496207650,arrowd,2019-05-27 13:09:48,28113,[28689],Build bug,0,This is mostly fixed by [url],2
@BryanCutler Please provide simple reproducible code to investigate further.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28775#issuecomment-493338235,muddham,2019-05-17 06:33:22,28775,[28776],Data bug,1,@BryanCutler Please provide simple reproducible code to investigate further.,0
"@muddham the additions to the test in #28776 reproduce the issue, but also here is a simple script

```python
c = tf.constant(0, shape=[4, 1, 2], dtype=tf.dtypes.uint32)
ds = tf.data.Dataset.from_tensor_slices(c)
it = ds.make_one_shot_iterator()
n = it.get_next()
with tf.Session() as sess:
    print(sess.run(n))
```

produces error:
```
UnimplementedError (see above for traceback): CopySliceToElement Unhandled data type: 22
	 [[node IteratorGetNext (defined at <ipython-input-9-74466e672a7d>:1) ]]
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/28775#issuecomment-493540753,BryanCutler,2019-05-17 17:48:23,28775,[28776],Data bug,1,"@muddham the additions to the test in #28776 reproduce the issue, but also here is a simple script ``[code]`[code]`[code]``",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28775"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28775"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28775#issuecomment-495760824,tensorflow-bot[bot],2019-05-24 19:19:59,28775,[28776],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I was able to reproduce the issue on Colab with TensorFlow version 1.13.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28959#issuecomment-495547392,achandraa,2019-05-24 09:45:18,28959,[29106],Code bug,0,I was able to reproduce the issue on Colab with TensorFlow version 1.13.,0
@jvishnuvardhan I had already opened a PR to resolve the issue :sweat_smile: ,IssueComment,https://github.com/tensorflow/tensorflow/issues/29105#issuecomment-497184374,bharatr21,2019-05-30 03:03:50,29105,[29118],Documentation bug,0,@jvishnuvardhan I had already opened a PR to resolve the issue :sweat_smile:,2
"Could you please give some more information or fill the issue template? 
Where does this link exist in the docs? (i.e. Where did you click it and realised it's broken?)",IssueComment,https://github.com/tensorflow/tensorflow/issues/29591#issuecomment-500469981,anestisdotpy,2019-06-10 15:52:45,29591,[29657],Visualization bug,0,Could you please give some more information or fill the issue template? Where does this link exist in the docs? (i.e. Where did you click it and realised it's broken?),0
"Hi dear Anestis, Yes. I was just browsing TensorFlow docs on the link below:
https://www.tensorflow.org/lite/models/pose_estimation/overview

But there is a broken link in the middle of the page
https://www.tensorflow.org/images/models/pose_estimation.gif

On Mon, Jun 10, 2019 at 8:29 PM Anestis Sakerlis <notifications@github.com>
wrote:

> Could you please give some more information?
> Where does this link exist in the docs? (i.e. Where did you click it and
> realised it's broken?)
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/29591?email_source=notifications&email_token=ADRWKGLZV7W745LLD4S2BNDPZZ27NA5CNFSM4HWR4D6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXKJBXI#issuecomment-500469981>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ADRWKGNHNRJX7PUL4ULRICLPZZ27NANCNFSM4HWR4D6A>
> .
>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/29591#issuecomment-500675751,AliShokri,2019-06-11 03:46:44,29591,[29657],Visualization bug,0,"Hi dear Anestis, Yes. I was just browsing TensorFlow docs on the link below: [url] But there is a broken link in the middle of the page [url] On Mon, Jun 10, 2019 at 8:29 PM Anestis Sakerlis <[email]> wrote: > Could you please give some more information? > Where does this link exist in the docs? (i.e. Where did you click it and > realised it's broken?) > > â€” > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub > <[url]#issuecomment-500469981>, > or mute the thread > <[url] > . >",0
"I believe it is supposed to point in this [link](https://raw.githubusercontent.com/irealva/tfjs-models/master/posenet/demos/camera.gif) and this [docs file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models/pose_estimation/overview.md) should be changed. We should wait for a tensorflower before opening a PR. 
Would you like to submit it if that's the case?",IssueComment,https://github.com/tensorflow/tensorflow/issues/29591#issuecomment-500744313,anestisdotpy,2019-06-11 08:36:19,29591,[29657],Visualization bug,0,I believe it is supposed to point in this [link]([url] and this [docs file]([url] should be changed. We should wait for a tensorflower before opening a PR. Would you like to submit it if that's the case?,0
"Thanks for the report!
That link should point here: https://www.tensorflow.org/images/lite/models/pose_estimation.gif
Would someone be able to make a PR?",IssueComment,https://github.com/tensorflow/tensorflow/issues/29591#issuecomment-500950380,lamberta,2019-06-11 17:44:45,29591,[29657],Visualization bug,0,Thanks for the report! That link should point here: [url] Would someone be able to make a PR?,2
@gpapan wdyt?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-316813471,drpngx,2017-07-20 19:59:38,11651,[29815],Algorithm design bug,0,@gpapan wdyt?,0
"Hi, 
I am also having the same issue with the requirement of static shape of the input.  ",IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-318979611,sharmaannapurna,2017-07-31 06:26:44,11651,[29815],Algorithm design bug,0,"Hi, I am also having the same issue with the requirement of static shape of the input.",-1
"+1
Can confirm this for TF v1.2.1.",IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-319827912,msmsajjadi,2017-08-02 23:39:34,11651,[29815],Algorithm design bug,0,+1 Can confirm this for TF v1.2.1.,0
"Good to hear!

For what it's worth in the meantime, to anyone else with this problem, I solved my requirement by replacing `extract_image_patches` with a carefully constructed sparse convolution (which i would speculate is what  `extract_image_patches` does under the hood in any case). You can see my fix via my repo link in the original post.",IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-320276678,PaddyT,2017-08-04 15:20:57,11651,[29815],Algorithm design bug,0,"Good to hear! For what it's worth in the meantime, to anyone else with this problem, I solved my requirement by replacing [code] with a carefully constructed sparse convolution (which i would speculate is what [code] does under the hood in any case). You can see my fix via my repo link in the original post.",3
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-354952101,tensorflowbutler,2018-01-03 07:41:55,11651,[29815],Algorithm design bug,0,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
Is that bug still in the latest version?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-355126580,drpngx,2018-01-03 21:03:49,11651,[29815],Algorithm design bug,0,Is that bug still in the latest version?,0
Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-360255107,tensorflowbutler,2018-01-24 19:58:51,11651,[29815],Algorithm design bug,0,Nagging Awaiting Response: It has been 14 days with no activityand the [code] label was assigned. Is this still an issue?,-2
"Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-360311591,drpngx,2018-01-24 23:39:23,11651,[29815],Algorithm design bug,0,"Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!",0
"I can confirm this still occurs in tensorflow 1.4.1, for example if I run:

```
input_image = tf.placeholder(tf.float32, (5, None, None, 5), ""tmp"")
extracted = tf.extract_image_patches(images=input_image,
                                         ksizes=[1, 2, 2, 1],
                                         strides=[1, 1, 1, 1],
                                         rates=[1, 1, 1, 1], padding='VALID')
grad = tf.gradients(tf.reduce_sum(extracted), input_image)
sess = tf.Session()
sess.run(grad, {input_image: np.random.normal(size=(5, 2, 2, 5))})
```

 I would still find it useful if this feature was added.",IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-360394207,chrisc36,2018-01-25 08:22:12,11651,[29815],Algorithm design bug,0,"I can confirm this still occurs in tensorflow 1.4.1, for example if I run: ``[code]`` I would still find it useful if this feature was added.",0
Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-364531677,tensorflowbutler,2018-02-09 19:14:50,11651,[29815],Algorithm design bug,0,Nagging Awaiting Response: It has been 14 days with no activityand the [code] label was assigned. Is this still an issue?,-2
Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-370128593,tensorflowbutler,2018-03-03 07:59:16,11651,[29815],Algorithm design bug,0,Nagging Awaiting Response: It has been 14 days with no activityand the [code] label was assigned. Is this still an issue?,-2
Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-373926436,tensorflowbutler,2018-03-17 14:59:49,11651,[29815],Algorithm design bug,0,Nagging Awaiting Response: It has been 14 days with no activityand the [code] label was assigned. Is this still an issue?,-2
It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-377783657,tensorflowbutler,2018-04-01 12:32:22,11651,[29815],Algorithm design bug,0,It has been 14 days with no activity and the [code] label was assigned. Is this still an issue?,0
It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-381979114,tensorflowbutler,2018-04-17 12:45:30,11651,[29815],Algorithm design bug,0,It has been 14 days with no activity and the [code] label was assigned. Is this still an issue?,0
It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-386081053,tensorflowbutler,2018-05-02 18:46:28,11651,[29815],Algorithm design bug,0,It has been 29 days with no activity and the [code] label was assigned. Is this still an issue?,0
Could I try to fix that issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-421130306,m2kz,2018-09-13 19:47:55,11651,[29815],Algorithm design bug,0,Could I try to fix that issue?,2
Problem still occurs with Tensorflow 2.0,IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-496606572,lioutasb,2019-05-28 17:12:49,11651,[29815],Algorithm design bug,0,Problem still occurs with Tensorflow 2.0,-2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=11651"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=11651"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/11651#issuecomment-504152786,tensorflow-bot[bot],2019-06-20 19:29:04,11651,[29815],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #29938 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29897#issuecomment-503368132,yongtang,2019-06-19 01:16:48,29897,[29938],Documentation bug,0,Added a PR #29938 for the fix.,3
Added a PR #29985 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29276#issuecomment-503803532,yongtang,2019-06-20 01:21:28,29276,[29985],Documentation bug,0,Added a PR #29985 for the fix.,0
@zendevil Looks like above code snippet is incomplete to reproduce the issue. Please provide the full code snippet to reproduce. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/29863#issuecomment-503014283,gadagashwini-zz,2019-06-18 08:59:11,29863,[29986],Data bug,1,@zendevil Looks like above code snippet is incomplete to reproduce the issue. Please provide the full code snippet to reproduce. Thanks!,1
"There are some variables that are defined in a file called google_res which I import. You probably can recreate error without that file. Good luck debugging this.
```
from sklearn.model_selection import train_test_split
import time

import numpy as np

import requests
from requests.auth import HTTPBasicAuth

from google_res import *

from imblearn.over_sampling import SMOTE



def knn(X_train, y_train, X_test, y_test):
    paramk = 11
    x = tf.placeholder(float, shape=X_train.shape)
    y = tf.placeholder(float, shape=X_test.shape[1:])
    computeL0Dist = tf.count_nonzero(x - y, axis=[1])
    find_k_closest_tr_products = tf.contrib.framework.argsort(computeL0Dist, direction='ASCENDING')
    find_labels_k_closest_tr_products = tf.gather(y_train, find_k_closest_tr_products[0:paramk])
    print('SHAPE', find_labels_k_closest_tr_products.shape)
    find_u_labels, find_idex, find_counts = tf.unique_with_counts(find_labels_k_closest_tr_products)
    find_predicted_label = tf.gather(find_u_labels, tf.argmax(find_counts))
    
    # running through the graph
    num_errs = 0
    num_test_products = y_test.shape[0]
    num_train_products = y_train.shape[0]
    
    with tf.Session() as sess:
        for i_te_p in range(0, num_test_products):
            predicted_label = sess.run([find_predicted_label], feed_dict={x:X_train, y:X_test[i_te_p]})
            if predicted_label == y_train[i_te_p]:
                num_errs += 1
                print(num_errs, ""/"", i_te_p)
                print(""\t\t"",predicted_label[0], ""\t\t\t\t"",t_labels[i_te_p])

                if (1):
                    plt.figure(1)
                    plt.subplot(1, 2, 1)
                    plt.imshow(y_test[i_te_p])
                    plt.title('test image has label %i' %(predicted_label[0]))

                    for i in range(num_train_products):
                        if y_train[i] == predicted_label:
                            plt.subplot(1, 2, 2)
                            plt.imshow(x_train[i])
                            plt.title('Correctly labeled as %i' % y_test[i_te_p])
                            plt.draw()
                            break
                    plt.savefig('./results.png')

start_time = time.time()
click_data = np.load('click_data.npy').tolist()
#search_terms_main = list(dict.fromkeys(search_terms_main))

search_terms = [i.split(' ') for i in search_terms_main]
# print(search_terms)
skipgram = []

# using dynamic programming 
def generate_skipgrams(li, length):
    skipgrams = []
    skipgrams.append([]) # we'll keep the zero length empty
    skipgrams.append([])
    for i in li:
        wrapper = []
        wrapper.append(i)
        skipgrams[1].append(wrapper)
    for i in range(1, length):
        skipgrams.append([])
        for j in range(len(skipgrams[i])):
            for k in range(len(li)):
                if not skipgrams[i][j][-1] == li[k]:
                    wrapper = []
                    wrapper.append(li[k])
                    to_append = skipgrams[i][j] + wrapper
                    
                    skipgrams[i + 1].append('%27' +'%20'.join(to_append) + '%27')
                    #skipgrams[i + 1].append(to_append)
    return (skipgrams[length])


skipgrams = []
for j in range(len(search_terms_main)):
    skipgrams.append(generate_skipgrams(search_terms_main[j].split(' '), 2))

num_features = 0 # for computing padding
for i in range(len(skipgrams)):
    if len(skipgrams[i]) > num_features:
        #print(len(skipgrams[i]))
        num_features = len(skipgrams[i])


#print(skipgrams)
#print(num_features)


def pad(skipgrams, max_pad_len):
    padded_skipgrams = []
    for i in range(len(skipgrams)):
        pad_len = max_pad_len - len(skipgrams[i])
        wrapper = []
        for j in range(pad_len):
            wrapper.append('%27%27')
        padded_skipgrams.append(skipgrams[i] + wrapper)

    return padded_skipgrams

skipgrams = pad(skipgrams, num_features)
#print(skipgrams)

# for i in range(len(skipgrams)):
#     print(len(skipgrams[i]))
# Dhiran's code. Expect Errors

first_phrase = [i.replace(' ','%20') for i in search_terms_main]
all_features = [] # stores all the features from feature_clean from various requests


def get_ngrams(l, n):
    ngrams = []
    for i in range(len(l) - n + 1):
        ngrams.append([])
        for j in range(n):
            ngrams[i].append(l[i+j])
    return ngrams


maximum = 0
# query = ''

for i in range(len(search_terms_main)):
    if len(search_terms_main[i].split(' ')) > maximum:
        maximum  = len(search_terms_main[i].split(' '))
        # query = search_terms_main[i]
ngrams = [] # ngrams for each search term

for c, st in enumerate(search_terms_main):
    ngrams.append([]) # this will contain all ngrams for the search term st.
    st_arr = st.split(' ')
    for n in range(1, len(st_arr) + 1):
        ngrams[c].append(get_ngrams(st_arr, n))
    

padding = []
for i in range(maximum):
    padding.append(0)
#print(len(padding))
#print(len(ngrams))

# adding first level padding
for i in range(len(ngrams)):
    for j in range(len(ngrams[i]), maximum):
            ngrams[i].append([])

for i in range(len(ngrams)):
    for j in range(maximum):
        for k in range(maximum - len(ngrams[i][j]) - j):
            padding_unit = []
            # for l in range(j + 1):
            #     padding_unit.append('')
            ngrams[i][j].append(padding_unit)

#first_phrase = first_phrase[154:]
#print(ngrams)
print('first phrase', len(first_phrase))

def get_prod_list(query):
    product_list = []
    for i in range(len(click_data)):   
        if click_data[i][0] == query:
            product_list.append(int(click_data[i][1]))
    return product_list


def clean_list(li):
    return list(map(lambda x: x.split('=')[1], li))

features_x = {}
features_y = {}
total_conf = [[0,0],[0,0]]


first_phrase = list(dict.fromkeys(first_phrase))

for j, elem in enumerate(first_phrase):
    print('so come here', j)
    #print(elem)
    url = '''http://xx.xxx.xx.xx:xxxx/solr/SomeName/select?defType=edismax&fl=[features%20efi.text_0=%27'''+first_phrase[j] + '%27'

    feature_count = 1
    # if j == 2:
    #     break
    # for i in range(len(search_terms[j])):
    #     print('search_terms', search_terms[j][i])
    #     url += '%20efi.text_' + str(feature_count) + '=' + search_terms[j][i]
    #     feature_count += 1

    # add all the ngram terms
    for k in range(len(ngrams[j])): # this goes from 1 gram to 13 grams 
        for l in range(maximum - k): # from one grams to 13grams
            to_add = ngrams[j][k][l] 
            url_compat = '%27' + '%20'.join(to_add) + '%27'
            url+= '%20efi.text_'+ str(feature_count) + '=' + url_compat
            feature_count += 1

    # all skipgrams
    for i in range(len(skipgrams[j])):
        url += '%20efi.text_' + str(feature_count) + '=' + skipgrams[j][i]
        feature_count += 1
    
    print('FEATURE COUNT', feature_count)
    # The last part 
    url += '''],%20score,%20tm_name,%20ts_title,%20tm_field_category_parent_name,%20ts_field_product_brand_1,%20id&indent=on&q='''+first_phrase[j]+'''&qf=ts_field_summary+ts_field_product_specifications+tm_name+ts_title+tm_field_category_parent_name+ts_field_product_brand_1+ts_field_product_details&wt=json'''
    val = requests.get(url, verify=False, auth=HTTPBasicAuth('user', 'S0MEPass\/\/0rd'))
    
    #ids = []
    #category = []
    #title = []
    features = {}
    
    if (val.json() == None):
        print('SKIPPING')
        continue
    print(elem)
    #print(val.json())
    for c, i in enumerate(val.json()['response']['docs']):
        print(i['id'][-7:-3])
        features[int(i['id'][-7:-3])] = i['[features]'].split(',')
   
    features = {k: list(map(lambda x: float(x.split('=')[1]), v)) for k, v in features.items()}    
    #print(features)
    # two extra to store query and id 
    features_x[elem] = []
    features_y[elem] = []
    for k, v in features.items():
        features_x[elem].append(v)
        products = get_prod_list(elem.replace('%20', ' '))
        
        if k in products:
            features_y[elem].append(True)
        else:
            features_y[elem].append(False)
    #print('FEATURES X', features_x[elem])
    #print('FEATURES Y', features_y[elem])
    features_x[elem] = np.asarray(features_x[elem], dtype=float)
    if (False in features_y[elem] and list(features_y[elem]).count(True) > 1):
        os = SMOTE(random_state=0, k_neighbors = 1)
        features_x[elem], features_y[elem] = os.fit_sample(features_x[elem], features_y[elem])    
        X_train, X_test, y_train, y_test = train_test_split(features_x[elem], features_y[elem], test_size=0.3, random_state=0)
        knn(X_train, X_test, y_train, y_test)
        total_conf += confusion


print(total_conf)
print((time.time()-start_time))



print(conf_all)

```",IssueComment,https://github.com/tensorflow/tensorflow/issues/29863#issuecomment-503130172,zendevil,2019-06-18 13:15:15,29863,[29986],Data bug,1,There are some variables that are defined in a file called google_res which I import. You probably can recreate error without that file. Good luck debugging this. ``[code]``,0
@zendevil I am unable to reproduce the issue with above code snippet. Looks some entities are not defined like search_terms_main. Can you help us to reproduce the issue. Thanks! ,IssueComment,https://github.com/tensorflow/tensorflow/issues/29863#issuecomment-503405256,gadagashwini-zz,2019-06-19 04:52:01,29863,[29986],Data bug,1,@zendevil I am unable to reproduce the issue with above code snippet. Looks some entities are not defined like search_terms_main. Can you help us to reproduce the issue. Thanks!,1
I think the issue is that bool support is not available for unique_with_counts. Added a PR #29986 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29863#issuecomment-503803850,yongtang,2019-06-20 01:23:18,29863,[29986],Data bug,1,I think the issue is that bool support is not available for unique_with_counts. Added a PR #29986 for the fix.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29863"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29863"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/29863#issuecomment-517818305,tensorflow-bot[bot],2019-08-02 19:29:01,29863,[29986],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #29987 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29867#issuecomment-503804184,yongtang,2019-06-20 01:25:12,29867,[29987],Data bug,0,Added a PR #29987 for the fix.,0
In general this is an error that is easy to fix in user code so I'd rather fix it there. It's ambiguous what to do with a floating point range.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29867#issuecomment-513387768,alextp,2019-07-19 21:43:03,29867,[29987],Data bug,0,In general this is an error that is easy to fix in user code so I'd rather fix it there. It's ambiguous what to do with a floating point range.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29867"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29867"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/29867#issuecomment-513387775,tensorflow-bot[bot],2019-07-19 21:43:04,29867,[29987],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
It works for numpy,IssueComment,https://github.com/tensorflow/tensorflow/issues/29867#issuecomment-514802818,sleighsoft,2019-07-24 21:14:48,29867,[29987],Data bug,0,It works for numpy,0
Added a PR #30048 for the doctoring fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29279#issuecomment-504691461,yongtang,2019-06-22 19:15:09,29279,[30048],Documentation bug,0,Added a PR #30048 for the doctoring fix.,0
Added a PR #30049 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/30029#issuecomment-504691424,yongtang,2019-06-22 19:14:38,30029,[30049],Data bug,0,Added a PR #30049 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30029"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30029"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30029#issuecomment-506066797,tensorflow-bot[bot],2019-06-26 22:22:30,30029,[30049],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #30053 for the shape check.,IssueComment,https://github.com/tensorflow/tensorflow/issues/30040#issuecomment-504712466,yongtang,2019-06-23 02:02:19,30040,[30053],Algorithm design bug,0,Added a PR #30053 for the shape check.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30040"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30040"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30040#issuecomment-512507821,tensorflow-bot[bot],2019-07-17 18:12:07,30040,[30053],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #30062 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/30061#issuecomment-504793571,yongtang,2019-06-23 22:34:10,30061,[30062],Documentation bug,0,Added a PR #30062 for the fix.,0
I am able to reproduce the reported issue with Tensorflow 1.12.0 and 1.13.1. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/29695#issuecomment-501568763,gadagashwini-zz,2019-06-13 06:34:12,29695,[30102],Code bug,1,I am able to reproduce the reported issue with Tensorflow 1.12.0 and 1.13.1. Thanks!,0
I can reproduce this issue on the latest master branch. PR #30102 is submitted to try to fix this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29695#issuecomment-505212836,feihugis,2019-06-24 23:01:46,29695,[30102],Code bug,1,I can reproduce this issue on the latest master branch. PR #30102 is submitted to try to fix this issue.,1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29695"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29695"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/29695#issuecomment-506894201,tensorflow-bot[bot],2019-06-28 22:23:49,29695,[30102],Code bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Look where tf.py_function is defined there is no such warning file present regarding dtype to be float. So why it is showing this?,IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-487798894,shashvatshahi1998,2019-04-30 01:42:57,28248,[30107],Data bug,0,Look where tf.py_function is defined there is no such warning file present regarding dtype to be float. So why it is showing this?,-2
I am facing the same issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-487897374,rbrueckner,2019-04-30 10:09:16,28248,[30107],Data bug,0,I am facing the same issue.,-1
@KichangKim There was no warning when `TF2.0.0-alpha0` or `tf-nightly` was used. The issue was reproduced with `tf-nightly-2.0-preview`. We will check for the source of error and resolve it. Thanks for finding this. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-489829085,jvishnuvardhan,2019-05-06 23:56:56,28248,[30107],Data bug,0,@KichangKim There was no warning when [code] or [code] was used. The issue was reproduced with [code]. We will check for the source of error and resolve it. Thanks for finding this. Thanks!,3
"Here:
https://github.com/tensorflow/tensorflow/blob/88ed9779719b8b2136a596c7b4dda875568894a3/tensorflow/python/eager/backprop.py#L841

Having the same issue even though the statement is not within `tf.GradientTape`.

Even simpler example:
```python
import tensorflow as tf

tensor = tf.constant([1,2,3])
tf.py_function(lambda x: x.numpy(), [tensor], tensor.dtype)
```

I am wondering why this code is called anyways. My example does not even use `GradientTape`.

Callstack of test.py (just includes code above):
![grafik](https://user-images.githubusercontent.com/9438971/59639047-54f5f480-915a-11e9-916c-a8e958fd6f14.png)

I am not sure it is intended that a `py_function` has a `GradientTape` by default.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-502620563,sleighsoft,2019-06-17 10:06:45,28248,[30107],Data bug,0,Here: [url]#L841 Having the same issue even though the statement is not within [code]. Even simpler example: ``[code]`[code]GradientTape[code]py_function[code]GradientTape` by default.,0
It's likely the tape.watch here https://github.com/tensorflow/tensorflow/blob/88520c4dd6aa804330b053a35676eeffc3380d65/tensorflow/python/ops/script_ops.py#L108 which needs to be called only for floating dtypes.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-505196367,alextp,2019-06-24 21:54:07,28248,[30107],Data bug,0,It's likely the tape.watch here [url]#L108 which needs to be called only for floating dtypes.,0
I'll happily accept a PR to fix this.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-505196414,alextp,2019-06-24 21:54:17,28248,[30107],Data bug,0,I'll happily accept a PR to fix this.,3
"The PR #30107 is submitted to fix this issue.

cc @alextp ",IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-505258700,feihugis,2019-06-25 02:51:45,28248,[30107],Data bug,0,The PR #30107 is submitted to fix this issue. cc @alextp,0
Looks like the PR failed a few checks. Is the issue still persisting?,IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-505738926,vineetred,2019-06-26 06:30:32,28248,[30107],Data bug,0,Looks like the PR failed a few checks. Is the issue still persisting?,0
This issue still exists in tf-2 version beta-1.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-506042846,shubhraaich,2019-06-26 21:00:36,28248,[30107],Data bug,0,This issue still exists in tf-2 version beta-1.,-2
You have to use nightly builds,IssueComment,https://github.com/tensorflow/tensorflow/issues/28248#issuecomment-506241397,sleighsoft,2019-06-27 08:10:26,28248,[30107],Data bug,0,You have to use nightly builds,0
Added a PR #29264 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29264#issuecomment-507026388,yongtang,2019-06-30 10:49:08,29264,[30257],Documentation bug,0,Added a PR #29264 for the fix.,3
Please provide us complete code to reproduce the issue.Thanks,IssueComment,https://github.com/tensorflow/tensorflow/issues/30122#issuecomment-505815209,ravikyram,2019-06-26 10:21:04,30122,[30258],Version compatibility bug,0,Please provide us complete code to reproduce the issue.Thanks,1
"The following is sufficient to reproduce the issue:

```
import numpy as np
import tensorflow as tf

print(tf.__version__)

train_input_0 = np.random.rand(1000, 1)
train_input_1 = np.random.rand(1000, 1)
train_labels  = np.random.rand(1000, 1)

val_input_0 = np.random.rand(1000, 1)
val_input_1 = np.random.rand(1000, 1)
val_labels  = np.random.rand(1000, 1)

input_0 = tf.keras.Input(shape=(None,), name='input_0')
input_1 = tf.keras.Input(shape=(None,), name='input_1')

class my_model(tf.keras.Model):
    def __init__(self):
        super(my_model, self).__init__(self)
        self.hidden_layer_0 = tf.keras.layers.Dense(100, activation=tf.nn.relu)
        self.hidden_layer_1 = tf.keras.layers.Dense(100, activation=tf.nn.relu)
        self.concat         = tf.keras.layers.Concatenate()

        self.out_layer    = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)

    def call(self, inputs =  [input_0, input_1]):
        activation_0 = self.hidden_layer_0(inputs['input_0'])
        activation_1 = self.hidden_layer_1(inputs['input_1'])
        concat       = self.concat([activation_0, activation_1])
      
        return self.out_layer(concat)

model = my_model()
opt = tf.optimizers.Adam()
loss = tf.keras.losses.MeanAbsoluteError()
model.compile(opt, loss)

model.fit(x = {'input_0' : train_input_0, 'input_1':  train_input_1}, y = train_labels, 
         validation_data = ({'input_0' : val_input_0, 'input_1':  val_input_1}, val_labels) )
```

This runs with 2.0.0-alpha0, but fails with 2.0.0-beta1
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30122#issuecomment-505885074,fnands,2019-06-26 13:52:56,30122,[30258],Version compatibility bug,0,"The following is sufficient to reproduce the issue: ``[code]`` This runs with 2.0.0-alpha0, but fails with 2.0.0-beta1",-2
"I am able to reproduce the issue in Colab ,works with  TF 2.0.0-alpha0, and fails with 2.0.0-beta1.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/30122#issuecomment-506249912,ravikyram,2019-06-27 08:34:19,30122,[30258],Version compatibility bug,0,"I am able to reproduce the issue in Colab ,works with TF 2.0.0-alpha0, and fails with 2.0.0-beta1.Thanks!",0
Added a PR #30258 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/30122#issuecomment-507026483,yongtang,2019-06-30 10:50:34,30122,[30258],Version compatibility bug,0,Added a PR #30258 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30122"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30122"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30122#issuecomment-515223100,tensorflow-bot[bot],2019-07-25 21:34:06,30122,[30258],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@zhjunqin As `MatchingFilesOp` sorts the matched files [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matching_files_op.cc#L63), the order of filenames returned should be deterministic. PR #30543 has been submitted to update the related docs. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/30436#issuecomment-509752214,feihugis,2019-07-09 18:21:47,30436,[30543],Documentation bug,1,"@zhjunqin As [code] sorts the matched files [here]([url]#L63), the order of filenames returned should be deterministic. PR #30543 has been submitted to update the related docs.",0
"@habernal We have executed your code in Google colab and in Jupyter notebook with TF version
 2.0 beta 1 and numpy version 1.16.4.We did not get any warnings.Please upgrade your numpy version and check whether the warnings still persists.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-509279875,ravikyram,2019-07-08 15:44:07,30427,[30559],Code bug,0,@habernal We have executed your code in Google colab and in Jupyter notebook with TF version 2.0 beta 1 and numpy version 1.16.4.We did not get any warnings.Please upgrade your numpy version and check whether the warnings still persists.Thanks!,2
"Thanks, @ravikyram - I've double-checked the installed libraries and found the culprit.

TF 2.0.b1 comes with numpy dependency 1.16.4 and it shows no warning. So it is correct you couldn't reproduce the bug, neither could I.

However, it turned out that I had numpy 1.17.0rc1 installed in the project (no idea from which library it was linked as I certainly didn't install it by hand).

**Numpy 1.17.0rc1** is responsible for complaining about these FutureWarnings. Perhaps not urgent to fix for now but once there is an upgrade to np 17, this will show up again, I guess.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-509504504,habernal,2019-07-09 06:16:04,30427,[30559],Code bug,0,"Thanks, @ravikyram - I've double-checked the installed libraries and found the culprit. TF 2.0.b1 comes with numpy dependency 1.16.4 and it shows no warning. So it is correct you couldn't reproduce the bug, neither could I. However, it turned out that I had numpy 1.17.0rc1 installed in the project (no idea from which library it was linked as I certainly didn't install it by hand). **Numpy 1.17.0rc1** is responsible for complaining about these FutureWarnings. Perhaps not urgent to fix for now but once there is an upgrade to np 17, this will show up again, I guess.",2
"In fact, the numpy dependency is treated differently given the tool you install TF (`pip` versus `setuptools`). Both tested in a clean virtual environment with only these libraries installed at the beginning:

``
pip==19.1.1
setuptools==41.0.1
wheel==0.33.4
``

1. Installing TF using pip:

```
$ pip install tensorflow==2.0.0b1 --no-cache-dir
...
Collecting numpy<2.0,>=1.14.5 (from tensorflow==2.0.0b1)
  Downloading https://files.pythonhosted.org/packages/...cc/numpy-1.16.4-cp36-cp....whl (13.9MB)
...
```

2. Installing TF as dependendy in `setup.py` containing only:

```
from setuptools import setup
setup(
    name='tf30427',
    version='0.0.1',
    install_requires=['tensorflow==2.0.0b1'],
)
```

and then installing as

```
$ python setup.py install
...
Searching for numpy<2.0,>=1.14.5
Reading https://pypi.org/simple/numpy/
Downloading https://files.pythonhosted.org/packages/e...17/numpy-1.17.0rc1-cp36-cp36...25e0
Best match: numpy 1.17.0rc1
Processing numpy-1.17.0rc1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
Installing numpy-1.17.0rc1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl to /xxx/venv/lib/python3.6/site-packages
Adding numpy 1.17.0rc1 to easy-install.pth file
...
```

They understand the requirement `numpy<2.0,>=1.14.5` differently: pip installs 1.16.4 while setuptools 1.17.0rc1.

Proposed fix:

Change the dependency to `numpy<1.17,>=1.14.5` to stick with the 1.16 version regardless of the installation procedure.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-509516497,habernal,2019-07-09 07:01:12,30427,[30559],Code bug,0,"In fact, the numpy dependency is treated differently given the tool you install TF ([code] versus [code]). Both tested in a clean virtual environment with only these libraries installed at the beginning: `[code][code]`[code]`[code]setup.py[code]`[code]`[code]`[code]`[code]numpy<2.0,>=1.14.5[code]numpy<1.17,>=1.14.5` to stick with the 1.16 version regardless of the installation procedure.",0
"And here's the core of the problem: https://github.com/pypa/setuptools/issues/855

as discovered by others, too: https://stackoverflow.com/q/54796975",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-509536984,habernal,2019-07-09 08:05:57,30427,[30559],Code bug,0,"And here's the core of the problem: [url] as discovered by others, too: [url]",0
@habernal let me know if we can close this issue since we found the solution. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-509931958,ravikyram,2019-07-10 06:45:56,30427,[30559],Code bug,0,@habernal let me know if we can close this issue since we found the solution. Thanks!,3
@habernal I think tensorflow could be updated to make it compatible with numpy 1.17+. Created a PR #30559 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-510059904,yongtang,2019-07-10 13:25:44,30427,[30559],Code bug,0,@habernal I think tensorflow could be updated to make it compatible with numpy 1.17+. Created a PR #30559 for the fix.,2
Hello i am having the same error. Can u plese tell me what to do with instruction to solve this problem.Thanks,IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-515685937,Akeaakar,2019-07-27 13:54:32,30427,[30559],Code bug,0,Hello i am having the same error. Can u plese tell me what to do with instruction to solve this problem.Thanks,0
@Akeaakar The issue has been fixed and merged into the master branch. In the next release of TF the issue should be gone.,IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-515690500,yongtang,2019-07-27 15:00:09,30427,[30559],Code bug,0,@Akeaakar The issue has been fixed and merged into the master branch. In the next release of TF the issue should be gone.,5
"@Akeaakar And for the time being, `pip install ""numpy<1.17""` to revert to numpy version 1.16.4",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-515770145,ssomers,2019-07-28 15:04:36,30427,[30559],Code bug,0,"@Akeaakar And for the time being, [code] to revert to numpy version 1.16.4",0
"With Ubuntu19.04, the combination of tensorflow-gpu 1.14.0 (or tensorflow-gpu 1.12.2) with numpy 1.17.0 has the same warnings as well. When change numpy version to 1.16.3, the warnings are gone.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-516414548,Zhiwei-Zhai,2019-07-30 13:17:53,30427,[30559],Code bug,0,"With Ubuntu19.04, the combination of tensorflow-gpu 1.14.0 (or tensorflow-gpu 1.12.2) with numpy 1.17.0 has the same warnings as well. When change numpy version to 1.16.3, the warnings are gone.",0
"Or you can supress the warnings using the below code.

```
import warnings
import tensorflow as tf

warnings.filterwarnings('ignore')
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-522920338,njanirudh,2019-08-20 08:52:15,30427,[30559],Code bug,0,Or you can supress the warnings using the below code. ``[code]``,0
"> Or you can supress the warnings using the below code.
> 
> ```
> import warnings
> import tensorflow as tf
> 
> warnings.filterwarnings('ignore')
> ```
seems this doesn't work for me. (numpy1.17.0 python3.7.3)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-526545983,htuhxf,2019-08-30 10:09:54,30427,[30559],Code bug,0,> Or you can supress the warnings using the below code. > > ``[code]`` seems this doesn't work for me. (numpy1.17.0 python3.7.3),-2
"> > Or you can supress the warnings using the below code.
> > ```
> > import warnings
> > import tensorflow as tf
> > 
> > warnings.filterwarnings('ignore')
> > ```
> 
> seems this doesn't work for me. (numpy1.17.0 python3.7.3)
```
import warnings
warnings.filterwarnings('ignore',category=FutureWarning)
import tensorflow as tf
```
Needs to be before the import, since that is where the warnings are coming from. Also added a restriction to only effect that warning category instead of silencing all warnings.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-527891497,Gra-tak,2019-09-04 13:05:24,30427,[30559],Code bug,0,"> > Or you can supress the warnings using the below code. > > ``[code]`[code]`[code]`` Needs to be before the import, since that is where the warnings are coming from. Also added a restriction to only effect that warning category instead of silencing all warnings.",0
"> import warnings
> warnings.filterwarnings('ignore',category=FutureWarning)
> import tensorflow as tf
It works for me even under a virtual environment
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-529211150,Michael-VT,2019-09-08 15:02:37,30427,[30559],Code bug,0,"> import warnings > warnings.filterwarnings('ignore',category=FutureWarning) > import tensorflow as tf It works for me even under a virtual environment",3
"I have numpy in ./venv/lib/python3.7/site-packages (1.17.2). In both Jupyter and VS Code, I get the idea. I really dislike the idea of ignoring the warning. Any fixes would be greatly appreciated. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-531413869,csarami,2019-09-13 22:47:11,30427,[30559],Code bug,0,"I have numpy in ./venv/lib/python3.7/site-packages (1.17.2). In both Jupyter and VS Code, I get the idea. I really dislike the idea of ignoring the warning. Any fixes would be greatly appreciated.",-2
"> pip install ""numpy<1.17""

After doing that, system installed `numpy-1.16.5`. But now `import tensorflow` says:
`ImportError: Something is wrong with the numpy installation.`",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-532309183,arianaa30,2019-09-17 16:59:46,30427,[30559],Code bug,0,"> pip install ""numpy<1.17"" After doing that, system installed [code]. But now [code] says: [code]",0
"numpy: `pip install --upgrade numpy`
keras: ` conda install -c conda-forge keras`

Upgrade your numpy and install keras by using the above command in Anaconda prompt.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-533447033,jagadeeshjr5,2019-09-20 07:43:53,30427,[30559],Code bug,0,numpy: [code] keras: [code] Upgrade your numpy and install keras by using the above command in Anaconda prompt.,0
"Hi, for reference, I got this fixed with these 2 version:
```
>>> import tensorflow as tf
>>> print(tf.__version__)
2.0.0-rc1
>>> import numpy as np
>>> print(np.__version__)
1.17.2
>>> exit()
```
09/24/19, hope this helps",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-534658939,Namburger,2019-09-24 17:18:03,30427,[30559],Code bug,0,"Hi, for reference, I got this fixed with these 2 version: ``[code]`` 09/24/19, hope this helps",3
Thanks @Namburger . The warnings are gone on 2.0.0-rc1.,IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-536277304,askerlee,2019-09-29 10:00:12,30427,[30559],Code bug,0,Thanks @Namburger . The warnings are gone on 2.0.0-rc1.,5
"With the latest release of tensorflow (i.e., 2.0.0) and numpy 1.17.2, the warning is back.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-537516674,UndeadKernel,2019-10-02 14:23:17,30427,[30559],Code bug,0,"With the latest release of tensorflow (i.e., 2.0.0) and numpy 1.17.2, the warning is back.",-2
"Can you provide a reproducer, @UndeadKernel ? I cannot reproduce:

```
>>> import tensorflow as tf
>>> tf.__version__
'2.0.0'
>>> import numpy as np
>>> np.__version__
'1.17.2'
>>> import tensorflow.python.framework.dtypes
>>> 
```

Also tried from a file:

```python
import tensorflow as tf
import numpy as np

print(""TF"", tf.__version__)
print(""NP"", np.__version__)

import tensorflow.python.framework.dtypes
```

but no warnings:

```
(gh_numpty) mihaimaruseac@ankh:/tmp/gh_numpty$ python test.py 
TF 2.0.0
NP 1.17.2
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541461013,mihaimaruseac,2019-10-13 21:21:58,30427,[30559],Code bug,0,"Can you provide a reproducer, @UndeadKernel ? I cannot reproduce: ``[code]`[code]`[code]`[code]`[code]``",0
"@mihaimaruseac, I can reproduce the problem with both examples of yours. That is, I see the following output:
```
2019-10-14 12:20:56.438892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
TF 2.0.0
NP 1.17.2
```

I'm using arch. Arch, if I recall correctly, adapts Tensorflow to work with Python 3.7.4. Or is this version of Python already supported by Tensorflow?",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541598732,UndeadKernel,2019-10-14 10:22:51,30427,[30559],Code bug,0,"@mihaimaruseac, I can reproduce the problem with both examples of yours. That is, I see the following output: ``[code]`` I'm using arch. Arch, if I recall correctly, adapts Tensorflow to work with Python 3.7.4. Or is this version of Python already supported by Tensorflow?",0
"@UndeadKernel I'm running Arch too, but I'm not getting any warnings as of now (they were present earlier). My packages are:
* python-tensorflow-opt-cuda: 2.0.0-2
* python-numpy-openblas: 1.17.2-1",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541603630,rharish101,2019-10-14 10:36:43,30427,[30559],Code bug,0,"@UndeadKernel I'm running Arch too, but I'm not getting any warnings as of now (they were present earlier). My packages are: * python-tensorflow-opt-cuda: 2.0.0-2 * python-numpy-openblas: 1.17.2-1",0
"This is indeed quite strange @rharish101, I have the same exact versions. I tried using `python-numpy` from the official repo and python-numpy-openblas` from the AUR and I see the same FutureWarning messages.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541699363,UndeadKernel,2019-10-14 14:07:12,30427,[30559],Code bug,0,"This is indeed quite strange @rharish101, I have the same exact versions. I tried using [code] from the official repo and python-numpy-openblas` from the AUR and I see the same FutureWarning messages.",0
"@UndeadKernel Could you try reinstalling the TensorFlow package? It might have changed in the latest patch (2.0.0-2 as opposed to 2.0.0-1). I remember that I, too, saw those warnings in the last few days, but as of today, they are gone, with the only difference that I updated TensorFlow 9 days ago.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541714381,rharish101,2019-10-14 14:32:34,30427,[30559],Code bug,0,"@UndeadKernel Could you try reinstalling the TensorFlow package? It might have changed in the latest patch (2.0.0-2 as opposed to 2.0.0-1). I remember that I, too, saw those warnings in the last few days, but as of today, they are gone, with the only difference that I updated TensorFlow 9 days ago.",0
"@rharish101, thank for the suggestion.
I noticed that `tensorboard` was not the same version as `tensorflow`. After reinstalling `tensorboard` (notice that this is ""tensorBoard"" and not ""TensorFlow""), the warning went away.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541722232,UndeadKernel,2019-10-14 14:45:46,30427,[30559],Code bug,0,"@rharish101, thank for the suggestion. I noticed that [code] was not the same version as [code]. After reinstalling [code] (notice that this is ""tensorBoard"" and not ""TensorFlow""), the warning went away.",3
"There is an official release of 2.0, you should not need to use the patched versions.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541753656,mihaimaruseac,2019-10-14 15:39:40,30427,[30559],Code bug,0,"There is an official release of 2.0, you should not need to use the patched versions.",1
To which patches are you referring @mihaimaruseac?,IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541906183,UndeadKernel,2019-10-14 20:35:22,30427,[30559],Code bug,0,To which patches are you referring @mihaimaruseac?,0
"2.0.0-1 and 2.0.0-2 mentioned in above comments

`pip install tensorflow==2.0.0` should work (might need to upgrade pip to the latest version if you're on an old one, due to the change to be manylinux2010 compliant)",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-541916106,mihaimaruseac,2019-10-14 20:55:11,30427,[30559],Code bug,0,"2.0.0-1 and 2.0.0-2 mentioned in above comments [code] should work (might need to upgrade pip to the latest version if you're on an old one, due to the change to be manylinux2010 compliant)",1
"try

pip3 [pip] install tf-nightly

the nightly build of tensorflow seems to have that problem sorted out, best of luck",IssueComment,https://github.com/tensorflow/tensorflow/issues/30427#issuecomment-550860522,Benjamin0000Rodriguez,2019-11-07 06:12:46,30427,[30559],Code bug,0,"try pip3 [pip] install tf-nightly the nightly build of tensorflow seems to have that problem sorted out, best of luck",3
@jvishnuvardhan Mind if I resolve this?,IssueComment,https://github.com/tensorflow/tensorflow/issues/29755#issuecomment-508211404,RonLek,2019-07-03 18:41:42,29755,[30683],Documentation bug,0,@jvishnuvardhan Mind if I resolve this?,3
@RonLek Please go ahead and resolve through PR. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/29755#issuecomment-509479335,jvishnuvardhan,2019-07-09 04:10:24,29755,[30683],Documentation bug,0,@RonLek Please go ahead and resolve through PR. Thanks!,3
"That file is here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/logging_ops.py

There is a code block sample in the warning note. The deprecation notice should be short and any code examples should move under `def Print`.

Thanks for taking a look",IssueComment,https://github.com/tensorflow/tensorflow/issues/29755#issuecomment-510959163,lamberta,2019-07-12 16:59:20,29755,[30683],Documentation bug,0,That file is here: [url] There is a code block sample in the warning note. The deprecation notice should be short and any code examples should move under [code]. Thanks for taking a look,2
@jvishnuvardhan  @lamberta Please let me know if it works fine. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/29755#issuecomment-511121238,RonLek,2019-07-13 13:13:46,29755,[30683],Documentation bug,0,@jvishnuvardhan @lamberta Please let me know if it works fine. Thanks!,2
Add a PR #30781 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/30750#issuecomment-512047034,yongtang,2019-07-17 00:05:52,30750,[30781],Data bug,0,Add a PR #30781 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30750"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30750"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30750#issuecomment-515603297,tensorflow-bot[bot],2019-07-26 21:21:41,30750,[30781],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Thanks. That guide is gone so removed link in https://github.com/tensorflow/tensorflow/pull/30824,IssueComment,https://github.com/tensorflow/tensorflow/issues/30566#issuecomment-512566917,lamberta,2019-07-17 21:00:53,30566,[30824],Visualization bug,0,Thanks. That guide is gone so removed link in [url],2
"@lamberta Out of curiosity, do you have any idea what happened to the original guide or where I could find it?",IssueComment,https://github.com/tensorflow/tensorflow/issues/30566#issuecomment-513609434,buck-ross,2019-07-22 01:37:32,30566,[30824],Visualization bug,0,"@lamberta Out of curiosity, do you have any idea what happened to the original guide or where I could find it?",0
"@haximilian Yep, some of the older /api_guides are archived here in tensorflow/docs (r1.11 branch): https://github.com/tensorflow/docs/tree/r1.11/site/en/api_guides/python
Though, as you've found, there are still some links that need to be removed.
These guides mostly existed pre-moduleâ€”and now modules have their own overview pages in the API docs.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30566#issuecomment-513614736,lamberta,2019-07-22 02:13:29,30566,[30824],Visualization bug,0,"@haximilian Yep, some of the older /api_guides are archived here in tensorflow/docs (r1.11 branch): [url] Though, as you've found, there are still some links that need to be removed. These guides mostly existed pre-moduleâ€”and now modules have their own overview pages in the API docs.",0
"@lgeiger After running the provided code, got the below error.
NotFoundError: cache/mnist_0.lockfile; No such file or directory [Op:IteratorGetNextSync]",IssueComment,https://github.com/tensorflow/tensorflow/issues/28798#issuecomment-493901527,muddham,2019-05-20 09:06:14,28798,[30825],Code bug,1,"@lgeiger After running the provided code, got the below error. NotFoundError: cache/mnist_0.lockfile; No such file or directory [Op:IteratorGetNextSync]",-2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28798"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28798"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28798#issuecomment-515114691,tensorflow-bot[bot],2019-07-25 16:32:23,28798,[30825],Code bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I think the issue is that, `make_csv_dataset` will try to probe the column name automatically if not present. In order to ""probe"" the column automatically, it use python's `csv` module to check for the first line of the file. But the compression_type was not accounted for in this situation.  Once column is available then internally CsvDataset process the file correctly, though.

Created a PR #30867 for the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/30849#issuecomment-513066012,yongtang,2019-07-19 02:30:48,30849,[30867],Data bug,0,"I think the issue is that, [code] will try to probe the column name automatically if not present. In order to ""probe"" the column automatically, it use python's [code] module to check for the first line of the file. But the compression_type was not accounted for in this situation. Once column is available then internally CsvDataset process the file correctly, though. Created a PR #30867 for the fix.",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30849"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30849"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/30849#issuecomment-515090285,tensorflow-bot[bot],2019-07-25 15:26:36,30849,[30867],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #31145 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/31137#issuecomment-516143482,yongtang,2019-07-29 20:10:29,31137,[31145],Data bug,0,Added a PR #31145 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31137"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31137"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/31137#issuecomment-517854472,tensorflow-bot[bot],2019-08-02 21:51:25,31137,[31145],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Created a PR #31734 to add int64 (and other types) for ResourceGather.,IssueComment,https://github.com/tensorflow/tensorflow/issues/31696#issuecomment-522344167,yongtang,2019-08-18 18:27:18,31696,[31734],Processor bug,1,Created a PR #31734 to add int64 (and other types) for ResourceGather.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31696"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31696"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/31696#issuecomment-523708235,tensorflow-bot[bot],2019-08-22 01:22:21,31696,[31734],Processor bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Thanks for filing the bug. Let's continue the discussion on https://github.com/tensorflow/tensorflow/pull/31757,IssueComment,https://github.com/tensorflow/tensorflow/issues/31756#issuecomment-522841480,wangtz,2019-08-20 03:49:14,31756,[31757],Test bug,0,Thanks for filing the bug. Let's continue the discussion on [url],2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31756"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31756"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/31756#issuecomment-528112541,tensorflow-bot[bot],2019-09-04 22:19:35,31756,[31757],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Feel free to propose a fix that allows setting the SDK as optional.,IssueComment,https://github.com/tensorflow/tensorflow/issues/31843#issuecomment-524016467,jdduke,2019-08-22 18:09:57,31843,[31918],Build bug,0,Feel free to propose a fix that allows setting the SDK as optional.,2
"There is something unclear to me currently.

Is it bazel, who requires SDK in addition to NDK in order to build android related projects, or tensorflow?",IssueComment,https://github.com/tensorflow/tensorflow/issues/31843#issuecomment-524052182,DoumanAsh,2019-08-22 19:52:38,31843,[31918],Build bug,0,"There is something unclear to me currently. Is it bazel, who requires SDK in addition to NDK in order to build android related projects, or tensorflow?",0
I suspect you'll need to modify something in this file: https://github.com/tensorflow/tensorflow/blob/master/third_party/android/android_configure.bzl,IssueComment,https://github.com/tensorflow/tensorflow/issues/31843#issuecomment-524065271,jdduke,2019-08-22 20:30:27,31843,[31918],Build bug,0,I suspect you'll need to modify something in this file: [url],0
"Ok, thx, I'll test various approaches and will be back with PR",IssueComment,https://github.com/tensorflow/tensorflow/issues/31843#issuecomment-524180789,DoumanAsh,2019-08-23 05:44:58,31843,[31918],Build bug,0,"Ok, thx, I'll test various approaches and will be back with PR",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31843"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31843"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/31843#issuecomment-547305485,tensorflow-bot[bot],2019-10-29 08:15:31,31843,[31918],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@tatatodd  -  Hi Todd, could you please take a look at this ?",IssueComment,https://github.com/tensorflow/tensorflow/issues/22071#issuecomment-434731542,Harshini-Gadige,2018-10-31 15:27:53,22071,[31993],Data bug,0,"@tatatodd - Hi Todd, could you please take a look at this ?",0
"**Tensorflow version:** b'v1.13.1-6-gd32c49d4e3' 1.13.1

The following code which attempts to profile the flops and params of ResNet50 reports 
FLOPS:51,351,635 PARAMS:25,636,712

Params seems ok but flops is way off (should be ~4GFLOPS).
Potentially could be the same issue
 
```python
import tensorflow as tf
import keras.backend as K
from keras.applications.resnet50 import ResNet50

def main():
    run_meta = tf.RunMetadata()
    with tf.Session(graph=tf.Graph()) as sess:
        K.set_session(sess)        
        
        m = ResNet50()

        opts = tf.profiler.ProfileOptionBuilder.float_operation()    
        flops = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)

        opts = tf.profiler.ProfileOptionBuilder.trainable_variables_parameter()    
        params = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)

        print('FLOPS:{:,} PARAMS:{:,}'.format(flops.total_float_ops, params.total_parameters))

if __name__ == '__main__':
    main()
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/22071#issuecomment-490107551,eyalsh,2019-05-07 14:37:31,22071,[31993],Data bug,0,"**Tensorflow version:** b'v1.13.1-6-gd32c49d4e3' 1.13.1 The following code which attempts to profile the flops and params of ResNet50 reports FLOPS:51,351,635 PARAMS:25,636,712 Params seems ok but flops is way off (should be ~4GFLOPS). Potentially could be the same issue ``[code]``",-1
"Hi @rmlarsen, since this issue hasn't got addressed yet, I created a commit that may solve the BatchMatMul op flops problem, could you help take a look? Thanks.",IssueComment,https://github.com/tensorflow/tensorflow/issues/22071#issuecomment-510185033,csarron,2019-07-10 18:54:12,22071,[31993],Data bug,0,"Hi @rmlarsen, since this issue hasn't got addressed yet, I created a commit that may solve the BatchMatMul op flops problem, could you help take a look? Thanks.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=22071"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=22071"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/22071#issuecomment-532228362,tensorflow-bot[bot],2019-09-17 13:46:47,22071,[31993],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32164"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32164"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32164#issuecomment-528478868,tensorflow-bot[bot],2019-09-05 17:08:33,32164,[32165],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29469"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29469"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/29469#issuecomment-530028193,tensorflow-bot[bot],2019-09-10 16:58:31,29469,[32325],Visualization bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@csukuangfj Is this resolved or still an issue? Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/32416#issuecomment-568605438,jvishnuvardhan,2019-12-23 23:27:06,32416,[32417],Memory bug,0,@csukuangfj Is this resolved or still an issue? Thanks!,0
"@jvishnuvardhan 
when this pullrequest https://github.com/tensorflow/tensorflow/pull/32417 is merged,
this issue should be closed by GitHub automatically; but more than 3 months have passed,
it is still not merged.

",IssueComment,https://github.com/tensorflow/tensorflow/issues/32416#issuecomment-568748725,csukuangfj,2019-12-24 13:29:16,32416,[32417],Memory bug,0,"@jvishnuvardhan when this pullrequest [url] is merged, this issue should be closed by GitHub automatically; but more than 3 months have passed, it is still not merged.",-3
@csukuangfj I see the reviewer approved the PR. So it will be merged soon. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/32416#issuecomment-568940247,jvishnuvardhan,2019-12-26 00:18:41,32416,[32417],Memory bug,0,@csukuangfj I see the reviewer approved the PR. So it will be merged soon. Thanks!,3
"@jvishnuvardhan 

Things are not always that easy like you thought. You can see that the pullrequest
has been approved for multiple times, but nothing happens when  the`ready to pull`
label is added.",IssueComment,https://github.com/tensorflow/tensorflow/issues/32416#issuecomment-568950957,csukuangfj,2019-12-26 02:23:11,32416,[32417],Memory bug,0,"@jvishnuvardhan Things are not always that easy like you thought. You can see that the pullrequest has been approved for multiple times, but nothing happens when the[code] label is added.",-2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32416"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32416"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32416#issuecomment-572797378,tensorflow-bot[bot],2020-01-09 23:04:34,32416,[32417],Memory bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"It's a documentation of Python r1.13, and the link correctly sends us to https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/activations.py
@dynamicwebpaige @rohanmeh  Am I missing soemthing here? ",IssueComment,https://github.com/tensorflow/tensorflow/issues/25828#issuecomment-473669824,lunayach,2019-03-17 14:15:44,25828,[32668],Documentation bug,0,"It's a documentation of Python r1.13, and the link correctly sends us to [url] @dynamicwebpaige @rohanmeh Am I missing soemthing here?",0
Is someone currently working on this?,IssueComment,https://github.com/tensorflow/tensorflow/issues/25828#issuecomment-501790035,jmammen,2019-06-13 17:00:15,25828,[32668],Documentation bug,0,Is someone currently working on this?,0
I can handle this. I can also do the deserialize function. Do we need a separate issue / pr for that?,IssueComment,https://github.com/tensorflow/tensorflow/issues/25828#issuecomment-533222188,onlyanegg,2019-09-19 17:04:10,25828,[32668],Documentation bug,0,I can handle this. I can also do the deserialize function. Do we need a separate issue / pr for that?,3
"I have updated the entire activations doc including the functions `get`, `serialize`, `deserialize`, `linear` etc. and created a pull request.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25828#issuecomment-533271075,asmitapoddar,2019-09-19 19:18:32,25828,[32668],Documentation bug,0,"I have updated the entire activations doc including the functions [code], [code], [code], [code] etc. and created a pull request.",3
"Thanks @asmitapoddar, I'll go review that for you.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25828#issuecomment-533357788,MarkDaoust,2019-09-20 00:33:59,25828,[32668],Documentation bug,0,"Thanks @asmitapoddar, I'll go review that for you.",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=25828"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=25828"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/25828#issuecomment-536084335,tensorflow-bot[bot],2019-09-27 20:23:52,25828,[32668],Documentation bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32770"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32770"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32770#issuecomment-539150547,tensorflow-bot[bot],2019-10-07 18:44:41,32770,[32773],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I have tried on colab with TF version 2.0 beta1,2.0.0-rc0, 2.0.0-rc1 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/cae08a626511eaab7fa6b4eda8f80405/untitled199.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-532581257,ravikyram,2019-09-18 08:33:31,32612,[33229],Deployment bug,0,"I have tried on colab with TF version 2.0 beta1,2.0.0-rc0, 2.0.0-rc1 and was able to reproduce the issue.Please, find the gist [here]([url]",0
"I also tested 2.0.0-rc1 and the issue persists. 
@ravikyram If there is a label for 2.0.0-rc1, can we also add it?",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-532582986,somedadaism,2019-09-18 08:37:53,32612,[33229],Deployment bug,0,"I also tested 2.0.0-rc1 and the issue persists. @ravikyram If there is a label for 2.0.0-rc1, can we also add it?",0
The same problem also exists for classes implementing `tf.keras.metrics.Metric`.,IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-532591306,somedadaism,2019-09-18 08:59:08,32612,[33229],Deployment bug,0,The same problem also exists for classes implementing [code].,-1
"@somedadaism Can you save the model before compiling with `MyCustomLoss` function. Then load the saved model and compile with `MyCustomLoss` function as shown below. Thanks!

```
import tensorflow as tf

print(tf.__version__)
class MyCustomLoss(tf.keras.losses.Loss):
    def __init__(self):
        super().__init__()

    def call(self, y_true, y_pred):
        return 1.



a = tf.keras.layers.Input(shape=(32,))
b = tf.keras.layers.Dense(32)(a)
model = tf.keras.models.Model(inputs=a, outputs=b)
model.save('./model.h5') # save first and then compile
model.compile('sgd', MyCustomLoss())

# load the model
model_new = tf.keras.models.load_model('./model.h5')
model_new.compile('sgd', MyCustomLoss())
```

",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-532875268,jvishnuvardhan,2019-09-18 21:32:02,32612,[33229],Deployment bug,0,@somedadaism Can you save the model before compiling with [code] function. Then load the saved model and compile with [code] function as shown below. Thanks! ``[code]``,2
"This does only work for this simple toy example. But if I want to fit the model and then save and the reload it will not work. I know how to workaround this thing myself but the intended way is not working for me. The same problem also exists for classes implementing `tf.keras.metrics.Metric.`
```
import tensorflow as tf

print(tf.__version__)
class MyCustomLoss(tf.keras.losses.Loss):
    def __init__(self):
        super().__init__()

    def call(self, y_true, y_pred):
        return 1.



a = tf.keras.layers.Input(shape=(32,))
b = tf.keras.layers.Dense(32)(a)
model = tf.keras.models.Model(inputs=a, outputs=b)
model.compile('sgd', MyCustomLoss()) # first compile, then fit, then save is the normal order.
model.fit(some_data, epochs=1) 
model.save('./model.h5') # I can not save any earlier!!!
# load the model
model_new = tf.keras.models.load_model('./model.h5')
model_new.compile('sgd', MyCustomLoss())
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-533538323,somedadaism,2019-09-20 12:44:10,32612,[33229],Deployment bug,0,This does only work for this simple toy example. But if I want to fit the model and then save and the reload it will not work. I know how to workaround this thing myself but the intended way is not working for me. The same problem also exists for classes implementing [code] ``[code]``,-2
"@somedadaism Custom functions are not compatible. 

`model.save` before `model.compile` works for small toy example and big model also.

When you load the saved model, load the model using `tf.keras.models.load_model` and then `compile`.

Please try this even for the above example or any other big model and let us know if you have any issue there.

If you don't have any custom function, then follow `define model`, then `compile model`, then `save the model`, and then `reload the model`. Thanks!
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-533837106,jvishnuvardhan,2019-09-21 23:27:08,32612,[33229],Deployment bug,0,"@somedadaism Custom functions are not compatible. [code] before [code] works for small toy example and big model also. When you load the saved model, load the model using [code] and then [code]. Please try this even for the above example or any other big model and let us know if you have any issue there. If you don't have any custom function, then follow [code], then [code], then [code], and then [code]. Thanks!",1
"By simple toy example I meant my code was so minimal that your workaround would work for it but not for the standard usecase. It is not related to the model size. The difference is that usually you also `fit` the model. I had updated the code in my last post to show how `save` before `compile` usually does not make sense. Can you have a second look at my last code snippet?
I think Custom Loss Functions and Metrics should be supported. Can you fix this so keras works as expected?",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-533839978,somedadaism,2019-09-22 00:35:09,32612,[33229],Deployment bug,0,By simple toy example I meant my code was so minimal that your workaround would work for it but not for the standard usecase. It is not related to the model size. The difference is that usually you also [code] the model. I had updated the code in my last post to show how [code] before [code] usually does not make sense. Can you have a second look at my last code snippet? I think Custom Loss Functions and Metrics should be supported. Can you fix this so keras works as expected?,-1
"@somedadaism I haven't tried `customloss` as `class object` but I tried it as `function`  like

```
# Custom Loss1 (for example) 
@tf.function() 
def customLoss1(yTrue,yPred):
  return tf.reduce_mean(yTrue-yPred) 
```

In this way you can save the model as usual (create model, compile, fit, save) and load the model using `load_model` with `custom_objects` like

`new_model=tf.keras.models.load_model(""./model.h5"",custom_objects={'customLoss1':customLoss1,'customLoss2':customLoss2})`

Please check entire gist [here](https://colab.sandbox.google.com/gist/jvishnuvardhan/04028d08660378ee7c2cef2b9c3bb2e9/custom_metric.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-534224111,jvishnuvardhan,2019-09-23 18:25:40,32612,[33229],Deployment bug,0,"@somedadaism I haven't tried [code] as [code] but I tried it as [code] like ``[code]`[code]load_model[code]custom_objects[code]new_model=tf.keras.models.load_model(""./model.h5"",custom_objects={'customLoss1':customLoss1,'customLoss2':customLoss2})` Please check entire gist [here]([url] Thanks!",0
"Hello, thank you for your effort. I know also how to workaround for the loss function. My favorite workaround for now is to use `load_model(path, compile=False)`. If it was only the loss functions this whole issue could be solved by just using normal functions as you propose. The fundamental problem is that the subclasses of `tf.keras.metrics.Metric` does not work either for presumably the same reason. Subclasses of this class can not be replaced by simple functions because metrics can be stateful. If I implement my own stateful metrics in the style of, for an example `tf.keras.metrics.mIoU` there is no alternative to this but if I save the model I can not load it anymore (or if I use my workaround I loose the optimizer state.) For this reason I think that a fix is necessary for the issue although there are workarounds that work in many cases.",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-534248672,somedadaism,2019-09-23 19:29:36,32612,[33229],Deployment bug,0,"Hello, thank you for your effort. I know also how to workaround for the loss function. My favorite workaround for now is to use [code]. If it was only the loss functions this whole issue could be solved by just using normal functions as you propose. The fundamental problem is that the subclasses of [code] does not work either for presumably the same reason. Subclasses of this class can not be replaced by simple functions because metrics can be stateful. If I implement my own stateful metrics in the style of, for an example [code] there is no alternative to this but if I save the model I can not load it anymore (or if I use my workaround I loose the optimizer state.) For this reason I think that a fix is necessary for the issue although there are workarounds that work in many cases.",0
@k-w-w Can you give me a rough estimation for the timeframe to expect for the fix of the issue? (codebase I will deliver to a client depends on it.),IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-535437270,somedadaism,2019-09-26 10:12:43,32612,[33229],Deployment bug,0,@k-w-w Can you give me a rough estimation for the timeframe to expect for the fix of the issue? (codebase I will deliver to a client depends on it.),0
"@k-w-w @jvishnuvardhan Are there any updates on the issue?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-538638435,somedadaism,2019-10-05 10:38:47,32612,[33229],Deployment bug,0,@k-w-w @jvishnuvardhan Are there any updates on the issue?,0
"@k-w-w The solution proposed by @ thierryherrmann  [here](https://github.com/tensorflow/tensorflow/pull/33229) is good, but only if the inputs to the loss object are not tensors. Otherwise, a serialization exception is generated.
We could try to convert the tensor into a numpy array inside `get_config()`, as it is done by the `LossWrapperFunction` class. Unfortunately, that does not work either. It seems Keras is not well integrated with eager execution. (Side note: having access to the `LossWrapperFunction` class would lead to much cleaner solutions).
I have created a gist [here](https://colab.research.google.com/gist/humcasma/d7d00d6d31c4cca623c1140f050e8f94/problem_loading_custom_loss.ipynb) with different attempts to solve the problem.",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-543605854,humcasma,2019-10-18 08:45:14,32612,[33229],Deployment bug,0,"@k-w-w The solution proposed by @ thierryherrmann [here]([url] is good, but only if the inputs to the loss object are not tensors. Otherwise, a serialization exception is generated. We could try to convert the tensor into a numpy array inside [code], as it is done by the [code] class. Unfortunately, that does not work either. It seems Keras is not well integrated with eager execution. (Side note: having access to the [code] class would lead to much cleaner solutions). I have created a gist [here]([url] with different attempts to solve the problem.",-2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32612"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32612"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-566210624,tensorflow-bot[bot],2019-12-16 19:38:13,32612,[33229],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added PR #33271 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/33253#issuecomment-541264723,yongtang,2019-10-12 00:40:51,33253,[33271],Data bug,1,Added PR #33271 for the fix.,0
Thank you for the quick fix! Any chance this could make it into 1.15 too?,IssueComment,https://github.com/tensorflow/tensorflow/issues/33253#issuecomment-541667538,t-kalinowski,2019-10-14 13:08:40,33253,[33271],Data bug,1,Thank you for the quick fix! Any chance this could make it into 1.15 too?,3
"@t-kalinowski We will have to wait for the PR to be merged into master. Once it is in the master, it might be cherry-picked into release 1.15 or 2.0. Though given 1.15's release schedule, I would not count on this fix being picked up in 1.15.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33253#issuecomment-542035187,yongtang,2019-10-15 04:50:14,33253,[33271],Data bug,1,"@t-kalinowski We will have to wait for the PR to be merged into master. Once it is in the master, it might be cherry-picked into release 1.15 or 2.0. Though given 1.15's release schedule, I would not count on this fix being picked up in 1.15.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33253"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33253"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33253#issuecomment-542179651,tensorflow-bot[bot],2019-10-15 12:08:07,33253,[33271],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"That's odd, because this code works in our CI. Which `protobuf` version are you using? It looks like `RepeatedCompositeContainer.append()` has been available since https://github.com/protocolbuffers/protobuf/commit/d8c2501b43c1b56e3efa74048a18f8ce06ba07fe , so we might need to bump a requirement.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-541886114,mrry,2019-10-14 19:54:17,33348,[33353],Data bug,0,"That's odd, because this code works in our CI. Which [code] version are you using? It looks like [code] has been available since [url] , so we might need to bump a requirement.",0
"Hmmm this is for the binary pip installed `tf-nightly` so not sure what version protobuf that is built with. Quick glance looks [like maybe 3.3.1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/protobuf/protobuf_optimized_pip.sh#L17), but I'm not overly familiar with the toolchain for TF-Core. 

As a data point... variable creation for today's MacOS nightly wheel works fine, however the linux wheel appears broken. Is there a mismatch in protobuf versions for the nightly builds?
https://colab.research.google.com/drive/11swg1klzul_ozOQZa61Wz-zoBJg25He3

cc @angerson 
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-541900721,seanpmorgan,2019-10-14 20:24:20,33348,[33353],Data bug,0,"Hmmm this is for the binary pip installed [code] so not sure what version protobuf that is built with. Quick glance looks [like maybe 3.3.1]([url]#L17), but I'm not overly familiar with the toolchain for TF-Core. As a data point... variable creation for today's MacOS nightly wheel works fine, however the linux wheel appears broken. Is there a mismatch in protobuf versions for the nightly builds? [url] cc @angerson",-1
"For binaries, the PIP dependency is `'protobuf >= 3.6.1'`:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L64

Right enough, https://github.com/protocolbuffers/protobuf/commit/d8c2501b43c1b56e3efa74048a18f8ce06ba07fe only appears from 3.8.0 onwards.

If you do `pip install -U protobuf=3.8.0` in your Linux env, does that fix the problem?",IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-541915323,mrry,2019-10-14 20:53:45,33348,[33353],Data bug,0,"For binaries, the PIP dependency is [code]: [url]#L64 Right enough, [url] only appears from 3.8.0 onwards. If you do [code] in your Linux env, does that fix the problem?",0
"Yup upgrade protobuf solves the issue:
https://colab.research.google.com/drive/11swg1klzul_ozOQZa61Wz-zoBJg25He3

Can we bump the requirements in `setup.py`",IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-541921230,seanpmorgan,2019-10-14 21:05:27,33348,[33353],Data bug,0,Yup upgrade protobuf solves the issue: [url] Can we bump the requirements in [code],2
Thanks for confirming! I just sent an PR to bump the requirement.,IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-541922626,mrry,2019-10-14 21:08:18,33348,[33353],Data bug,0,Thanks for confirming! I just sent an PR to bump the requirement.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33348"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33348"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-544741129,tensorflow-bot[bot],2019-10-21 22:51:25,33348,[33353],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"When I upgrade protobuf from version 3.6.0 to any higher versions, its showing 
""ImportError: DLL load failed: The specified procedure could not be found"". Earlier I was using 3.11 but that was giving me the above error but someone suggested to downgrade the version to 3.6. After downgrading its now showing this same attribute error.


EDIT: Was using tensorflow version 2.1. Downgrading it to 2.0 resolved the issue. Though it is still telling me to upgrade protobuf version(currently using 3.6 to avoid DLL import failed issue).",IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-591785253,Arpan2798,2020-02-27 05:13:13,33348,[33353],Data bug,0,"When I upgrade protobuf from version 3.6.0 to any higher versions, its showing ""ImportError: DLL load failed: The specified procedure could not be found"". Earlier I was using 3.11 but that was giving me the above error but someone suggested to downgrade the version to 3.6. After downgrading its now showing this same attribute error. EDIT: Was using tensorflow version 2.1. Downgrading it to 2.0 resolved the issue. Though it is still telling me to upgrade protobuf version(currently using 3.6 to avoid DLL import failed issue).",-2
"python3.6 (anaconda)
tensorflow2.1.0
![image](https://user-images.githubusercontent.com/52851180/80276101-c4dcf000-8718-11ea-9165-be33091e3157.png)
![image](https://user-images.githubusercontent.com/52851180/80276107-d0c8b200-8718-11ea-82c1-05541eac48d0.png)

That(""tf.Variable(5)"") used by tensorflow2.0.0 is ok, but it isn't used by tensorflow2.1.0.
what I can do some change",IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-619349294,Gfqwy,2020-04-25 09:21:25,33348,[33353],Data bug,0,"python3.6 (anaconda) tensorflow2.1.0 ![image]([url] ![image]([url] That(""tf.Variable(5)"") used by tensorflow2.0.0 is ok, but it isn't used by tensorflow2.1.0. what I can do some change",-1
"It might help other users if I report that I had error messages
`AttributeError: 'RepeatedCompositeFieldContainer' object has no attribute 'append'`
trying to run basic Tensorflow functionalities, like  
`model = tf.keras.models.Sequential(...)`
or
`pred = model.predict(dataset_X)`, where instead of training a model, I had specified it using `tf.constant_initializer(...)`.

This happened on a fresh install of Python 3.8 and Tensorflow 2.2, but also previously on Python (~)3.7 with Tensorflow 2.1, while it was all functioning in Tensorflow 2.0.

The solution was to upgrade `protobuf` from 3.6.1 to 3.11.3, and also to make sure that the `PYTHONPATH` was correct. My modified `~/.bashrc` had to be updated so that 
`export PYTHONPATH=""/usr/local/lib64/python3.6/site-packages""`
was replaced with
`export PYTHONPATH=""/usr/local/lib64/python3.8/site-packages""`
Otherwise Python found exclusively the older version of protobuf in /usr/local/lib64/python3.6/site-packages.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-628256622,Melykuti,2020-05-13 21:30:48,33348,[33353],Data bug,0,"It might help other users if I report that I had error messages [code] trying to run basic Tensorflow functionalities, like [code] or [code], where instead of training a model, I had specified it using [code]. This happened on a fresh install of Python 3.8 and Tensorflow 2.2, but also previously on Python (~)3.7 with Tensorflow 2.1, while it was all functioning in Tensorflow 2.0. The solution was to upgrade [code] from 3.6.1 to 3.11.3, and also to make sure that the [code] was correct. My modified [code] had to be updated so that [code] was replaced with [code] Otherwise Python found exclusively the older version of protobuf in /usr/local/lib64/python3.6/site-packages.",0
"yes. as stated [here](https://www.tensorflow.org/install/docker) the command needs to be changed.

docker < 19.03:
docker run --runtime=nvidia -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" \
    tensorflow/tensorflow:devel-gpu-py3 bash

docker >= 19.03:
docker run --gpus all -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" \
    tensorflow/tensorflow:devel-gpu-py3 bash
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33346#issuecomment-542027159,blairhan,2019-10-15 04:08:17,33346,[33367],Documentation bug,0,"yes. as stated [here]([url] the command needs to be changed. docker < 19.03: docker run --runtime=nvidia -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" \ tensorflow/tensorflow:devel-gpu-py3 bash docker >= 19.03: docker run --gpus all -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" \ tensorflow/tensorflow:devel-gpu-py3 bash",0
Added PR #33367 with docs updated.,IssueComment,https://github.com/tensorflow/tensorflow/issues/33346#issuecomment-542034751,yongtang,2019-10-15 04:48:09,33346,[33367],Documentation bug,0,Added PR #33367 with docs updated.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33346"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33346"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33346#issuecomment-556318510,tensorflow-bot[bot],2019-11-20 19:59:02,33346,[33367],Documentation bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #33406 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/33394#issuecomment-542510514,yongtang,2019-10-16 04:40:25,33394,[33406],Algorithm design bug,0,Added a PR #33406 for the fix.,0
"@netw0rkf10w The above PR will fix the issue for you. In the mean time you can provide converted tensors of `y_pred` and `y_true`  as follows. Thanks!
`loss = cce(
  tf.convert_to_tensor([0, 1, 2]),
  tf.convert_to_tensor([[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]]))` ",IssueComment,https://github.com/tensorflow/tensorflow/issues/33394#issuecomment-547535093,jvishnuvardhan,2019-10-29 17:18:48,33394,[33406],Algorithm design bug,0,@netw0rkf10w The above PR will fix the issue for you. In the mean time you can provide converted tensors of [code] and [code] as follows. Thanks! [code],3
@jvishnuvardhan Thanks a lot!,IssueComment,https://github.com/tensorflow/tensorflow/issues/33394#issuecomment-547609425,netw0rkf10w,2019-10-29 20:15:24,33394,[33406],Algorithm design bug,0,@jvishnuvardhan Thanks a lot!,5
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33394"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33394"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33394#issuecomment-547609462,tensorflow-bot[bot],2019-10-29 20:15:30,33394,[33406],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Still doesn't work. Can't reproduce the example from documentation.
`---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-21-8338a7552986> in <module>()
----> 1 sce(y_true, y_pred)

/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py in __call__(self, y_true, y_pred, sample_weight)
    124         y_true, y_pred, sample_weight)
    125     with K.name_scope(scope_name or self.__class__.__name__), graph_ctx:
--> 126       losses = self.call(y_true, y_pred)
    127       return losses_utils.compute_weighted_loss(
    128           losses, sample_weight, reduction=self._get_reduction())

/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py in call(self, y_true, y_pred)
    219       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(
    220           y_pred, y_true)
--> 221     return self.fn(y_true, y_pred, **self._fn_kwargs)
    222 
    223   def get_config(self):

/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py in sparse_categorical_crossentropy(y_true, y_pred, from_logits, axis)
    976 def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):
    977   return K.sparse_categorical_crossentropy(
--> 978       y_true, y_pred, from_logits=from_logits, axis=axis)
    979 
    980 

/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py in sparse_categorical_crossentropy(target, output, from_logits, axis)
   4528   if not from_logits:
   4529     if (isinstance(output, (ops.EagerTensor, variables_module.Variable)) or
-> 4530         output.op.type != 'Softmax'):
   4531       epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)
   4532       output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)

AttributeError: 'list' object has no attribute 'op'`",IssueComment,https://github.com/tensorflow/tensorflow/issues/33394#issuecomment-648757738,ilyarudyak,2020-06-24 11:14:24,33394,[33406],Algorithm design bug,0,Still doesn't work. Can't reproduce the example from documentation. [code],-3
@ilyarudyak Can you please create a new issue and provide a standalone code to reproduce the issue?  Please ping me in that issue. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/33394#issuecomment-648969147,jvishnuvardhan,2020-06-24 17:47:28,33394,[33406],Algorithm design bug,0,@ilyarudyak Can you please create a new issue and provide a standalone code to reproduce the issue? Please ping me in that issue. Thanks!,2
"I'm getting `AttributeError: 'list' object has no attribute 'op'` when I try to get the output node name of a loaded model as follows:

```
model = tf.keras.models.load_model('test_model.h5')
output_names = model.outputs.op.name
```

My Tensorflow version is: 2.5.0",IssueComment,https://github.com/tensorflow/tensorflow/issues/33394#issuecomment-901928727,Ekberjan,2021-08-19 13:45:17,33394,[33406],Algorithm design bug,0,I'm getting [code] when I try to get the output node name of a loaded model as follows: ``[code]`` My Tensorflow version is: 2.5.0,0
(Assigning to @hlopko to detach this issue from our auto-assignment pipeline. Thanks for tracking this!),IssueComment,https://github.com/tensorflow/tensorflow/issues/32835#issuecomment-536073659,angerson,2019-09-27 19:47:11,32835,[33415],Build bug,0,(Assigning to @hlopko to detach this issue from our auto-assignment pipeline. Thanks for tracking this!),2
I have a fix for this.,IssueComment,https://github.com/tensorflow/tensorflow/issues/32835#issuecomment-542606220,laszlocsomor,2019-10-16 09:10:38,32835,[33415],Build bug,0,I have a fix for this.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32835"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32835"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32835#issuecomment-545929529,tensorflow-bot[bot],2019-10-24 13:55:24,32835,[33415],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@angeliand 
I am able to successfully execute Colab notebook provided by you with a warning message.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/d23afdb38149eeb3fc179a6e30d20721/untitled254.ipynb).Please, let me know is this still an issue?.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-540927286,ravikyram,2019-10-11 06:20:04,33216,[33610],Algorithm design bug,0,"@angeliand I am able to successfully execute Colab notebook provided by you with a warning message.Please, find the gist [here]([url] let me know is this still an issue?.Thanks!",3
"As I have said, the problem is with what gets logged **during** the epoch. Not after. In your notebook you did not interrupt the training to view the printed log during the epoch. If interrupted the described behaviour can still be seen.
Also, I recommend running the script in command line (or anywhere, where the output is printed line by line), where the problem can be viewed without stopping the training.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-540942882,angeliand,2019-10-11 07:09:40,33216,[33610],Algorithm design bug,0,"As I have said, the problem is with what gets logged **during** the epoch. Not after. In your notebook you did not interrupt the training to view the printed log during the epoch. If interrupted the described behaviour can still be seen. Also, I recommend running the script in command line (or anywhere, where the output is printed line by line), where the problem can be viewed without stopping the training.",0
"@angeliand 
I tried running in command line and i am able to execute the .py file successfully. Please find the log file in the attachment.Is this the expected output?
[text.txt.tar.gz](https://github.com/tensorflow/tensorflow/files/3716797/text.txt.tar.gz).I could reproduce the issue in colab when i interrupted during training.Thanks!
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-540998553,ravikyram,2019-10-11 09:52:22,33216,[33610],Algorithm design bug,0,@angeliand I tried running in command line and i am able to execute the .py file successfully. Please find the log file in the attachment.Is this the expected output? [text.txt.tar.gz]([url] could reproduce the issue in colab when i interrupted during training.Thanks!,0
"As I have stated in the original post, the bug does not cause crashing, but it is still inconvenient and can be avoided easily with a minor fix (I have also offered a solution).
If logging is line by line (so when it doesnâ€™t refresh) eg. in PyCharm or when logging to file, the problem can be viewed easier. It appears during the first epoch and ceases when that is done. (Probably because after the first epoch, we know the number of steps.) This is why training has to be interrupted in colab to view the issue (or you can check the runtime logs in colab!).
Also the IteratorGetNext warning appears at the end of the first epoch before validating steps. This is because the training loop does not know the number of steps to take (â€”> times to â€œqueryâ€ the dataset) and the dataset runs out. 

All in all, this is not huge but still not what would be the expected behaviour. 
I will provide a log file from PyCharm in a few hours. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-541006428,angeliand,2019-10-11 10:17:29,33216,[33610],Algorithm design bug,0,"As I have stated in the original post, the bug does not cause crashing, but it is still inconvenient and can be avoided easily with a minor fix (I have also offered a solution). If logging is line by line (so when it doesnâ€™t refresh) eg. in PyCharm or when logging to file, the problem can be viewed easier. It appears during the first epoch and ceases when that is done. (Probably because after the first epoch, we know the number of steps.) This is why training has to be interrupted in colab to view the issue (or you can check the runtime logs in colab!). Also the IteratorGetNext warning appears at the end of the first epoch before validating steps. This is because the training loop does not know the number of steps to take (â€”> times to â€œqueryâ€ the dataset) and the dataset runs out. All in all, this is not huge but still not what would be the expected behaviour. I will provide a log file from PyCharm in a few hours.",0
"PyCharm output is line-by-line, so the problem can be seen better. Here is the output without the proposed solution: 
[keras_bug_op.txt](https://github.com/tensorflow/tensorflow/files/3717600/keras_bug_op.txt)
And here is the correct (expected) output after using the proposed solution:
[keras_bug_sol.txt](https://github.com/tensorflow/tensorflow/files/3717605/keras_bug_sol.txt)
Hope this helps.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-541050263,angeliand,2019-10-11 12:48:23,33216,[33610],Algorithm design bug,0,"PyCharm output is line-by-line, so the problem can be seen better. Here is the output without the proposed solution: [keras_bug_op.txt]([url] And here is the correct (expected) output after using the proposed solution: [keras_bug_sol.txt]([url] Hope this helps.",3
@angeliand Are you willing to contribute through PR to update relevant codes? Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-541795458,jvishnuvardhan,2019-10-14 16:58:49,33216,[33610],Algorithm design bug,0,@angeliand Are you willing to contribute through PR to update relevant codes? Thanks!,3
"Sure. I'm busy in the next few days, but I will do it after that.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-542572290,angeliand,2019-10-16 07:51:47,33216,[33610],Algorithm design bug,0,"Sure. I'm busy in the next few days, but I will do it after that.",2
It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-548351529,tensorflowbutler,2019-10-31 12:34:35,33216,[33610],Algorithm design bug,0,It has been 14 days with no activity and the [code] label was assigned. Is this still an issue?,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33216"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33216"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33216#issuecomment-548914109,tensorflow-bot[bot],2019-11-01 19:07:38,33216,[33610],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"You need brackets for the input. Try this:
```
c = tf.strings.split(['a b'])
c.values
```

",IssueComment,https://github.com/tensorflow/tensorflow/issues/33623#issuecomment-545829533,blairhan,2019-10-24 09:22:28,33623,[33625],Data bug,0,You need brackets for the input. Try this: ``[code]``,0
"> You need brackets for the input. Try this:
> 
> ```
> c = tf.strings.split(['a b'])
> c.values
> ```

tf.strings.split('a b',result_type='RaggedTensor') works and returns a Tensor.In fact, it should return a RaggedTensor",IssueComment,https://github.com/tensorflow/tensorflow/issues/33623#issuecomment-545874312,fsx950223,2019-10-24 11:27:09,33623,[33625],Data bug,0,"> You need brackets for the input. Try this: > > ``[code]`` tf.strings.split('a b',result_type='RaggedTensor') works and returns a Tensor.In fact, it should return a RaggedTensor",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33623"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33623"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33623#issuecomment-555216691,tensorflow-bot[bot],2019-11-18 21:26:42,33623,[33625],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Further Analysis shows that the real and imaginary components in the output are getting swapped with each other causing the array mismatch on Big Endian.
@jiefangxuanyan I could see [PR](https://github.com/tensorflow/tensorflow/pull/9876) for fixing endianness problem in the `decode_raw_op` functionality. However, the tests for complex data types have been recently added and need more changes for incorporating this particular case.
Could you please have a look?",IssueComment,https://github.com/tensorflow/tensorflow/issues/33496#issuecomment-543518378,abhay1722,2019-10-18 05:37:38,33496,[33816],Test bug,1,"Further Analysis shows that the real and imaginary components in the output are getting swapped with each other causing the array mismatch on Big Endian. @jiefangxuanyan I could see [PR]([url] for fixing endianness problem in the [code] functionality. However, the tests for complex data types have been recently added and need more changes for incorporating this particular case. Could you please have a look?",0
"@abhay1722,
In the process of reproducing the error, I have cloned the Branch corresponding to TF Version 2.0 and ran the command, 

`bazel test //usr/local/google/home/mothukuru/tensorflow- 2.0/tensorflow/python/kernel_tests:decode_raw_op_test` but it resulted in the below error, 

```
ERROR: The 'test' command is only supported from within a workspace (below a directory having a WORKSPACE file).
See documentation at https://docs.bazel.build/versions/master/build-ref.html#workspace
INFO: Writing tracer profile to '/usr/local/google/home/mothukuru/.cache/bazel/_bazel_mothukuru/d41d8cd98f00b204e9800998ecf8427e/command.profile.gz'
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
```

Can you please help us reproduce the error. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/33496#issuecomment-544462851,rmothukuru,2019-10-21 10:58:34,33496,[33816],Test bug,1,"@abhay1722, In the process of reproducing the error, I have cloned the Branch corresponding to TF Version 2.0 and ran the command, [code] but it resulted in the below error, ``[code]`` Can you please help us reproduce the error. Thanks!",0
"> @abhay1722,
> In the process of reproducing the error, I have cloned the Branch corresponding to TF Version 2.0 and ran the command,
> 
> `bazel test //usr/local/google/home/mothukuru/tensorflow- 2.0/tensorflow/python/kernel_tests:decode_raw_op_test` but it resulted in the below error,
> 
> ```
> ERROR: The 'test' command is only supported from within a workspace (below a directory having a WORKSPACE file).
> See documentation at https://docs.bazel.build/versions/master/build-ref.html#workspace
> INFO: Writing tracer profile to '/usr/local/google/home/mothukuru/.cache/bazel/_bazel_mothukuru/d41d8cd98f00b204e9800998ecf8427e/command.profile.gz'
> WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
> ```
> 
> Can you please help us reproduce the error. Thanks!

@rmothukuru I suggest that you run the test from the location where you have cloned the Tensorflow repo.
For instance, If I clone the [repo](https://github.com/tensorflow/tensorflow.git) in the `/home/test` folder, then I must do the following:-
```
cd /home/test/tensorflow/
bazel test //tensorflow/python/kernel_tests:decode_raw_op_test
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/33496#issuecomment-548730018,abhay1722,2019-11-01 09:52:21,33496,[33816],Test bug,1,"> @abhay1722, > In the process of reproducing the error, I have cloned the Branch corresponding to TF Version 2.0 and ran the command, > > [code] but it resulted in the below error, > > ``[code]`[code]/home/test[code]`[code]``",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33496"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33496"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33496#issuecomment-555623059,tensorflow-bot[bot],2019-11-19 17:40:47,33496,[33816],Test bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I could reproduce the issue with Tf 2.0.0. Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/48e54114ef599b79cd9d09e4a7fb9736/untitled201.ipynb). Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/33383#issuecomment-542550396,gadagashwini-zz,2019-10-16 06:52:50,33383,[33887],Data bug,1,I could reproduce the issue with Tf 2.0.0. Please see the gist [here]([url] Thanks!,0
"This is working as intended. The good dataset dropped `0.0` while the bad dataset dropped `1 / 0.0`.

@scharron What output would you expect for your example?",IssueComment,https://github.com/tensorflow/tensorflow/issues/33383#issuecomment-547687717,jsimsa,2019-10-30 00:31:24,33383,[33887],Data bug,1,This is working as intended. The good dataset dropped [code] while the bad dataset dropped [code]. @scharron What output would you expect for your example?,0
"@jsimsa Oops sorry I went too fast, I fixed the code to reproduce

(if zipping `good` then `bad` it works, but the reverse does not)
 ",IssueComment,https://github.com/tensorflow/tensorflow/issues/33383#issuecomment-548303972,scharron,2019-10-31 10:25:17,33383,[33887],Data bug,1,"@jsimsa Oops sorry I went too fast, I fixed the code to reproduce (if zipping [code] then [code] it works, but the reverse does not)",0
"I think the issue is that, in case of zip, when error or end-of-sequence encountered the remaining components are not ""flushed out"".  So out-of-sync happens when ignore_errors is in play.

Created a PR #33887, think this could fix the issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33383#issuecomment-548423329,yongtang,2019-10-31 15:12:27,33383,[33887],Data bug,1,"I think the issue is that, in case of zip, when error or end-of-sequence encountered the remaining components are not ""flushed out"". So out-of-sync happens when ignore_errors is in play. Created a PR #33887, think this could fix the issue.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33383"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33383"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33383#issuecomment-548978293,tensorflow-bot[bot],2019-11-01 23:01:08,33383,[33887],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thanks !

Wouldn't it be possible and useful to also issue a warning if the `tf.data.experimental.ignore_errors` is applied to any Dataset used as input to `tf.data.Dataset.zip`.

This could also result in datasets desynchronization if any of the zipped datasets drops any item, and in my opinion shouldn't be the behaviour of a `zip` function.



 ",IssueComment,https://github.com/tensorflow/tensorflow/issues/33383#issuecomment-549381841,scharron,2019-11-04 14:35:26,33383,[33887],Data bug,1,"Thanks ! Wouldn't it be possible and useful to also issue a warning if the [code] is applied to any Dataset used as input to [code]. This could also result in datasets desynchronization if any of the zipped datasets drops any item, and in my opinion shouldn't be the behaviour of a [code] function.",1
"@dbonner 

I tried to reproduce the issue. However i am seeing the different error.`AttributeError: 'LinearRegressionTF' object has no attribute 'fit'` .Please, help me with the reproducible code . It helps in localizing the issue faster.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33799#issuecomment-547267137,ravikyram,2019-10-29 05:49:28,33799,[33953],Version compatibility bug,0,"@dbonner I tried to reproduce the issue. However i am seeing the different error.[code] .Please, help me with the reproducible code . It helps in localizing the issue faster.",0
"@ravikyram 
I'm sorry the code is not properly indented in a number of places when it appears in github.  I can't seem to edit it to get it to show properly.  Please find an attached file (moved to next post)  with the properly indented code that reproduces this error on my system when running in one cell in Jupyter Notebook.
Apologies .... See the next post for the correct file.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33799#issuecomment-547482144,dbonner,2019-10-29 15:33:28,33799,[33953],Version compatibility bug,0,@ravikyram I'm sorry the code is not properly indented in a number of places when it appears in github. I can't seem to edit it to get it to show properly. Please find an attached file (moved to next post) with the properly indented code that reproduces this error on my system when running in one cell in Jupyter Notebook. Apologies .... See the next post for the correct file.,-1
"@ravikyram 
I've finally got this right.  Sorry to mess you around with this.  Github markdown removed the underscores on the init part of the LinearRegressionTF() class when I pasted it in.  This got transferred through to the code file.  The correct code is attached.  It runs fine in Python 3.7 but errors in Python 3.8.  I have also removed the reference to the subdirectory ""small_data"" so you can run the code with the file ""cal_house.json.gz"" in the current working directory.
[code_py38_tf2_error.txt](https://github.com/tensorflow/tensorflow/files/3786825/code_py38_tf2_error.txt)
[cal_house.json.gz](https://github.com/tensorflow/tensorflow/files/3786826/cal_house.json.gz)

",IssueComment,https://github.com/tensorflow/tensorflow/issues/33799#issuecomment-547727485,dbonner,2019-10-30 03:48:54,33799,[33953],Version compatibility bug,0,"@ravikyram I've finally got this right. Sorry to mess you around with this. Github markdown removed the underscores on the init part of the LinearRegressionTF() class when I pasted it in. This got transferred through to the code file. The correct code is attached. It runs fine in Python 3.7 but errors in Python 3.8. I have also removed the reference to the subdirectory ""small_data"" so you can run the code with the file ""cal_house.json.gz"" in the current working directory. [code_py38_tf2_error.txt]([url] [cal_house.json.gz]([url]",1
"Hi @ymodak,
Have you had a chance to test the python 3.8 error I reported (Issue: #33799).
All the best,
Dan",IssueComment,https://github.com/tensorflow/tensorflow/issues/33799#issuecomment-549109518,dbonner,2019-11-03 06:33:12,33799,[33953],Version compatibility bug,0,"Hi @ymodak, Have you had a chance to test the python 3.8 error I reported (Issue: #33799). All the best, Dan",0
"I am able to reproduce the issue with the following command on python 3.8 (master build):
```
bazel test -s --verbose_failures --disk_cache=/home/ubuntu/bazel \
        //tensorflow/python:image_ops_test
```

Haven't figure out the reason yet.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33799#issuecomment-549161453,yongtang,2019-11-03 17:48:31,33799,[33953],Version compatibility bug,0,I am able to reproduce the issue with the following command on python 3.8 (master build): ``[code]`` Haven't figure out the reason yet.,0
@dbonner @ymodak Added a PR #33953 for the fix. Please take a look.,IssueComment,https://github.com/tensorflow/tensorflow/issues/33799#issuecomment-549173002,yongtang,2019-11-03 20:02:57,33799,[33953],Version compatibility bug,0,@dbonner @ymodak Added a PR #33953 for the fix. Please take a look.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33799"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33799"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33799#issuecomment-551038960,tensorflow-bot[bot],2019-11-07 11:24:21,33799,[33953],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I recieved this error also when using tensorflow 1.13.2 + python 3.8 I am considering opening a separate issue. ,IssueComment,https://github.com/tensorflow/tensorflow/issues/33799#issuecomment-552819479,odinsbane,2019-11-12 09:54:19,33799,[33953],Version compatibility bug,0,I recieved this error also when using tensorflow 1.13.2 + python 3.8 I am considering opening a separate issue.,0
"@DoumanAsh 

Sorry for the late reply; I've been out on a conference.

Hm, I'm not sure what that flag does, and re: your question of:

> Is there any particular reason for that?

The people owning TFLite and who delivers the TFLite GPU are different set of people with the latter (I belong here) being more agnostic of what the proper way is :p 

Please feel free to send a PR to me and @jdduke ",IssueComment,https://github.com/tensorflow/tensorflow/issues/33676#issuecomment-551938109,impjdi,2019-11-08 18:25:29,33676,[34108],Processor bug,0,"@DoumanAsh Sorry for the late reply; I've been out on a conference. Hm, I'm not sure what that flag does, and re: your question of: > Is there any particular reason for that? The people owning TFLite and who delivers the TFLite GPU are different set of people with the latter (I belong here) being more agnostic of what the proper way is :p Please feel free to send a PR to me and @jdduke",1
"Hi @DoumanAsh, thanks for flagging, we should absolutely be consistent. If you want to propose a PR, feel free to, otherwise I can take a look.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33676#issuecomment-551948849,jdduke,2019-11-08 18:56:59,33676,[34108],Processor bug,0,"Hi @DoumanAsh, thanks for flagging, we should absolutely be consistent. If you want to propose a PR, feel free to, otherwise I can take a look.",3
"Looking over at the delegate API, I see only C API (which is marked visible in code).
So I think the simplest approach would be is to by default build with `hidden` visibility.
Which doesn't require any extra linking script (this is also what we do internally when we build delegate)

So I'd suggest it as PR with visibility hidden by default for now as all vital APIs are marked with `TFL_CAPI_EXPORT` which resolves to corresponding attribute.
@jdduke does it sound good to you?",IssueComment,https://github.com/tensorflow/tensorflow/issues/33676#issuecomment-551956381,DoumanAsh,2019-11-08 19:19:06,33676,[34108],Processor bug,0,"Looking over at the delegate API, I see only C API (which is marked visible in code). So I think the simplest approach would be is to by default build with [code] visibility. Which doesn't require any extra linking script (this is also what we do internally when we build delegate) So I'd suggest it as PR with visibility hidden by default for now as all vital APIs are marked with [code] which resolves to corresponding attribute. @jdduke does it sound good to you?",1
"As a side question.
I noticed that 1.15 brought a new GPU Delegate.
Are there any plans for which is going to be a final one?",IssueComment,https://github.com/tensorflow/tensorflow/issues/33676#issuecomment-551962374,DoumanAsh,2019-11-08 19:36:44,33676,[34108],Processor bug,0,As a side question. I noticed that 1.15 brought a new GPU Delegate. Are there any plans for which is going to be a final one?,0
"The new GPU delegate you are referring to probably has the logic of ""try to use OpenCL if available,  fallback to OpenGL otherwise"".  I'm not 100% certain whether we will kill off the ""old"" OpenGL delegate, but chances are high.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33676#issuecomment-551965739,impjdi,2019-11-08 19:46:44,33676,[34108],Processor bug,0,"The new GPU delegate you are referring to probably has the logic of ""try to use OpenCL if available, fallback to OpenGL otherwise"". I'm not 100% certain whether we will kill off the ""old"" OpenGL delegate, but chances are high.",0
"Hi @DoumanAsh, the V2 delegate is going to be the default going forward. The pre-compiled GPU delegate (on JCenter/Maven) has already been updated to use this variant, as has our benchmark tooling. We're preparing a blog post, and will likely deprecate the ""V1"" API at some point.",IssueComment,https://github.com/tensorflow/tensorflow/issues/33676#issuecomment-551965901,jdduke,2019-11-08 19:47:13,33676,[34108],Processor bug,0,"Hi @DoumanAsh, the V2 delegate is going to be the default going forward. The pre-compiled GPU delegate (on JCenter/Maven) has already been updated to use this variant, as has our benchmark tooling. We're preparing a blog post, and will likely deprecate the ""V1"" API at some point.",3
"Good to know, I will be shifting our code base to use it then",IssueComment,https://github.com/tensorflow/tensorflow/issues/33676#issuecomment-551969371,DoumanAsh,2019-11-08 19:58:07,33676,[34108],Processor bug,0,"Good to know, I will be shifting our code base to use it then",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33676"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33676"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/33676#issuecomment-559228437,tensorflow-bot[bot],2019-11-27 19:47:20,33676,[34108],Processor bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Hi @tensorflower, I opened a pull request there #34295  for this issue. If someone would like to review it, I'd very appreciate it  ðŸ˜„ ",IssueComment,https://github.com/tensorflow/tensorflow/issues/34250#issuecomment-553662687,pengwu22,2019-11-14 00:07:13,34250,[34295],Data bug,1,"Hi @tensorflower, I opened a pull request there #34295 for this issue. If someone would like to review it, I'd very appreciate it ðŸ˜„",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34250"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34250"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/34250#issuecomment-555277316,tensorflow-bot[bot],2019-11-19 00:41:07,34250,[34295],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I found the tensorflow jar does not include `org/tensorflow/native/linux-x86_64/libtensorflow_framework.so`, but include `org/tensorflow/native/linux-x86_64/libtensorflow_framework.so.1`, so it failed to copy `libtensorflow_framework.so` to tmp directory when loading the native library.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34256#issuecomment-553686566,sharkdtu,2019-11-14 01:49:43,34256,[34453],Code bug,0,"I found the tensorflow jar does not include [code], but include [code], so it failed to copy [code] to tmp directory when loading the native library.",-2
`NativeLibrary.getMajorVersionNumber` returns `null` when libtensorflow and libtensorflow_jni jar were shaded to my jar,IssueComment,https://github.com/tensorflow/tensorflow/issues/34256#issuecomment-553719855,sharkdtu,2019-11-14 04:32:30,34256,[34453],Code bug,0,[code] returns [code] when libtensorflow and libtensorflow_jni jar were shaded to my jar,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34256"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34256"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/34256#issuecomment-574868252,tensorflow-bot[bot],2020-01-15 21:38:40,34256,[34453],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I had the same problem (using a shaded jar, `NativeLibrary.getMajorVersionNumber` returned null). But since your fix wasn't yet available in the 1.15 release, I worked around it by adding an `Implementation-Version` that starts with `1.` to the shaded jar's manifest using Maven's `ManifestResourceTransformer`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34256#issuecomment-596670276,mttsndrs,2020-03-09 17:29:55,34256,[34453],Code bug,0,"I had the same problem (using a shaded jar, [code] returned null). But since your fix wasn't yet available in the 1.15 release, I worked around it by adding an [code] that starts with [code] to the shaded jar's manifest using Maven's [code].",0
@mttsndrs Could you share what you did with the manifest resource transformer? I'm having a similar problem.,IssueComment,https://github.com/tensorflow/tensorflow/issues/34256#issuecomment-784515082,geometrikal,2021-02-23 21:10:34,34256,[34453],Code bug,0,@mttsndrs Could you share what you did with the manifest resource transformer? I'm having a similar problem.,0
"@geometrikal I added this to the pom.xml:
```
    <properties>
        <tensorflow.version>1.15.0</tensorflow.version>
    </properties>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <configuration>
                    <transformers combine.self=""override"">
                        <transformer implementation=""org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"">
                            <manifestEntries>
                                <!--
                                Note: When loaded from a jar, tensorflow will use the
                                ""Implementation-Version"" tag in the jar's manifest to identify the
                                tensorflow_framework lib to extract. When packaged in a shaded jar,
                                this can cause problems locating the correct version of the
                                tensorflow library.
                                By overriding the ""Implementation-Version"" tag here, we ensure that
                                the correct tensorflow_framework lib gets extracted at runtime.
                                -->
                                <Implementation-Version>${tensorflow.version}</Implementation-Version>
                            </manifestEntries>
                        </transformer>
                    </transformers>
                </configuration>
            </plugin>
        </plugins>
    </build>
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/34256#issuecomment-784541103,mttsndrs,2021-02-23 21:57:24,34256,[34453],Code bug,0,@geometrikal I added this to the pom.xml: ``[code]``,0
"I have tried on colab with TF version 2.0 ,2.1.0-dev20191111 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/4f70bc0621bc1d362ed8d465b7cb054a/untitled377.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-554920723,ravikyram,2019-11-18 09:05:06,34332,[34779],Data bug,0,"I have tried on colab with TF version 2.0 ,2.1.0-dev20191111 and was able to reproduce the issue.Please, find the gist [here]([url] Thanks!",0
"The current behavior was intended, but on second thought, I think you are right and that this behavior is incorrect. I previously incorrectly believed `Variable.assign` returned a tensor, not a Variable, and wanted the returned tensor to have the same dtype as the input tensor (float32).

Luckily, this issue occurs relatively rarely. AutoCastVariables act identically to Variables outside `Layer.call`, and inside `Layer.call`, variables are rarely assigned to. Still, the current behavior is very confusing and so this should be fixed.

@alextp, do you know what the purpose of the  [`_UnreadVariable`](https://github.com/tensorflow/tensorflow/blob/2692ea8ec1953e42952597adb5b5099181a679b2/tensorflow/python/ops/resource_variable_ops.py#L1806) is, which is returned from [`ResourceVariable.assign`](https://github.com/tensorflow/tensorflow/blob/2692ea8ec1953e42952597adb5b5099181a679b2/tensorflow/python/ops/resource_variable_ops.py#L799)? Why not simply return the ResourceVariable? Do you think I should I create a `_UnreadAutoCastVariable` subclass?",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-555291521,reedwm,2019-11-19 01:38:39,34332,[34779],Data bug,0,"The current behavior was intended, but on second thought, I think you are right and that this behavior is incorrect. I previously incorrectly believed [code] returned a tensor, not a Variable, and wanted the returned tensor to have the same dtype as the input tensor (float32). Luckily, this issue occurs relatively rarely. AutoCastVariables act identically to Variables outside [code], and inside [code], variables are rarely assigned to. Still, the current behavior is very confusing and so this should be fixed. @alextp, do you know what the purpose of the [[code]]([url]#L1806) is, which is returned from [[code]]([url]#L799)? Why not simply return the ResourceVariable? Do you think I should I create a [code] subclass?",1
"@reedwm Thanks for taking a look.

The reason why I am looking deeper at the implementation of `AutoCastVariable` is because we are in the process of subclassing `tf.Variable` in https://github.com/larq/larq/issues/306 with the goal to have a `QuantizedVariable` that can be used to define arbitrary fake quantizations like binary or ternary  quantization which would allow easy research on extreme quantization. For this we are looking closely at the implementation of `AutoCastVariable`.

@reedwm @alextp Do you think it makes sense to have a more formalized way to easily subclass `tf.Variable` or `tf.Tensor` in userland? It seams this already happens in a few places (e.g. `AutoCastVariable` or #34379) and would allow quite powerful use cases.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-555462542,lgeiger,2019-11-19 11:20:24,34332,[34779],Data bug,0,@reedwm Thanks for taking a look. The reason why I am looking deeper at the implementation of [code] is because we are in the process of subclassing [code] in [url] with the goal to have a [code] that can be used to define arbitrary fake quantizations like binary or ternary quantization which would allow easy research on extreme quantization. For this we are looking closely at the implementation of [code]. @reedwm @alextp Do you think it makes sense to have a more formalized way to easily subclass [code] or [code] in userland? It seams this already happens in a few places (e.g. [code] or #34379) and would allow quite powerful use cases.,3
"@reedwm the purpose of `_UnreadVariable` is allowing code like `x = tf.assign_add(x, foo); x = tf.assign_add(x, bar)` which was possible with ref variables and so to ease the transition to resource variables I made `_UnreadVariable`

@lgeiger I'm with you, I really don't like how complex variables are right now. I think if you control the variable creation site I recommend instead of subclassing variable you implement a tf.Module which implements the variable interface and has a tf.register_tensor_conversion_function for itself (so it can be implicitly cast to a tensor). If you cannot control the variable creation site I mostly recommend the same thing but you might want to use a variable_creation_scope to intercept variable creation and return your custom class. Just make sure to use the underlying creator when creating the variables inside your fake-variable.

Re subclassing tensors, the answer is an emphatic no. We need to have Tensor be a C type (at least in eager mode) for performance in many places, as eventually tensors will have to be passed to kernels.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-555600557,alextp,2019-11-19 16:51:26,34332,[34779],Data bug,0,"@reedwm the purpose of [code] is allowing code like [code] which was possible with ref variables and so to ease the transition to resource variables I made [code] @lgeiger I'm with you, I really don't like how complex variables are right now. I think if you control the variable creation site I recommend instead of subclassing variable you implement a tf.Module which implements the variable interface and has a tf.register_tensor_conversion_function for itself (so it can be implicitly cast to a tensor). If you cannot control the variable creation site I mostly recommend the same thing but you might want to use a variable_creation_scope to intercept variable creation and return your custom class. Just make sure to use the underlying creator when creating the variables inside your fake-variable. Re subclassing tensors, the answer is an emphatic no. We need to have Tensor be a C type (at least in eager mode) for performance in many places, as eventually tensors will have to be passed to kernels.",0
"> The reason why I am looking deeper at the implementation of AutoCastVariable is because we are in the process of subclassing tf.Variable in larq/larq#306

I think having an implementation similar to `AutoCastVariable` is the way to go. I agree it would be nice to have a more formalized way to subclass `tf.Variable` but it currently doesn't exist unfortunately.

> I think if you control the variable creation site I recommend instead of subclassing variable you implement a tf.Module

@alextp, I would still recommend subclassing tf.Variable. I used to subclass Trackable, but I switched to tf.Variable in 74c52531846cc10a63fb244966ab6bfd000af747 as many parts of the code have isinstance checks on tf.Variable. DistributedVariable also subclasses Variable for a similar reason. And tf.Module has some extraneous properties that don't make a lot of sense on a Variable, such as `Module.trainable_variables`.

> the purpose of _UnreadVariable is allowing code like x = tf.assign_add(x, foo); x = tf.assign_add(x, bar) 

Ah I see, returning an `_UnreadVariable` instead of `self` allows this to properly work with Sessions and Graphs, which don't have automatic control dependencies. Otherwise, if `self` is returned, the variable assignment might not run.

I could fix this by copying or subclassing `_UnreadVariable`. I could also just return `self`, which has slightly incorrect semantics when Sessions/Graphs are used with `tf.compat.v1`. I'll try to think of a better solution, especially considering QuantizedVariable will have the same issue. I'm pretty sure DistributedVariables also has this issue.

",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-555726271,reedwm,2019-11-19 21:35:16,34332,[34779],Data bug,0,"> The reason why I am looking deeper at the implementation of AutoCastVariable is because we are in the process of subclassing tf.Variable in larq/larq#306 I think having an implementation similar to [code] is the way to go. I agree it would be nice to have a more formalized way to subclass [code] but it currently doesn't exist unfortunately. > I think if you control the variable creation site I recommend instead of subclassing variable you implement a tf.Module @alextp, I would still recommend subclassing tf.Variable. I used to subclass Trackable, but I switched to tf.Variable in 74c52531846cc10a63fb244966ab6bfd000af747 as many parts of the code have isinstance checks on tf.Variable. DistributedVariable also subclasses Variable for a similar reason. And tf.Module has some extraneous properties that don't make a lot of sense on a Variable, such as [code]. > the purpose of _UnreadVariable is allowing code like x = tf.assign_add(x, foo); x = tf.assign_add(x, bar) Ah I see, returning an [code] instead of [code] allows this to properly work with Sessions and Graphs, which don't have automatic control dependencies. Otherwise, if [code] is returned, the variable assignment might not run. I could fix this by copying or subclassing [code]. I could also just return [code], which has slightly incorrect semantics when Sessions/Graphs are used with [code]. I'll try to think of a better solution, especially considering QuantizedVariable will have the same issue. I'm pretty sure DistributedVariables also has this issue.",0
Thanks a lot for the insights. It would be cool if we could come up with a simple solution for this.,IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-557789262,lgeiger,2019-11-23 11:18:27,34332,[34779],Data bug,0,Thanks a lot for the insights. It would be cool if we could come up with a simple solution for this.,3
"> I could fix this by copying or subclassing `_UnreadVariable`. I could also just return `self`, which has slightly incorrect semantics when Sessions/Graphs are used with `tf.compat.v1`

@reedwm Since `AutoCastVariable` just wraps an other variable, what about returning a new instance wrapping the `_UnreadVariable` returned by the assign op. Would something like the following work?
```python
def assign(self, value, use_locking=None, name=None, read_value=True):
    assign_op_or_var = self._variable.assign(value, use_locking, name, read_value)
    return self.__class__(assign_op_or_var) if read_value else assign_op_or_var
#   return AutoCastVariable(assign_op_or_var) if read_value else assign_op_or_var
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-559880954,lgeiger,2019-11-29 21:09:04,34332,[34779],Data bug,0,"> I could fix this by copying or subclassing [code]. I could also just return [code], which has slightly incorrect semantics when Sessions/Graphs are used with [code] @reedwm Since [code] just wraps an other variable, what about returning a new instance wrapping the [code] returned by the assign op. Would something like the following work? ``[code]``",0
"I think that would work, and is very simple. I didn't think of that before. Thanks for the suggestion!

Do you want to implement it for AutoCastVariable? If not, I'd be happy to.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-560576062,reedwm,2019-12-02 20:53:31,34332,[34779],Data bug,0,"I think that would work, and is very simple. I didn't think of that before. Thanks for the suggestion! Do you want to implement it for AutoCastVariable? If not, I'd be happy to.",4
"> I think that would work, and is very simple.

Great!

> Do you want to implement it for AutoCastVariable? If not, I'd be happy to.

:+1: Will send a PR and add some tests once TensorFlow finishes compiling on my machine.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-560588708,lgeiger,2019-12-02 21:28:12,34332,[34779],Data bug,0,"> I think that would work, and is very simple. Great! > Do you want to implement it for AutoCastVariable? If not, I'd be happy to. :+1: Will send a PR and add some tests once TensorFlow finishes compiling on my machine.",5
I opened a small PR: #34779,IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-560965968,lgeiger,2019-12-03 02:10:10,34332,[34779],Data bug,0,I opened a small PR: #34779,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34332"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34332"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-562368814,tensorflow-bot[bot],2019-12-05 23:46:01,34332,[34779],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
#34779 doesn't fully close this issue since Distribution Strategy is not fully supported yet (see https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353481035),IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-562375150,lgeiger,2019-12-06 00:11:59,34332,[34779],Data bug,0,#34779 doesn't fully close this issue since Distribution Strategy is not fully supported yet (see [url]#discussion_r353481035),-1
"You're right, reopening.

Once Distribution Strategy returns a variable from `DistributionVariable.assign`, this issue can be fixed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-562375522,reedwm,2019-12-06 00:13:36,34332,[34779],Data bug,0,"You're right, reopening. Once Distribution Strategy returns a variable from [code], this issue can be fixed.",1
:+1: Thanks for the help with debugging,IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-562376228,lgeiger,2019-12-06 00:16:45,34332,[34779],Data bug,0,:+1: Thanks for the help with debugging,5
@lgeiger Is this still an issue? Can you please check with `tf-nightly` and let us know. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-599746488,jvishnuvardhan,2020-03-16 20:35:23,34332,[34779],Data bug,0,@lgeiger Is this still an issue? Can you please check with [code] and let us know. Thanks!,0
"This is still an issue. The `tf.distribute.Strategy` team is working on a way to return a variable from `DistributionVariable.assign` and until then, this issue cannot be fully fixed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-599762797,reedwm,2020-03-16 21:18:24,34332,[34779],Data bug,0,"This is still an issue. The [code] team is working on a way to return a variable from [code] and until then, this issue cannot be fully fixed.",-1
"@jvishnuvardhan Sorry for the late response. Indeed this is still an issue in the latest nightly. Here is an updated code example for the distribution case:
```python
import tensorflow as tf
from tensorflow.python.keras.mixed_precision.experimental import autocast_variable
from tensorflow.python.distribute import strategy_combinations

strategy_combinations.set_virtual_cpus_to_at_least(3)
with tf.distribute.MirroredStrategy(['/cpu:1', '/cpu:2']).scope():
    var = tf.Variable(0., dtype=tf.float32)
    var = autocast_variable.AutoCastVariable(var)

    with tf.compat.v1.get_default_graph()._enable_auto_casting_variables(tf.float16):
        assert var.dtype == tf.float16
        # assign should return an AutoCastVariable but returns tf.Variable
        var_assign = var.assign(5.)
        assert not isinstance(var_assign, autocast_variable.AutoCastVariable)
        assert var_assign.dtype == tf.float32
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-618089514,lgeiger,2020-04-22 23:23:17,34332,[34779],Data bug,0,@jvishnuvardhan Sorry for the late response. Indeed this is still an issue in the latest nightly. Here is an updated code example for the distribution case: ``[code]``,-1
Can we close this?,IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-849992910,bhack,2021-05-27 22:52:25,34332,[34779],Data bug,0,Can we close this?,0
"> Can we close this?

This is still an issue in the latest nightly, but now only shows up in non eager mode. Before this happened in both execution contexts. Here is some updated code that reproduces the failure with the new API:
```python
import tensorflow as tf
from tensorflow.python.keras.mixed_precision import autocast_variable
from tensorflow.python.distribute import strategy_combinations
tf.compat.v1.disable_eager_execution()

strategy_combinations.set_virtual_cpus_to_at_least(3)
with tf.distribute.MirroredStrategy(['/cpu:1', '/cpu:2']).scope():
    var = tf.Variable(0., dtype=tf.float32)
    var = autocast_variable.AutoCastVariable(var)
    with autocast_variable.enable_auto_cast_variables(tf.float16):
        assert tf.identity(var).dtype == tf.float16
        # assign should return an AutoCastVariable but returns tf.Variable
        var_assign = var.assign(5.)
        assert isinstance(var_assign, autocast_variable.AutoCastVariable)
        assert tf.identity(var).dtype == tf.float16
```
        ",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-850305754,lgeiger,2021-05-28 10:02:34,34332,[34779],Data bug,0,"> Can we close this? This is still an issue in the latest nightly, but now only shows up in non eager mode. Before this happened in both execution contexts. Here is some updated code that reproduces the failure with the new API: ``[code]``",0
@lgeiger Do you think that you could add this with a minimal refactoring as a [DISABLED test](https://github.com/google/googletest/blob/master/docs/advanced.md#temporarily-disabling-tests)?,IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-850398378,bhack,2021-05-28 12:54:15,34332,[34779],Data bug,0,@lgeiger Do you think that you could add this with a minimal refactoring as a [DISABLED test]([url]#temporarily-disabling-tests)?,0
"> Do you think that you could add this with a minimal refactoring as a DISABLED test?

@bhack These cases are already covered in [`tensorflow/python/keras/mixed_precision/autocast_variable_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/mixed_precision/autocast_variable_test.py).

In fact I just opened #49856 earlier today to enable the distribution strategy tests in eager mode which have been fixed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-850416243,lgeiger,2021-05-28 13:23:31,34332,[34779],Data bug,0,> Do you think that you could add this with a minimal refactoring as a DISABLED test? @bhack These cases are already covered in [[code]]([url] In fact I just opened #49856 earlier today to enable the distribution strategy tests in eager mode which have been fixed.,3
"What I mean is that if we have DISABLED tests referencing specific tickets we could regularly check what is ""still not"" working as we expected and running the CI with an extra step on DISABLED tests (or any other semantic filter we want to use). 

In this way we could see if the behavior is changed or if it solved when the specific test is failing. 
In that case we could comment again or close the related ticket.

So in DISABLED tests we assert the BUG not the correct behavior.

E.g. In this way we could have covered the evolution of this bug since 2019.

This is just an idea cause we currently don't run specific DISABLED tests (or any special test filter semantics) in the CI. 

/cc @mihaimaruseac @reedwm 
",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-850428908,bhack,2021-05-28 13:42:40,34332,[34779],Data bug,0,"What I mean is that if we have DISABLED tests referencing specific tickets we could regularly check what is ""still not"" working as we expected and running the CI with an extra step on DISABLED tests (or any other semantic filter we want to use). In this way we could see if the behavior is changed or if it solved when the specific test is failing. In that case we could comment again or close the related ticket. So in DISABLED tests we assert the BUG not the correct behavior. E.g. In this way we could have covered the evolution of this bug since 2019. This is just an idea cause we currently don't run specific DISABLED tests (or any special test filter semantics) in the CI. /cc @mihaimaruseac @reedwm",0
"This is a good idea, but I personally don't think it's worth the infrastructure complexity of running DISABLED tests to check whether a bug is fixed. Typically if a bug is fixed, someone will write a corresponding unit test. This bug is an exception, but even so, it was not fully fixed (it still doesn't work with distribution strategies in graph mode).",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-853378257,reedwm,2021-06-02 20:58:34,34332,[34779],Data bug,0,"This is a good idea, but I personally don't think it's worth the infrastructure complexity of running DISABLED tests to check whether a bug is fixed. Typically if a bug is fixed, someone will write a corresponding unit test. This bug is an exception, but even so, it was not fully fixed (it still doesn't work with distribution strategies in graph mode).",-1
"@reedwm I have an initial draft proposal about this internally, please ping me if you are interested.

>  Typically if a bug is fixed, someone will write a corresponding unit test.

But we still have some good side effects with DISABLED tests. 

Just to mention a few of these:

- Improved triage. We will have a good proxy of the final test (the one when ""a bug is fixed, someone will write a corresponding unit test"")
- We have for sure a more isolated code gist to reproduce the bug specially over the time axis (some tickets stay open for months, years).
- We don't need to periodically ping and review all the old tickets about reproducibility with master or with last release often with an not so isolated gist or without the original submitter/subscribers availability.
- We could run this on tf-nightly wheels without compiling TF.
- If we exclude some complex env we could run these test on Github Action directly or on Self-hosted Github Action runners.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-853413478,bhack,2021-06-02 22:04:33,34332,[34779],Data bug,0,"@reedwm I have an initial draft proposal about this internally, please ping me if you are interested. > Typically if a bug is fixed, someone will write a corresponding unit test. But we still have some good side effects with DISABLED tests. Just to mention a few of these: - Improved triage. We will have a good proxy of the final test (the one when ""a bug is fixed, someone will write a corresponding unit test"") - We have for sure a more isolated code gist to reproduce the bug specially over the time axis (some tickets stay open for months, years). - We don't need to periodically ping and review all the old tickets about reproducibility with master or with last release often with an not so isolated gist or without the original submitter/subscribers availability. - We could run this on tf-nightly wheels without compiling TF. - If we exclude some complex env we could run these test on Github Action directly or on Self-hosted Github Action runners.",0
"Hi There,

 This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! 

 Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-994135379,tensorflowbutler,2021-12-14 23:27:10,34332,[34779],Data bug,0,"Hi There, This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras]([url] repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks!",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34332"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34332"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/34332#issuecomment-1010211941,google-ml-butler[bot],2022-01-11 17:48:57,34332,[34779],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"There issue seems to be that, when `import carla` is presented, I/O operation fails for `std::ostringstream s`.

Created a PR #34847 so that in case of failure, fallback to normal conversion.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34828#issuecomment-561955121,yongtang,2019-12-05 03:45:33,34828,[34847],Build bug,0,"There issue seems to be that, when [code] is presented, I/O operation fails for [code]. Created a PR #34847 so that in case of failure, fallback to normal conversion.",0
I have also created the trivial pull request which passes `experimental_relas_shapes` to the wrapped bound methods.,IssueComment,https://github.com/tensorflow/tensorflow/issues/34905#issuecomment-564428918,foxik,2019-12-11 08:16:01,34905,[35021],Data bug,0,I have also created the trivial pull request which passes [code] to the wrapped bound methods.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34905"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34905"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/34905#issuecomment-566200574,tensorflow-bot[bot],2019-12-16 19:13:10,34905,[35021],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35117"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35117"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35117#issuecomment-581826341,tensorflow-bot[bot],2020-02-04 09:48:55,35117,[35125],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
How to include gtl correctly for the gtl::string_as_array function used in the file?,IssueComment,https://github.com/tensorflow/tensorflow/issues/35040#issuecomment-564770504,rahul003,2019-12-11 22:56:16,35040,[35139],Test bug,0,How to include gtl correctly for the gtl::string_as_array function used in the file?,0
Added #35139 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/35040#issuecomment-565834846,yongtang,2019-12-15 18:35:48,35040,[35139],Test bug,0,Added #35139 for the fix.,0
"My phone is jacked

On Wed, Dec 18, 2019, 03:35 TensorFlow Copybara <notifications@github.com>
wrote:

> Closed #35040 <https://github.com/tensorflow/tensorflow/issues/35040> via
> #35139 <https://github.com/tensorflow/tensorflow/pull/35139>.
>
> â€”
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/35040?email_source=notifications&email_token=AOBPXOV2MJCKFJZ47ADS7J3QZHVETA5CNFSM4JZWLOSKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOVRWQPPY#event-2892826559>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AOBPXOUSB7IYOQQBUJOS2JTQZHVETANCNFSM4JZWLOSA>
> .
>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35040#issuecomment-566953973,hf-sky-hf,2019-12-18 09:39:14,35040,[35139],Test bug,0,"My phone is jacked On Wed, Dec 18, 2019, 03:35 TensorFlow Copybara <[email]> wrote: > Closed #35040 <[url] via > #35139 <[url] > > â€” > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub > <[url]#event-2892826559>, > or unsubscribe > <[url] > . >",-3
Created PR #35196 with the upgrade of boringssl,IssueComment,https://github.com/tensorflow/tensorflow/issues/35179#issuecomment-566828296,yongtang,2019-12-18 01:42:11,35179,[35196],Build bug,0,Created PR #35196 with the upgrade of boringssl,2
Issue being tracked in the PR https://github.com/tensorflow/tensorflow/pull/35196.,IssueComment,https://github.com/tensorflow/tensorflow/issues/35179#issuecomment-575473235,abhay1722,2020-01-17 05:39:59,35179,[35196],Build bug,0,Issue being tracked in the PR [url],0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35179"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35179"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35179#issuecomment-575473242,tensorflow-bot[bot],2020-01-17 05:40:01,35179,[35196],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@guglielmocamporese Are you willing to open a PR to fix the doc?,IssueComment,https://github.com/tensorflow/tensorflow/issues/35136#issuecomment-565851841,yongtang,2019-12-15 22:07:51,35136,[35232],Documentation bug,0,@guglielmocamporese Are you willing to open a PR to fix the doc?,0
"@Squadrick,
Hello, Please try giving `run_eagerly=True` as a parameter to compile it should work fine, kindly refer the [link](https://www.tensorflow.org/guide/keras/overview#train_and_evaluate).
Also find the [gist](https://colab.sandbox.google.com/gist/oanush/e1262a3a58d8bf0e6bb4419b361e78d7/34890.ipynb) of colab. Let us know if it helped.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/34890#issuecomment-562503935,oanush,2019-12-06 09:41:09,34890,[35768],Documentation bug,0,"@Squadrick, Hello, Please try giving [code] as a parameter to compile it should work fine, kindly refer the [link]([url]#train_and_evaluate). Also find the [gist]([url] of colab. Let us know if it helped.Thanks!",3
"@oanush My issue is more to do with the incorrect documentation. I eventually figured out how to run the model, but the documentation for `tf.keras.Sequential` is completely wrong. And for anyone wanting the same thing, they're more likely to go to the page of `tf.keras.Sequential` than the link you posted.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34890#issuecomment-562822070,Squadrick,2019-12-07 06:58:31,34890,[35768],Documentation bug,0,"@oanush My issue is more to do with the incorrect documentation. I eventually figured out how to run the model, but the documentation for [code] is completely wrong. And for anyone wanting the same thing, they're more likely to go to the page of [code] than the link you posted.",-3
@karmel Any update on this?,IssueComment,https://github.com/tensorflow/tensorflow/issues/34890#issuecomment-573180340,Squadrick,2020-01-10 19:49:09,34890,[35768],Documentation bug,0,@karmel Any update on this?,0
"Hi @Squadrick, what part of the doc is incorrect? It doesn't say it's an argument to init. But could clarify in the doc string that it should be called in compile. It would be useful to add the param to the .compile method.
Can you send a PR for https://www.tensorflow.org/api_docs/python/tf/keras/Sequential?version=nightly ?
The pages have a link ""View source"" to edit the docstring.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34890#issuecomment-573210844,lamberta,2020-01-10 21:23:16,34890,[35768],Documentation bug,0,"Hi @Squadrick, what part of the doc is incorrect? It doesn't say it's an argument to init. But could clarify in the doc string that it should be called in compile. It would be useful to add the param to the .compile method. Can you send a PR for [url] ? The pages have a link ""View source"" to edit the docstring.",2
"My bad. I figured `Properties` meant things that could be passed to `__init__`. The docs are correct. I'll close this issue, thanks for the help. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/34890#issuecomment-573293285,Squadrick,2020-01-11 08:00:36,34890,[35768],Documentation bug,0,"My bad. I figured [code] meant things that could be passed to [code]. The docs are correct. I'll close this issue, thanks for the help.",3
I'll create the PR soon.,IssueComment,https://github.com/tensorflow/tensorflow/issues/34890#issuecomment-573293353,Squadrick,2020-01-11 08:01:55,34890,[35768],Documentation bug,0,I'll create the PR soon.,3
https://github.com/tensorflow/tensorflow/issues/29867 seems related but it's from time before this feature worked.,IssueComment,https://github.com/tensorflow/tensorflow/issues/35710#issuecomment-572652973,hartikainen,2020-01-09 16:54:04,35710,[35821],Version compatibility bug,0,[url] seems related but it's from time before this feature worked.,0
"@hartikainen 
I have tried on colab with TF version 2.1 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/99ab8383b4ad24661d44b476fd4a903e/untitled545.ipynb).However i am not seeing any issue with TF 2.0. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/35710#issuecomment-572880359,ravikyram,2020-01-10 05:30:06,35710,[35821],Version compatibility bug,0,"@hartikainen I have tried on colab with TF version 2.1 and was able to reproduce the issue.Please, find the gist [here]([url] i am not seeing any issue with TF 2.0. Thanks!",2
"@ravikyram Yeah, my point was that this seems like a regression from 2.0 to 2.1, since it behaves as I would expect on 2.0. What I'm not sure is if the ""regression"" is expected or not.",IssueComment,https://github.com/tensorflow/tensorflow/issues/35710#issuecomment-572983593,hartikainen,2020-01-10 10:42:34,35710,[35821],Version compatibility bug,0,"@ravikyram Yeah, my point was that this seems like a regression from 2.0 to 2.1, since it behaves as I would expect on 2.0. What I'm not sure is if the ""regression"" is expected or not.",0
Added a PR #35821 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/35710#issuecomment-573730943,yongtang,2020-01-13 15:51:28,35710,[35821],Version compatibility bug,0,Added a PR #35821 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35710"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35710"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35710#issuecomment-573908590,tensorflow-bot[bot],2020-01-13 22:44:11,35710,[35821],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thanks for fixing this!

As a side note, the @tensorflow-bot's survey messages are completely useless, since once you have answered it once in another issue, you always just get a message saying ""You've already responded"". Is there a way to fix that?",IssueComment,https://github.com/tensorflow/tensorflow/issues/35710#issuecomment-574065344,hartikainen,2020-01-14 08:41:10,35710,[35821],Version compatibility bug,0,"Thanks for fixing this! As a side note, the @tensorflow-bot's survey messages are completely useless, since once you have answered it once in another issue, you always just get a message saying ""You've already responded"". Is there a way to fix that?",1
@hartikainen Thanks for bringing this @tensorflow-bot's survey issue. We will work on it soon. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/35710#issuecomment-574388899,jvishnuvardhan,2020-01-14 21:45:34,35710,[35821],Version compatibility bug,0,@hartikainen Thanks for bringing this @tensorflow-bot's survey issue. We will work on it soon. Thanks!,3
"@n-gao Thanks for reporting the issue. Agree. It is defined correctly in the [`tf-nightly`](https://www.tensorflow.org/api_docs/python/tf/linalg/diag_part?version=nightly) but in the examples `tf.matrix_diag_part` should have been replaced by `tf.linalg.diag_part`. Thanks!

Are you interested in creating PR to update the docs. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/35760#issuecomment-573814623,jvishnuvardhan,2020-01-13 18:53:11,35760,[35829],Documentation bug,0,@n-gao Thanks for reporting the issue. Agree. It is defined correctly in the [[code]]([url] but in the examples [code] should have been replaced by [code]. Thanks! Are you interested in creating PR to update the docs. Thanks!,3
"It's still the old documentation: https://www.tensorflow.org/api_docs/python/tf/linalg/diag_part
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35760#issuecomment-612036089,gaebor,2020-04-10 13:48:17,35760,[35829],Documentation bug,0,It's still the old documentation: [url],-2
"The simple workaround would be to add
```python
    if not tf.is_tensor(value):
        return tf.convert_to_tensor(value, dtype)
```
to the beginning of the definition of `tf.cast()`.

This is related to tensorflow#26033 - not having to support our own ""default dtype"" implementation would remove the need for a lot of the calls to tf.cast.",IssueComment,https://github.com/tensorflow/tensorflow/issues/35938#issuecomment-575162755,st--,2020-01-16 13:57:38,35938,[35961],Data bug,0,"The simple workaround would be to add ``[code]`[code]tf.cast()`. This is related to tensorflow#26033 - not having to support our own ""default dtype"" implementation would remove the need for a lot of the calls to tf.cast.",0
Added PR #35961 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/35938#issuecomment-575440272,yongtang,2020-01-17 02:48:11,35938,[35961],Data bug,0,Added PR #35961 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35938"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35938"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35938#issuecomment-577283929,tensorflow-bot[bot],2020-01-22 16:59:47,35938,[35961],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"`tf.image.extract_image_patches` is quite useful and I used it before to create a sliding window effect. It makes sense to add full support for all common types.

Added a PR #35962 for complex number support.",IssueComment,https://github.com/tensorflow/tensorflow/issues/35955#issuecomment-575440697,yongtang,2020-01-17 02:50:16,35955,[35962],Data bug,1,[code] is quite useful and I used it before to create a sliding window effect. It makes sense to add full support for all common types. Added a PR #35962 for complex number support.,3
Wow. That was fast!,IssueComment,https://github.com/tensorflow/tensorflow/issues/35955#issuecomment-575454935,lminer,2020-01-17 04:03:55,35955,[35962],Data bug,1,Wow. That was fast!,5
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35955"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35955"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35955#issuecomment-577322876,tensorflow-bot[bot],2020-01-22 18:31:43,35955,[35962],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@0x0badc0de ,
I was able to replicate the issue for `dtype='int'` , works fine for` 'float'`, [gist](https://colab.sandbox.google.com/gist/oanush/2ae5d64fed93e8376bc70c37dea8e35f/35430.ipynb) of colab replicating the issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/35430#issuecomment-569180018,oanush,2019-12-27 03:50:13,35430,[36037],Deployment bug,0,"@0x0badc0de , I was able to replicate the issue for [code] , works fine for[code], [gist]([url] of colab replicating the issue.",0
Added PR #36037 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/35430#issuecomment-576013836,yongtang,2020-01-19 15:08:34,35430,[36037],Deployment bug,0,Added PR #36037 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35430"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35430"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35430#issuecomment-577797422,tensorflow-bot[bot],2020-01-23 17:59:35,35430,[36037],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thanks for the report. Meanwhile you may refer those links from the website.
See https://www.tensorflow.org/lite/convert
For GitHub the location has changed https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/toco/g3doc",IssueComment,https://github.com/tensorflow/tensorflow/issues/36099#issuecomment-577332939,ymodak,2020-01-22 18:55:53,36099,[36157],Documentation bug,0,Thanks for the report. Meanwhile you may refer those links from the website. See [url] For GitHub the location has changed [url],2
Hi. Would like to contribute. How can i get write access right? Thanks,IssueComment,https://github.com/tensorflow/tensorflow/issues/36099#issuecomment-577616498,maxence-drouhin,2020-01-23 10:17:38,36099,[36157],Documentation bug,0,Hi. Would like to contribute. How can i get write access right? Thanks,3
Thanks. Please submit a pull request to the repo and someone will review. See the TF contributor guide for instructions: https://www.tensorflow.org/community/contribute,IssueComment,https://github.com/tensorflow/tensorflow/issues/36099#issuecomment-577774207,lamberta,2020-01-23 17:01:58,36099,[36157],Documentation bug,0,Thanks. Please submit a pull request to the repo and someone will review. See the TF contributor guide for instructions: [url],2
"For anyone coming across this issue, I've found that I can work around it by padding the output before returning results.

```python
def CTCDecoder():
    def decoder(y_pred):
        input_shape = tf.keras.backend.shape(y_pred)
        input_length = tf.ones(shape=input_shape[0]) * tf.keras.backend.cast(input_shape[1], 'float32')
        unpadded = tf.keras.backend.ctc_decode(y_pred, input_length)[0][0]
        unpadded_shape = tf.keras.backend.shape(unpadded)
        # I don't *think* I should have to do this but it seems as though I do.
        padded = tf.pad(
            unpadded,
            paddings=[[0, 0], [0, input_shape[1] - unpadded_shape[1]]],
            constant_values=-1
        )
        return padded
    return tf.keras.layers.Lambda(decoder, name='decode')
```

The following snippet verifies consistency across different batch sizes.

```python
input_layer = tf.keras.layers.Input((48, 37))
x = CTCDecoder()(input_layer)
model = tf.keras.models.Model(inputs=input_layer, outputs=x)

X = np.random.uniform(size=(100, 48, 37))

y100 = model.predict(X, batch_size=100)
y1 = model.predict(X, batch_size=1)
y32 = model.predict(X, batch_size=32)

np.testing.assert_almost_equal(y100, y1)
np.testing.assert_almost_equal(y100, y32)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/35799#issuecomment-573434431,faustomorales,2020-01-12 16:51:36,35799,[36316],Data bug,0,"For anyone coming across this issue, I've found that I can work around it by padding the output before returning results. ``[code]`[code]`[code]``",2
"It seems that small modifications to `keras.backend` could resolve this.

https://github.com/tensorflow/tensorflow/blob/30b98cc73a8b046c8ce0915f6c0c7398a4947192/tensorflow/python/keras/backend.py#L5817-L5832

I would have thought that `st.dense_shape` should be something like `(input_shape[0], input_shape[1]` where `input_shape = tf.keras.backend.shape(y_pred)` (assuming you add this line before the transpose at the top of the function). But this causes the first assertion in the associated test (see below) to fail because it assumes that the output has not been padded with -1 values, which seems incorrect to me but I'm really not sure.

https://github.com/tensorflow/tensorflow/blob/03c045e146d441a0db4bd5cc1ecef1517e5c6708/tensorflow/python/keras/backend_test.py#L1779-L1783

I'm not sure exactly what the desired behavior is here. If the current behavior is correct, then I propose that this issue be closed without action as the workaround above suits my purposes just fine. Otherwise, I'm glad to file a PR with adjustments to the function and associated test.",IssueComment,https://github.com/tensorflow/tensorflow/issues/35799#issuecomment-573438281,faustomorales,2020-01-12 17:34:15,35799,[36316],Data bug,0,"It seems that small modifications to [code] could resolve this. [url]#L5817-L5832 I would have thought that [code] should be something like [code] where [code] (assuming you add this line before the transpose at the top of the function). But this causes the first assertion in the associated test (see below) to fail because it assumes that the output has not been padded with -1 values, which seems incorrect to me but I'm really not sure. [url]#L1779-L1783 I'm not sure exactly what the desired behavior is here. If the current behavior is correct, then I propose that this issue be closed without action as the workaround above suits my purposes just fine. Otherwise, I'm glad to file a PR with adjustments to the function and associated test.",1
"@faustomorales, would you be open to send out a PR with your modification that fixes the problem? Thanks in advance.",IssueComment,https://github.com/tensorflow/tensorflow/issues/35799#issuecomment-577850314,rchao,2020-01-23 20:00:47,35799,[36316],Data bug,0,"@faustomorales, would you be open to send out a PR with your modification that fixes the problem? Thanks in advance.",3
"Yes, certainly I can do that. Will try to get it out soon.

On Thu, Jan 23, 2020 at 2:00 PM Rick Chao <notifications@github.com> wrote:

> @faustomorales <https://github.com/faustomorales>, would you be open to
> send out a PR with your modification that fixes the problem? Thanks in
> advance.
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/35799?email_source=notifications&email_token=ACKIZ2OI6QV2U2SFF5MJH43Q7HZPNA5CNFSM4KFYS7QKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJYUXSQ#issuecomment-577850314>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACKIZ2PX3BPPYMTIDYORP23Q7HZPNANCNFSM4KFYS7QA>
> .
>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35799#issuecomment-578164925,faustomorales,2020-01-24 14:58:45,35799,[36316],Data bug,0,"Yes, certainly I can do that. Will try to get it out soon. On Thu, Jan 23, 2020 at 2:00 PM Rick Chao <[email]> wrote: > @faustomorales <[url] would you be open to > send out a PR with your modification that fixes the problem? Thanks in > advance. > > â€” > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub > <[url]#issuecomment-577850314>, > or unsubscribe > <[url] > . >",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35799"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35799"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35799#issuecomment-635516861,google-ml-butler[bot],2020-05-28 18:22:23,35799,[36316],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Please note,I have found the same issue for code in TF 2.x as well.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36359#issuecomment-580594381,Saduf2019,2020-01-31 05:57:55,36359,[36364],Version compatibility bug,0,"Please note,I have found the same issue for code in TF 2.x as well.",-1
"@wenmin-wu Please take a look at this [comment](https://github.com/tensorflow/tensorflow/pull/21757#issuecomment-416835941) i.e.,
in the documentation of `tf.nn.embedding_lookup_sparse` its mentioned that **This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids**

So, due to this, the change has not been merged. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/36359#issuecomment-581675510,gowthamkpr,2020-02-03 23:51:23,36359,[36364],Version compatibility bug,0,"@wenmin-wu Please take a look at this [comment]([url]#issuecomment-416835941) i.e., in the documentation of [code] its mentioned that **This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids** So, due to this, the change has not been merged.",0
"@gowthamkpr Even though this is true, the sum of weights can also be zero. 
I come across this problem because I want to embed user actions on items. Some people don't have any action on items. So for these users, I can only set `sp_ids=[0]`, `sp_weights=[0]`. With the current implementation, it will divide by 0. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/36359#issuecomment-581724160,wenmin-wu,2020-02-04 03:17:20,36359,[36364],Version compatibility bug,0,"@gowthamkpr Even though this is true, the sum of weights can also be zero. I come across this problem because I want to embed user actions on items. Some people don't have any action on items. So for these users, I can only set [code], [code]. With the current implementation, it will divide by 0.",-2
@wenmin-wu Can you please share a reproducible test case where the sum of weights are zero. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/36359#issuecomment-582110966,gowthamkpr,2020-02-04 20:56:23,36359,[36364],Version compatibility bug,0,@wenmin-wu Can you please share a reproducible test case where the sum of weights are zero. Thanks!,0
"@gowthamkpr Just now I found this issue can be solved with `tf.nn.safe_embedding_lookup_sparse` (tested with 1.14.0, I think the same for the other versions).  Here're the code snippets for reproducing.

```Python
import tensorflow as tf

E = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])
ids = tf.SparseTensor([[0,0]], np.array([0], dtype='int64'), dense_shape=[1,1])
weights = tf.SparseTensor([[0,0]], [0.0], dense_shape=[1,1])

with tf.Session() as sess:
    print(sess.run(tf.nn.embedding_lookup_sparse(E, ids, weights, combiner='mean')))
# ouput: [[nan nan nan]]

with tf.Session() as sess:
    print(sess.run(tf.nn.safe_embedding_lookup_sparse(E, ids, weights, combiner='mean')))

# output: [[0. 0. 0.]]
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/36359#issuecomment-582977896,wenmin-wu,2020-02-06 16:07:11,36359,[36364],Version compatibility bug,0,"@gowthamkpr Just now I found this issue can be solved with [code] (tested with 1.14.0, I think the same for the other versions). Here're the code snippets for reproducing. ``[code]``",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36359"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36359"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36359#issuecomment-582980133,tensorflow-bot[bot],2020-02-06 16:11:46,36359,[36364],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36525"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36525"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36525#issuecomment-591727913,tensorflow-bot[bot],2020-02-27 01:19:52,36525,[36526],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"For whatever it's worth, if you use polyval inside a custom Keras layer then eager execution of polyval doesn't work either due to an OperatorNotAllowedInGraphError. I can also provide a simple example of this, but I'm not sure whether it merits a new issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34947#issuecomment-562995563,mjwatkins2,2019-12-08 21:21:33,34947,[36597],Data bug,0,"For whatever it's worth, if you use polyval inside a custom Keras layer then eager execution of polyval doesn't work either due to an OperatorNotAllowedInGraphError. I can also provide a simple example of this, but I'm not sure whether it merits a new issue.",-1
"I have tried on colab with TF version 2.0,2.1.0-dev20191013,2.1.0-rc0 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/4a1b6e066c3e50b9011e86cc0213475d/untitled455.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/34947#issuecomment-563883990,ravikyram,2019-12-10 06:22:55,34947,[36597],Data bug,0,"I have tried on colab with TF version 2.0,2.1.0-dev20191013,2.1.0-rc0 and was able to reproduce the issue.Please, find the gist [here]([url] Thanks!",0
I've been getting this too using custom_gradients. Would love to know a solution,IssueComment,https://github.com/tensorflow/tensorflow/issues/34947#issuecomment-573276430,shaunster0,2020-01-11 03:33:22,34947,[36597],Data bug,0,I've been getting this too using custom_gradients. Would love to know a solution,1
"`tf.math.polyval` only works with lists of tensors, but it doesn't verify its arguments before starting the work and it errors out internally. The fact that it works in eager mode is incidental.

So you'll need to split `coeffs`:

```
        coeffs = tf.eye(5)
        coeffs = tf.split(coeffs, 5)  # Convert coeffs to a list of tensors.
        pv = tf.math.polyval(coeffs, x)
```

The op implementation could be improved in a couple of ways:
 * it should ensure coeffs is a list and raise an appropriate error message
 * it may be made to work with tensor coeffs, which should be fairly straightforward",IssueComment,https://github.com/tensorflow/tensorflow/issues/34947#issuecomment-583743345,mdanatg,2020-02-08 14:53:08,34947,[36597],Data bug,0,"[code] only works with lists of tensors, but it doesn't verify its arguments before starting the work and it errors out internally. The fact that it works in eager mode is incidental. So you'll need to split [code]: ``[code]`` The op implementation could be improved in a couple of ways: * it should ensure coeffs is a list and raise an appropriate error message * it may be made to work with tensor coeffs, which should be fairly straightforward",-2
Hello! I would love to work on this. Could you guide me?,IssueComment,https://github.com/tensorflow/tensorflow/issues/34947#issuecomment-585041078,Joey155,2020-02-12 05:46:55,34947,[36597],Data bug,0,Hello! I would love to work on this. Could you guide me?,5
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34947"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34947"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/34947#issuecomment-585060402,tensorflow-bot[bot],2020-02-12 07:02:19,34947,[36597],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@Joey155 it might be interesting to see if polyval can be made to work with tensor inputs by taking its source code and putting it in a `tf.function`. That said, there are a couple of bugs and `GradientTape` doesn't give high-order gradients for `tf.while_loop`, which would need to be fixed first.",IssueComment,https://github.com/tensorflow/tensorflow/issues/34947#issuecomment-585253630,mdanatg,2020-02-12 15:14:59,34947,[36597],Data bug,0,"@Joey155 it might be interesting to see if polyval can be made to work with tensor inputs by taking its source code and putting it in a [code]. That said, there are a couple of bugs and [code] doesn't give high-order gradients for [code], which would need to be fixed first.",-1
@mdanatg the issue is closed now. But i will check out your directions all the same.,IssueComment,https://github.com/tensorflow/tensorflow/issues/34947#issuecomment-585542083,Joey155,2020-02-13 04:16:36,34947,[36597],Data bug,0,@mdanatg the issue is closed now. But i will check out your directions all the same.,1
Working on a fix,IssueComment,https://github.com/tensorflow/tensorflow/issues/36721#issuecomment-585863666,mihaimaruseac,2020-02-13 17:04:53,36721,[36732],Visualization bug,0,Working on a fix,1
"Inspired by #32776 and https://github.com/tensorflow/tensorflow/commit/58b236b235ce57808c917feb19b9f895f628710c, I apply the following patch to resolve symbolic links, and it works.
```diff
diff --git a/third_party/gpus/cuda_configure.bzl b/third_party/gpus/cuda_configure.bzl
index af1bc96f00..2fd0bef286 100644
--- a/third_party/gpus/cuda_configure.bzl
+++ b/third_party/gpus/cuda_configure.bzl
@@ -373,8 +373,8 @@ def _cuda_include_path(repository_ctx, cuda_config):
             )
     inc_entries = []
     if target_dir != """":
-        inc_entries.append(target_dir)
-    inc_entries.append(cuda_config.cuda_toolkit_path + ""/include"")
+        inc_entries.append(str(repository_ctx.path(target_dir).realpath))
+    inc_entries.append(str(repository_ctx.path(cuda_config.cuda_toolkit_path + ""/include"").realpath))
     return inc_entries

 def enable_cuda(repository_ctx):
diff --git a/third_party/gpus/find_cuda_config.py b/third_party/gpus/find_cuda_config.py
index 39f2c21d3f..57067b3562 100644
--- a/third_party/gpus/find_cuda_config.py
+++ b/third_party/gpus/find_cuda_config.py
@@ -449,7 +449,7 @@ def find_cuda_config():
   cuda_version = os.environ.get(""TF_CUDA_VERSION"", """")
   base_paths = _list_from_env(""TF_CUDA_PATHS"",
                               _get_default_cuda_paths(cuda_version))
-  base_paths = [path for path in base_paths if os.path.exists(path)]
+  base_paths = [os.path.realpath(path) for path in base_paths if os.path.exists(path)]

   result = {}
   if ""cuda"" in libraries:
```

I don't know why others don't have this problem (only saw @shubham769 reported the problem), but the above solution should make sense.",IssueComment,https://github.com/tensorflow/tensorflow/issues/35122#issuecomment-589858889,njzjz,2020-02-21 22:11:50,35122,[37006],Build bug,0,"Inspired by #32776 and [url] I apply the following patch to resolve symbolic links, and it works. ``[code]`` I don't know why others don't have this problem (only saw @shubham769 reported the problem), but the above solution should make sense.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35122"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35122"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35122#issuecomment-596657179,tensorflow-bot[bot],2020-03-09 17:07:44,35122,[37006],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I think it should be possible to add support for keepdims == True to the ragged versions of reduce_xyz.,IssueComment,https://github.com/tensorflow/tensorflow/issues/37000#issuecomment-644202792,edloper,2020-06-15 15:25:17,37000,[37014],Data bug,0,I think it should be possible to add support for keepdims == True to the ragged versions of reduce_xyz.,1
"Encountered the same problem with `reduce_std`, would be very useful if this was fixed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37000#issuecomment-770434618,PawelFaron,2021-01-31 19:17:37,37000,[37014],Data bug,0,"Encountered the same problem with [code], would be very useful if this was fixed.",-2
"I have tried on colab with TF version 2.1.0-rc2, 2.2.0-dev20200128 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/55d11b811078c362ff6e49379da72353/untitled597.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/36259#issuecomment-579671773,ravikyram,2020-01-29 09:35:07,36259,[37018],Deployment bug,0,"I have tried on colab with TF version 2.1.0-rc2, 2.2.0-dev20200128 and was able to reproduce the issue.Please, find the gist [here]([url]",0
I found this bug too and fixed in #37018,IssueComment,https://github.com/tensorflow/tensorflow/issues/36259#issuecomment-591422321,howl-anderson,2020-02-26 13:21:06,36259,[37018],Deployment bug,0,I found this bug too and fixed in #37018,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36259"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36259"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36259#issuecomment-593523373,tensorflow-bot[bot],2020-03-02 17:37:25,36259,[37018],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"The same problem. I also tried NDK 14b and stricyly followed the official guideline:
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android
to configure the android NDK/SDK, but it didn't work.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36967#issuecomment-590167941,PoonKinWang,2020-02-24 04:59:43,36967,[37033],Build bug,0,"The same problem. I also tried NDK 14b and stricyly followed the official guideline: [url] to configure the android NDK/SDK, but it didn't work.",-3
"this should resolve this problem

```diff
--- a/tensorflow/lite/delegates/gpu/cl/selectors/BUILD
+++ b/tensorflow/lite/delegates/gpu/cl/selectors/BUILD
@@ -119,6 +119,7 @@ cc_library(
         ""//tensorflow/lite/delegates/gpu/cl/kernels:resize"",
         ""//tensorflow/lite/delegates/gpu/cl/kernels:softmax"",
         ""//tensorflow/lite/delegates/gpu/cl/kernels:softmax1x1"",
+        ""//tensorflow/lite/delegates/gpu/cl/kernels:space_to_depth"",
         ""//tensorflow/lite/delegates/gpu/cl/kernels:strided_slice"",
         ""//tensorflow/lite/delegates/gpu/cl/kernels:transpose"",
         ""//tensorflow/lite/delegates/gpu/common:operations"",
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/36967#issuecomment-590648511,freedomtan,2020-02-25 02:23:01,36967,[37033],Build bug,0,this should resolve this problem ``[code]``,0
@freedomtan  By the way which is the recommended NDK version? As per the [documentation](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#bazel) it seems to be 14b; but it does not seem to work ,IssueComment,https://github.com/tensorflow/tensorflow/issues/36967#issuecomment-590673947,anilsathyan7,2020-02-25 04:12:06,36967,[37033],Build bug,0,@freedomtan By the way which is the recommended NDK version? As per the [documentation]([url]#bazel) it seems to be 14b; but it does not seem to work,-2
@anilsathyan7 it seems the documentation you mentioned should be updated :-) I was able to build `benchmark_model` and `label_image` using NDK 20.,IssueComment,https://github.com/tensorflow/tensorflow/issues/36967#issuecomment-590676126,freedomtan,2020-02-25 04:22:29,36967,[37033],Build bug,0,@anilsathyan7 it seems the documentation you mentioned should be updated :-) I was able to build [code] and [code] using NDK 20.,2
"> @anilsathyan7 it seems the documentation you mentioned should be updated :-) I was able to build `benchmark_model` and `label_image` using NDK 20.

Thanks for helping. But I met another problem at benchmark build: ""Linking of rule '//tensorflow/lite/tools/benchmark:benchmark_model'""
I tried to add '//tensorflow/lite/tools/benchmark:benchmark_model' cc_library like that mentioned above but it doesn't work.
Can you help me to address it? Thanks in advance.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36967#issuecomment-590705419,PoonKinWang,2020-02-25 06:25:58,36967,[37033],Build bug,0,"> @anilsathyan7 it seems the documentation you mentioned should be updated :-) I was able to build [code] and [code] using NDK 20. Thanks for helping. But I met another problem at benchmark build: ""Linking of rule '//tensorflow/lite/tools/benchmark:benchmark_model'"" I tried to add '//tensorflow/lite/tools/benchmark:benchmark_model' cc_library like that mentioned above but it doesn't work. Can you help me to address it? Thanks in advance.",1
"I added that particular line in cc_library and it solved the problem.
The compilation was successful  and  the benchmark was verified!!!
Here is the benchmark_model binary ...
( I tried it in  google colab using the aforementioned settings  i.e. NDK20, arm_64)
[benchmark_arm64.zip](https://github.com/tensorflow/tensorflow/files/4249247/benchmark_arm64.zip)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36967#issuecomment-590781782,anilsathyan7,2020-02-25 09:55:29,36967,[37033],Build bug,0,"I added that particular line in cc_library and it solved the problem. The compilation was successful and the benchmark was verified!!! Here is the benchmark_model binary ... ( I tried it in google colab using the aforementioned settings i.e. NDK20, arm_64) [benchmark_arm64.zip]([url]",5
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36967"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36967"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36967#issuecomment-590781806,tensorflow-bot[bot],2020-02-25 09:55:32,36967,[37033],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@PoonKinWang sorry, I don't get exactly what your problem is.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36967#issuecomment-590846582,freedomtan,2020-02-25 12:39:20,36967,[37033],Build bug,0,"@PoonKinWang sorry, I don't get exactly what your problem is.",0
"@bela127, Thanks for reporting this issue. 
Can you provide the complete code snippet to reproduce the reported issue. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/36963#issuecomment-590285397,gadagashwini-zz,2020-02-24 11:53:58,36963,[37115],Data bug,0,"@bela127, Thanks for reporting this issue. Can you provide the complete code snippet to reproduce the reported issue. Thanks!",2
"Thanks for replying so fast,
I will build a minimum test script today and provide it as soon as possible.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36963#issuecomment-590295567,bela127,2020-02-24 12:24:46,36963,[37115],Data bug,0,"Thanks for replying so fast, I will build a minimum test script today and provide it as soon as possible.",4
"here you go:
full test script with 3 test cases

```
import tensorflow as tf
keras = tf.keras


def main():
    eager = True                    ### please change to FALSE in eager mode all 3 tests are fine
    test_nr = 1 # 1 or 2 or 3       ### please test 1 and 2 and 3 -> diffrent errors
                                    ### error 3 ist clear, TensorShape is not tf.function compatible
                                    ### error 1,2 has somthing todo with the image.resize implementation
                                    ### runtime tensor is not evaluated and so the value is None
    
    tf.config.experimental_run_functions_eagerly(eager)
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
    
    inputs = tf.constant(100.,shape=[1,100,100,20])
    inputs_small = tf.constant(100.,shape=[1,80,80,20])
    
    if eager or test_nr == 1:
        print(""Scaled1"")
        scaled_shared = Scaled1()
        test_scaled_shared = test(scaled_shared, optimizer, training = True)
        out = test_scaled_shared([inputs,inputs_small])
        print(""Scaled1"")
    
    if eager or test_nr == 2:
        print(""Scaled2"")
        scaled_shared = Scaled2()
        test_scaled_shared = test(scaled_shared, optimizer, training = True)
        out = test_scaled_shared([inputs,inputs_small])
        print(""Scaled2"")
        
    if eager or test_nr == 3:
        print(""Scaled3"")
        scaled_shared = Scaled3()
        test_scaled_shared = test(scaled_shared, optimizer, training = True)
        out = test_scaled_shared([inputs,inputs_small])
        print(""Scaled3"")

def test(op, optimizer, **kwargs):
    def run(inputs):
        with tf.GradientTape() as tape:
            tape.watch(op.trainable_variables)
            outputs = op(inputs, **kwargs)
        g = tape.gradient(outputs, op.trainable_variables)
        optimizer.apply_gradients(zip(g, op.trainable_variables))
        return outputs, g
    return run
  
class Scale(keras.layers.Layer):
    def __init__(self, destination_channel = None, name = ""Scale"", **kwargs):
        super().__init__(name = name, **kwargs)
        self.destination_channel = destination_channel
        
    def build(self, input_shape):
        if self.destination_channel is None:
            self.destination_channel = input_shape[-1]
        self.compress_input = keras.layers.Convolution2D(int(input_shape[-1]/2), kernel_size=1, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())
        self.conv = keras.layers.Convolution2D(input_shape[-1], kernel_size=3, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())
        self.pool = keras.layers.MaxPool2D(pool_size=3,strides=1,padding=""SAME"")
        self.compress_output = keras.layers.Convolution2D(self.destination_channel, kernel_size=1, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())
        super().build(input_shape)

    @tf.function
    def call(self, inputs, destination_size):
        
        compressed_input = self.compress_input(inputs)
        conv = self.conv(compressed_input)
        pool = self.pool(inputs)
        
        scaled_conv = tf.image.resize(conv, destination_size, preserve_aspect_ratio=True, antialias=True)
        scaled_pool = tf.image.resize(pool, destination_size, preserve_aspect_ratio=True, antialias=True)
        
        concat = keras.layers.concatenate([scaled_pool, scaled_conv])
        compressed_output = self.compress_output(concat)
        return compressed_output
    
    def get_config(self):
        config = super().get_config()
        config.update({'destination_channel': self.destination_channel,
                       })
        return config


class Scaled1(keras.layers.Layer):
    def __init__(self, name = ""Scaled1"", **kwargs):
        super().__init__(name = name, **kwargs)

        
    def build(self, input_shape):
        res_shape, shc_shape = input_shape
        self.scale_up = Scale(destination_channel = res_shape[-1])
        self.scale_down = Scale()
        super().build(input_shape)
        
    def call(self, inputs):
        inputs_res, inputs_shc = inputs
        shape1 = tf.shape(inputs_shc)[1:3]
        shape2 = tf.shape(inputs_shc)[1:3]
        
        scaled_res = self.scale_down(inputs_res, shape1)
        scaled_dense = self.scale_up(scaled_res, shape2)
        return scaled_dense      
    
class Scaled2(keras.layers.Layer):
    def __init__(self, name = ""Scaled2"", **kwargs):
        super().__init__(name = name, **kwargs)

        
    def build(self, input_shape):
        res_shape, shc_shape = input_shape
        self.scale_up = Scale(destination_channel = res_shape[-1])
        self.scale_down = Scale()
        super().build(input_shape)
        
    def call(self, inputs):
        inputs_res, inputs_shc = inputs
        
        shape1 = tf.cast(tf.shape(inputs_shc)[1:3], dtype = tf.int32)
        shape2 = tf.cast(tf.shape(inputs_shc)[1:3], dtype = tf.int32)
        
        scaled_res = self.scale_down(inputs_res, shape1)
        scaled_dense = self.scale_up(scaled_res, shape2)
        return scaled_dense
        
class Scaled3(keras.layers.Layer):
    def __init__(self, name = ""Scaled2"", **kwargs):
        super().__init__(name = name, **kwargs)

        
    def build(self, input_shape):
        res_shape, shc_shape = input_shape
        self.scale_up = Scale(destination_channel = res_shape[-1])
        self.scale_down = Scale()
        super().build(input_shape)
        
    def call(self, inputs):
        inputs_res, inputs_shc = inputs
        
        shape1 = inputs_shc.shape[1:3]
        shape2 = inputs_shc.shape[1:3]
        
        scaled_res = self.scale_down(inputs_res, shape1)
        scaled_dense = self.scale_up(scaled_res, shape2)
        return scaled_dense

  
if __name__ == '__main__':
    main()
    
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/36963#issuecomment-590309704,bela127,2020-02-24 13:03:41,36963,[37115],Data bug,0,here you go: full test script with 3 test cases ``[code]``,0
"Could able to replicate the reported issue with TF 2.1 and TF-nightly.
Please find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/b758c604ee2b51b63905bf69fd10b57f/untitled401.ipynb). Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/36963#issuecomment-590699741,gadagashwini-zz,2020-02-25 06:04:13,36963,[37115],Data bug,0,Could able to replicate the reported issue with TF 2.1 and TF-nightly. Please find the gist [here]([url] Thanks,1
"I have similar problems when adding signatures function for an existing model. But if I remove the `preserve_aspect_ratio=True`, everything works well.

",IssueComment,https://github.com/tensorflow/tensorflow/issues/36963#issuecomment-591236755,enzoliao,2020-02-26 04:48:19,36963,[37115],Data bug,0,"I have similar problems when adding signatures function for an existing model. But if I remove the [code], everything works well.",-1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36963"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36963"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36963#issuecomment-595343413,tensorflow-bot[bot],2020-03-05 17:12:40,36963,[37115],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"thanks, changed to nightly and the fix is working",IssueComment,https://github.com/tensorflow/tensorflow/issues/36963#issuecomment-596513339,bela127,2020-03-09 13:08:12,36963,[37115],Data bug,0,"thanks, changed to nightly and the fix is working",5
"@SoloSynth1 I had accessed the page provided, it says 404 error. We will take a look. Thanks for bringing this to our notice.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28169#issuecomment-487978241,muddham,2019-04-30 14:38:27,28169,[37171],Documentation bug,0,"@SoloSynth1 I had accessed the page provided, it says 404 error. We will take a look. Thanks for bringing this to our notice.",2
"First two links are not working as shown in the [screenshot](https://screenshot.googleplex.com/Tv3SBDNQrmU). 
First link that is not working (bold_italic): Defined in tensorflow/_api/v1/image/**___init__.py_**
Second link that is not working (bold_italic): See the _**Images**_ guide . Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/28169#issuecomment-488431680,jvishnuvardhan,2019-05-01 21:16:08,28169,[37171],Documentation bug,0,First two links are not working as shown in the [screenshot]([url] First link that is not working (bold_italic): Defined in tensorflow/_api/v1/image/**___init__.py_** Second link that is not working (bold_italic): See the _**Images**_ guide . Thanks!,0
"I can add an updated API guide similar to [image.md](https://github.com/tensorflow/docs/blob/r1.11/site/en/api_guides/python/image.md)

@muddham @jvishnuvardhan please share your views. Thank you",IssueComment,https://github.com/tensorflow/tensorflow/issues/28169#issuecomment-590842957,vijayphoenix,2020-02-25 12:29:53,28169,[37171],Documentation bug,0,I can add an updated API guide similar to [image.md]([url] @muddham @jvishnuvardhan please share your views. Thank you,3
"Hi @vijayphoenix 

We don't have an api-gides section anymore, but if you want to add that information back to the [docstring of the `tf.image` module](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops.py), that could be good.

If you take this on, remember that the generated page includes a list of all the symbols in the module.

also remember that if you include example code, please use [doctest format](https://docs.python.org/3/library/doctest.html), so the example gets tested.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28169#issuecomment-590879603,MarkDaoust,2020-02-25 13:58:04,28169,[37171],Documentation bug,0,"Hi @vijayphoenix We don't have an api-gides section anymore, but if you want to add that information back to the [docstring of the [code] module]([url] that could be good. If you take this on, remember that the generated page includes a list of all the symbols in the module. also remember that if you include example code, please use [doctest format]([url] so the example gets tested.",2
"Hi @MarkDaoust,
I will do the necessary changes and make a PR.

Thank you for your input.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28169#issuecomment-590950018,vijayphoenix,2020-02-25 16:18:21,28169,[37171],Documentation bug,0,"Hi @MarkDaoust, I will do the necessary changes and make a PR. Thank you for your input.",3
"Hi @MarkDaoust,
I made a PR https://github.com/tensorflow/tensorflow/pull/37171 addressing this issue. Please take a look.
Thank you",IssueComment,https://github.com/tensorflow/tensorflow/issues/28169#issuecomment-593253997,vijayphoenix,2020-03-02 07:11:00,28169,[37171],Documentation bug,0,"Hi @MarkDaoust, I made a PR [url] addressing this issue. Please take a look. Thank you",3
"LGTM, Thanks.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28169#issuecomment-593493823,MarkDaoust,2020-03-02 16:36:26,28169,[37171],Documentation bug,0,"LGTM, Thanks.",3
@tigert1998 Are you interested in raising a PR to update the docs? Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/37111#issuecomment-592109979,jvishnuvardhan,2020-02-27 18:32:47,37111,[37192],Documentation bug,0,@tigert1998 Are you interested in raising a PR to update the docs? Thanks!,3
"No, since I don't know either.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37111#issuecomment-592461032,tigert1998,2020-02-28 10:53:43,37111,[37192],Documentation bug,0,"No, since I don't know either.",0
"@tigert1998 and @jvishnuvardhan , I have added line in doc corresponding to the necessity of `converter.representative_dataset`. You have also mentioned something about order of inputs. I don't understand that. Can you please elaborate so that I will also make changes corresponding to that in the doc if needed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37111#issuecomment-592951146,ashutosh1919,2020-02-29 14:30:29,37111,[37192],Documentation bug,0,"@tigert1998 and @jvishnuvardhan , I have added line in doc corresponding to the necessity of [code]. You have also mentioned something about order of inputs. I don't understand that. Can you please elaborate so that I will also make changes corresponding to that in the doc if needed.",1
"@ashutosh1919 
For instance, suppose that I generate a `saved_model` model with the following code:
```py
# inputs: List[Tensor]
# outputs: List[Tensor]

inputs_dic = {
    ""input_{}"".format(idx): i
    for idx, i in zip(range(len(inputs)), inputs)
}
outputs_dic = {
    ""output_{}"".format(idx): o
    for idx, o in zip(range(len(outputs)), outputs)
}
builder = tf.saved_model.builder.SavedModelBuilder(path)
sigs = {}
sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \
    tf.saved_model.signature_def_utils.predict_signature_def(
    inputs_dic, outputs_dic
)
builder.add_meta_graph_and_variables(
    sess,
    [tag_constants.SERVING],
    signature_def_map=sigs
)
builder.save()
```

Then I try to load the `saved_model` with `tf.lite.TFLiteConverter.from_saved_model` and configure the quantization options of this `converter`, including `representative_dataset`. However, I found that the fed inputs in `representative_data_gen` are not always in the order of `input_0`, `input_1`, etc. Plus, it is also not specified in the doc in detail.

It is not something that a end-user like me can pull a request. I checked the code. It seems that tflite feed inputs in the order of the presents of inputs in the serialized protobuf. It's kind of a ""default"" order. But nobody knows what the ""default"" order is.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37111#issuecomment-593046179,tigert1998,2020-03-01 02:56:53,37111,[37192],Documentation bug,0,"@ashutosh1919 For instance, suppose that I generate a [code] model with the following code: ``[code]`[code]saved_model[code]tf.lite.TFLiteConverter.from_saved_model[code]converter[code]representative_dataset[code]representative_data_gen[code]input_0[code]input_1`, etc. Plus, it is also not specified in the doc in detail. It is not something that a end-user like me can pull a request. I checked the code. It seems that tflite feed inputs in the order of the presents of inputs in the serialized protobuf. It's kind of a ""default"" order. But nobody knows what the ""default"" order is.",-2
"@tigert1998 , Can you please provide the link of the file in tensorflow where you have checked this code. I also want to take a look at it.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37111#issuecomment-595215829,ashutosh1919,2020-03-05 12:59:14,37111,[37192],Documentation bug,0,"@tigert1998 , Can you please provide the link of the file in tensorflow where you have checked this code. I also want to take a look at it.",0
"This has not been resolved yet. It seems like the order is arbitrary. The order even changes when loading the same saved model file. When there are multiple inputs of different shapes, the tflite converter is unusable.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37111#issuecomment-769835782,DaviesX,2021-01-29 14:25:52,37111,[37192],Documentation bug,0,"This has not been resolved yet. It seems like the order is arbitrary. The order even changes when loading the same saved model file. When there are multiple inputs of different shapes, the tflite converter is unusable.",-3
"@DaviesX Can you please open a new issue with a simple standalone code to reproduce the issue? As the current issue is older, it is better to open a new issue so that we can track and resolve the issue faster. Thanks! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/37111#issuecomment-770102193,jvishnuvardhan,2021-01-29 23:24:25,37111,[37192],Documentation bug,0,"@DaviesX Can you please open a new issue with a simple standalone code to reproduce the issue? As the current issue is older, it is better to open a new issue so that we can track and resolve the issue faster. Thanks!",2
@jvishnuvardhan  My issue actually has other causes besides having multiple inputs. This should go to a separate issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/37111#issuecomment-770376472,DaviesX,2021-01-31 12:41:33,37111,[37192],Documentation bug,0,@jvishnuvardhan My issue actually has other causes besides having multiple inputs. This should go to a separate issue.,0
"@mwinel , Hello, why do you think that these random function need examples?",IssueComment,https://github.com/tensorflow/tensorflow/issues/31277#issuecomment-694671628,idiomaticrefactoring,2020-09-18 05:59:03,31277,[37281],Documentation bug,0,"@mwinel , Hello, why do you think that these random function need examples?",0
"I'll start working on it...
Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37445#issuecomment-596591851,ManishAradwad,2020-03-09 15:13:54,37445,[37520],Documentation bug,0,I'll start working on it... Thanks!,3
@ManishAradwad Can you please link the PR with this issue? Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/37445#issuecomment-597712840,jvishnuvardhan,2020-03-11 15:50:40,37445,[37520],Documentation bug,0,@ManishAradwad Can you please link the PR with this issue? Thanks!,2
Was able to reproduce the issue with TF 2.1 and TF-nightly. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/835c0ddf7b10b0c134967080939efffe/37416.ipynb). Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/37416#issuecomment-596360274,amahendrakar,2020-03-09 06:58:53,37416,[37528],Documentation bug,0,Was able to reproduce the issue with TF 2.1 and TF-nightly. Please find the Gist [here]([url] Thanks!,2
"@LeechMuse 
In the code provided by you `y_true` = [0, 0, 1, 1], `y_pred` = [1, 1, 1., 1.] , top_k = top-k classes to be considered to calculate precision. 

If top_k = none it consider all the classes.

Precision is calculated by TP/TP+FP. So in the case top_k =1 it considers the first value only to calculate precision (ie y_true = [0]  and y_pred = [1]) so precision is zero. 

Similarly top_k=2 considers first 2 values y_true` = [0, 0] and y_pred` = [1, 1] so precision is zero. 
If top_k=3 then y_true` = [0, 0,1] and y_pred` = [1,1,1.] so precision is 0.33.

In this example top_k =4 or None is same because it uses all the values. In that case `y_true` = [0, 0, 1, 1], `y_pred` = [1, 1, 1., 1.]  so precision will be 0.5. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/af71a7be1c9cc0e945f79536d540fbb3/untitled710.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37416#issuecomment-596394858,ravikyram,2020-03-09 08:31:53,37416,[37528],Documentation bug,0,"@LeechMuse In the code provided by you [code] = [0, 0, 1, 1], [code] = [1, 1, 1., 1.] , top_k = top-k classes to be considered to calculate precision. If top_k = none it consider all the classes. Precision is calculated by TP/TP+FP. So in the case top_k =1 it considers the first value only to calculate precision (ie y_true = [0] and y_pred = [1]) so precision is zero. Similarly top_k=2 considers first 2 values y_true[code] = [1, 1] so precision is zero. If top_k=3 then y_true[code] = [1,1,1.] so precision is 0.33. In this example top_k =4 or None is same because it uses all the values. In that case [code] = [0, 0, 1, 1], [code] = [1, 1, 1., 1.] so precision will be 0.5. Please, find the gist [here]([url] Thanks!",0
"Sure, this is true, but in that case it's not on average, and instead you should say precision at top_k (ties are broken by the order in which the values are provided).

If it was on average, it should be expected to break ties according to expectation. So in the case of top_k=1, it should still be 0.5, because under random assignment of order (given that all y_hat are equal), 0.5 of the permutations will have 1 in the first element in the array.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37416#issuecomment-596635546,LeechMuse,2020-03-09 16:30:42,37416,[37528],Documentation bug,0,"Sure, this is true, but in that case it's not on average, and instead you should say precision at top_k (ties are broken by the order in which the values are provided). If it was on average, it should be expected to break ties according to expectation. So in the case of top_k=1, it should still be 0.5, because under random assignment of order (given that all y_hat are equal), 0.5 of the permutations will have 1 in the first element in the array.",0
"> @LeechMuse
> In the code provided by you `y_true` = [0, 0, 1, 1], `y_pred` = [1, 1, 1., 1.] , top_k = top-k classes to be considered to calculate precision.
> 
> If top_k = none it consider all the classes.
> 
> Precision is calculated by TP/TP+FP. So in the case top_k =1 it considers the first value only to calculate precision (ie y_true = [0] and y_pred = [1]) so precision is zero.
> 
> Similarly top_k=2 considers first 2 values y_true` = [0, 0] and y_pred` = [1, 1] so precision is zero.
> If top_k=3 then y_true` = [0, 0,1] and y_pred` = [1,1,1.] so precision is 0.33.
> 
> In this example top_k =4 or None is same because it uses all the values. In that case `y_true` = [0, 0, 1, 1], `y_pred` = [1, 1, 1., 1.] so precision will be 0.5. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/af71a7be1c9cc0e945f79536d540fbb3/untitled710.ipynb). Thanks!

@ravikyram , I think this example should also be added in the doc, so here it is. PR #37528 adds this example to doc.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37416#issuecomment-598067343,ashutosh1919,2020-03-12 08:35:25,37416,[37528],Documentation bug,0,"> @LeechMuse > In the code provided by you [code] = [0, 0, 1, 1], [code] = [1, 1, 1., 1.] , top_k = top-k classes to be considered to calculate precision. > > If top_k = none it consider all the classes. > > Precision is calculated by TP/TP+FP. So in the case top_k =1 it considers the first value only to calculate precision (ie y_true = [0] and y_pred = [1]) so precision is zero. > > Similarly top_k=2 considers first 2 values y_true[code] = [1, 1] so precision is zero. > If top_k=3 then y_true[code] = [1,1,1.] so precision is 0.33. > > In this example top_k =4 or None is same because it uses all the values. In that case [code] = [0, 0, 1, 1], [code] = [1, 1, 1., 1.] so precision will be 0.5. Please, find the gist [here]([url] Thanks! @ravikyram , I think this example should also be added in the doc, so here it is. PR #37528 adds this example to doc.",3
"@jpatts, Documentation is available for tf-nightly version. Please take a look at doc [here](https://www.tensorflow.org/api_docs/python/tf/keras/losses/get?version=nightly) for more about `identifier` and `returns`. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-593783278,gadagashwini-zz,2020-03-03 06:01:51,37240,[37538],Documentation bug,0,"@jpatts, Documentation is available for tf-nightly version. Please take a look at doc [here]([url] for more about [code] and [code]. Thanks!",3
"@gadagashwini, I saw the nightly documentation after this post, however there is still no explanation for what a â€œloss configuration dictionaryâ€ is. Thatâ€™s the larger problem for this. The way I tried to do it is the intuitive way, but it doesnâ€™t work for the reasons I showed above, so I would like to know how itâ€™s supposed to be used.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-593784637,princessofpillows,2020-03-03 06:07:27,37240,[37538],Documentation bug,0,"@gadagashwini, I saw the nightly documentation after this post, however there is still no explanation for what a â€œloss configuration dictionaryâ€ is. Thatâ€™s the larger problem for this. The way I tried to do it is the intuitive way, but it doesnâ€™t work for the reasons I showed above, so I would like to know how itâ€™s supposed to be used.",-2
"@jpatts would you mind to elaborate what exactly are you trying to do?

there are some examples how to serialize custom objects and functions 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/generic_utils_test.py#L146",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-593891551,lc0,2020-03-03 10:58:23,37240,[37538],Documentation bug,0,@jpatts would you mind to elaborate what exactly are you trying to do? there are some examples how to serialize custom objects and functions [url]#L146,0
"@lc0 I gave an example at the top of this issue showing what Iâ€™m trying to do. To use a configuration dictionary, I need two mandatory JSON parameters, â€œclass_nameâ€ and â€œconfigâ€. This can be seen in [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/generic_utils.py#L308) code section:
```
def class_and_config_for_serialized_keras_object(
    config,
    module_objects=None,
    custom_objects=None,
    printable_module_name='object'):
  """"""Returns the class name and config for a serialized keras object.""""""
  if (not isinstance(config, dict) or 'class_name' not in config or
      'config' not in config):
    raise ValueError('Improper config format: ' + str(config))
```
However, when I do this, the â€œclass_nameâ€ is used for the initialization and â€œconfigâ€ is used as function inputs. The â€œconfigâ€ should be setting â€œclass_nameâ€ parameter options during function initialization.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-594059495,princessofpillows,2020-03-03 17:05:00,37240,[37538],Documentation bug,0,"@lc0 I gave an example at the top of this issue showing what Iâ€™m trying to do. To use a configuration dictionary, I need two mandatory JSON parameters, â€œclass_nameâ€ and â€œconfigâ€. This can be seen in [this]([url]#L308) code section: ``[code]`` However, when I do this, the â€œclass_nameâ€ is used for the initialization and â€œconfigâ€ is used as function inputs. The â€œconfigâ€ should be setting â€œclass_nameâ€ parameter options during function initialization.",-1
"This is the block of code where this is happening.
```
if isinstance(identifier, dict):
    # In this case we are dealing with a Keras config dictionary.
    config = identifier
    (cls, cls_config) = class_and_config_for_serialized_keras_object(
        config, module_objects, custom_objects, printable_module_name)

    if hasattr(cls, 'from_config'):
      arg_spec = tf_inspect.getfullargspec(cls.from_config)
      custom_objects = custom_objects or {}

      if 'custom_objects' in arg_spec.args:
        return cls.from_config(
            cls_config,
            custom_objects=dict(
                list(_GLOBAL_CUSTOM_OBJECTS.items()) +
                list(custom_objects.items())))
      with CustomObjectScope(custom_objects):
        return cls.from_config(cls_config)
    else:
      # Then `cls` may be a function returning a class.
      # in this case by convention `config` holds
      # the kwargs of the function.
      custom_objects = custom_objects or {}
      with CustomObjectScope(custom_objects):
        return cls(**cls_config)
```
The way I send the dictionary, I am being put down the ""config holds the kwargs of the function"" path. I think I want to be going down the ""from_config"" path, but don't know how to do so.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-594117533,princessofpillows,2020-03-03 19:10:36,37240,[37538],Documentation bug,0,"This is the block of code where this is happening. ``[code]cls[code]config[code]`` The way I send the dictionary, I am being put down the ""config holds the kwargs of the function"" path. I think I want to be going down the ""from_config"" path, but don't know how to do so.",-1
"[This](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/losses.py#L148) is the ""from_config"" method for the loss class.
```
@classmethod
  def from_config(cls, config):
    """"""Instantiates a `Loss` from its config (output of `get_config()`).
    Args:
        config: Output of `get_config()`.
    Returns:
        A `Loss` instance.
    """"""
    return cls(**config)

  def get_config(self):
    """"""Returns the config dictionary for a `Loss` instance.""""""
    return {'reduction': self.reduction, 'name': self.name}
```
This is confusing, as `cls(**cls_config)` and `cls.from_config(cls_config)` end up being the same thing...",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-594121265,princessofpillows,2020-03-03 19:19:12,37240,[37538],Documentation bug,0,"[This]([url]#L148) is the ""from_config"" method for the loss class. ``[code]Loss[code]get_config()[code]get_config()[code]Loss[code]Loss[code]`[code]cls(**cls_config)[code]cls.from_config(cls_config)` end up being the same thing...",0
"Bump. Iâ€™m pretty sure that the issues Iâ€™m having are from the loss functions not actually having settable parameters. IE you canâ€™t set â€œfrom_logitsâ€ during initialization, it needs to be set every time it is executed. So in this case, â€œconfigâ€ is literally just calling the function with itâ€™s supplied parameters. This makes me question why this is a feature... ",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-596029912,princessofpillows,2020-03-07 01:39:29,37240,[37538],Documentation bug,0,"Bump. Iâ€™m pretty sure that the issues Iâ€™m having are from the loss functions not actually having settable parameters. IE you canâ€™t set â€œfrom_logitsâ€ during initialization, it needs to be set every time it is executed. So in this case, â€œconfigâ€ is literally just calling the function with itâ€™s supplied parameters. This makes me question why this is a feature...",-2
"I can explain why this doesn't work -- when you pass a dict, the class name should be the actual name of the class.  `categorical_crossentropy` is a function, and not a class. I think the documentation should be improved here. 

@pavithrasv  Should we modify `losses.get` to return partial functions, if the class name is the name of a function?",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-597956720,k-w-w,2020-03-12 01:10:50,37240,[37538],Documentation bug,0,"I can explain why this doesn't work -- when you pass a dict, the class name should be the actual name of the class. [code] is a function, and not a class. I think the documentation should be improved here. @pavithrasv Should we modify [code] to return partial functions, if the class name is the name of a function?",0
"Thank you very much for the clarification @k-w-w.
So this returns a function:
```
loss = tf.keras.losses.get(""categorical_crossentropy"")
print(loss)

<function categorical_crossentropy at 0x000002886AFC7318>
```
And this returns the class.
```
jsn = {""class_name"":""CategoricalCrossentropy"", 
       ""config"": {
            ""from_logits"": True
        }
}
loss = tf.keras.losses.get(jsn)
print(loss)

<tensorflow.python.keras.losses.CategoricalCrossentropy object at 0x0000018D9E219CC8>
```
This solves my problem completely. I agree that the documentation should be updated, as this was very confusing. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-597960336,princessofpillows,2020-03-12 01:25:30,37240,[37538],Documentation bug,0,"Thank you very much for the clarification @k-w-w. So this returns a function: ``[code]`[code]`[code]`` This solves my problem completely. I agree that the documentation should be updated, as this was very confusing.",2
"@jpatts and @k-w-w , please take a look at PR #37538 and suggest more changes if needed. I have added descriptions and examples which will clarify all doubts regarding `tf.keras.losses.get`",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-598192702,ashutosh1919,2020-03-12 13:43:17,37240,[37538],Documentation bug,0,"@jpatts and @k-w-w , please take a look at PR #37538 and suggest more changes if needed. I have added descriptions and examples which will clarify all doubts regarding [code]",2
"Thank you for the response @k-w-w and the quick PR @ashutosh1919 .

@k-w-w Yes, we can look into returning partial functions if class name is the name of a function. From the top of my head i think `deserialize_keras_object` may need to be modified for that.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37240#issuecomment-598543960,pavithrasv,2020-03-13 04:37:01,37240,[37538],Documentation bug,0,"Thank you for the response @k-w-w and the quick PR @ashutosh1919 . @k-w-w Yes, we can look into returning partial functions if class name is the name of a function. From the top of my head i think [code] may need to be modified for that.",3
@tobillsung-doc Do you want to raise a PR to update the docs? Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/37239#issuecomment-594776248,jvishnuvardhan,2020-03-04 19:27:43,37239,[37539],Documentation bug,0,@tobillsung-doc Do you want to raise a PR to update the docs? Thanks!,3
"@jvishnuvardhan Yes, please. Thank you.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37239#issuecomment-595273118,tobillsung-doc,2020-03-05 14:59:23,37239,[37539],Documentation bug,0,"@jvishnuvardhan Yes, please. Thank you.",3
"It seems some dependency is missed. Do 
```
> c++filt _ZN10tensorflow8internal10LogMessageC1EPKcii
tensorflow::internal::LogMessage::LogMessage(char const*, int, int)
```
then you can find that `tensorflow::internal::LogMessage::LogMessage(char const*, int, int)` is in `//tensorflow/core/platform:logging`. Add `//tensorflow/core/platform:logging` then you'll find other undefined symbols. 

Anyway, the following should work

```diff
diff --git a/tensorflow/compiler/tf2tensorrt/BUILD b/tensorflow/compiler/tf2tensorrt/BUILD
index 9da873a..371a580 100644
--- a/tensorflow/compiler/tf2tensorrt/BUILD
+++ b/tensorflow/compiler/tf2tensorrt/BUILD
@@ -560,6 +560,9 @@ pybind_extension(
     module_name = ""_pywrap_py_utils"",
     deps = [
         "":py_utils"",
+        ""//tensorflow/core/platform:env"",
+        ""//tensorflow/core/platform:logging"",
+        ""//tensorflow/core/platform:status"",
         ""@pybind11"",
     ],
 )

```",IssueComment,https://github.com/tensorflow/tensorflow/issues/37523#issuecomment-598100616,freedomtan,2020-03-12 09:56:14,37523,[37560],Build bug,0,"It seems some dependency is missed. Do ``[code]`[code]tensorflow::internal::LogMessage::LogMessage(char const*, int, int)[code]//tensorflow/core/platform:logging[code]//tensorflow/core/platform:logging[code]`[code]``",0
Is building from -devel docker image supported workflow? It seems important enough for developer productivity to deserve an integration test.,IssueComment,https://github.com/tensorflow/tensorflow/issues/37523#issuecomment-598908585,sshrdp,2020-03-13 20:58:22,37523,[37560],Build bug,0,Is building from -devel docker image supported workflow? It seems important enough for developer productivity to deserve an integration test.,1
"@freedomtan 
As there is a pr to monitor this issue, please confirm if  we may move this issue to closed status.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37523#issuecomment-599577498,Saduf2019,2020-03-16 14:47:46,37523,[37560],Build bug,0,"@freedomtan As there is a pr to monitor this issue, please confirm if we may move this issue to closed status.",0
"@Saduf2019 you should ask @lezh who opened this issue, not me :)",IssueComment,https://github.com/tensorflow/tensorflow/issues/37523#issuecomment-599579365,freedomtan,2020-03-16 14:51:24,37523,[37560],Build bug,0,"@Saduf2019 you should ask @lezh who opened this issue, not me :)",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37523"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37523"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37523#issuecomment-599640665,tensorflow-bot[bot],2020-03-16 16:45:48,37523,[37560],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@alexdwu13 Thanks for creating the issue. Would you like to create a PR to update the doc? Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/37067#issuecomment-591478428,jvishnuvardhan,2020-02-26 15:16:32,37067,[37565],Documentation bug,0,@alexdwu13 Thanks for creating the issue. Would you like to create a PR to update the doc? Thanks!,3
"@jvishnuvardhan I'd be happy to create a PR -- but I myself am not clear about the usage. I've tried munging YUV images to the input format expected by `tf.image.yuv_to_rgb` but have so far not been successful https://stackoverflow.com/questions/60067415/what-is-the-correct-usage-of-tf-image-yuv-to-rgb-output-is-distorted.
Would you be able to grab ahold of the original authors of this method?",IssueComment,https://github.com/tensorflow/tensorflow/issues/37067#issuecomment-591698581,alexdwu13,2020-02-26 23:32:23,37067,[37565],Documentation bug,0,@jvishnuvardhan I'd be happy to create a PR -- but I myself am not clear about the usage. I've tried munging YUV images to the input format expected by [code] but have so far not been successful [url] Would you be able to grab ahold of the original authors of this method?,0
"I left a comment on the PR 37565. I think the documentation has been incorrect on the [-0.5, 0.5] range for the UV channels. And there are bigger issues with the function itself. 

1. Prior to this issue, the documentation specified that the U and V channels need to be in the range [-0.5, 0.5]. That is incorrect. The kernels in the source show that the correct ranges are 

u: -0.43601035 to + 0.43601035
v: -0.61497538 to + 0.61497538

2. The defined ranges for U and V per the ITU spec are in fact 

[-0.436, +0.436]
[-0.615, +0.615]

3. 

The PR 37565 created a linear interpolation example for the (incorrectly documented) range of [-0.5, 0.5] for the U and V channels. 

4.

PR 37565  implies that a TF developer might end up with a YUV range of [0, 256). That is extremely unlikely because the YUV space is not ""square"", it is ""diamond"" and corners like YUV= (1,1,1) are in fact impossible colors. YUV=(1,1,1) would mean a ""maximum bright white color with a lot of red and blue"". This results in a color with more red and blue than an LCD display can render, or the human eye can perceive. 

>>> tf.image.yuv_to_rgb(tf.constant([1.0, 0.436, 0.615]))
<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.7010281, 0.4708535, 1.8859789], dtype=float32)>

The conceivable sources of a YUV image would be directly pulled from an analog CRT display, or, via transforms on a tensor that came from the tf.image.rgb_to_yuv. The former seems very unlikely, the latter is also unlikely because manipulating YUV directly without running into clipping against the ""diamond shaped"" visible color space is very difficult. 

5. 

Finally, the rgb_to_yuv and yuv_to_rgb functions are problematic because they assume a linear, non-gamma corrected RGB color values. The vast majority of images on the web or captured by a camera will be rendered in a gamma corrected color-space, namely sRGB. 

--

To fix the documentation, I'd suggest a quick update to the correct UV ranges.  I'd also suggest a strong caveat that this function is likely not what people are looking for - a better transform for gamma corrected RGB (namely, sRGB) would be YCbCr. I'd also suggest we remove the example recently added of the linear transform, since it's unlikely a developer would ever get the raw YUV values from something other than the rgb_to_yuv function. 

Here is the start of some example code for yuv_to_rgb... if these suggestions make sense, I'll finish this up and make it a PR.

def yuv_to_rgb(images):
  """"""Converts one or more images from YUV to RGB.

  Outputs a tensor of the same shape as the `images` tensor, containing the RGB
  value of the pixels.
  The output is only well defined if the Y values in images are in [0,1],
  U values are in [-0.43601035, 0.43601035], and V value are in 
  [-0.61497538,0.61497538].


  # Test approximate range of Y, U, and V. 
  >>> rgb_images = tf.random.uniform(shape=[60000, 32, 32, 3], minval=0, maxval=256, dtype=tf.int32)
  >>> rgb_images = tf.cast(rgb_images, tf.uint8)
  >>> rgb_float_images = tf.image.convert_image_dtype(rgb_images, tf.float32)
  >>> yuv_images = tf.image.rgb_to_yuv(rgb_float_images)

  >>> # Approximate min and max for Y channel
  >>> tf.reduce_min(yuv_images[...,0])
  <tf.Tensor: shape=(), dtype=float32, numpy=0.0>
  >>> tf.reduce_max(yuv_images[...,0])
  <tf.Tensor: shape=(), dtype=float32, numpy=1.0>

  # Approximate min and max for U channel
  >>> tf.reduce_min(yuv_images[...,1])
  <tf.Tensor: shape=(), dtype=float32, numpy=-0.43543333>
  >>> tf.reduce_max(yuv_images[...,1])
  <tf.Tensor: shape=(), dtype=float32, numpy=0.43601036>

  # Approximate min and max for V channel
  >>> tf.reduce_min(yuv_images[...,2])
  <tf.Tensor: shape=(), dtype=float32, numpy=-0.6149754>
  >>> tf.reduce_max(yuv_images[...,2])
  <tf.Tensor: shape=(), dtype=float32, numpy=0.6149754>

  This function is likely not appropriate for images typically found on the web or generated by
  digital cameras. Those typically adjust the RGB values to be gamma corrected, meaning they are rendered in the sRGB color space. The YCbCr colorspace was designed for the 
  sRGB colorspace and may be more appropriate. The YUV colorspace
  was based on analog, non-gamma corrected RGB values. 
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37067#issuecomment-640362229,yaoshiang,2020-06-08 04:39:28,37067,[37565],Documentation bug,0,"I left a comment on the PR 37565. I think the documentation has been incorrect on the [-0.5, 0.5] range for the UV channels. And there are bigger issues with the function itself. 1. Prior to this issue, the documentation specified that the U and V channels need to be in the range [-0.5, 0.5]. That is incorrect. The kernels in the source show that the correct ranges are u: -0.43601035 to + 0.43601035 v: -0.61497538 to + 0.61497538 2. The defined ranges for U and V per the ITU spec are in fact [-0.436, +0.436] [-0.615, +0.615] 3. The PR 37565 created a linear interpolation example for the (incorrectly documented) range of [-0.5, 0.5] for the U and V channels. 4. PR 37565 implies that a TF developer might end up with a YUV range of [0, 256). That is extremely unlikely because the YUV space is not ""square"", it is ""diamond"" and corners like YUV= (1,1,1) are in fact impossible colors. YUV=(1,1,1) would mean a ""maximum bright white color with a lot of red and blue"". This results in a color with more red and blue than an LCD display can render, or the human eye can perceive. >>> tf.image.yuv_to_rgb(tf.constant([1.0, 0.436, 0.615])) <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.7010281, 0.4708535, 1.8859789], dtype=float32)> The conceivable sources of a YUV image would be directly pulled from an analog CRT display, or, via transforms on a tensor that came from the tf.image.rgb_to_yuv. The former seems very unlikely, the latter is also unlikely because manipulating YUV directly without running into clipping against the ""diamond shaped"" visible color space is very difficult. 5. Finally, the rgb_to_yuv and yuv_to_rgb functions are problematic because they assume a linear, non-gamma corrected RGB color values. The vast majority of images on the web or captured by a camera will be rendered in a gamma corrected color-space, namely sRGB. -- To fix the documentation, I'd suggest a quick update to the correct UV ranges. I'd also suggest a strong caveat that this function is likely not what people are looking for - a better transform for gamma corrected RGB (namely, sRGB) would be YCbCr. I'd also suggest we remove the example recently added of the linear transform, since it's unlikely a developer would ever get the raw YUV values from something other than the rgb_to_yuv function. Here is the start of some example code for yuv_to_rgb... if these suggestions make sense, I'll finish this up and make it a PR. def yuv_to_rgb(images): """"""Converts one or more images from YUV to RGB. Outputs a tensor of the same shape as the [code] tensor, containing the RGB value of the pixels. The output is only well defined if the Y values in images are in [0,1], U values are in [-0.43601035, 0.43601035], and V value are in [-0.61497538,0.61497538]. # Test approximate range of Y, U, and V. >>> rgb_images = tf.random.uniform(shape=[60000, 32, 32, 3], minval=0, maxval=256, dtype=tf.int32) >>> rgb_images = tf.cast(rgb_images, tf.uint8) >>> rgb_float_images = tf.image.convert_image_dtype(rgb_images, tf.float32) >>> yuv_images = tf.image.rgb_to_yuv(rgb_float_images) >>> # Approximate min and max for Y channel >>> tf.reduce_min(yuv_images[...,0]) <tf.Tensor: shape=(), dtype=float32, numpy=0.0> >>> tf.reduce_max(yuv_images[...,0]) <tf.Tensor: shape=(), dtype=float32, numpy=1.0> # Approximate min and max for U channel >>> tf.reduce_min(yuv_images[...,1]) <tf.Tensor: shape=(), dtype=float32, numpy=-0.43543333> >>> tf.reduce_max(yuv_images[...,1]) <tf.Tensor: shape=(), dtype=float32, numpy=0.43601036> # Approximate min and max for V channel >>> tf.reduce_min(yuv_images[...,2]) <tf.Tensor: shape=(), dtype=float32, numpy=-0.6149754> >>> tf.reduce_max(yuv_images[...,2]) <tf.Tensor: shape=(), dtype=float32, numpy=0.6149754> This function is likely not appropriate for images typically found on the web or generated by digital cameras. Those typically adjust the RGB values to be gamma corrected, meaning they are rendered in the sRGB color space. The YCbCr colorspace was designed for the sRGB colorspace and may be more appropriate. The YUV colorspace was based on analog, non-gamma corrected RGB values.",-1
"Just FYI, keras-team is working on some documents that clearly defines the API contract for all the important interfaces for Keras, and we will update the docs related very soon.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-586414137,qlzh727,2020-02-14 18:33:15,36757,[37574],Documentation bug,0,"Just FYI, keras-team is working on some documents that clearly defines the API contract for all the important interfaces for Keras, and we will update the docs related very soon.",3
"I think #37574 only cover part of the functionnality for call(), and the major part for eager/graph context is not covered yet.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-599614984,qlzh727,2020-03-16 15:55:59,36757,[37574],Documentation bug,0,"I think #37574 only cover part of the functionnality for call(), and the major part for eager/graph context is not covered yet.",-1
"Any pointers on the proper way to enable eager execution on layer.call()? I hit this issue converting a model that uses a custom layer to tflite. The conversion fails since the custom layer call function is not being executed eagerly (tf.executing_eagerly() is returning False). I have been looking around on the documentation, and just can't find how to force my custom layer to use eager mode...",IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-609541698,adelcast,2020-04-06 03:03:38,36757,[37574],Documentation bug,0,"Any pointers on the proper way to enable eager execution on layer.call()? I hit this issue converting a model that uses a custom layer to tflite. The conversion fails since the custom layer call function is not being executed eagerly (tf.executing_eagerly() is returning False). I have been looking around on the documentation, and just can't find how to force my custom layer to use eager mode...",-1
"@adelcast, to run the layer.call() body in eager context, you need to invoke model.compile(run_eagerly=True). Note that this will have performance slow down due to eager runtime, and should only used for debug purpose.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-609914819,qlzh727,2020-04-06 16:57:46,36757,[37574],Documentation bug,0,"@adelcast, to run the layer.call() body in eager context, you need to invoke model.compile(run_eagerly=True). Note that this will have performance slow down due to eager runtime, and should only used for debug purpose.",0
@qlzh727 Do we want to close this or are we waiting for a contribution?,IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-821189392,bhack,2021-04-16 13:46:43,36757,[37574],Documentation bug,0,@qlzh727 Do we want to close this or are we waiting for a contribution?,0
"Though the TF webpage doesn't show the recent updates, I think this was resolved in the `master` branch. The description is much more clear now. I added a PR to add description about running in eager mode as described in https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-609914819. Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-859977884,jvishnuvardhan,2021-06-12 01:31:38,36757,[37574],Documentation bug,0,"Though the TF webpage doesn't show the recent updates, I think this was resolved in the [code] branch. The description is much more clear now. I added a PR to add description about running in eager mode as described in [url]#issuecomment-609914819. Thanks",3
"@qlzh727 Can we add this as part of FAQs in Keras website? Thanks

There is a related question in FAQs https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call ",IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-949300856,jvishnuvardhan,2021-10-22 05:35:34,36757,[37574],Documentation bug,0,@qlzh727 Can we add this as part of FAQs in Keras website? Thanks There is a related question in FAQs [url]#whats-the-difference-between-model-methods-predict-and-call,2
Sure.,IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-951144068,qlzh727,2021-10-25 17:27:10,36757,[37574],Documentation bug,0,Sure.,0
"Hi There,

 This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! 

 Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/36757#issuecomment-994126730,tensorflowbutler,2021-12-14 23:12:05,36757,[37574],Documentation bug,0,"Hi There, This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras]([url] repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks!",0
"@buaasun 
could you please provide us with simple stand alone code for us to replicate the issue faced by you.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37593#issuecomment-599381619,Saduf2019,2020-03-16 07:19:39,37593,[37684],Algorithm design bug,0,@buaasun could you please provide us with simple stand alone code for us to replicate the issue faced by you.,0
"@Saduf2019 @gowthamkpr 
This error occurs with a low probability. `n->in_edges()` returns EdgeSet which contains `std::set<Edge*>`, so `in_edges` are ordered by the pointer of Edge. In most cases, pointers are allocated sequentially, so it works. But when executed many times, the error occurs randomly.

I write a simple unit test as below.
```c++

#include ""tensorflow/cc/client/client_session.h""
#include ""tensorflow/cc/framework/grad_op_registry.h""
#include ""tensorflow/cc/framework/gradients.h""
#include ""tensorflow/cc/framework/testutil.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/core/framework/graph.pb.h""
#include ""tensorflow/core/framework/node_def_util.h""
#include ""tensorflow/core/framework/tensor_testutil.h""
#include ""tensorflow/core/lib/core/status_test_util.h""
#include ""tensorflow/core/platform/test.h""

namespace tensorflow {
namespace {
using namespace ops;

class GradientsTest : public ::testing::Test {
 protected:
  GradientsTest() {}

  void TestSingle(const Scope& scope) {
    int N = 5 + rand() % 10;
    // Construct forward graph.
    OutputList inputs;
    for (int i = 0; i < N; ++i) {
      auto a = Const(scope, i, {1});
      inputs.push_back(a);
    }

    auto pack = Stack(scope, inputs);
    TF_ASSERT_OK(scope.status());

    // Construct grad inputs.
    OutputList output_grads;
    Tensor ts(DT_INT32, {N, 1});
    auto v = ts.matrix<int32>();
    for (int i = 0; i < N; ++i) {
      v(i, 0) = i;
    }
    auto dy = Const(scope, ts);
    output_grads.push_back(dy);
    // Call AddSymbolicGradients.
    std::vector<Output> grad_outputs;
    TF_ASSERT_OK(AddSymbolicGradients(scope, {pack.output}, inputs, output_grads, &grad_outputs));
    ClientSession session((scope));
    std::vector<Tensor> in_grad;
    TF_ASSERT_OK(session.Run(grad_outputs, &in_grad));
    for (int i = 0; i < N; ++i) {
      test::ExpectTensorEqual<int>(in_grad[i], test::AsTensor<int>({i}, {1}));
    }
  }
};
TEST_F(GradientsTest, SubScopeTest) {
  Scope scope = Scope::NewRootScope();
  for (int cnt = 0; cnt < 1000; ++cnt) {
    LOG(INFO) << cnt;
    TestSingle(scope.NewSubScope(std::to_string(cnt)));
  }
}

}  // namespace
}  // namespace tensorflow
```
As in code, the test run 1000 cnts, about 5 of them failed.



",IssueComment,https://github.com/tensorflow/tensorflow/issues/37593#issuecomment-599891246,buaasun,2020-03-17 05:54:39,37593,[37684],Algorithm design bug,0,"@Saduf2019 @gowthamkpr This error occurs with a low probability. [code] returns EdgeSet which contains [code], so [code] are ordered by the pointer of Edge. In most cases, pointers are allocated sequentially, so it works. But when executed many times, the error occurs randomly. I write a simple unit test as below. ``[code]`` As in code, the test run 1000 cnts, about 5 of them failed.",-1
"I don't work on TF anymore, sorry!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37593#issuecomment-600218754,skye,2020-03-17 18:06:35,37593,[37684],Algorithm design bug,0,"I don't work on TF anymore, sorry!",-1
Thanks for debugging this! Your proposal looks good. Would you like to send a PR for the fix?,IssueComment,https://github.com/tensorflow/tensorflow/issues/37593#issuecomment-600349653,saxenasaurabh,2020-03-17 23:32:14,37593,[37684],Algorithm design bug,0,Thanks for debugging this! Your proposal looks good. Would you like to send a PR for the fix?,4
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37593"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37593"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37593#issuecomment-601908807,tensorflow-bot[bot],2020-03-20 21:00:33,37593,[37684],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@PRDrum5 

Can you please share the simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37086#issuecomment-591807472,ravikyram,2020-02-27 06:35:10,37086,[37798],Deployment bug,0,@PRDrum5 Can you please share the simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!,3
"Sure

Here I've made a simple model but not defined the input_signature for the tf.function for the `__call__` of the model. In doing so there is **no**  concrete functions at all. But the error message which is returned implies that there are multiple and that this is the issue.

My suggestion is that the error thrown should be clear that in this scinario the user has not defined any concrete functions rather that suggesting that there exists more than one which is not the case.

```
import tensorflow as tf
from tensorflow.keras.layers import Dense


# Define very simple classification model
class Model(tf.Module):
    def __init__(self):
        super(Model, self).__init__()

        self.d1 = Dense(2, activation='relu')
        self.d2 = Dense(2, activation='softmax')
    
    @tf.function
    def __call__(self, x):
        print(""Tracing the model"")
        x = self.d1(x)
        return self.d2(x)

model = Model()

example_data = tf.constant([[1.0, 2.0]])
preds = model(example_data)
tf.print(preds)

# Save the model
tf.saved_model.save(model, './model_example')


# Load the saved model and convert to TFLite
converter = tf.lite.TFLiteConverter.from_saved_model('./model_example')
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)


```",IssueComment,https://github.com/tensorflow/tensorflow/issues/37086#issuecomment-591866457,PRDrum5,2020-02-27 09:19:45,37086,[37798],Deployment bug,0,Sure Here I've made a simple model but not defined the input_signature for the tf.function for the [code] of the model. In doing so there is **no** concrete functions at all. But the error message which is returned implies that there are multiple and that this is the issue. My suggestion is that the error thrown should be clear that in this scinario the user has not defined any concrete functions rather that suggesting that there exists more than one which is not the case. ``[code]``,-2
"I have tried on colab with TF version 2.1.0,2.2.0-dev20200227  and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/39a05cacd98c1c561c6c2b94f986db69/untitled683.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37086#issuecomment-592397338,ravikyram,2020-02-28 08:03:40,37086,[37798],Deployment bug,0,"I have tried on colab with TF version 2.1.0,2.2.0-dev20200227 and was able to reproduce the issue.Please, find the gist [here]([url] Thanks!",0
@gargn for this case is it possible to provide the signature w/ the `from_saved_model` method? Or do they have to load the model and then explicitly call `from_concrete_functions`?,IssueComment,https://github.com/tensorflow/tensorflow/issues/37086#issuecomment-594888936,jdduke,2020-03-04 22:16:18,37086,[37798],Deployment bug,0,@gargn for this case is it possible to provide the signature w/ the [code] method? Or do they have to load the model and then explicitly call [code]?,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37086"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37086"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37086#issuecomment-618755038,google-ml-butler[bot],2020-04-24 01:41:24,37086,[37798],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@mcourteaux, first of all validation pass is not considered as training and during training of network actually dropout layer is not bypassed instead of that all neuron's weight of dropout layer is multiplied by probability p of its existence. 
![Screenshot from 2020-03-22 09-45-00](https://user-images.githubusercontent.com/36735394/77242230-5c36bb00-6c22-11ea-9633-92394b501149.png)
For more detail you can refer [this](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf) paper.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37792#issuecomment-602145931,khimraj,2020-03-22 04:20:14,37792,[37816],Documentation bug,0,"@mcourteaux, first of all validation pass is not considered as training and during training of network actually dropout layer is not bypassed instead of that all neuron's weight of dropout layer is multiplied by probability p of its existence. ![Screenshot from 2020-03-22 09-45-00]([url] For more detail you can refer [this]([url] paper.",0
"So, based on your statement ""validation pass is not considered as training"", all types of noise and dropout do not affect validation loss computations.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37792#issuecomment-602185118,mcourteaux,2020-03-22 11:32:16,37792,[37816],Documentation bug,0,"So, based on your statement ""validation pass is not considered as training"", all types of noise and dropout do not affect validation loss computations.",0
Yes validation pass is not considered as training and dropout layer doesn't affect validation loss.,IssueComment,https://github.com/tensorflow/tensorflow/issues/37792#issuecomment-602186507,khimraj,2020-03-22 11:44:11,37792,[37816],Documentation bug,0,Yes validation pass is not considered as training and dropout layer doesn't affect validation loss.,0
"> Yes validation pass is not considered as training and dropout layer doesn't affect validation loss.

Hi. I can clearly see that dropout is not considered during validation from your answer. But I was wondering if this is also true for weight regularization. That is, will the weight regularization loss be considered during validation? Thank you.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37792#issuecomment-1006316949,riemanli,2022-01-06 06:25:55,37792,[37816],Documentation bug,0,"> Yes validation pass is not considered as training and dropout layer doesn't affect validation loss. Hi. I can clearly see that dropout is not considered during validation from your answer. But I was wondering if this is also true for weight regularization. That is, will the weight regularization loss be considered during validation? Thank you.",0
"Me now being a little more familiar with the code, I would say: Yes, it will be considered. The loss function never changes, not in training or validation, or evaluation. Just the noise/dropout layer is bypassed, and the network produces a prediction in the fullest ""quality"" (ie: without the distortions from those layers).",IssueComment,https://github.com/tensorflow/tensorflow/issues/37792#issuecomment-1006450011,mcourteaux,2022-01-06 10:24:11,37792,[37816],Documentation bug,0,"Me now being a little more familiar with the code, I would say: Yes, it will be considered. The loss function never changes, not in training or validation, or evaluation. Just the noise/dropout layer is bypassed, and the network produces a prediction in the fullest ""quality"" (ie: without the distortions from those layers).",0
"@zaccharieramzi , can you explain the issue using example and elaborate it ? The given description is not enough to clearly understand the issue. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37669#issuecomment-602400545,ashutosh1919,2020-03-23 05:54:00,37669,[37832],Documentation bug,0,"@zaccharieramzi , can you explain the issue using example and elaborate it ? The given description is not enough to clearly understand the issue. Thanks!",0
Well it's a doc issue so it's not really fit for an example. I just meant that the docs for `tensor_scatter_nd_add` should not mention a `shape` argument that is not part of the arguments of `tensor_scatter_nd_add`.,IssueComment,https://github.com/tensorflow/tensorflow/issues/37669#issuecomment-602462043,zaccharieramzi,2020-03-23 08:50:18,37669,[37832],Documentation bug,0,Well it's a doc issue so it's not really fit for an example. I just meant that the docs for [code] should not mention a [code] argument that is not part of the arguments of [code].,-1
"Thanks for the quick reply @zaccharieramzi . Are you able to locate the file where `tensor_scatter_nd_add` is implemented? If Yes, then please also provide the link. I am not able to locate the method.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37669#issuecomment-602475602,ashutosh1919,2020-03-23 09:19:30,37669,[37832],Documentation bug,0,"Thanks for the quick reply @zaccharieramzi . Are you able to locate the file where [code] is implemented? If Yes, then please also provide the link. I am not able to locate the method.",1
"Like I pointed in the issue there is no link to the source code in the docs (that's another problem I guess). I think it's because it's a C++ op.
However, I don't understand why you would need it to understand this particular issue.
Anyway, I think the function is implemented here: https://github.com/tensorflow/tensorflow/blob/5214758e1f9335008a788be554633d974f569cf1/tensorflow/compiler/tf2xla/kernels/scatter_nd_op.cc#L172",IssueComment,https://github.com/tensorflow/tensorflow/issues/37669#issuecomment-602499124,zaccharieramzi,2020-03-23 10:07:35,37669,[37832],Documentation bug,0,"Like I pointed in the issue there is no link to the source code in the docs (that's another problem I guess). I think it's because it's a C++ op. However, I don't understand why you would need it to understand this particular issue. Anyway, I think the function is implemented here: [url]#L172",0
"@zaccharieramzi , I have found the code with the doc [here](https://github.com/tensorflow/java/blob/master/tensorflow-core/tensorflow-core-api/src/gen/java/org/tensorflow/op/core/TensorScatterNdAdd.java).",IssueComment,https://github.com/tensorflow/tensorflow/issues/37669#issuecomment-602512233,ashutosh1919,2020-03-23 10:34:39,37669,[37832],Documentation bug,0,"@zaccharieramzi , I have found the code with the doc [here]([url]",0
"Oh you meant the docstring code, right.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37669#issuecomment-602518550,zaccharieramzi,2020-03-23 10:48:43,37669,[37832],Documentation bug,0,"Oh you meant the docstring code, right.",0
"@zaccharieramzi and @mihaimaruseac , I have raised PR [#35](https://github.com/tensorflow/java/pull/35) to resolve this issue. Please review.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37669#issuecomment-602520725,ashutosh1919,2020-03-23 10:53:29,37669,[37832],Documentation bug,0,"@zaccharieramzi and @mihaimaruseac , I have raised PR [#35]([url] to resolve this issue. Please review.",0
"@mihaimaruseac , sorry for wrong PR. review #37832 for this issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37669#issuecomment-602611357,ashutosh1919,2020-03-23 14:02:57,37669,[37832],Documentation bug,0,"@mihaimaruseac , sorry for wrong PR. review #37832 for this issue.",0
"I'll start working on this.
 ",IssueComment,https://github.com/tensorflow/tensorflow/issues/37896#issuecomment-603965308,ManishAradwad,2020-03-25 17:06:31,37896,[37905],Documentation bug,0,I'll start working on this.,2
Please tag me in PR fixing this,IssueComment,https://github.com/tensorflow/tensorflow/issues/37896#issuecomment-603967127,mihaimaruseac,2020-03-25 17:09:41,37896,[37905],Documentation bug,0,Please tag me in PR fixing this,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37961"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37961"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37961#issuecomment-606790959,tensorflow-bot[bot],2020-03-31 18:17:10,37961,[37962],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@zhaozheng09 good,IssueComment,https://github.com/tensorflow/tensorflow/issues/37961#issuecomment-1471517638,dazheyizu,2023-03-16 08:30:55,37961,[37962],Deployment bug,0,@zhaozheng09 good,2
"@llan-ml 
could you please share the tensorflow version and simple stand alone code for us to replicate the issue faced.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37638#issuecomment-600018701,Saduf2019,2020-03-17 11:24:40,37638,[38142],Data bug,0,@llan-ml could you please share the tensorflow version and simple stand alone code for us to replicate the issue faced.,0
"@Saduf2019 I tested on `2.1` and `nightly`. The code is as follows:
```python
import tensorflow as tf

def foo(t):
  print(t.shape)
  print(tf.shape(t))
  print(""====="")
  t1 = tf.sparse.transpose(t)
  print(t1.shape)
  print(tf.shape(t1))
  print(""====="")
  t2 = tf.sparse.reduce_sum(t, axis=1)
  print(t2.shape)
  print(tf.shape(t2))
  print(""====="")

t = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]], values=[1., 2], dense_shape=[3, 4])
tf.function(foo)(t)
```

BTW, can't you access the colab link in my original post? ",IssueComment,https://github.com/tensorflow/tensorflow/issues/37638#issuecomment-600057217,llan-ml,2020-03-17 13:00:15,37638,[38142],Data bug,0,"@Saduf2019 I tested on [code] and [code]. The code is as follows: ``[code]`` BTW, can't you access the colab link in my original post?",0
"i am able to replicate this issue, please find gist [here](https://colab.sandbox.google.com/gist/Saduf2019/06ff7c15f1bd9b04f65bbb140019224c/untitled96.ipynb)",IssueComment,https://github.com/tensorflow/tensorflow/issues/37638#issuecomment-600528927,Saduf2019,2020-03-18 10:00:07,37638,[38142],Data bug,0,"i am able to replicate this issue, please find gist [here]([url]",0
"It looks like [sparse_transpose](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/sparse_ops.py#L2597) defaults to an unknown rank for all but the fully-defined shapes, which is too strict.

So a workaround would be this:
```
def foo(t):
  print(t.shape)
  print(tf.shape(t))
  t = tf.SparseTensor(values=t.values, indices=t.indices, dense_shape=[3, 4])
  ...
```

It should be straightforward to add an extra check so that a known rank is preserved.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37638#issuecomment-600697771,mdanatg,2020-03-18 15:44:14,37638,[38142],Data bug,0,"It looks like [sparse_transpose]([url]#L2597) defaults to an unknown rank for all but the fully-defined shapes, which is too strict. So a workaround would be this: ``[code]`` It should be straightforward to add an extra check so that a known rank is preserved.",0
"@mdanatg @llan-ml I added a PR #38142 to address the `sparse.transpose` issue. For the other issue `sparse.reduce_sum`, it is inference from the C++ `SparseReduceSumSparse` ops which
will output unknown shape anyway. So it may not be easily fixable. I leave the `sparse.reduce_sum`.

Please take a look at PR #38142 for shape of `sparse.transpose`",IssueComment,https://github.com/tensorflow/tensorflow/issues/37638#issuecomment-607464357,yongtang,2020-04-01 20:08:26,37638,[38142],Data bug,0,"@mdanatg @llan-ml I added a PR #38142 to address the [code] issue. For the other issue [code], it is inference from the C++ [code] ops which will output unknown shape anyway. So it may not be easily fixable. I leave the [code]. Please take a look at PR #38142 for shape of [code]",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37638"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37638"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37638#issuecomment-608439592,google-ml-butler[bot],2020-04-03 13:40:39,37638,[38142],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I could replicate the issue with Tf 2.1.
Please find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/e8c8b2522f2b3c5839880fdf65247537/38172.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/38172#issuecomment-608254456,gadagashwini-zz,2020-04-03 06:26:34,38172,[38209],Data bug,0,I could replicate the issue with Tf 2.1. Please find the gist [here]([url] Thanks!,0
"I tested above case on my Windows system Python 3.7.7. I did not see any error as shown in below image. I will check on Ubuntu and get back.

![image](https://user-images.githubusercontent.com/5499416/78391106-5d44f080-7603-11ea-866b-329c1e5e3a76.png)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/38172#issuecomment-608583286,rakesh-malviya,2020-04-03 18:04:36,38172,[38209],Data bug,0,I tested above case on my Windows system Python 3.7.7. I did not see any error as shown in below image. I will check on Ubuntu and get back. ![image]([url],0
Added a PR #38209 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/38172#issuecomment-608650041,yongtang,2020-04-03 20:45:51,38172,[38209],Data bug,0,Added a PR #38209 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38172"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38172"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/38172#issuecomment-610464910,google-ml-butler[bot],2020-04-07 15:46:35,38172,[38209],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I'll start working on this, Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/38199#issuecomment-608974853,ManishAradwad,2020-04-04 05:03:04,38199,[38214],Documentation bug,0,"I'll start working on this, Thanks!",5
"@FrankwaP The nightly version of docs mention 
`y_true : The ground truth values. y_true values are expected to be 0 or 1.`",IssueComment,https://github.com/tensorflow/tensorflow/issues/38199#issuecomment-608979270,ManishAradwad,2020-04-04 05:50:32,38199,[38214],Documentation bug,0,@FrankwaP The nightly version of docs mention [code],0
"Maybe ""y_true : The ground truth values in one-hot-encoded format."" would add some clarity?",IssueComment,https://github.com/tensorflow/tensorflow/issues/38199#issuecomment-609029926,FrankwaP,2020-04-04 13:37:28,38199,[38214],Documentation bug,0,"Maybe ""y_true : The ground truth values in one-hot-encoded format."" would add some clarity?",1
@FrankwaP CAn you be clear on what you are describing here. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/38199#issuecomment-610310795,gowthamkpr,2020-04-07 10:34:53,38199,[38214],Documentation bug,0,@FrankwaP CAn you be clear on what you are describing here. Thanks!,0
"Oh sorry!

The original/binary hinge loss expects a (n_samples,1) size vector for y_true, with -1 or 1 values. So it's a form of label encoding.

The categorical hinge loss has been adapted for N>2 classes, and now use a one-hot-encoded (n_samples,n_classes) size tensor for y_true.

So I think that specifying that we need a one-hot-encoded tensor is more explicit that specifying that the values should be 0 or 1, especially for people who also knows the binary hinge loss.",IssueComment,https://github.com/tensorflow/tensorflow/issues/38199#issuecomment-610318260,FrankwaP,2020-04-07 10:52:37,38199,[38214],Documentation bug,0,"Oh sorry! The original/binary hinge loss expects a (n_samples,1) size vector for y_true, with -1 or 1 values. So it's a form of label encoding. The categorical hinge loss has been adapted for N>2 classes, and now use a one-hot-encoded (n_samples,n_classes) size tensor for y_true. So I think that specifying that we need a one-hot-encoded tensor is more explicit that specifying that the values should be 0 or 1, especially for people who also knows the binary hinge loss.",1
"
[cnn_multichannel_dense_f0_b0.h5.zip](https://github.com/tensorflow/tensorflow/files/4416739/cnn_multichannel_dense_f0_b0.h5.zip)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/38135#issuecomment-607392558,tripathysa,2020-04-01 17:40:42,38135,[38339],Deployment bug,0,[cnn_multichannel_dense_f0_b0.h5.zip]([url],0
"Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/8ffb93fe9c91670fb8e3e6d21038bbcd/38135-2-1.ipynb), [TF v2.2.0-rc2](https://colab.research.google.com/gist/amahendrakar/78f9cc5cc4fdcebbe9e8e62745af53aa/38135-2-2.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/3f7747e2187f252273d49872d4615c48/38135-tf-nightly.ipynb). Works fine on [TF v2.0](https://colab.research.google.com/gist/amahendrakar/e1c64f58d7da6e77b9a5dae802664dea/38135-2-0.ipynb). Please find the attached gist. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/38135#issuecomment-607788060,amahendrakar,2020-04-02 11:27:51,38135,[38339],Deployment bug,0,Was able to reproduce the issue with [TF v2.1]([url] [TF v2.2.0-rc2]([url] and [TF-nightly]([url] Works fine on [TF v2.0]([url] Please find the attached gist. Thanks!,2
@tripathysa Can you please share simple standalone code to reproduce the issue? The provided `*.h5` file is not sufficient to find root-cause of the issue. If your code is proprietary code then please try to use public data to create a standalone code. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/38135#issuecomment-607901224,jvishnuvardhan,2020-04-02 15:03:28,38135,[38339],Deployment bug,0,@tripathysa Can you please share simple standalone code to reproduce the issue? The provided [code] file is not sufficient to find root-cause of the issue. If your code is proprietary code then please try to use public data to create a standalone code. Thanks!,0
"@jvishnuvardhan : Do you mean sharing train code? Yes its proprietary.  If some change is needed in the train code, then it will be a problem since the trained models are being supported by all TF versions except 2.1 and we donâ€™t want to retrain them again.

@amahendrakar was already able to reproduce the issue with:
`import tensorflow as tf

model = tf.keras.models.load_model('cnn_multichannel_dense_f0_b0.h5', compile=False)â€™",IssueComment,https://github.com/tensorflow/tensorflow/issues/38135#issuecomment-607948748,tripathysa,2020-04-02 16:23:03,38135,[38339],Deployment bug,0,"@jvishnuvardhan : Do you mean sharing train code? Yes its proprietary. If some change is needed in the train code, then it will be a problem since the trained models are being supported by all TF versions except 2.1 and we donâ€™t want to retrain them again. @amahendrakar was already able to reproduce the issue with: `import tensorflow as tf model = tf.keras.models.load_model('cnn_multichannel_dense_f0_b0.h5', compile=False)â€™",-1
It looks like `config['config']` is expected to be a dictionary here in 2.1 while its a list(https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/utils/generic_utils.py#L252) but in 2.0. no such assumed deserialization happens as I see it.,IssueComment,https://github.com/tensorflow/tensorflow/issues/38135#issuecomment-607967384,tripathysa,2020-04-02 16:56:33,38135,[38339],Deployment bug,0,It looks like [code] is expected to be a dictionary here in 2.1 while its a list([url]#L252) but in 2.0. no such assumed deserialization happens as I see it.,0
@jvishnuvardhan @k-w-w @tripathysa #38339 has been submitted to fix this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/38135#issuecomment-610727908,feihugis,2020-04-08 03:13:20,38135,[38339],Deployment bug,0,@jvishnuvardhan @k-w-w @tripathysa #38339 has been submitted to fix this issue.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38135"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38135"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/38135#issuecomment-638438071,google-ml-butler[bot],2020-06-03 20:16:26,38135,[38339],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38498"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38498"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/38498#issuecomment-615403948,google-ml-butler[bot],2020-04-17 18:43:11,38498,[38499],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@fbordignon Added a PR #38819 for the fix. Thanks for pointing out!,IssueComment,https://github.com/tensorflow/tensorflow/issues/38818#issuecomment-618087604,yongtang,2020-04-22 23:17:13,38818,[38819],Documentation bug,0,@fbordignon Added a PR #38819 for the fix. Thanks for pointing out!,4
"Great, thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/38818#issuecomment-618099476,fbordignon,2020-04-22 23:59:52,38818,[38819],Documentation bug,0,"Great, thanks!",5
Tried on Colab with TF version 2.0-beta and was able to replicate the issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/29661#issuecomment-502082411,achandraa,2019-06-14 12:02:11,29661,[38899],Data bug,0,Tried on Colab with TF version 2.0-beta and was able to replicate the issue.,0
Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/60c13c6f2c1cc4948add81e210f150c1/2-1-template.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/cf4dab2373adf64de686a77e94cad76c/tf-nightly.ipynb) i.e. 2.2.0-dev20200327. Please find the attached gist. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/29661#issuecomment-605289423,amahendrakar,2020-03-27 19:57:47,29661,[38899],Data bug,0,Was able to reproduce the issue with [TF v2.1]([url] and [TF-nightly]([url] i.e. 2.2.0-dev20200327. Please find the attached gist. Thanks!,2
"This is fixed with tf-nightly version '2.2.0-dev20200402'. Thanks!
```python
tf.Tensor([0 4 4 4 4 4], shape=(6,), dtype=int32)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/29661#issuecomment-608142552,ymodak,2020-04-02 23:22:01,29661,[38899],Data bug,0,This is fixed with tf-nightly version '2.2.0-dev20200402'. Thanks! ``[code]``,5
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29661"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29661"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/29661#issuecomment-617366393,google-ml-butler[bot],2020-04-21 19:27:38,29661,[38899],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"It is working as expected in GPU. But, the error still persists with CPU. 
[Here](https://colab.research.google.com/gist/jvishnuvardhan/858ba13ef8b77cf63355c84bd398e026/tf-nightly.ipynb) is the gist with GPU and [here](https://colab.research.google.com/gist/jvishnuvardhan/4b80e167f59162e373f0fc5591d9c14d/tf-nightly.ipynb) with CPU. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/29661#issuecomment-617442860,jvishnuvardhan,2020-04-21 22:17:59,29661,[38899],Data bug,0,"It is working as expected in GPU. But, the error still persists with CPU. [Here]([url] is the gist with GPU and [here]([url] with CPU. Thanks!",1
"Added a PR #38899 for the fix. In comparison with `tf.histogram_fixed_width` which throws out InvalidArgument in case value_range is not monotonous increasing (implemented in C++ kernel), I think `tf.histogram_fixed_width_bins` needs to apply the same restriction, as was specified in its docstring.",IssueComment,https://github.com/tensorflow/tensorflow/issues/29661#issuecomment-619452705,yongtang,2020-04-25 23:10:05,29661,[38899],Data bug,0,"Added a PR #38899 for the fix. In comparison with [code] which throws out InvalidArgument in case value_range is not monotonous increasing (implemented in C++ kernel), I think [code] needs to apply the same restriction, as was specified in its docstring.",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29661"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29661"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/29661#issuecomment-624705442,google-ml-butler[bot],2020-05-06 15:06:42,29661,[38899],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"The following will work as well (move `-` to end as otherwise it will be considered as range, and prefix with `r` to not escape). This avoid three backslash`\\\` which might be less understandable:
```
VALID_OP_NAME_REGEX = re.compile(r""^[A-Za-z0-9.][A-Za-z0-9_.\\/>-]*$"")
_VALID_SCOPE_NAME_REGEX = re.compile(r""^[A-Za-z0-9_.\\/>-]*$"")
```

Added a PR #39029 for the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39019#issuecomment-621266348,yongtang,2020-04-29 14:57:49,39019,[39029],Code bug,0,"The following will work as well (move [code] to end as otherwise it will be considered as range, and prefix with [code] to not escape). This avoid three backslash[code] which might be less understandable: ``[code]`` Added a PR #39029 for the fix.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39019"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39019"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39019#issuecomment-621981962,google-ml-butler[bot],2020-04-30 17:04:38,39019,[39029],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to reproduce the issue with TF v2.1, [TF v2.2.0-rc3](https://colab.research.google.com/gist/amahendrakar/6baa93476d84d2fef692b159e39eaaaa/39004.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/869d37d6c2c3909353ce483f01fa5df0/39004-tf-nightly.ipynb). Please find the attached gist. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/39004#issuecomment-621226004,amahendrakar,2020-04-29 13:56:43,39004,[39123],Algorithm design bug,0,"Was able to reproduce the issue with TF v2.1, [TF v2.2.0-rc3]([url] and [TF-nightly]([url] Please find the attached gist. Thanks!",0
Potentially related to #36790,IssueComment,https://github.com/tensorflow/tensorflow/issues/39004#issuecomment-623022836,ymodak,2020-05-02 22:19:07,39004,[39123],Algorithm design bug,0,Potentially related to #36790,0
Added a PR #39123 for the fix of this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39004#issuecomment-623138575,yongtang,2020-05-03 16:36:19,39004,[39123],Algorithm design bug,0,Added a PR #39123 for the fix of this issue.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39004"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39004"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39004#issuecomment-624222724,google-ml-butler[bot],2020-05-05 18:16:57,39004,[39123],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I replicate the issue with TF 2.0.0.rc0. Please take a look at [gist here](https://colab.sandbox.google.com/gist/gadagashwini/514760082d2c9017a6a4cd51977e3a51/untitled138.ipynb). Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/32380#issuecomment-530239148,gadagashwini-zz,2019-09-11 06:22:55,32380,[39131],Algorithm design bug,0,I replicate the issue with TF 2.0.0.rc0. Please take a look at [gist here]([url] Thanks!,0
Added a PR #39131 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/32380#issuecomment-623176556,yongtang,2020-05-03 20:29:33,32380,[39131],Algorithm design bug,0,Added a PR #39131 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32380"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32380"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32380#issuecomment-624259003,google-ml-butler[bot],2020-05-05 19:27:58,32380,[39131],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@MarkDaoust 
Tagging you for escalation. Kindly excuse me if this is unprofessional.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36790#issuecomment-586675521,mamtoraah,2020-02-16 06:55:40,36790,[39134],Data bug,0,@MarkDaoust Tagging you for escalation. Kindly excuse me if this is unprofessional.,0
@Hemal-Mamtora Could you please confirm if the issue faced by you is similar to existing [issue](https://github.com/tensorflow/tensorflow/issues/33365),IssueComment,https://github.com/tensorflow/tensorflow/issues/36790#issuecomment-586847155,Saduf2019,2020-02-17 07:07:28,36790,[39134],Data bug,0,@Hemal-Mamtora Could you please confirm if the issue faced by you is similar to existing [issue]([url],0
"Yes, seems like TF 2.0 has issues with float 64

Till when would this issue be resolved ?",IssueComment,https://github.com/tensorflow/tensorflow/issues/36790#issuecomment-586974026,mamtoraah,2020-02-17 12:35:51,36790,[39134],Data bug,0,"Yes, seems like TF 2.0 has issues with float 64 Till when would this issue be resolved ?",-1
"Hi @Hemal-Mamtora , 

I think you're right.

It looks like this is being caused by the mismatch of [metric.py recognizing `floatx`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/metrics.py#L146)  but [metric_utils.py casting directly to float32](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/metrics_utils.py#L427) .

@pavithrasv, what's the right way to fix this?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36790#issuecomment-587503562,MarkDaoust,2020-02-18 15:02:52,36790,[39134],Data bug,0,"Hi @Hemal-Mamtora , I think you're right. It looks like this is being caused by the mismatch of [metric.py recognizing [code]]([url]#L146) but [metric_utils.py casting directly to float32]([url]#L427) . @pavithrasv, what's the right way to fix this?",1
Thank you @MarkDaoust. It should be cast to the predictions' dtype. If anyone would like to work on the fix please feel free to send me a PR.,IssueComment,https://github.com/tensorflow/tensorflow/issues/36790#issuecomment-587590173,pavithrasv,2020-02-18 17:52:45,36790,[39134],Data bug,0,Thank you @MarkDaoust. It should be cast to the predictions' dtype. If anyone would like to work on the fix please feel free to send me a PR.,3
Added a fix and test case in PR #39134 that will address this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/36790#issuecomment-623194975,yongtang,2020-05-03 22:43:05,36790,[39134],Data bug,0,Added a fix and test case in PR #39134 that will address this issue.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36790"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36790"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36790#issuecomment-635477560,google-ml-butler[bot],2020-05-28 17:07:19,36790,[39134],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #39137 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39136#issuecomment-623237213,yongtang,2020-05-04 03:09:08,39136,[39137],Data bug,1,Added a PR #39137 for the fix.,0
"Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/caaefad7a4ba4579d410e203fa20057c/39136-tf-nightly.ipynb), [TF v2.2.0-rc4](https://colab.research.google.com/gist/amahendrakar/b2ef86f09489bdad388f089ab3ba315b/39136-2-2.ipynb#scrollTo=52pV0lOQX93A) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/b01f15c8b4e12c9e879f62eca2fb8395/39136-tf-nightly.ipynb). Please find the attached gist. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/39136#issuecomment-623589885,amahendrakar,2020-05-04 17:11:34,39136,[39137],Data bug,1,Was able to reproduce the issue with [TF v2.1]([url] [TF v2.2.0-rc4]([url]#scrollTo=52pV0lOQX93A) and [TF-nightly]([url] Please find the attached gist. Thanks!,2
@aaudiber please review the PR from Yong.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39136#issuecomment-623676045,jsimsa,2020-05-04 20:02:43,39136,[39137],Data bug,1,@aaudiber please review the PR from Yong.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39136"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39136"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39136#issuecomment-625422143,google-ml-butler[bot],2020-05-07 18:26:42,39136,[39137],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Issue replicating for the TF version-1.14, kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/8f7790e5d292c7d84482bd3c9629d2e0/32236.ipynb) of colab.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/32236#issuecomment-528775377,oanush,2019-09-06 09:03:42,32236,[39159],Data bug,0,"Issue replicating for the TF version-1.14, kindly find the [gist]([url] of colab.Thanks!",1
@javidcf I tried with latest TF and the issue should have been fixed. I will close this issue but feel free to reopen if issue persists.,IssueComment,https://github.com/tensorflow/tensorflow/issues/32236#issuecomment-623153797,yongtang,2020-05-03 18:02:58,32236,[39159],Data bug,0,@javidcf I tried with latest TF and the issue should have been fixed. I will close this issue but feel free to reopen if issue persists.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32236"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32236"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32236#issuecomment-623153804,google-ml-butler[bot],2020-05-03 18:03:00,32236,[39159],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@yongtang Thanks for having a look. Unfortunately, this still happens in graph mode, e.g. with `tf.function`:

```python
@tf.function
def f():
    return tf.boolean_mask([1, 2, 3], [True, False, True],
                           axis=tf.constant(0, dtype=tf.int32))
f()
# TypeError: slice indices must be integers or None or have an __index__ method
```

Tested in TensorFlow 2.2.0-rc4.",IssueComment,https://github.com/tensorflow/tensorflow/issues/32236#issuecomment-623375182,javidcf,2020-05-04 10:06:28,32236,[39159],Data bug,0,"@yongtang Thanks for having a look. Unfortunately, this still happens in graph mode, e.g. with [code]: ``[code]`` Tested in TensorFlow 2.2.0-rc4.",-2
@javidcf  Added a PR for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/32236#issuecomment-623559917,yongtang,2020-05-04 16:14:57,32236,[39159],Data bug,0,@javidcf Added a PR for the fix.,3
@javidcf Update:  Added a PR #39159 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/32236#issuecomment-623560349,yongtang,2020-05-04 16:15:42,32236,[39159],Data bug,0,@javidcf Update: Added a PR #39159 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32236"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32236"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32236#issuecomment-624253681,google-ml-butler[bot],2020-05-05 19:17:17,32236,[39159],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"The second and the third examples are expected. In the second example,
```
tf.map_fn(fn, np.array([1.]))
```
`np.array([1.])` is a tensor (converted to tensor by np.array), so it is a **single element of shape `[1]`.**

The third example:
```
tf.map_fn(fn, [1.])
```
is a list of one tensor `1.` as map_fn treat it as **a list of one (scalar) element `1.`**, thus you see an error.

The first example `tf.map_fn(fn, [])` is not something that has been captured in the implementation of `tf.map_fn`. I think it makes sense to return an explicit error here.

Created a PR #39241 for the fix of  `tf.map_fn(fn, [])`",IssueComment,https://github.com/tensorflow/tensorflow/issues/39229#issuecomment-624928147,yongtang,2020-05-06 22:40:33,39229,[39241],Data bug,0,"The second and the third examples are expected. In the second example, ``[code]`[code]np.array([1.])[code][1][code]`[code]`[code]1.[code]1.[code]tf.map_fn(fn, [])[code]tf.map_fn[code]tf.map_fn(fn, [])`",0
"Hi,

I really don't think you should raise when the list is empty. Every framework out there just returns an empty sequence when using map on an empty sequence.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39229#issuecomment-625120761,AdrienCorenflos,2020-05-07 08:50:21,39229,[39241],Data bug,0,"Hi, I really don't think you should raise when the list is empty. Every framework out there just returns an empty sequence when using map on an empty sequence.",-2
"Was able to reproduce the issue with TF v2.1, [TF v2.2.0-rc4](https://colab.research.google.com/gist/amahendrakar/c164706bf7bd7f67bf13fe6719e0a489/39229.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/81517ce8a62dd8cc9f121c1956630636/39229-tf-nightly.ipynb). Please find the attached gist. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/39229#issuecomment-625184963,amahendrakar,2020-05-07 11:02:31,39229,[39241],Data bug,0,"Was able to reproduce the issue with TF v2.1, [TF v2.2.0-rc4]([url] and [TF-nightly]([url] Please find the attached gist. Thanks!",2
"@AdrienCorenflos If you want to map over a sequence, then you must pass that sequence to `map_fn` as a Tensor.  

If you pass a non-Tensor sequence to `map_fn`, then it does *not* map over that sequence.  Instead, it unstacks each tensor in that sequence, and calls the function with a list constructed from those unstacked slices.

I.e., `tf.map_fn(func, [a, b, c])` is equivalent to Python's `map(func, a, b, c)`, and *not* to `map(func, [a, b, c])`.  So calling `tf.map_fn(func, [])` is equivalent to calling `map(func)` in Python, which does indeed give an error (`""map() requires at least two args""`).

A more complex example might help illustrate what's going on here -- we can pass any nested structure in to `elems`, including e.g. nested dictionaries.  So if I call:

```
tf.map_fn(func, {'a': t1, 'b': [t2, t3]})
```

Then `func` will be called with:
```
func({'a': t1[0], 'b': [t2[0], t3[0]})
func({'a': t1[1], 'b': [t2[1], t3[1]})
func({'a': t1[2], 'b': [t2[2], t3[2]})
...
func({'a': t1[N], 'b': [t2[N], t3[N]})
```

Where `N==t1.shape[0]==t2.shape[0]==t3.shape[0]`.  By default, each function needs to return a value with the same structure that was passed in.  E.g., in the example above, `func` must return a dictionary with keys `a` and `b`, where `a` is a tensor and `b` is a list of two tensors.  If you want `func` to return a different structure, then you need to specify that structure with the `fn_output_signature` argument.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39229#issuecomment-625361513,edloper,2020-05-07 16:30:44,39229,[39241],Data bug,0,"@AdrienCorenflos If you want to map over a sequence, then you must pass that sequence to [code] as a Tensor. If you pass a non-Tensor sequence to [code], then it does *not* map over that sequence. Instead, it unstacks each tensor in that sequence, and calls the function with a list constructed from those unstacked slices. I.e., [code] is equivalent to Python's [code], and *not* to [code]. So calling [code] is equivalent to calling [code] in Python, which does indeed give an error ([code]). A more complex example might help illustrate what's going on here -- we can pass any nested structure in to [code], including e.g. nested dictionaries. So if I call: ``[code]`[code]func[code]`[code]`[code]N==t1.shape[0]==t2.shape[0]==t3.shape[0][code]func[code]a[code]b[code]a[code]b[code]func[code]fn_output_signature` argument.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39229"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39229"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39229#issuecomment-651518100,google-ml-butler[bot],2020-06-30 04:08:04,39229,[39241],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Also, the two of the code blocks should be actual code blocks.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39454#issuecomment-627280623,bersbersbers,2020-05-12 11:23:26,39454,[39461],Documentation bug,0,"Also, the two of the code blocks should be actual code blocks.",0
Added PR #39461 to update the docstring. Also combined the example code sessions into one for documentation to render correctly with one block.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39454#issuecomment-627411877,yongtang,2020-05-12 15:19:26,39454,[39461],Documentation bug,0,Added PR #39461 to update the docstring. Also combined the example code sessions into one for documentation to render correctly with one block.,3
Thanks @yongtang!,IssueComment,https://github.com/tensorflow/tensorflow/issues/39454#issuecomment-630573812,MarkDaoust,2020-05-19 04:35:09,39454,[39461],Documentation bug,0,Thanks @yongtang!,3
Added a PR #39481 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39475#issuecomment-627691893,yongtang,2020-05-13 01:33:29,39475,[39481],Data bug,0,Added a PR #39481 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39475"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39475"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39475#issuecomment-628262990,google-ml-butler[bot],2020-05-13 21:46:54,39475,[39481],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
See #38517 and #38671,IssueComment,https://github.com/tensorflow/tensorflow/issues/39696#issuecomment-631600704,mihaimaruseac,2020-05-20 16:58:31,39696,[39725],Code bug,0,See #38517 and #38671,0
"@mihaimaruseac @cxyanhk The issue is the renaming of mkl-dnn to oneDNN, so GitHub re-archives the package (with different directory). The old link in mkl_dnn now is an alias of oneDNN which has a different top-level directory inside the archive.

Create a PR #39725 for the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39696#issuecomment-631604030,yongtang,2020-05-20 17:04:28,39696,[39725],Code bug,0,"@mihaimaruseac @cxyanhk The issue is the renaming of mkl-dnn to oneDNN, so GitHub re-archives the package (with different directory). The old link in mkl_dnn now is an alias of oneDNN which has a different top-level directory inside the archive. Create a PR #39725 for the fix.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39696"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39696"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39696#issuecomment-631790361,google-ml-butler[bot],2020-05-20 23:27:24,39696,[39725],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #39825 for complex tensor support.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39815#issuecomment-633151212,yongtang,2020-05-23 22:59:43,39815,[39825],Data bug,0,Added a PR #39825 for complex tensor support.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39815"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39815"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39815#issuecomment-634780542,google-ml-butler[bot],2020-05-27 16:25:13,39815,[39825],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Having a similar issue when I try running Jupyter notebook on GPU using jupyter/tensorflow-notebook Docker image from Dockerhub. It seems like CUDA fails to load so Jupyter notebook ends up running without GPU acceleration.

```
[I 18:36:11.117 NotebookApp] Kernel started: ef831313-da54-458c-9ce2-e854e67bec73
2020-03-18 18:36:14.799904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-03-18 18:36:14.801346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-03-18 18:36:16.140605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-18 18:36:16.148127: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error
2020-03-18 18:36:16.148180: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: jupyter-gpu-9f69d4848-lfx4b
2020-03-18 18:36:16.148193: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: aimp-jupyter-gpu-9f69d4848-lfx4b
2020-03-18 18:36:16.148331: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.40.4
2020-03-18 18:36:16.148378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.40.4
2020-03-18 18:36:16.148390: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 418.40.4
2020-03-18 18:36:16.148896: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-18 18:36:16.155651: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2596985000 Hz
2020-03-18 18:36:16.156455: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556699f800e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-18 18:36:16.156486: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version 
```

Here is the Dockerfile I use:

```
FROM jupyter/tensorflow-notebook

USER root

RUN apt-get update && apt-get install -y gnupg2 &&\
	wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.1.243-1_amd64.deb &&\
	apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub &&\
	dpkg -i cuda-repo-ubuntu1804_10.1.243-1_amd64.deb &&\
	rm -f cuda-repo-ubuntu1804_10.1.243-1_amd64.deb &&\
	apt-get update &&\
	wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb &&\
	apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb &&\
	rm -f nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb &&\
	apt-get update &&\
	apt-get install -y --no-install-recommends \
		cuda-10-1 \
		libcudnn7=7.6.4.38-1+cuda10.1  \
		libcudnn7-dev=7.6.4.38-1+cuda10.1 &&\
	apt-get install -y --no-install-recommends \
		libnvinfer6=6.0.1-1+cuda10.1 \
		libnvinfer-dev=6.0.1-1+cuda10.1 \
		libnvinfer-plugin6=6.0.1-1+cuda10.1 &&\
	jupyter serverextension enable --py jupyterlab --sys-prefix &&\
 	pip install jupyter-tensorboard==0.2.0 certifi==2019.11.28 &&\
 	jupyter tensorboard enable
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-600798925,stevancvetkovic,2020-03-18 18:43:47,37689,[39956],Code bug,0,Having a similar issue when I try running Jupyter notebook on GPU using jupyter/tensorflow-notebook Docker image from Dockerhub. It seems like CUDA fails to load so Jupyter notebook ends up running without GPU acceleration. ``[code]`[code]`[code]``,-2
"@bjarthur 

Could you check this [issue ](https://github.com/tensorflow/tensorflow/issues/19266#issuecomment-399686258 )which is similar to your issue. If those solutions doesn't work, could you uninstall and reinstall CUDA and cuDNN? Please let us know how it progresses. Also, try to uninstall and reinstall tensorflow-gpu and try following the instructions from [TensorFlow website](source). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-601120349,ravikyram,2020-03-19 11:07:40,37689,[39956],Code bug,0,"@bjarthur Could you check this [issue ]([url]#issuecomment-399686258 )which is similar to your issue. If those solutions doesn't work, could you uninstall and reinstall CUDA and cuDNN? Please let us know how it progresses. Also, try to uninstall and reinstall tensorflow-gpu and try following the instructions from [TensorFlow website](source). Thanks!",0
"@stevancvetkovic this is *not* a similar issue to yours!  please don't hijack this issue.  i am trying to run tensorflow on a machine *without a GPU*.  and so no, @ravikyram , that issue you refer me to is also not relevant as that concerns using tensorflow *with a GPU*.

not all machine learning problems, even neural network ones, are big enough to need a GPU.  mine is just as fast with CPU alone.  tensorflow 2 now just has one installation procedure irrespective of whether you use a GPU or not (`pip install tensorflow`).  this differs from TF 1 where there were two (`pip install tensorflow-gpu` or `pip install tensorflow`).

my complaint here is that TF2 emits an error message when running on a machine *without a GPU* that says it tried to initialize the CUDA libraries.  before doing that it should check to see if there is a GPU in the first place.  throwing errors like that when in fact there is not one and the code continues to run fine makes parsing log files to see that everything is okay more complicated.   seems like an easy fix to me to change TF to first check if a GPU exists before trying to initialize CUDA.  thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-602031757,bjarthur,2020-03-21 11:36:38,37689,[39956],Code bug,0,"@stevancvetkovic this is *not* a similar issue to yours! please don't hijack this issue. i am trying to run tensorflow on a machine *without a GPU*. and so no, @ravikyram , that issue you refer me to is also not relevant as that concerns using tensorflow *with a GPU*. not all machine learning problems, even neural network ones, are big enough to need a GPU. mine is just as fast with CPU alone. tensorflow 2 now just has one installation procedure irrespective of whether you use a GPU or not ([code]). this differs from TF 1 where there were two ([code] or [code]). my complaint here is that TF2 emits an error message when running on a machine *without a GPU* that says it tried to initialize the CUDA libraries. before doing that it should check to see if there is a GPU in the first place. throwing errors like that when in fact there is not one and the code continues to run fine makes parsing log files to see that everything is okay more complicated. seems like an easy fix to me to change TF to first check if a GPU exists before trying to initialize CUDA. thanks!",-2
@ravikyram I have the same problem and it is very confusing for the users. Is anyone already working on a fix for this? I can work on it if you could point me in the correct direction as to where to look in the codebase.,IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-603173897,dakshvar22,2020-03-24 11:03:31,37689,[39956],Code bug,0,@ravikyram I have the same problem and it is very confusing for the users. Is anyone already working on a fix for this? I can work on it if you could point me in the correct direction as to where to look in the codebase.,1
"Can we suppress that error when running on CPU. This is pure noise. The app is working as expected without any problem. I can't see any reason why it would deserve an error. A warning maybe, but not an error.

```
2020-03-18 08:16:55.455184: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-627994152,mbelang,2020-05-13 13:40:52,37689,[39956],Code bug,0,"Can we suppress that error when running on CPU. This is pure noise. The app is working as expected without any problem. I can't see any reason why it would deserve an error. A warning maybe, but not an error. ``[code]``",-2
"Our applications are very stable, and we setup notifications to our phones whenever there is an error, but this stupid tensorflow error blows up our phones on every deployment. Extremely annoying. Please be a good python citizen and only log errors.. when there is an error! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-627996177,edouardlp,2020-05-13 13:44:13,37689,[39956],Code bug,0,"Our applications are very stable, and we setup notifications to our phones whenever there is an error, but this stupid tensorflow error blows up our phones on every deployment. Extremely annoying. Please be a good python citizen and only log errors.. when there is an error!",-4
"> Can we suppress that error when running on CPU. This is pure noise. The app is working as expected without any problem. I can't see any reason why it would deserve an error. A warning maybe, but not an error.
> 
> ```
> 2020-03-18 08:16:55.455184: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
> ```

I have the same problem with `pytest` with `-s` flag on CPU. This is going to create problem cause it is parsed as an error. /cc @seanpmorgan ",IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-635458573,bhack,2020-05-28 16:35:32,37689,[39956],Code bug,0,"> Can we suppress that error when running on CPU. This is pure noise. The app is working as expected without any problem. I can't see any reason why it would deserve an error. A warning maybe, but not an error. > > ``[code]`[code]pytest[code]-s` flag on CPU. This is going to create problem cause it is parsed as an error. /cc @seanpmorgan",-2
I've a stub PR at https://github.com/tensorflow/tensorflow/pull/39956,IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-635496758,bhack,2020-05-28 17:43:54,37689,[39956],Code bug,0,I've a stub PR at [url],0
"@bjarthur As a workaround solution TF2 still publishes a `tensorflow-cpu` which should omit this attempt of dynamic kernel loading and is a significantly smaller package:
https://pypi.org/project/tensorflow-cpu/#history",IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-637909382,seanpmorgan,2020-06-03 02:05:29,37689,[39956],Code bug,0,@bjarthur As a workaround solution TF2 still publishes a [code] which should omit this attempt of dynamic kernel loading and is a significantly smaller package: [url]#history,1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37689"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37689"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37689#issuecomment-639284287,google-ml-butler[bot],2020-06-05 06:24:22,37689,[39956],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"The issue was that in docstring `max(0, K - 1 - len(inner_shape))` crossed two lines and doc rendering doesn't work anymore. Created a PR #40057 for the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/40052#issuecomment-637000911,yongtang,2020-06-01 17:27:22,40052,[40057],Documentation bug,0,The issue was that in docstring [code] crossed two lines and doc rendering doesn't work anymore. Created a PR #40057 for the fix.,1
@yongtang  Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/40052#issuecomment-637583828,DNXie,2020-06-02 14:35:43,40052,[40057],Documentation bug,0,@yongtang Thanks!,3
"@gfkeith 
I ran the code shared on tf 2.1 and do not face any issues, please refer to this [gist here](https://colab.sandbox.google.com/gist/Saduf2019/98438a3fdb809ce58e8ece5b2932d0bd/untitled205.ipynb) ",IssueComment,https://github.com/tensorflow/tensorflow/issues/40016#issuecomment-636888216,Saduf2019,2020-06-01 14:20:17,40016,[40101],Algorithm design bug,0,"@gfkeith I ran the code shared on tf 2.1 and do not face any issues, please refer to this [gist here]([url]",3
"Hi @Saduf2019,

The behaviour appears to be different on Colab, I'm not sure why. It still isn't 100% correct, if you run [this](https://gist.github.com/gfkeith/055a0519535b1f2fdba633bc9611931b) the count is negative (indicating overflow) but the mean and variance still seem reasonable. On my computer, they are also negative.

This seems to be the due to the default numpy dtype. On colab, `np.sum` (relevant [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L178)) seems to return int64 (even when summing dtype int32 arrays), whereas on my computer it returns int32 (hence the overflow), unless the dtype is set specifically to int64. For some reason, it is set to int32 for count [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L158). I think if this were set to int64, the behaviour would be the same (i.e. overflow not a problem for count until the state variable is set, which is only [dtype int32](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L101), hence why `norm.count` is negative for both). The mean and variance being negative for mine and not colab is explained by the working `accumulator.count` overflowing on mine (so negative) and not colab, as it multiplies mean [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L184) and variance [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L191).",IssueComment,https://github.com/tensorflow/tensorflow/issues/40016#issuecomment-637556946,gfkeith,2020-06-02 13:51:18,40016,[40101],Algorithm design bug,0,"Hi @Saduf2019, The behaviour appears to be different on Colab, I'm not sure why. It still isn't 100% correct, if you run [this]([url] the count is negative (indicating overflow) but the mean and variance still seem reasonable. On my computer, they are also negative. This seems to be the due to the default numpy dtype. On colab, [code] (relevant [here]([url]#L178)) seems to return int64 (even when summing dtype int32 arrays), whereas on my computer it returns int32 (hence the overflow), unless the dtype is set specifically to int64. For some reason, it is set to int32 for count [here]([url]#L158). I think if this were set to int64, the behaviour would be the same (i.e. overflow not a problem for count until the state variable is set, which is only [dtype int32]([url]#L101), hence why [code] is negative for both). The mean and variance being negative for mine and not colab is explained by the working [code] overflowing on mine (so negative) and not colab, as it multiplies mean [here]([url]#L184) and variance [here]([url]#L191).",0
"Interestingly, it looks like the dtype of the layer is changed to int64 in master [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/normalization.py#L119), but the running type is still int32 [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/normalization.py#L180).",IssueComment,https://github.com/tensorflow/tensorflow/issues/40016#issuecomment-637568564,gfkeith,2020-06-02 14:10:22,40016,[40101],Algorithm design bug,0,"Interestingly, it looks like the dtype of the layer is changed to int64 in master [here]([url]#L119), but the running type is still int32 [here]([url]#L180).",0
#40101 ,IssueComment,https://github.com/tensorflow/tensorflow/issues/40016#issuecomment-640804651,tanzhenyu,2020-06-08 18:44:32,40016,[40101],Algorithm design bug,0,#40101,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40016"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40016"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40016#issuecomment-640932822,google-ml-butler[bot],2020-06-08 23:06:21,40016,[40101],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@bhack this issue has been fixed in 2.3.0, is there a reason why its moved back to ""in progress""",IssueComment,https://github.com/tensorflow/tensorflow/issues/40016#issuecomment-691336156,goldiegadde,2020-09-11 22:19:08,40016,[40101],Algorithm design bug,0,"@bhack this issue has been fixed in 2.3.0, is there a reason why its moved back to ""in progress""",0
Honestly I don't remeber this action as I was not in this thread. But ok.,IssueComment,https://github.com/tensorflow/tensorflow/issues/40016#issuecomment-691340249,bhack,2020-09-11 22:33:49,40016,[40101],Algorithm design bug,0,Honestly I don't remeber this action as I was not in this thread. But ok.,0
"> Interestingly, it looks like the dtype of the layer is changed to int64 in master [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/normalization.py#L119), but the running type is still int32 [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/normalization.py#L180).

You probably need to install tf-nightly to verify that, given colab doesn't automatically include latest changes",IssueComment,https://github.com/tensorflow/tensorflow/issues/40016#issuecomment-691345650,tanzhenyu,2020-09-11 22:56:36,40016,[40101],Algorithm design bug,0,"> Interestingly, it looks like the dtype of the layer is changed to int64 in master [here]([url]#L119), but the running type is still int32 [here]([url]#L180). You probably need to install tf-nightly to verify that, given colab doesn't automatically include latest changes",0
"Issue replicating for [tf-nightly](https://colab.sandbox.google.com/gist/oanush/8de62f184ff385f8c95404fa6b8d36f4/36236.ipynb), thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-579062006,oanush,2020-01-28 03:25:25,36236,[40191],Algorithm design bug,0,Issue replicating for [tf-nightly]([url] thanks!,0
I am having the same problem.  Removing all tf.function decorators causes the problem to go away.,IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-579526427,ecpoppenheimer,2020-01-28 23:43:13,36236,[40191],Algorithm design bug,0,I am having the same problem. Removing all tf.function decorators causes the problem to go away.,-1
"This is severe for performance, experiencing troubles as well!",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-590466069,PwnerHarry,2020-02-24 17:57:15,36236,[40191],Algorithm design bug,0,"This is severe for performance, experiencing troubles as well!",-4
"Well, the `* 1` on strategic places (as described above) makes the `tf.functions` work again and there is no slowdown (a proper fix will do a very similar thing from the performance point of view).

So what you can try is after every call to LSTM/GRU (or after an enclosing Bidirectional) write `* 1`, until the bug is fixed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-590512571,foxik,2020-02-24 19:40:35,36236,[40191],Algorithm design bug,0,"Well, the [code] on strategic places (as described above) makes the [code] work again and there is no slowdown (a proper fix will do a very similar thing from the performance point of view). So what you can try is after every call to LSTM/GRU (or after an enclosing Bidirectional) write [code], until the bug is fixed.",2
"> Well, the `* 1` on strategic places (as described above) makes the `tf.functions` work again and there is no slowdown (a proper fix will do a very similar thing from the performance point of view).
> 
> So what you can try is after every call to LSTM/GRU (or after an enclosing Bidirectional) write `* 1`, until the bug is fixed.

Well I am using a significantly more complex model. It feels painful to do this, I am looking forward to the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-590515833,PwnerHarry,2020-02-24 19:48:01,36236,[40191],Algorithm design bug,0,"> Well, the [code] on strategic places (as described above) makes the [code] work again and there is no slowdown (a proper fix will do a very similar thing from the performance point of view). > > So what you can try is after every call to LSTM/GRU (or after an enclosing Bidirectional) write [code], until the bug is fixed. Well I am using a significantly more complex model. It feels painful to do this, I am looking forward to the fix.",-2
"I keep running into this issue myself; it's a horrific regression relative to TF1.x, where no such problems existed.

It would be really great if the TF team would fix this in the next release, for example by auto-converting to a dense tensor on entry into the backwards function. Yes, there might be more performant options, but the current behaviour is simply breaking code.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-600270160,mmjb,2020-03-17 20:01:39,36236,[40191],Algorithm design bug,0,"I keep running into this issue myself; it's a horrific regression relative to TF1.x, where no such problems existed. It would be really great if the TF team would fix this in the next release, for example by auto-converting to a dense tensor on entry into the backwards function. Yes, there might be more performant options, but the current behaviour is simply breaking code.",-4
"Any updates on this?
Changing this [line](https://github.com/tensorflow/tensorflow/blob/eab9701d541f5b8d54a898f81c3344c7b7d672b4/tensorflow/python/eager/function.py#L1971) to
```
  tensor_inputs.append(ops.convert_to_tensor(arg))
```
solves the issue on 2.2.0-rc3 but just wondering if there is a proper change from TF team.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-622149526,junhyeokahn,2020-04-30 22:26:14,36236,[40191],Algorithm design bug,0,Any updates on this? Changing this [line]([url]#L1971) to ``[code]`` solves the issue on 2.2.0-rc3 but just wondering if there is a proper change from TF team.,0
A gentle bump after another month -- still not working on current TF-nightly 2.3.0-dev20200602.,IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-637968902,foxik,2020-06-03 05:47:14,36236,[40191],Algorithm design bug,0,A gentle bump after another month -- still not working on current TF-nightly 2.3.0-dev20200602.,-1
"I've raised a similar issue  #31952 before, which got fixed. However that fix only works when the grads are calculated outside a graph ( i.e. in eager mode). It might shed some light on how to fix it in graph mode though. cc the author of that fix: @alextp 
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-638017180,David-Mao,2020-06-03 07:34:55,36236,[40191],Algorithm design bug,0,"I've raised a similar issue #31952 before, which got fixed. However that fix only works when the grads are calculated outside a graph ( i.e. in eager mode). It might shed some light on how to fix it in graph mode though. cc the author of that fix: @alextp",1
Can you send a PR changing the line and adding a test?,IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-639136990,alextp,2020-06-04 21:48:28,36236,[40191],Algorithm design bug,0,Can you send a PR changing the line and adding a test?,0
"@alextp I can easily do it, but I am not sure it is a correct solution. Looking at the current master:
https://github.com/tensorflow/tensorflow/blob/9221044560b9ed34d60a4b07dc0895552d2540c5/tensorflow/python/eager/function.py#L1873-L1906
I assume it would make sense to test specifically for IndexedSlices only, and perform the same shape check as in the case of tf.Tensor? Hm, I think the best solution would be to do something like
```python
      elif isinstance(arg, (ops.Tensor, ops.IndexedSlices)): 
        if isinstance(arg, ops.IndexedSlices):
          tensor_inputs.append(ops.convert_to_tensor(arg))
        else
          tensor_inputs.append(arg)
```
and then continue with the shape-checking code.

Looking even deeper, maybe we should do the rewrite for the backward pass only? Here
https://github.com/tensorflow/tensorflow/blob/9221044560b9ed34d60a4b07dc0895552d2540c5/tensorflow/python/eager/function.py#L737-L747
the gradients in the backward pass are collected -- it would be enough to convert the IndexedSlices to Tensors here. So that the least number of silent conversions would happen (and the backward pass is the only problematic one).

Personally I would do the rewrite only for the backward pass -- what do you think @alextp? If you think it is fine, I will prepare the patch (including a test).",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-639279208,foxik,2020-06-05 06:08:41,36236,[40191],Algorithm design bug,0,"@alextp I can easily do it, but I am not sure it is a correct solution. Looking at the current master: [url]#L1873-L1906 I assume it would make sense to test specifically for IndexedSlices only, and perform the same shape check as in the case of tf.Tensor? Hm, I think the best solution would be to do something like ``[code]`` and then continue with the shape-checking code. Looking even deeper, maybe we should do the rewrite for the backward pass only? Here [url]#L737-L747 the gradients in the backward pass are collected -- it would be enough to convert the IndexedSlices to Tensors here. So that the least number of silent conversions would happen (and the backward pass is the only problematic one). Personally I would do the rewrite only for the backward pass -- what do you think @alextp? If you think it is fine, I will prepare the patch (including a test).",2
"I have simplified the problematic input not to reference LSTM/GRU:
```python
@tf.function
def summing_rnn(inputs):
  return tf.reduce_sum(inputs, axis=1)

@tf.function
def gradients(inputs):
  with tf.GradientTape() as tape:
    tape.watch(inputs)
    hidden = summing_rnn(inputs)
    hidden = tf.gather(hidden, tf.constant([0]))
    loss = tf.reduce_mean(hidden)
  return tape.gradient(loss, inputs)

gradients(tf.constant([[[1.0], [2.0]]])) # No error is raised
```

I am also creating a pull request.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-639435371,foxik,2020-06-05 11:54:42,36236,[40191],Algorithm design bug,0,I have simplified the problematic input not to reference LSTM/GRU: ``[code]`` I am also creating a pull request.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36236"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36236"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36236#issuecomment-641440421,google-ml-butler[bot],2020-06-09 16:53:50,36236,[40191],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #40214 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/40204#issuecomment-639969314,yongtang,2020-06-06 03:25:48,40204,[40214],Data bug,1,Added a PR #40214 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40204"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40204"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40204#issuecomment-641558749,google-ml-butler[bot],2020-06-09 20:43:29,40204,[40214],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I have tried in colab with TF version 2.1, 2.2 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/cf487e179e38859d2301e11969b41bbb/untitled25.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/40471#issuecomment-644111277,ravikyram,2020-06-15 12:42:36,40471,[40480],Version compatibility bug,0,"I have tried in colab with TF version 2.1, 2.2 and was able to reproduce the issue.Please, find the gist [here]([url]",0
Added a PR #40480 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/40471#issuecomment-644264600,yongtang,2020-06-15 17:21:47,40471,[40480],Version compatibility bug,0,Added a PR #40480 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40471"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40471"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40471#issuecomment-646894811,google-ml-butler[bot],2020-06-19 23:22:18,40471,[40480],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #40585 for complex support,IssueComment,https://github.com/tensorflow/tensorflow/issues/40577#issuecomment-646138225,yongtang,2020-06-18 16:19:39,40577,[40585],Data bug,0,Added a PR #40585 for complex support,3
"Hi @yongtang , thanks for taking care of this.

Do you know if by any chance there is a link between this issue (i.e. complex support not being straightfoward) and issue #40672 ?",IssueComment,https://github.com/tensorflow/tensorflow/issues/40577#issuecomment-647533518,zaccharieramzi,2020-06-22 13:52:39,40577,[40585],Data bug,0,"Hi @yongtang , thanks for taking care of this. Do you know if by any chance there is a link between this issue (i.e. complex support not being straightfoward) and issue #40672 ?",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40577"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40577"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40577#issuecomment-655305657,google-ml-butler[bot],2020-07-08 06:01:26,40577,[40585],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40609"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40609"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40609#issuecomment-647645999,google-ml-butler[bot],2020-06-22 16:56:44,40609,[40610],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I have tried in colab with TF 2.0,2.1,2.2, nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/2df7914ebc51be2db05ffe646a4b4122/untitled38.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/40580#issuecomment-646427292,ravikyram,2020-06-19 04:24:42,40580,[40626],Data bug,0,"I have tried in colab with TF 2.0,2.1,2.2, nightly versions and was able to reproduce the issue.Please, find the gist [here]([url]",0
Added a PR #40626 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/40580#issuecomment-646898069,yongtang,2020-06-19 23:36:50,40580,[40626],Data bug,0,Added a PR #40626 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40580"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40580"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40580#issuecomment-661175203,google-ml-butler[bot],2020-07-20 16:46:13,40580,[40626],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #40636 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/40633#issuecomment-647008477,yongtang,2020-06-20 15:17:02,40633,[40636],Data bug,0,Added a PR #40636 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40633"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40633"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40633#issuecomment-648280691,google-ml-butler[bot],2020-06-23 16:41:16,40633,[40636],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to reproduce the issue with TF v2.2 and TF-nightly. Running the code on Colab crashes the session, whereas running the code on terminal throws an error stating `Check failed: d < dims() (0 vs. 0)`.

Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7eed4878232eb4ffaf58e5f86257987e/40653.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/40653#issuecomment-647631701,amahendrakar,2020-06-22 16:30:22,40653,[40693],Code bug,1,"Was able to reproduce the issue with TF v2.2 and TF-nightly. Running the code on Colab crashes the session, whereas running the code on terminal throws an error stating [code]. Please find the gist of it [here]([url] Thanks!",-1
Added a PR #40693 to improve the error message.,IssueComment,https://github.com/tensorflow/tensorflow/issues/40653#issuecomment-647816555,yongtang,2020-06-22 23:19:44,40653,[40693],Code bug,1,Added a PR #40693 to improve the error message.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40653"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40653"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40653#issuecomment-667840640,google-ml-butler[bot],2020-08-03 06:55:01,40653,[40693],Code bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40758"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40758"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/40758#issuecomment-654411142,google-ml-butler[bot],2020-07-06 19:00:34,40758,[40763],Memory bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I would like to work on this issue.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-635883120,kandekar007,2020-05-29 09:50:13,39981,[40779],Documentation bug,0,I would like to work on this issue.,3
Thanks! Feel free to submit a PR,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-636285172,rohan100jain,2020-05-30 06:23:37,39981,[40779],Documentation bug,0,Thanks! Feel free to submit a PR,3
"Can I work on this issue?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-636655203,Reece-Reklai,2020-06-01 07:09:46,39981,[40779],Documentation bug,0,Can I work on this issue?,0
"I can fix this, can i work on the issue?",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-640078133,jlamprou,2020-06-06 15:29:20,39981,[40779],Documentation bug,0,"I can fix this, can i work on the issue?",3
"@r-barnes @rohan100jain @Saduf2019 Can I work on this issue ??
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-644376443,aavishkarmishra,2020-06-15 20:39:02,39981,[40779],Documentation bug,0,@r-barnes @rohan100jain @Saduf2019 Can I work on this issue ??,0
I don't have the authority to assign fix responsibility here.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-644414419,r-barnes,2020-06-15 22:05:32,39981,[40779],Documentation bug,0,I don't have the authority to assign fix responsibility here.,0
"@paulis-reece @Satist @aavishkarmishra @kandekar007 

First one to land the PR fixing the issue wins. There is no one assigning issues to contributors.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-644843325,mihaimaruseac,2020-06-16 15:37:42,39981,[40779],Documentation bug,0,@paulis-reece @Satist @aavishkarmishra @kandekar007 First one to land the PR fixing the issue wins. There is no one assigning issues to contributors.,0
"But, where to send the PR(repo) ?

On Tue 16 Jun, 2020, 9:08 PM Mihai Maruseac, <notifications@github.com>
wrote:

> @paulis-reece <https://github.com/paulis-reece> @Satist
> <https://github.com/Satist> @aavishkarmishra
> <https://github.com/aavishkarmishra> @kandekar007
> <https://github.com/kandekar007>
>
> First one to land the PR fixing the issue wins. There is no one assigning
> issues to contributors.
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-644843325>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AKM6BK4JJ3GJJU6KZY2TAPLRW6GVVANCNFSM4NN2JQKQ>
> .
>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-644855571,abhinavsp0730,2020-06-16 15:59:27,39981,[40779],Documentation bug,0,"But, where to send the PR(repo) ? On Tue 16 Jun, 2020, 9:08 PM Mihai Maruseac, <[email]> wrote: > @paulis-reece <[url] @Satist > <[url] @aavishkarmishra > <[url] @kandekar007 > <[url] > > First one to land the PR fixing the issue wins. There is no one assigning > issues to contributors. > > â€” > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub > <[url]#issuecomment-644843325>, > or unsubscribe > <[url] > . >",0
This repo.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-644894868,mihaimaruseac,2020-06-16 17:09:01,39981,[40779],Documentation bug,0,This repo.,0
"@mihaimaruseac  Hi can anyone help me to locate these files in  repo , as in docs folder there is readme that tell to locate them in docs repo and in docs repo there are links which just open the web page",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-648461137,aavishkarmishra,2020-06-23 22:28:00,39981,[40779],Documentation bug,0,"@mihaimaruseac Hi can anyone help me to locate these files in repo , as in docs folder there is readme that tell to locate them in docs repo and in docs repo there are links which just open the web page",-1
https://cs.opensource.google/search?q=tf.math.maximum&ss=tensorflow%2Ftensorflow:tensorflow%2F&ssfr=1,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-649084304,mihaimaruseac,2020-06-24 21:32:25,39981,[40779],Documentation bug,0,[url],0
@mihaimaruseac why this is not updated in main website ?,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652647812,aavishkarmishra,2020-07-01 21:09:04,39981,[40779],Documentation bug,0,@mihaimaruseac why this is not updated in main website ?,0
@yashk2810 @lamberta Was the nightly not regenerated for this symbol? Or maybe the PR was not a fully working solution?,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652663109,mihaimaruseac,2020-07-01 21:47:56,39981,[40779],Documentation bug,0,@yashk2810 @lamberta Was the nightly not regenerated for this symbol? Or maybe the PR was not a fully working solution?,0
When did that go into tf-nightly?,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652667115,yashk2810,2020-07-01 21:59:31,39981,[40779],Documentation bug,0,When did that go into tf-nightly?,0
How to resolve this problem anyone have any idea ?,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652668055,aavishkarmishra,2020-07-01 22:02:15,39981,[40779],Documentation bug,0,How to resolve this problem anyone have any idea ?,0
"> resolve this problem

I am working on that :)",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652668487,yashk2810,2020-07-01 22:03:30,39981,[40779],Documentation bug,0,> resolve this problem I am working on that :),2
"> When did that go into tf-nightly?

Should be 5 day ago, 1e2bf4efce13b0fd3875d3f431ba699665392cc2 (318509604)",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652673890,mihaimaruseac,2020-07-01 22:18:53,39981,[40779],Documentation bug,0,"> When did that go into tf-nightly? Should be 5 day ago, 1e2bf4efce13b0fd3875d3f431ba699665392cc2 (318509604)",0
"Ahh.. I see the problem. There should be a newline after `Example:`. All doctests should have a newline before and after. Once that's fixed, it'll start appearing on the website.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652677348,yashk2810,2020-07-01 22:29:00,39981,[40779],Documentation bug,0,"Ahh.. I see the problem. There should be a newline after [code]. All doctests should have a newline before and after. Once that's fixed, it'll start appearing on the website.",1
I just submitted a fix for this. This should go live tomorrow or day-after-tomorrow whenever the change makes it to nightly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652680231,yashk2810,2020-07-01 22:38:23,39981,[40779],Documentation bug,0,I just submitted a fix for this. This should go live tomorrow or day-after-tomorrow whenever the change makes it to nightly.,3
"### Do we have to force line chage wherever we want a new line?
@yashk2810 
>As in case of markdown it changes line normally we don't have to force it(without using double space).",IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652681068,aavishkarmishra,2020-07-01 22:41:12,39981,[40779],Documentation bug,0,### Do we have to force line chage wherever we want a new line? @yashk2810 >As in case of markdown it changes line normally we don't have to force it(without using double space).,0
A new line is necessary because we do some regex matching to add stuff around it to display it on the site.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-652691101,yashk2810,2020-07-01 23:17:26,39981,[40779],Documentation bug,0,A new line is necessary because we do some regex matching to add stuff around it to display it on the site.,0
"@bjourne 
Please share the stand alone indented code for us to replicate this issue, also please share the tf version.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41193#issuecomment-656032268,Saduf2019,2020-07-09 09:56:11,41193,[41293],Version compatibility bug,0,"@bjourne Please share the stand alone indented code for us to replicate this issue, also please share the tf version.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41193"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41193"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41193#issuecomment-658494306,google-ml-butler[bot],2020-07-15 01:34:01,41193,[41293],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to reproduce the issue with TF v2.2, TF v2.3.0rc1 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/dcb5cf2d4a0f50849bbab85534c76781/41370-tf-nightly.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/41370#issuecomment-658211028,amahendrakar,2020-07-14 14:24:41,41370,[41386],Data bug,0,"Was able to reproduce the issue with TF v2.2, TF v2.3.0rc1 and TF-nightly. Please find the gist of it [here]([url] Thanks!",2
I think we need a PR to add functionality there.,IssueComment,https://github.com/tensorflow/tensorflow/issues/41370#issuecomment-658299760,mihaimaruseac,2020-07-14 17:06:11,41370,[41386],Data bug,0,I think we need a PR to add functionality there.,0
@jstzwj Are you interested to raise a PR? Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/41370#issuecomment-658349532,jvishnuvardhan,2020-07-14 18:47:29,41370,[41386],Data bug,0,@jstzwj Are you interested to raise a PR? Thanks!,3
"The issue is actually that  `Acos` is not covered in `XLA` for complex, thus triggered the incorrect result. Added a PR #41386 to add XLA complex support of `Acos` for the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41370#issuecomment-658352371,yongtang,2020-07-14 18:53:22,41370,[41386],Data bug,0,"The issue is actually that [code] is not covered in [code] for complex, thus triggered the incorrect result. Added a PR #41386 to add XLA complex support of [code] for the fix.",1
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41370#issuecomment-662072653,google-ml-butler[bot],2020-07-21 19:52:05,41370,[41386],Data bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
The PR #41386 is pending and is awaiting for review.,IssueComment,https://github.com/tensorflow/tensorflow/issues/41370#issuecomment-662085159,yongtang,2020-07-21 20:19:17,41370,[41386],Data bug,0,The PR #41386 is pending and is awaiting for review.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41370"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41370"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41370#issuecomment-674742245,google-ml-butler[bot],2020-08-17 08:33:28,41370,[41386],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"So, I am having this issue, was this solved?",IssueComment,https://github.com/tensorflow/tensorflow/issues/41370#issuecomment-828440146,NEGU93,2021-04-28 13:06:42,41370,[41386],Data bug,0,"So, I am having this issue, was this solved?",0
"The Problem is with the `channel=1` parameter.
You are converting the image to Grayscale, which is nothing but a weighted average of the channels. So this changes the value of the pixels.
This code works perfectly, for `channel=0` where the number of channels of the original image is preserved, causing no change in the value of the pixels.
For more info refer to:
https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/image/decode_png
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-487656184,captain-pool,2019-04-29 16:49:18,28256,[41472],Data bug,1,"The Problem is with the [code] parameter. You are converting the image to Grayscale, which is nothing but a weighted average of the channels. So this changes the value of the pixels. This code works perfectly, for [code] where the number of channels of the original image is preserved, causing no change in the value of the pixels. For more info refer to: [url]",0
"1. That is not the problem, and the code doesn't work perfectly if I use channel=0.
     if I use channel=0, I get again a RGB image with 3 channels, which I don't want.
     I want the single channel indexed-based image.


2. The documentation doesn't mention anything about taking a weighted average of the channels.

3. I am sorry, the image I have provided it not the best, please try this code:
```
from PIL import Image
import numpy as np
import tensorflow as tf
tf.enable_eager_execution()

PATH = '/tmp/xX4Stvh.png'

im = tf.gfile.FastGFile(PATH, 'rb').read()
ar = tf.image.decode_png(im, channels=0)
tf_max = tf.reduce_max(ar)
print(tf_max)

im = Image.open(PATH)
ar = np.asarray(im)
pil_max = np.max(ar)
print(pil_max)
```
on this image:
https://i.imgur.com/xX4Stvh.png

it has only three colors, so the difference in behaviour will be more apparent",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-487864104,adrianstaniec,2019-04-30 08:35:47,28256,[41472],Data bug,1,"1. That is not the problem, and the code doesn't work perfectly if I use channel=0. if I use channel=0, I get again a RGB image with 3 channels, which I don't want. I want the single channel indexed-based image. 2. The documentation doesn't mention anything about taking a weighted average of the channels. 3. I am sorry, the image I have provided it not the best, please try this code: ``[code]`` on this image: [url] it has only three colors, so the difference in behaviour will be more apparent",-2
">     1. That is not the problem, and the code doesn't work perfectly if I use channel=0.
>        if I use channel=0, I get again a RGB image with 3 channels, which I don't want.
>        I want the single channel indexed-based image.
> 
>     2. The documentation doesn't mention anything about taking a weighted average of the channels.
> 
>     3. I am sorry, the image I have provided it not the best, please try this code:
> 
> 
> ```
> from PIL import Image
> import numpy as np
> import tensorflow as tf
> tf.enable_eager_execution()
> 
> PATH = '/tmp/xX4Stvh.png'
> 
> im = tf.gfile.FastGFile(PATH, 'rb').read()
> ar = tf.image.decode_png(im, channels=0)
> tf_max = tf.reduce_max(ar)
> print(tf_max)
> 
> im = Image.open(PATH)
> ar = np.asarray(im)
> pil_max = np.max(ar)
> print(pil_max)
> ```
> 
> on this image:
> https://i.imgur.com/xX4Stvh.png
> 
> it has only three colors, so the difference in behaviour will be more apparent

Sorry for the confusion. The Main reason for this error is, PIL opens images in palette mode. This means the color from the channels are mapped to a color palette and that palette index is provided in each location of the image. However tensorflow, decodes the image into Channels and doesn't use this concept of palette. So, when the Pillow Image object is converted to numpy array, the values at the various positions is not intensity of the pixels of the color channel, which is in the case of tensorflow.

The correct way to verify this is:
```python
from PIL import Image
import numpy as np
import tensorflow as tf
tf.enable_eager_execution()

PATH = '/tmp/xX4Stvh.png'

im = tf.gfile.FastGFile(PATH, 'rb').read()
ar = tf.image.decode_png(im, channels=0)
tf_max = tf.reduce_max(ar)
print(tf_max)

im = Image.open(PATH).convert('RGB') # This convert() function converts from 
                                     # PIL exclusive Palette mode to channel mode
ar = np.asarray(im)
pil_max = np.max(ar)
print(pil_max)
```

And about the weighted average thing. When you are loading a color image in channel mode and request it to convert to grayscale (`channels=0` does that). A weighted average on all the channels(R,G,B) is calculated to produce the value for one channel. (That's why the number of channels for grayscaled image is 1 and RGB colored image, is 3)
Reference: 
1. https://stackoverflow.com/a/52307690/9947584
2. https://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-487931227,captain-pool,2019-04-30 12:24:40,28256,[41472],Data bug,1,"> 1. That is not the problem, and the code doesn't work perfectly if I use channel=0. > if I use channel=0, I get again a RGB image with 3 channels, which I don't want. > I want the single channel indexed-based image. > > 2. The documentation doesn't mention anything about taking a weighted average of the channels. > > 3. I am sorry, the image I have provided it not the best, please try this code: > > > ``[code]`[code]`[code]`[code]channels=0` does that). A weighted average on all the channels(R,G,B) is calculated to produce the value for one channel. (That's why the number of channels for grayscaled image is 1 and RGB colored image, is 3) Reference: 1. [url] 2. [url]#Converting_color_to_grayscale",-2
"thanks for the response capitan-pool
So the whole point is that I actually only care about these palette indexes, not about the RGB values.
Those palette index values are the target class IDs for semantic segmentation.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-488087203,adrianstaniec,2019-04-30 19:39:03,28256,[41472],Data bug,1,"thanks for the response capitan-pool So the whole point is that I actually only care about these palette indexes, not about the RGB values. Those palette index values are the target class IDs for semantic segmentation.",0
"> thanks for the response capitan-pool
> So the whole point is that I actually only care about these palette indexes, not about the RGB values.
> Those palette index values are the target class IDs for semantic segmentation.

Huh? That has nothing to do with semantic segmentation. You don't care about Palette Values for any sort of deep vision related tasks, in general. You need to use the 3 Channels of RGB, 4 Channels of RGBA, or 1 channel of Grayscale, while working with images.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-488235942,captain-pool,2019-05-01 08:37:36,28256,[41472],Data bug,1,"> thanks for the response capitan-pool > So the whole point is that I actually only care about these palette indexes, not about the RGB values. > Those palette index values are the target class IDs for semantic segmentation. Huh? That has nothing to do with semantic segmentation. You don't care about Palette Values for any sort of deep vision related tasks, in general. You need to use the 3 Channels of RGB, 4 Channels of RGBA, or 1 channel of Grayscale, while working with images.",-3
"ok, forget the segmentation part.

Could you just answer this question:
*How can I achieve the same behavior with tensorflow as I had with PIL?*

because what you have suggested before is the opposite,
you modified the PIL code to match the tensorflow implementation",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-488298763,adrianstaniec,2019-05-01 14:33:24,28256,[41472],Data bug,1,"ok, forget the segmentation part. Could you just answer this question: *How can I achieve the same behavior with tensorflow as I had with PIL?* because what you have suggested before is the opposite, you modified the PIL code to match the tensorflow implementation",-2
"> ok, forget the segmentation part.
> 
> Could you just answer this question:
> _How can I achieve the same behavior with tensorflow as I had with PIL?_
> 
> because what you have suggested before is the opposite,
> you modified the PIL code to match the tensorflow implementation

You can do something similar using,
```python
import tensorflow as tf
img = tf.image.decode_png(tf.io.read_file(/path/to/png/file))
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-488303924,captain-pool,2019-05-01 14:51:20,28256,[41472],Data bug,1,"> ok, forget the segmentation part. > > Could you just answer this question: > _How can I achieve the same behavior with tensorflow as I had with PIL?_ > > because what you have suggested before is the opposite, > you modified the PIL code to match the tensorflow implementation You can do something similar using, ``[code]``",-1
"Could someone else look at this issue, please?
I am sorry, but captain-pool doesn't get it",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-491740849,adrianstaniec,2019-05-13 09:07:57,28256,[41472],Data bug,1,"Could someone else look at this issue, please? I am sorry, but captain-pool doesn't get it",-2
This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-494971938,jvishnuvardhan,2019-05-22 21:02:42,28256,[41472],Data bug,1,This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow]([url] There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!,1
"the only way you could do is to re-save your png file in ""RGB"" mode . in this case,  the image datas are the indices of  paletteï¼Œwhich you needed to training a semantic segment model , and decoding function in tensorflow works correctly  . side effect is that you cant see anything in preview, because its intensity is too low to be seen",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-496767048,chenweizhi,2019-05-29 03:13:29,28256,[41472],Data bug,1,"the only way you could do is to re-save your png file in ""RGB"" mode . in this case, the image datas are the indices of paletteï¼Œwhich you needed to training a semantic segment model , and decoding function in tensorflow works correctly . side effect is that you cant see anything in preview, because its intensity is too low to be seen",-2
This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-499666503,jvishnuvardhan,2019-06-06 21:02:56,28256,[41472],Data bug,1,This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow]([url] There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!,1
"I just met the same problem, it looks like there is no way to get the correct palette indexes with native tensorflow. However, I solved my problem with `tf.py_func`. I'll leave my code here in case somebody finds it useful.
```python
import tensorflow as tf
import numpy as np
from PIL import Image

dataset = tf.data.Dataset.from_tensor_slices({
    'image': ['img00.png', 'img01.png'],
    'index': [0, 1]
    })

def load_image_func(image, index):
    return np.array(Image.open(image)), index

dataset = dataset.map(lambda x: (
    tf.py_func(load_image_func, [x['image'], x['index']], [tf.uint8, x['index'].dtype])))
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-513312714,doraeric,2019-07-19 17:33:32,28256,[41472],Data bug,1,"I just met the same problem, it looks like there is no way to get the correct palette indexes with native tensorflow. However, I solved my problem with [code]. I'll leave my code here in case somebody finds it useful. ``[code]``",2
"A clean solution would be to re-implement a custom op to decode a PNG without palette conversion.

Currently, the conversion is done at [core level](https://github.com/tensorflow/tensorflow/blob/38cdb9ff8548efc920039d68dd94b5581db6314a/tensorflow/core/lib/png/png_io.cc#L284):
```cpp
  // convert palette to rgb(a) if needs be.
  if (context->color_type == PNG_COLOR_TYPE_PALETTE)
    png_set_palette_to_rgb(context->png_ptr);
```

If you are at TF 1.X, you can wrap the PIL-call with `py_func` in order to get the desired behavior, like:

```python
def read_png(mask):
    def read_fn(p):
        return np.asarray(Image.open(p))
    return tf.py_func(read_fn, [mask], tf.uint8)
```

and then build your pipe, like:

```python

ar = read_png(im)
tf_max = tf.reduce_max(ar)

with tf.Session() as sess:
    print(sess.run(tf_max))
```

**Note**: in TF1.X this works only in graph-mode. In TF2.X a similar trick should be possible with `tf.numpy_function` or `tf.py_function`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-593471718,alar0330,2020-03-02 15:53:36,28256,[41472],Data bug,1,"A clean solution would be to re-implement a custom op to decode a PNG without palette conversion. Currently, the conversion is done at [core level]([url]#L284): ``[code]`[code]py_func[code]`[code]`[code]`[code]`[code]tf.numpy_function[code]tf.py_function`.",0
"This is a valid issue that shouldn't be closed and likely drives user away if not properly handled, as it represents an important use case. @adrianstaniec you're right it doesn't work and for exactly the reasons @alar0330 mentioned.
I believe the fix doesn't require any API level change, i.e., tf.image.decode_png(mask_path) should have same behavior as np.array(Image.Open(mask_path))  
But for now, either use `tf.numpy_function`, or `tf.data.Dataset.from_generator` and let generator use Image.Open(mask_path)",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-654521474,tanzhenyu,2020-07-06 23:59:32,28256,[41472],Data bug,1,"This is a valid issue that shouldn't be closed and likely drives user away if not properly handled, as it represents an important use case. @adrianstaniec you're right it doesn't work and for exactly the reasons @alar0330 mentioned. I believe the fix doesn't require any API level change, i.e., tf.image.decode_png(mask_path) should have same behavior as np.array(Image.Open(mask_path)) But for now, either use [code], or [code] and let generator use Image.Open(mask_path)",-1
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-657904348,google-ml-butler[bot],2020-07-14 00:55:13,28256,[41472],Data bug,1,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
The issue comes from a redundant ` png_set_rgb_to_gray` call in the C++ kernel for palette-based images. I have created a PR #41472 to fix this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-659690787,yongtang,2020-07-16 21:43:17,28256,[41472],Data bug,1,The issue comes from a redundant [code] call in the C++ kernel for palette-based images. I have created a PR #41472 to fix this issue.,1
"After the rollback of the fix, this is now again a problem. When loading index PNGs TF should allow the user to choose whether to use the palette to convert the pixel index or choose to load the raw index value themselves. 

Thanks to @alar0330 for the workaround.",IssueComment,https://github.com/tensorflow/tensorflow/issues/28256#issuecomment-938273129,mvonpohle,2021-10-08 01:45:17,28256,[41472],Data bug,1,"After the rollback of the fix, this is now again a problem. When loading index PNGs TF should allow the user to choose whether to use the palette to convert the pixel index or choose to load the raw index value themselves. Thanks to @alar0330 for the workaround.",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41501"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41501"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41501#issuecomment-660819878,google-ml-butler[bot],2020-07-20 05:56:36,41501,[41502],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"So the error isn't that misleading, you're getting it because you're broadcasting it to too big a tensor. 
```
InvalidArgumentError: Shape [2,2,2,2,2,2,2,2,2,2,2,2] would have more than 2**63 - 1 elements [Op:BroadcastTo]
```
 appears when the number of elements has exceeded the given limit. You will have more than 2**63 - 1 elements when you broadcast it to the given shape [110, 53, 104, 147, 157, 123, 5, 24, 188, 40, 5, 2] or the upper limit of shapes [2,2,2,2,2,2,2,2,2,2,2,2].",IssueComment,https://github.com/tensorflow/tensorflow/issues/41504#issuecomment-660332446,lordtt13,2020-07-17 20:52:05,41504,[41514],Code bug,1,"So the error isn't that misleading, you're getting it because you're broadcasting it to too big a tensor. ``[code]`` appears when the number of elements has exceeded the given limit. You will have more than 2**63 - 1 elements when you broadcast it to the given shape [110, 53, 104, 147, 157, 123, 5, 24, 188, 40, 5, 2] or the upper limit of shapes [2,2,2,2,2,2,2,2,2,2,2,2].",0
"The issue is that the construction of error message in tensor_shape.cc does not copy all dims of shape, only the current dim of the shape (when error check happens). Created a PR #41514 for the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41504#issuecomment-660358914,yongtang,2020-07-17 22:12:32,41504,[41514],Code bug,1,"The issue is that the construction of error message in tensor_shape.cc does not copy all dims of shape, only the current dim of the shape (when error check happens). Created a PR #41514 for the fix.",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41504"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41504"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41504#issuecomment-662109531,google-ml-butler[bot],2020-07-21 21:13:19,41504,[41514],Code bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I also observed the following API aliases can cause the same issue in older versions of tensorflow.
Users should be cautious when using them on both CPU and GPU up to tensorflow 2.3.4 (v2.3.3-137-gea90cf44f73).

> On GPU, it throws an ""CUDA runtime implicit initialization on GPU:0 failed."" Exception before tensorflow 2.4.0 (v2.4.0-rc4-71-g582c8d236cb).

- `(tf.broadcast_to)`, `tf.compat.v1.broadcast_to`

<details>
  <summary>Code to reproduce the issue in <code>tf.compat.v1.broadcast_to</code> in older versions</summary>

```python
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION, flush=True)
print(tf.config.list_physical_devices(), flush=True)


try:
    x = tf.constant([1, 2, 3])
    tf.compat.v1.broadcast_to(x, [110, 53, 104, 147, 157, 123, 5, 24, 188, 40, 5, 2])
except Exception as e:
    print(""Failed! Error:"", str(e), flush=True)
else:
    print(""Success!"", flush=True)
```

On my CPU machine, it throws an error with a fixed shape <code>[2,2,2,2,2,2,2,2,2,2,2,2]</code> instead of the given shape <code>[110, 53, 104, 147, 157, 123, 5, 24, 188, 40, 5, 2]</code>, which is not expected.

```text
v2.3.3-137-gea90cf44f73 2.3.4
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]
Failed! Error: Shape [2,2,2,2,2,2,2,2,2,2,2,2] would have more than 2**63 - 1 elements [Op:BroadcastTo]
```

While on GPU, it throws a ""CUDA runtime implicit initialization on GPU:0 failed."" Exception, which is also unexpected.

```text
v2.3.3-137-gea90cf44f73 2.3.4
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Failed! Error: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid
```
</details>

It seems to be fixed in tensorflow 2.4.0 (v2.4.0-rc4-71-g582c8d236cb) and later versions.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41504#issuecomment-1729350585,oawxkw,2023-09-21 11:07:58,41504,[41514],Code bug,1,"I also observed the following API aliases can cause the same issue in older versions of tensorflow. Users should be cautious when using them on both CPU and GPU up to tensorflow 2.3.4 (v2.3.3-137-gea90cf44f73). > On GPU, it throws an ""CUDA runtime implicit initialization on GPU:0 failed."" Exception before tensorflow 2.4.0 (v2.4.0-rc4-71-g582c8d236cb). - [code], [code] <details> <summary>Code to reproduce the issue in <code>tf.compat.v1.broadcast_to</code> in older versions</summary> ``[code]`[code]`[code]`[code]`[code]`` </details> It seems to be fixed in tensorflow 2.4.0 (v2.4.0-rc4-71-g582c8d236cb) and later versions.",0
"Great catch, thanks! @MeghnaNatraj can you take this one?",IssueComment,https://github.com/tensorflow/tensorflow/issues/41352#issuecomment-660265050,jdduke,2020-07-17 18:14:41,41352,[41529],Code bug,0,"Great catch, thanks! @MeghnaNatraj can you take this one?",4
"@faustomorales Thank you for catching this bug. Let us know if you've filed a PR, otherwise I'll go ahead and make the update.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41352#issuecomment-660275756,MeghnaNatraj,2020-07-17 18:37:43,41352,[41529],Code bug,0,"@faustomorales Thank you for catching this bug. Let us know if you've filed a PR, otherwise I'll go ahead and make the update.",3
I'm happy to file the PR for this in the next couple of days. Just wanted to file an issue before I assume that this behavior was unintentional. Thanks for the feedback!,IssueComment,https://github.com/tensorflow/tensorflow/issues/41352#issuecomment-660305651,faustomorales,2020-07-17 19:46:15,41352,[41529],Code bug,0,I'm happy to file the PR for this in the next couple of days. Just wanted to file an issue before I assume that this behavior was unintentional. Thanks for the feedback!,4
"@faustomorales Whenever you file the PR, feel free to add me as a reviewer for a quicker turnaround time. Thank you.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41352#issuecomment-660323235,MeghnaNatraj,2020-07-17 20:28:41,41352,[41529],Code bug,0,"@faustomorales Whenever you file the PR, feel free to add me as a reviewer for a quicker turnaround time. Thank you.",3
"@faustomorales

Would a more robust option be to use a try statement to attempt to import the runtime from tensorflow and fall back to tflite_runtime if it fails to load the module? 
What is the rationale behind having the check be done with the file name?

Best,
Sebastian ",IssueComment,https://github.com/tensorflow/tensorflow/issues/41352#issuecomment-660598031,jspaezp,2020-07-19 06:49:58,41352,[41529],Code bug,0,"@faustomorales Would a more robust option be to use a try statement to attempt to import the runtime from tensorflow and fall back to tflite_runtime if it fails to load the module? What is the rationale behind having the check be done with the file name? Best, Sebastian",0
"> @faustomorales
> 
> 
> 
> Would a more robust option be to use a try statement to attempt to import the runtime from tensorflow and fall back to tflite_runtime if it fails to load the module? 
> 
> What is the rationale behind having the check be done with the file name?
> 
> 
> 
> Best,
> 
> Sebastian 

Switching to a try/catch seems more idiomatc (ask forgiveness, not permission) but would result in TensorFlow getting used if a user has installed TensorFlow *and* the TFLite runtime in the same environment. In the best case, this causes surprising behavior (the TFLite runtime would rely on TensorFlow when it was intended to operate independently). In the worst case, there could be an API mismatch between TFLite and TensorFlow. For those reasons, I think it would be wise to stick with the path check. Let me know if I've missed something!",IssueComment,https://github.com/tensorflow/tensorflow/issues/41352#issuecomment-660729476,faustomorales,2020-07-19 23:51:46,41352,[41529],Code bug,0,"> @faustomorales > > > > Would a more robust option be to use a try statement to attempt to import the runtime from tensorflow and fall back to tflite_runtime if it fails to load the module? > > What is the rationale behind having the check be done with the file name? > > > > Best, > > Sebastian Switching to a try/catch seems more idiomatc (ask forgiveness, not permission) but would result in TensorFlow getting used if a user has installed TensorFlow *and* the TFLite runtime in the same environment. In the best case, this causes surprising behavior (the TFLite runtime would rely on TensorFlow when it was intended to operate independently). In the worst case, there could be an API mismatch between TFLite and TensorFlow. For those reasons, I think it would be wise to stick with the path check. Let me know if I've missed something!",0
"@faustomorales thanks for the explanation, really look forward to this patch being released in a stable version (right now I am patching ""manually"" the file to bundle it in pyinstaller).
Best! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/41352#issuecomment-661347976,jspaezp,2020-07-20 21:40:30,41352,[41529],Code bug,0,"@faustomorales thanks for the explanation, really look forward to this patch being released in a stable version (right now I am patching ""manually"" the file to bundle it in pyinstaller). Best!",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41352"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41352"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41352#issuecomment-661842037,google-ml-butler[bot],2020-07-21 12:53:23,41352,[41529],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I have tried in colab with TF version 2.2, 2.3-rc1,nightly versions(`2.4.0-dev20200719`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/adcddd8a7a1b1f8280c3f44685d57064/untitled151.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/41546#issuecomment-660913551,ravikyram,2020-07-20 09:26:33,41546,[41548],Processor bug,1,"I have tried in colab with TF version 2.2, 2.3-rc1,nightly versions([code]) and was able to reproduce the issue.Please, find the gist [here]([url]",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41546"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41546"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41546#issuecomment-783438831,google-ml-butler[bot],2021-02-22 15:05:31,41546,[41548],Processor bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"The issue is in:

https://github.com/tensorflow/tensorflow/blob/v2.3.0-rc2/tensorflow/core/api_def/base_api/api_def_MatrixInverse.pbtxt#L18-L22

where the summary spans across the description. Created a PR #41665 for the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41656#issuecomment-663088435,yongtang,2020-07-23 15:57:05,41656,[41665],Documentation bug,0,The issue is in: [url]#L18-L22 where the summary spans across the description. Created a PR #41665 for the fix.,0
Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/97a184c5b298585bd18887b72e57c3e1/39572.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/6a8783e3a871557adffddc2899e76661/39572-tf-nightly.ipynb). Please find the attached gist. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-629202914,amahendrakar,2020-05-15 12:17:59,39572,[41790],Deployment bug,1,Was able to reproduce the issue with [TF v2.2]([url] and [TF-nightly]([url] Please find the attached gist. Thanks!,2
"Looks like the fusion in MLIR is broken. I can reproduce this with the following minimal function as well:
```python
length = 66
a = tf.random.uniform([length, length], dtype=tf.float32)
c = tf.random.uniform([length], dtype=tf.float32)

@tf.function
def func(x):
    return tf.matmul(x, a) * c
```
The weights in the generated flatbuffer are definitely different.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-629232601,lgeiger,2020-05-15 13:21:27,39572,[41790],Deployment bug,1,Looks like the fusion in MLIR is broken. I can reproduce this with the following minimal function as well: ``[code]`` The weights in the generated flatbuffer are definitely different.,-2
It looks like this is not a new issue. I can reproduce this in v2.1.0 as well.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-629298577,lgeiger,2020-05-15 15:17:38,39572,[41790],Deployment bug,1,It looks like this is not a new issue. I can reproduce this in v2.1.0 as well.,-1
"https://github.com/tensorflow/tensorflow/blob/020a88ac127caa1e333ce36873ad2602abc5f7d7/tensorflow/compiler/mlir/lite/transforms/optimize.cc#L361-L368
These lines are skipped if the filter is square matrix.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-629329708,ghost,2020-05-15 15:48:08,39572,[41790],Deployment bug,1,[url]#L361-L368 These lines are skipped if the filter is square matrix.,0
"Hi @liufengdb,

Do you think you can take a look?",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-630103920,daverim,2020-05-18 10:52:29,39572,[41790],Deployment bug,1,"Hi @liufengdb, Do you think you can take a look?",0
"lgeiger, I'm a little bit confused by your example. The patterns used for `tf.matmul(x, a) * c` in your example is different from the issue description, right? ",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-630618125,liufengdb,2020-05-19 06:43:30,39572,[41790],Deployment bug,1,"lgeiger, I'm a little bit confused by your example. The patterns used for [code] in your example is different from the issue description, right?",0
"> lgeiger, I'm a little bit confused by your example. The patterns used for `tf.matmul(x, a) * c` in your example is different from the issue description, right?

@liufengdb Thanks for checking it out. Yes, the example is different on purpose since it uses a subset of the ops of the original example and I thought it might be helpful for debugging to have a smaller graph that reproduces the same issue. Please let me know if the two examples are not related, I am happy to open up a new issue for it.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-630728836,lgeiger,2020-05-19 10:21:03,39572,[41790],Deployment bug,1,"> lgeiger, I'm a little bit confused by your example. The patterns used for [code] in your example is different from the issue description, right? @liufengdb Thanks for checking it out. Yes, the example is different on purpose since it uses a subset of the ops of the original example and I thought it might be helpful for debugging to have a smaller graph that reproduces the same issue. Please let me know if the two examples are not related, I am happy to open up a new issue for it.",2
"https://github.com/tensorflow/tensorflow/blob/ed0eb69b76f9ff7ac952a3f36692d2c86929a6bf/tensorflow/compiler/mlir/lite/tests/optimize.mlir#L252-L264
The test is invalid too.

```
cst0 = [[1.0, 2.0],
        [3.0, 4.0]]

cst1 = [1.0, 2.0]

arg0 = [x, y]

%0 = tfl.fully_connected(arg0, cst0) = tf.matmul(arg0, tf.transpose(cst0)) = [1.0x + 2.0y, 3.0x + 4.0y]

%1 = tfl.mul(%0, cst1) = [1.0x + 2.0y, 6.0x + 8.0y] = tf.matmul(arg0, [[1.0, 6.0], [2.0, 8.0]]) = tf.matmul(arg0, tf.transpose([[1.0, 2.0], [6.0, 8.0]]))

%[[CONSTANT]] = [[1.0, 2.0], [6.0, 8.0]]  !=  [[1.0, 4.0], [3.0, 8.0]]  


```",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-631902251,ghost,2020-05-21 06:09:24,39572,[41790],Deployment bug,1,[url]#L252-L264 The test is invalid too. ``[code]``,-2
Are there any updates on this? It looks like the related PR is stale #40013 but it would be great if this issue would be fixed.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-656125638,lgeiger,2020-07-09 13:25:04,39572,[41790],Deployment bug,1,Are there any updates on this? It looks like the related PR is stale #40013 but it would be great if this issue would be fixed.,1
"I submitted #41790 a few weeks ago to fix this, any chance someone could review it?",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-671811373,lgeiger,2020-08-11 08:35:08,39572,[41790],Deployment bug,1,"I submitted #41790 a few weeks ago to fix this, any chance someone could review it?",1
"This is still a major issue and a fix is available at #41790, it would be great if this could still make it into the 2.4 release.",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-696571090,lgeiger,2020-09-22 08:05:06,39572,[41790],Deployment bug,1,"This is still a major issue and a fix is available at #41790, it would be great if this could still make it into the 2.4 release.",2
"I can still reproduce this in the latest tf-nightly: https://colab.research.google.com/drive/1kcw_zhk_7wj8zOVf3VH1V-2GjN0eFQJF?usp=sharing

Any news on when #41790 could get a review?",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-708622138,lgeiger,2020-10-14 19:47:00,39572,[41790],Deployment bug,1,I can still reproduce this in the latest tf-nightly: [url] Any news on when #41790 could get a review?,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39572"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39572"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39572#issuecomment-723061020,google-ml-butler[bot],2020-11-06 12:42:48,39572,[41790],Deployment bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@WindQAQ 

I have tried in colab with TF nightly version(2.4.0-dev20200730) and was able to reproduce the issue.However if I change 
`@tf.function(experimental_compile=True)`to `@tf.function`in the code I am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/5167b8076f8f98b64664c351843fec89/untitled209.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/41915#issuecomment-666972293,ravikyram,2020-07-31 07:15:41,41915,[41916],Data bug,1,"@WindQAQ I have tried in colab with TF nightly version(2.4.0-dev20200730) and was able to reproduce the issue.However if I change [code]to [code]in the code I am not seeing any issue.Please, find the gist [here]([url]",0
"> @WindQAQ
> 
> I have tried in colab with TF nightly version(2.4.0-dev20200730) and was able to reproduce the issue.However if I change
> `@tf.function(experimental_compile=True)`to `@tf.function`in the code I am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/5167b8076f8f98b64664c351843fec89/untitled209.ipynb).Thanks!

Yes, but in that case, it does not utilize XLA.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41915#issuecomment-667239701,WindQAQ,2020-07-31 17:21:29,41915,[41916],Data bug,1,"> @WindQAQ > > I have tried in colab with TF nightly version(2.4.0-dev20200730) and was able to reproduce the issue.However if I change > [code]to [code]in the code I am not seeing any issue.Please, find the gist [here]([url] Yes, but in that case, it does not utilize XLA.",0
It looks like the ops is missing an XLA kernel for the gradient. @cheshire / @rmlarsen  could you triage?,IssueComment,https://github.com/tensorflow/tensorflow/issues/41915#issuecomment-668570468,mdanatg,2020-08-04 12:36:35,41915,[41916],Data bug,1,It looks like the ops is missing an XLA kernel for the gradient. @cheshire / @rmlarsen could you triage?,0
Thanks for the triage! I think it misses the XLA kernel for `EuclideanNorm` instead of its gradient as the gradient is defined with python ops [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_grad.py#L52-L64).,IssueComment,https://github.com/tensorflow/tensorflow/issues/41915#issuecomment-668747386,WindQAQ,2020-08-04 18:11:23,41915,[41916],Data bug,1,Thanks for the triage! I think it misses the XLA kernel for [code] instead of its gradient as the gradient is defined with python ops [here]([url]#L52-L64).,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41915"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41915"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41915#issuecomment-673112154,google-ml-butler[bot],2020-08-12 21:08:29,41915,[41916],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"The problem is that the formatted tensor string is escaped:
`b'\xf0\x9f\x98\x8a:""\\360\\237\\230\\212""'`",IssueComment,https://github.com/tensorflow/tensorflow/issues/42001#issuecomment-667960603,bhack,2020-08-03 11:05:59,42001,[42067],Data bug,1,The problem is that the formatted tensor string is escaped: [code],-1
Also the formatted tensor is in Octal Escape Sequence ,IssueComment,https://github.com/tensorflow/tensorflow/issues/42001#issuecomment-667967962,bhack,2020-08-03 11:23:13,42001,[42067],Data bug,1,Also the formatted tensor is in Octal Escape Sequence,0
Added a PR #42067 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42001#issuecomment-669314584,yongtang,2020-08-05 17:05:35,42001,[42067],Data bug,1,Added a PR #42067 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42001"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42001"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42001#issuecomment-670320923,google-ml-butler[bot],2020-08-07 04:53:57,42001,[42067],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@yixingfu The colab gist you shared cannot be opened due to permissions. Can you please save it as GitHub gist and share again? Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/41874#issuecomment-666036107,ymodak,2020-07-30 02:01:49,41874,[42074],Deployment bug,0,@yixingfu The colab gist you shared cannot be opened due to permissions. Can you please save it as GitHub gist and share again? Thanks!,2
"Here is the gist
https://gist.github.com/yixingfu/79e0693627c8e0aeaccaead6d4068cbf",IssueComment,https://github.com/tensorflow/tensorflow/issues/41874#issuecomment-666049491,yixingfu,2020-07-30 02:34:38,41874,[42074],Deployment bug,0,Here is the gist [url],0
"As per new tf-nightly version 2.4.0-dev20200803 the error is not raised while loading weights.
See [gist](https://colab.research.google.com/gist/ymodak/a6e26acf6a1bfb3d2d042cac55a8b655/callback-exception.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/41874#issuecomment-668140759,ymodak,2020-08-03 17:17:41,41874,[42074],Deployment bug,0,As per new tf-nightly version 2.4.0-dev20200803 the error is not raised while loading weights. See [gist]([url],0
"No it still raises error when loading weight. And this error comes from the checkpoint failing to save, which should actually raise an error. 

I think I know where the error come from. I will open a PR to fix it soon.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41874#issuecomment-668670670,yixingfu,2020-08-04 15:38:56,41874,[42074],Deployment bug,0,"No it still raises error when loading weight. And this error comes from the checkpoint failing to save, which should actually raise an error. I think I know where the error come from. I will open a PR to fix it soon.",1
"You are right this works for `tf` format but not `h5`.
I forgot to reset the colab runtime while testing for different formats so didn't get any error.
Feel free to raise a PR and tag this issue thread. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/41874#issuecomment-668842933,ymodak,2020-08-04 21:51:57,41874,[42074],Deployment bug,0,You are right this works for [code] format but not [code]. I forgot to reset the colab runtime while testing for different formats so didn't get any error. Feel free to raise a PR and tag this issue thread. Thanks!,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41874"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41874"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41874#issuecomment-673033838,google-ml-butler[bot],2020-08-12 18:19:04,41874,[42074],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42105"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42105"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42105#issuecomment-670994393,google-ml-butler[bot],2020-08-09 01:51:53,42105,[42109],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Reopening since #42109 seems to not be solving this issue (this op is V2, the PR fixes on V1)",IssueComment,https://github.com/tensorflow/tensorflow/issues/42105#issuecomment-712480797,mihaimaruseac,2020-10-19 22:39:37,42105,[42109],Data bug,0,"Reopening since #42109 seems to not be solving this issue (this op is V2, the PR fixes on V1)",-1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42105"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42105"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42105#issuecomment-712524886,google-ml-butler[bot],2020-10-20 01:04:57,42105,[42109],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Does the CVE-2020-15265 Vulnerability Affect 1.15.5?,IssueComment,https://github.com/tensorflow/tensorflow/issues/42105#issuecomment-816466090,lvyuqi,2021-04-09 07:10:14,42105,[42109],Data bug,0,Does the CVE-2020-15265 Vulnerability Affect 1.15.5?,0
"Yes, but we no longer patch 1.15. Please update post 2.1",IssueComment,https://github.com/tensorflow/tensorflow/issues/42105#issuecomment-817242344,mihaimaruseac,2021-04-11 03:46:54,42105,[42109],Data bug,0,"Yes, but we no longer patch 1.15. Please update post 2.1",0
"Hello, is there any chance that vulnerability fix will be applied in versions like 2.3.4? ",IssueComment,https://github.com/tensorflow/tensorflow/issues/42105#issuecomment-911222537,mgmm13,2021-09-02 05:51:52,42105,[42109],Data bug,0,"Hello, is there any chance that vulnerability fix will be applied in versions like 2.3.4?",0
"Hi. Not in 2.3.4, as the 2.3.x has reached end of life.

It is already included in 2.4.0 and later",IssueComment,https://github.com/tensorflow/tensorflow/issues/42105#issuecomment-911905151,mihaimaruseac,2021-09-02 17:27:55,42105,[42109],Data bug,0,"Hi. Not in 2.3.4, as the 2.3.x has reached end of life. It is already included in 2.4.0 and later",0
"@mihaimaruseac noted on this, thank you for the feedback.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42105#issuecomment-912167901,mgmm13,2021-09-03 00:54:25,42105,[42109],Data bug,0,"@mihaimaruseac noted on this, thank you for the feedback.",3
Added a PR #42143 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42129#issuecomment-670798991,yongtang,2020-08-08 00:51:52,42129,[42143],Data bug,1,Added a PR #42143 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42129"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42129"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42129#issuecomment-712441186,google-ml-butler[bot],2020-10-19 21:04:28,42129,[42143],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Does this issue affect the 1.15.5 version?
Corresponding CVE Vulnerability CVE-2020-15266",IssueComment,https://github.com/tensorflow/tensorflow/issues/42129#issuecomment-816463380,lvyuqi,2021-04-09 07:05:34,42129,[42143],Data bug,1,Does this issue affect the 1.15.5 version? Corresponding CVE Vulnerability CVE-2020-15266,0
"Yes, but being low severity and given that patching 1.15 and 2.0 is extremely expensive we no longer patched it.

Recommendation is to update past 2.1",IssueComment,https://github.com/tensorflow/tensorflow/issues/42129#issuecomment-817328092,mihaimaruseac,2021-04-11 15:44:23,42129,[42143],Data bug,1,"Yes, but being low severity and given that patching 1.15 and 2.0 is extremely expensive we no longer patched it. Recommendation is to update past 2.1",0
"Hello, is there any chance that vulnerability fix will be applied in versions like 2.3.4?",IssueComment,https://github.com/tensorflow/tensorflow/issues/42129#issuecomment-911232214,mgmm13,2021-09-02 06:02:42,42129,[42143],Data bug,1,"Hello, is there any chance that vulnerability fix will be applied in versions like 2.3.4?",0
"Hi. Not in 2.3.4, as the 2.3.x has reached end of life.

It is already included in 2.4.0 and later",IssueComment,https://github.com/tensorflow/tensorflow/issues/42129#issuecomment-911904615,mihaimaruseac,2021-09-02 17:27:09,42129,[42143],Data bug,1,"Hi. Not in 2.3.4, as the 2.3.x has reached end of life. It is already included in 2.4.0 and later",0
"@mihaimaruseac noted on this, thank you for the feedback.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42129#issuecomment-912168031,mgmm13,2021-09-03 00:54:49,42129,[42143],Data bug,1,"@mihaimaruseac noted on this, thank you for the feedback.",3
"I have tried in colab with TF versions 2.2,2.3-rc0,nightly versions(`2.4.0-dev20200705`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/95302a74087ba08432ece90213095b22/untitled83.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/41090#issuecomment-654031729,ravikyram,2020-07-06 05:59:45,41090,[42237],Algorithm design bug,0,"I have tried in colab with TF versions 2.2,2.3-rc0,nightly versions([code]) and was able to reproduce the issue.Please, find the gist [here]([url]",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41090"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41090"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41090#issuecomment-717274037,google-ml-butler[bot],2020-10-27 14:15:30,41090,[42237],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"A workaround is to wrap the function with lambda layer:

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np


def main():
    inputs = layers.Input(shape=(None,))
    stft = layers.Lambda(lambda x: tf.signal.stft(x, 512, 20, pad_end=True))(inputs)
    model = keras.Model(inputs=inputs, outputs=stft)
    signals = tf.constant(np.random.rand(2, 512))
    print(model(signals))
    print('All done.')


if __name__ == '__main__':
    main()
```

https://colab.research.google.com/drive/1l4OYzh4sy-6d9BAszCC39e9B6uFYRpHD?usp=sharing",IssueComment,https://github.com/tensorflow/tensorflow/issues/42254#issuecomment-672686136,WindQAQ,2020-08-12 07:25:25,42254,[42269],Data bug,0,A workaround is to wrap the function with lambda layer: ``[code]`` [url],0
"@WindQAQ I am not sure if this is an option in my case. In my case I would have to wrap the entire preprocessing pipeline in a keras layer; But that might not be a bad idea after all..

Also it's possible to just pad it manually (see my original post).",IssueComment,https://github.com/tensorflow/tensorflow/issues/42254#issuecomment-672689960,stefan-falk,2020-08-12 07:33:15,42254,[42269],Data bug,0,@WindQAQ I am not sure if this is an option in my case. In my case I would have to wrap the entire preprocessing pipeline in a keras layer; But that might not be a bad idea after all.. Also it's possible to just pad it manually (see my original post).,0
"I am able to replicate this issue, please have a look at the [gist here](https://colab.research.google.com/gist/Saduf2019/2207fbafc2e0bb6a2d763eb24db01746/untitled364.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/42254#issuecomment-672699649,Saduf2019,2020-08-12 07:45:16,42254,[42269],Data bug,0,"I am able to replicate this issue, please have a look at the [gist here]([url] Thanks!",1
"@stefan-falk 
I made a change to your code and do not see the error, please refer to [this gist](https://colab.research.google.com/gist/Saduf2019/39afa070a5feb386627085bddf1d8f69/untitled364.ipynb) and update.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42254#issuecomment-672702408,Saduf2019,2020-08-12 07:50:13,42254,[42269],Data bug,0,"@stefan-falk I made a change to your code and do not see the error, please refer to [this gist]([url] and update.",0
"Hi @stefan-falk, can you try to modify this line
https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/ops/signal/shape_ops.py#L164
to
```python
           ops.convert_to_tensor([[0, pad_samples]]),
```
to see if it fixes the error?",IssueComment,https://github.com/tensorflow/tensorflow/issues/42254#issuecomment-672704081,WindQAQ,2020-08-12 07:53:13,42254,[42269],Data bug,0,"Hi @stefan-falk, can you try to modify this line [url]#L164 to ``[code]`` to see if it fixes the error?",0
"@WindQAQ I tested it in a debug session an can confirm that it works if we use `ops.convert_to_tensor([[0, pad_samples]])`

![image](https://user-images.githubusercontent.com/43335432/89991286-e6d88f00-dc83-11ea-9def-f5ec527a8a41.png)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42254#issuecomment-672713571,stefan-falk,2020-08-12 08:09:39,42254,[42269],Data bug,0,@WindQAQ I tested it in a debug session an can confirm that it works if we use [code] ![image]([url],3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42254"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42254"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42254#issuecomment-673220486,google-ml-butler[bot],2020-08-13 03:02:52,42254,[42269],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Hello @janjongboom,
Could you have a look at my PR (#41285) ? I think it can solve this issue.

Regards,
Biagio.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41816#issuecomment-666217718,biagiom,2020-07-30 08:17:25,41816,[42314],Algorithm design bug,0,"Hello @janjongboom, Could you have a look at my PR (#41285) ? I think it can solve this issue. Regards, Biagio.",2
It looks like this is related to the linked PR (and should be fixed by it). Thanks for pointing out this issue. Let's verify that once the PR lands this is resolved.,IssueComment,https://github.com/tensorflow/tensorflow/issues/41816#issuecomment-670157595,njeffrie,2020-08-06 19:47:33,41816,[42314],Algorithm design bug,0,It looks like this is related to the linked PR (and should be fixed by it). Thanks for pointing out this issue. Let's verify that once the PR lands this is resolved.,2
@dansitu ^,IssueComment,https://github.com/tensorflow/tensorflow/issues/41816#issuecomment-670402524,janjongboom,2020-08-07 08:36:45,41816,[42314],Algorithm design bug,0,@dansitu ^,0
PR https://github.com/tensorflow/tensorflow/pull/42314 provides a fix for this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/41816#issuecomment-680840415,felix-johnny,2020-08-26 12:11:06,41816,[42314],Algorithm design bug,0,PR [url] provides a fix for this issue.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41816"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41816"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41816#issuecomment-698146305,google-ml-butler[bot],2020-09-24 06:38:25,41816,[42314],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added PR #42334 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42248#issuecomment-673736274,yongtang,2020-08-13 22:13:21,42248,[42334],Data bug,1,Added PR #42334 for the fix.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42248"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42248"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42248#issuecomment-674357733,google-ml-butler[bot],2020-08-15 06:36:12,42248,[42334],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
SWIG no longer used. Closing,IssueComment,https://github.com/tensorflow/tensorflow/issues/41806#issuecomment-922684820,Flamefire,2021-09-20 07:13:38,41806,[42362],Build bug,0,SWIG no longer used. Closing,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41806"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41806"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41806#issuecomment-922684836,google-ml-butler[bot],2021-09-20 07:13:40,41806,[42362],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to reproduce the issue with TF v2.1, TF v2.3 and TF-nightly. 

Session crashes on running the `tf.nest.assert_same_structure` line. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7e2519ef8640e2d849516d0d363ae230/42329.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/42329#issuecomment-674058024,amahendrakar,2020-08-14 12:49:07,42329,[42397],Data bug,0,"Was able to reproduce the issue with TF v2.1, TF v2.3 and TF-nightly. Session crashes on running the [code] line. Please find the gist of it [here]([url] Thanks!",-1
The issue is more or less complicated and is related to pybind's handling of mismatched python type binding. A easy fix might be to enforce the type passed to pybind conforms to bool (for check_types and expand_composites). Created a PR #42397 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42329#issuecomment-674437560,yongtang,2020-08-15 19:17:39,42329,[42397],Data bug,0,The issue is more or less complicated and is related to pybind's handling of mismatched python type binding. A easy fix might be to enforce the type passed to pybind conforms to bool (for check_types and expand_composites). Created a PR #42397 for the fix.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42329"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42329"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42329#issuecomment-676833348,google-ml-butler[bot],2020-08-20 00:50:15,42329,[42397],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Copying some communication over email into this github issue:

Hi Yair,

We don't have an easy way to reproduce your error, so could you try one of these two fixes at your end and send in a PR if either of them work:

 * Add an appropriate check for your compiler version / platform in tensorflow/lite/c/common.h similar to [this commit](https://github.com/tensorflow/tensorflow/commit/481aec85d669dad80f8d8e0c53e03c45f956959d).

 * If that doesn't work, try changing the initialization of the offending line to const TfLiteIntArray kZeroLengthIntArray = {0};
   * This bit of initialization has changed over different commits ([1](https://github.com/tensorflow/tensorflow/commit/076bbc5edfe655299b006b3c1b2c6281d330d638#diff-6dace628e5372fb3c3fbb76e0fd9d37aR51), [2](https://github.com/tensorflow/tensorflow/commit/290487b03ed7a9fa78af6faa2d8c19f7e5fde30e#diff-6dace628e5372fb3c3fbb76e0fd9d37aR56), [3](https://github.com/tensorflow/tensorflow/commit/c29d6434bae6680039ca4c8b9aaf6dd30dae4c62#diff-6dace628e5372fb3c3fbb76e0fd9d37aR53)) so if option 1 does the trick for you, that would likely be more future-proof.

Thanks,
Advait
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42468#issuecomment-675865723,advaitjain,2020-08-19 05:48:18,42468,[42464],Build bug,0,"Copying some communication over email into this github issue: Hi Yair, We don't have an easy way to reproduce your error, so could you try one of these two fixes at your end and send in a PR if either of them work: * Add an appropriate check for your compiler version / platform in tensorflow/lite/c/common.h similar to [this commit]([url] * If that doesn't work, try changing the initialization of the offending line to const TfLiteIntArray kZeroLengthIntArray = {0}; * This bit of initialization has changed over different commits ([1]([url]#diff-6dace628e5372fb3c3fbb76e0fd9d37aR51), [2]([url]#diff-6dace628e5372fb3c3fbb76e0fd9d37aR56), [3]([url]#diff-6dace628e5372fb3c3fbb76e0fd9d37aR53)) so if option 1 does the trick for you, that would likely be more future-proof. Thanks, Advait",0
Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/6b83b64430a0181a042c3280456cb3c9/42522.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/a66eb01a0b9126a8a601a87d6396ff5f/42522-tf-nightly.ipynb). Please find the attached gist. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/42522#issuecomment-678251267,amahendrakar,2020-08-21 11:50:50,42522,[42549],Code bug,1,Was able to reproduce the issue with [TF v2.3]([url] and [TF-nightly]([url] Please find the attached gist. Thanks!,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42522"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42522"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42522#issuecomment-693981989,google-ml-butler[bot],2020-09-17 06:43:45,42522,[42549],Code bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I've narrowed this down to [one line in `overlap_and_add` that does a `StridedSlice`](https://github.com/tensorflow/tensorflow/blob/77245d0/tensorflow/python/ops/signal/reconstruction_ops.py#L148):

```python
    # Truncate so that signal.shape = (15, 2)
    # ab fg kl 00 00 00 cd hi mn 00 00 00 e0 j0 o0
    signal = signal[..., :(frames + segments - 1) * segments, :]
```

This seems to result in a `StridedSlice` op with the following properties:
```
begin = [0, 0]
end = [2050, 0]
strides = [1, 1]
begin_mask = 1 (i.e.: dims[0])
end_mask = 1 (i.e.: dims[0])
```

This is odd, as the slice includes a `:` as its final element, which should indicate that the entire dimension should be used, but the serialized graph includes both the beginning and end of that dimension as `0`. The `begin_mask` and `end_mask` are both set to `1`, indicating that the stride should use the whole of the _first_ dimension (bit 0), according to [the docs](https://www.tensorflow.org/api_docs/python/tf/strided_slice):

> If the ith bit of begin_mask is set, begin[i] is ignored and the fullest possible range in that dimension is used instead. end_mask works analogously, except with the end range.

Given that the regular TensorFlow runtime seems to handle this slice just fine, this leads me to believe that the issue might be in the TFLite converter. Indeed, before TFLite conversion, the `StridedSlice` takes in an additional dimension has the following properties:

```
begin = [0, 0, 0]
end = [0, 2050, 0]
strides = [1, 1, 1]
ellipsis_mask = 1
begin_mask = 6 (i.e.: dims[1] and dims[2])
end_mask = 4 (i.e.: dims[2] alone)
```

It looks like the TensorFlow Lite converter may be incorrectly optimizing the `begin_mask` and `end_mask` here, due to the `ellipsis_mask`. **If I remove the ellipsis entirely, the problem does go away.**

A quick fix for this would be to change `reconstruction_ops.py:148` to specify the exact end of its slice operation, to work around this bug:
```python
signal = signal[..., : (frames + segments - 1) * segments, :array_ops.shape(signal)[-1]]
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/42481#issuecomment-676501585,psobot,2020-08-19 15:37:30,42481,[42579],Deployment bug,0,I've narrowed this down to [one line in [code] that does a [code]]([url]#L148): ``[code]`[code]StridedSlice[code]`[code]`[code]:[code]0[code]begin_mask[code]end_mask[code]1[code]StridedSlice[code]`[code]`[code]begin_mask[code]end_mask[code]ellipsis_mask[code]reconstruction_ops.py:148[code]`[code]``,0
@renjie-liu Can you please have a look,IssueComment,https://github.com/tensorflow/tensorflow/issues/42481#issuecomment-676619685,karimnosseir,2020-08-19 19:34:39,42481,[42579],Deployment bug,0,@renjie-liu Can you please have a look,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42481"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42481"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42481#issuecomment-683916349,google-ml-butler[bot],2020-08-31 17:21:51,42481,[42579],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@drebain 

I have tried in colab with Tensorflow -GPU version 2.3.0 and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/1179cb07cd83075aacbfa1dc7835e8f9/untitled267.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-677218315,ravikyram,2020-08-20 05:56:44,42500,[42615],Processor bug,1,"@drebain I have tried in colab with Tensorflow -GPU version 2.3.0 and i am not seeing any issue.Please, find the gist [here]([url]",3
"The output includes `INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)` which I think indicates that it is only running with a single GPU available. The crash only happens when there are at least two devices present. I don't know if this is possible to test with colab.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-677236501,drebain,2020-08-20 06:03:07,42500,[42615],Processor bug,1,The output includes [code] which I think indicates that it is only running with a single GPU available. The crash only happens when there are at least two devices present. I don't know if this is possible to test with colab.,0
"This might have something to do with the version of CUDA, or the type of GPU being used (see [similar issue](https://github.com/tensorflow/tensorflow/issues/30665). Could you try this with the latest version of TF?

`!pip install tf-nightly-gpu`",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-678636964,dynamicwebpaige,2020-08-22 12:48:51,42500,[42615],Processor bug,1,"This might have something to do with the version of CUDA, or the type of GPU being used (see [similar issue]([url] Could you try this with the latest version of TF? [code]",0
"I have encountered the same ""invalid resource handle"" crash with Tensorflow 2.2.0 and 2.3.0 on machines with RTX 2080 as well as V100 GPUs. I have tried CUDA 10.0, 10.1, and 10.2.

I have just now updated my personal machine to the NVIDIA 450 driver and installed CUDA 11.0 + tf-nightly-gpu:
```
2020-08-22 18:24:52.424497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-08-22 18:24:54.262314: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-22 18:24:54.262349: I tensorflow/compiler/jit/xla_gpu_device.cc:69] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-22 18:24:54.271839: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-22 18:24:54.354837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:09:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.83GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2020-08-22 18:24:54.355405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:42:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.83GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2020-08-22 18:24:54.355431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-08-22 18:24:54.372287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-08-22 18:24:54.383247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-22 18:24:54.387885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-22 18:24:54.405073: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-22 18:24:54.409284: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-08-22 18:24:54.411034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-08-22 18:24:54.415315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-08-22 18:24:54.416756: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-22 18:24:54.420115: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-22 18:24:54.420145: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-08-22 18:24:54.664832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:09:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.83GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2020-08-22 18:24:54.665355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:42:00.0 name: GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.83GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s
2020-08-22 18:24:54.665387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-08-22 18:24:54.665407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-08-22 18:24:54.665418: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-22 18:24:54.665428: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-22 18:24:54.665437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-22 18:24:54.665446: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-08-22 18:24:54.665459: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-08-22 18:24:54.667603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-08-22 18:24:54.668415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-08-22 18:24:56.003639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-22 18:24:56.003708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
2020-08-22 18:24:56.003716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
2020-08-22 18:24:56.003720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
2020-08-22 18:24:56.008774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7253 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:09:00.0, compute capability: 7.5)
2020-08-22 18:24:56.012643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 5707 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080, pci bus id: 0000:42:00.0, compute capability: 7.5)
WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.
2020-08-22 18:24:56.171346: F tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc:108] Non-OK-status: GpuLaunchKernel(GatherOpKernel<T, int32, true>, config.block_count, config.thread_per_block, 0, d.stream(), params, indices, out, gather_dim_size, indices_size, slice_size, out_size) status: Internal: invalid resource handle
Aborted (core dumped)
```
This is the output of the reproduction script above running with `tf.__version__ == '2.4.0-dev20200822'`",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-678717815,drebain,2020-08-23 01:39:43,42500,[42615],Processor bug,1,"I have encountered the same ""invalid resource handle"" crash with Tensorflow 2.2.0 and 2.3.0 on machines with RTX 2080 as well as V100 GPUs. I have tried CUDA 10.0, 10.1, and 10.2. I have just now updated my personal machine to the NVIDIA 450 driver and installed CUDA 11.0 + tf-nightly-gpu: ``[code]call_for_each_replica[code]experimental_run[code]run[code]`[code]tf.__version__ == '2.4.0-dev20200822'`",0
"I think I have found the cause of the issue. The GPU implementation of the dynamic_partition op ends by registering a callback which runs after `ComputeAsync()` returns, but apparently does not ensure that the correct CUDA device is active when the callback executes. As long as the only GPU being used is the default ""GPU:0"" this works, but it can fail when attempting to run on a different device. In fact, I have been able to reproduce the crash with an even simpler script that does not require `MirroredStrategy`:

    import tensorflow as tf
    N = 100
    M = 4
    with tf.device(""GPU:1""):
      data = tf.random.uniform((N,))
      partitions = tf.random.uniform((N,), maxval=M, dtype=tf.int32)
      tf.dynamic_partition(data, partitions, M)

I have made a [simple patch](https://github.com/drebain/tensorflow/commit/113555fab7c1a607991b41cdf3974f5f8e0873ea) for the dynamic_stitch op that makes the above script (as well as the one in the original issue) work by copying some of the code from before `ComputeAsync()` is called, which I think sets up the CUDA device. I doubt this is a robust or correct solution, but hopefully it saves someone some time debugging.

As I mentioned before, I have consistently been able to reproduce this under a variety of conditions, but it's possible that the error is non-deterministic if the scheduling of the callback has an effect.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-678748141,drebain,2020-08-23 08:55:17,42500,[42615],Processor bug,1,"I think I have found the cause of the issue. The GPU implementation of the dynamic_partition op ends by registering a callback which runs after [code] returns, but apparently does not ensure that the correct CUDA device is active when the callback executes. As long as the only GPU being used is the default ""GPU:0"" this works, but it can fail when attempting to run on a different device. In fact, I have been able to reproduce the crash with an even simpler script that does not require [code]: import tensorflow as tf N = 100 M = 4 with tf.device(""GPU:1""): data = tf.random.uniform((N,)) partitions = tf.random.uniform((N,), maxval=M, dtype=tf.int32) tf.dynamic_partition(data, partitions, M) I have made a [simple patch]([url] for the dynamic_stitch op that makes the above script (as well as the one in the original issue) work by copying some of the code from before [code] is called, which I think sets up the CUDA device. I doubt this is a robust or correct solution, but hopefully it saves someone some time debugging. As I mentioned before, I have consistently been able to reproduce this under a variety of conditions, but it's possible that the error is non-deterministic if the scheduling of the callback has an effect.",1
"Thanks @drebain for digging into the root cause! We have been able to repro the issue as well on different GPUs, and do not believe it is specific to GPU or TF version. Assigning to @sanjoy to take a look further. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-678884848,guptapriya,2020-08-24 03:29:59,42500,[42615],Processor bug,1,"Thanks @drebain for digging into the root cause! We have been able to repro the issue as well on different GPUs, and do not believe it is specific to GPU or TF version. Assigning to @sanjoy to take a look further.",2
"Hi @drebain,

Your fix looks correct to me; would you be willing to create a PR fixing the bug and adding the test?  You can use [`collective_nccl_test`](https://github.com/tensorflow/tensorflow/blob/09f5609f0fd282943defd4608ee90bb6883a394b/tensorflow/core/kernels/BUILD#L240-L261) as an example on how to add a multi-GPU test to TensorFlow.

You'll need to switch between ROCm and CUDA though, like we do [here](https://github.com/tensorflow/tensorflow/blob/09f5609f0fd282943defd4608ee90bb6883a394b/tensorflow/core/kernels/segment_reduction_ops_impl.h#L47-L56).",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-678901729,sanjoy,2020-08-24 04:51:18,42500,[42615],Processor bug,1,"Hi @drebain, Your fix looks correct to me; would you be willing to create a PR fixing the bug and adding the test? You can use [[code]]([url]#L240-L261) as an example on how to add a multi-GPU test to TensorFlow. You'll need to switch between ROCm and CUDA though, like we do [here]([url]#L47-L56).",3
"@sanjoy Yes, I will add a test that makes sure the op can run when launched on any GPU + the ROCm switch and open a PR.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-678915974,drebain,2020-08-24 05:44:02,42500,[42615],Processor bug,1,"@sanjoy Yes, I will add a test that makes sure the op can run when launched on any GPU + the ROCm switch and open a PR.",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42500"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42500"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42500#issuecomment-683101147,google-ml-butler[bot],2020-08-28 19:25:25,42500,[42615],Processor bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Looks like `.device` returns the [device of the operation](https://github.com/tensorflow/tensorflow/blob/0d7e40f0dba759a54a8ee4e4c2a96e05937e14c2/tensorflow/python/framework/ops.py#L420) which is not correct for operations with `HostMemory` outputs, like [int32 identity](https://github.com/tensorflow/tensorflow/blob/0d7e40f0dba759a54a8ee4e4c2a96e05937e14c2/tensorflow/core/kernels/identity_op.cc#L162).

We can probably add a method that returns the true devices for a given `TFE_TensorHandle` (`Tensor`s know how to deallocate themselves so this information is in principle already present), but this is a high impact API change and we need to think this through.

Also, @VoVAllen , what should be the behavior of `to_dlpack` if it is passed a non-GPU tensor?",IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-657110282,sanjoy,2020-07-11 18:45:22,41307,[42646],Processor bug,1,"Looks like [code] returns the [device of the operation]([url]#L420) which is not correct for operations with [code] outputs, like [int32 identity]([url]#L162). We can probably add a method that returns the true devices for a given [code] ([code]s know how to deallocate themselves so this information is in principle already present), but this is a high impact API change and we need to think this through. Also, @VoVAllen , what should be the behavior of [code] if it is passed a non-GPU tensor?",-1
CC @jaingaurav ,IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-657110313,sanjoy,2020-07-11 18:45:34,41307,[42646],Processor bug,1,CC @jaingaurav,0
"For DLPack, there's a ctx field indicating which device this pointer belongs to. 

Two things I think needed:
- Be able to get the real device of the pointer
  - I believe there should be such API in tensorflow now, because operator needs to know the pointer's location for further computation.
- Be able to explicitly copy int32 tensor to gpu
  - Currently our workaround is `cast it to uint32 -> copy to gpu ->cast it back to int32`

I understand why int32 tensor are on cpu if using tf.constant, but why it needs exception in `tf.identity` also that still not copying it to gpu?",IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-657385914,VoVAllen,2020-07-13 06:32:14,41307,[42646],Processor bug,1,"For DLPack, there's a ctx field indicating which device this pointer belongs to. Two things I think needed: - Be able to get the real device of the pointer - I believe there should be such API in tensorflow now, because operator needs to know the pointer's location for further computation. - Be able to explicitly copy int32 tensor to gpu - Currently our workaround is [code] I understand why int32 tensor are on cpu if using tf.constant, but why it needs exception in [code] also that still not copying it to gpu?",0
"> * I believe there should be such API in tensorflow now, because operator needs to know the pointer's location for further computation.

I agree, I have filed a Google-internal bug about this.

> but why it needs exception in `tf.identity` also that still not copying it to gpu?

The `int32` `Identity` kernel [explicitly places](https://github.com/tensorflow/tensorflow/blob/ac3456f3ad9ab8af38d933f823aa665358f7c4fe/tensorflow/core/kernels/identity_op.cc#L134) its input and output on the host, via a `HostMemory` annotation.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-657970001,sanjoy,2020-07-14 05:10:18,41307,[42646],Processor bug,1,"> * I believe there should be such API in tensorflow now, because operator needs to know the pointer's location for further computation. I agree, I have filed a Google-internal bug about this. > but why it needs exception in [code] also that still not copying it to gpu? The [code] [code] kernel [explicitly places]([url]#L134) its input and output on the host, via a [code] annotation.",0
Any updates on this issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-663812399,VoVAllen,2020-07-25 05:26:44,41307,[42646],Processor bug,1,Any updates on this issue?,0
"Internally we decided that this is a documentation bug.  The physical device of a `Tensor` can be accessed via the `backing_device` property, not the `device` property.",IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-663813800,sanjoy,2020-07-25 05:45:42,41307,[42646],Processor bug,1,"Internally we decided that this is a documentation bug. The physical device of a [code] can be accessed via the [code] property, not the [code] property.",0
"Is there any API to get the `backing_device` I can use to fix the bug in dlpack for now? Currently I use https://github.com/tensorflow/tensorflow/blob/3ace29966b79711b848a76135248c743b2fdeace/tensorflow/c/eager/dlpack.cc#L112, which seems the op device instead of backing_devicce",IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-663832929,VoVAllen,2020-07-25 09:16:45,41307,[42646],Processor bug,1,"Is there any API to get the [code] I can use to fix the bug in dlpack for now? Currently I use [url]#L112, which seems the op device instead of backing_devicce",-1
Just call BackingDeviceName instead of DeviceName,IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-664476392,alextp,2020-07-27 15:47:41,41307,[42646],Processor bug,1,Just call BackingDeviceName instead of DeviceName,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41307"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41307"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/41307#issuecomment-685856707,google-ml-butler[bot],2020-09-02 16:38:20,41307,[42646],Processor bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I wondered this myself. Since `random_adjust_brightness` provides a value in the interval `[-max_delta, max_delta)` it seems that negative values should be accepted.

I wondered whether this could be an issue with underflow for unsigned integer representations? The calculation is done as a float, but scaling and casting negative results (e.g. -0.1) to uint could give some weird behaviour. You can't just set a hard limit of 0 either, because some projects scale pixel values between -1 and 1. (https://www.tensorflow.org/api_docs/python/tf/keras/applications/xception/preprocess_input)

Edit: never mind, I've just seen that the return command for `adjust_brightness` takes care of overflow/underflow with the saturate argument:
`return convert_image_dtype(adjusted, orig_dtype, saturate=True)`",IssueComment,https://github.com/tensorflow/tensorflow/issues/42704#issuecomment-685239507,chrisrapson,2020-09-02 02:06:14,42704,[42705],Documentation bug,0,"I wondered this myself. Since [code] provides a value in the interval [code] it seems that negative values should be accepted. I wondered whether this could be an issue with underflow for unsigned integer representations? The calculation is done as a float, but scaling and casting negative results (e.g. -0.1) to uint could give some weird behaviour. You can't just set a hard limit of 0 either, because some projects scale pixel values between -1 and 1. ([url] Edit: never mind, I've just seen that the return command for [code] takes care of overflow/underflow with the saturate argument: [code]",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42704"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42704"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42704#issuecomment-689293343,google-ml-butler[bot],2020-09-09 04:28:11,42704,[42705],Documentation bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@ongun-kanat,
I tried to reproduce the error, but I am facing an error stating `NameError: name '__file__' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/fc4c5821238be70114a666c8c4ead564/38041-2-1.ipynb).

In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/38041#issuecomment-606440287,amahendrakar,2020-03-31 07:03:08,38041,[42718],Deployment bug,0,"@ongun-kanat, I tried to reproduce the error, but I am facing an error stating [code]. Please find the gist of it [here]([url] In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!",0
"It is the complete script file that I am trying to run. Just a PoC code.

The script is not designed to be run in a notebook. `__file__` is obviously undefined since you're not running it in a script called by python executable. 

I don't know if users have write permission for files in collab notebooks but you can try it with a hardcoded file name.

```python3
import tensorflow as tf
import tensorflow_core as tfcore

graph = tf.Graph()

with graph.as_default():
    A = tf.raw_ops.Placeholder(dtype=tf.dtypes.float32, shape=None, name=""A"")
    B = tf.raw_ops.Placeholder(dtype=tf.dtypes.float32, shape=None, name=""B"")
    Result = tf.raw_ops.Add(x=A, y=B, name=""Result"")


with tfcore.python.Session(graph=graph) as sess:
    builder = tfcore.python.saved_model.builder.SavedModelBuilder(""saved_model"")
    save_signature = tfcore.python.saved_model.signature_def_utils.predict_signature_def(
        inputs={""A"": A, ""B"": B},
        outputs={""Result"": Result})
    builder.add_meta_graph_and_variables(sess=sess,
                                         signature_def_map={""predict"": save_signature},
                                         tags=[""test_tag""],
                                         main_op=Result)
    builder.save(as_text=True) 
```

Otherwise run it in a proper computer, container or VM.",IssueComment,https://github.com/tensorflow/tensorflow/issues/38041#issuecomment-606530016,ongun-kanat,2020-03-31 10:12:02,38041,[42718],Deployment bug,0,"It is the complete script file that I am trying to run. Just a PoC code. The script is not designed to be run in a notebook. [code] is obviously undefined since you're not running it in a script called by python executable. I don't know if users have write permission for files in collab notebooks but you can try it with a hardcoded file name. ``[code]`` Otherwise run it in a proper computer, container or VM.",0
Was able to reproduce the issue. Please find the Gist [here](https://colab.research.google.com/gist/amahendrakar/e391040cc4d3fe2064732d0741f18d55/38041-2-1.ipynb). Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/38041#issuecomment-607388754,amahendrakar,2020-04-01 17:33:33,38041,[42718],Deployment bug,0,Was able to reproduce the issue. Please find the Gist [here]([url] Thanks!,1
The suggested fix should work -- can you submit a PR (with a test)? Thank you!,IssueComment,https://github.com/tensorflow/tensorflow/issues/38041#issuecomment-612321656,k-w-w,2020-04-11 04:19:18,38041,[42718],Deployment bug,0,The suggested fix should work -- can you submit a PR (with a test)? Thank you!,3
"@ongun-kanat 
Can you please update on the above comment.
Is this still an issue?",IssueComment,https://github.com/tensorflow/tensorflow/issues/38041#issuecomment-682022462,Saduf2019,2020-08-27 15:30:07,38041,[42718],Deployment bug,0,@ongun-kanat Can you please update on the above comment. Is this still an issue?,0
"@Saduf2019 I submitted a PR for the issue. Sorry, I had forgotten it.",IssueComment,https://github.com/tensorflow/tensorflow/issues/38041#issuecomment-682290552,ongun-kanat,2020-08-28 02:32:56,38041,[42718],Deployment bug,0,"@Saduf2019 I submitted a PR for the issue. Sorry, I had forgotten it.",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38041"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38041"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/38041#issuecomment-684126195,google-ml-butler[bot],2020-09-01 00:53:26,38041,[42718],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thanks, created a PR based on your patch.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42832#issuecomment-686112095,advaitjain,2020-09-02 23:41:48,42832,[42908],Test bug,1,"Thanks, created a PR based on your patch.",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42832"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42832"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42832#issuecomment-686644195,google-ml-butler[bot],2020-09-03 17:36:11,42832,[42908],Test bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/9d4cbcc58a6b57b56c107d0ea30419ca/42909-tf-nightly.ipynb). Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/42909#issuecomment-686486515,amahendrakar,2020-09-03 13:21:38,42909,[42935],Code bug,0,Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here]([url] Thanks!,1
"Note sure if this is the best approach, but modifying [/tensorflow/tensorflow/python/ops/math_grad.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_grad.py) as follows could fix it.

1. Adding the following import statements:
    ```
    from tensorflow.python.ops import sparse_ops
    from tensorflow.python.ops import sets_impl
    ```
2. In the definition of `_ProdGrad(op, grad)`, replacing
    ```
      other, _ = array_ops.setdiff1d(idx, reduced)
    ```
    with
    ```
      other = sparse_ops.sparse_tensor_to_dense(sets_impl.set_difference([idx], [reduced]))[0]
    ```",IssueComment,https://github.com/tensorflow/tensorflow/issues/42909#issuecomment-686679392,prasanthcakewalk,2020-09-03 18:35:33,42909,[42935],Code bug,0,"Note sure if this is the best approach, but modifying [/tensorflow/tensorflow/python/ops/math_grad.py]([url] as follows could fix it. 1. Adding the following import statements: ``[code]`[code]_ProdGrad(op, grad)[code]`[code]`[code]`[code]``",0
The issue could be fixed by using the internal non-deprecated version of `gen_array_ops.list_diff` (instead of the deprecated `setdiff1d` API endpoint). Created a PR #42935 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42909#issuecomment-686710157,yongtang,2020-09-03 19:28:08,42909,[42935],Code bug,0,The issue could be fixed by using the internal non-deprecated version of [code] (instead of the deprecated [code] API endpoint). Created a PR #42935 for the fix.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42909"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42909"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42909#issuecomment-687424972,google-ml-butler[bot],2020-09-04 22:16:49,42909,[42935],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Making the optimization levels configurable from the command line sounds good to me.

We are not particular about the optimization level for the debug build so if it works for you I would suggest making it common for all builds to reduce the number of options and make it easier to switch between debug and non-debug builds with the same optimization level.

Something like
```
OPTIMIZATION_LEVEL := -O3
CXXFLAGS := -std=c++11 -Wstrict-aliasing -DTF_LITE_STATIC_MEMORY $(CC_WARNINGS) $(OPTIMIZATION_LEVEL)
CCFLAGS := -DTF_LITE_STATIC_MEMORY $(CC_WARNINGS) $(OPTIMIZATION_LEVEL)
```

A pull request for this would be welcome.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42924#issuecomment-686627407,advaitjain,2020-09-03 17:02:58,42924,[42962],Build bug,0,Making the optimization levels configurable from the command line sounds good to me. We are not particular about the optimization level for the debug build so if it works for you I would suggest making it common for all builds to reduce the number of options and make it easier to switch between debug and non-debug builds with the same optimization level. Something like ``[code]`` A pull request for this would be welcome.,4
"A common optimization level works for us, I'll submit a pull request right away.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42924#issuecomment-686983325,jenselofsson,2020-09-04 07:55:33,42924,[42962],Build bug,0,"A common optimization level works for us, I'll submit a pull request right away.",4
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42924"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42924"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42924#issuecomment-689181414,google-ml-butler[bot],2020-09-08 23:04:37,42924,[42962],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@advaitjain Could you take a look at this issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-688640170,thaink,2020-09-08 06:10:01,42964,[43109],Data bug,0,@advaitjain Could you take a look at this issue?,0
"@keithm-xmos I think you are using a bad TARGET=""x86"". Can you try and remove that?

`make -f tensorflow/lite/micro/tools/make/Makefile test_micro_interpreter_test`

That passes for me on Darwin x86_64.

",IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-689636566,nkreeger,2020-09-09 15:25:48,42964,[43109],Data bug,0,"@keithm-xmos I think you are using a bad TARGET=""x86"". Can you try and remove that? [code] That passes for me on Darwin x86_64.",0
@nkreeger Did you make the modification to micro_interpreter_test.cc before rebuilding and running your suggestion?  It fails on x86 and xcore for me.  I think you will find that it will fail on any platform.  ,IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-689641213,keithm-xmos,2020-09-09 15:33:21,42964,[43109],Data bug,0,@nkreeger Did you make the modification to micro_interpreter_test.cc before rebuilding and running your suggestion? It fails on x86 and xcore for me. I think you will find that it will fail on any platform.,-2
"@keithm-xmos ah sorry i missed that - our macro is a little confusing and the test code isn't the cleanest at the moment.

Try this:
TF_LITE_MICRO_EXPECT_GT(interpreter.tensors_size(), static_cast<size_t>(0));

That works for me - the macro is checking that |0 > tensors_size| which is always false.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-689648631,nkreeger,2020-09-09 15:45:29,42964,[43109],Data bug,0,"@keithm-xmos ah sorry i missed that - our macro is a little confusing and the test code isn't the cleanest at the moment. Try this: TF_LITE_MICRO_EXPECT_GT(interpreter.tensors_size(), static_cast<size_t>(0)); That works for me - the macro is checking that |0 > tensors_size| which is always false.",-1
"@nkreeger I applied your suggestion and I get the following: 

```
Testing TestInterpreter
interpreter.tensors_size() > static_cast<size_t>(0) failed at tensorflow/lite/micro/micro_interpreter_test.cc:87
Output tensors not at index 0 are allocated from the persistent memory arena. Repeat calls will cause excess allocation!
Testing TestMultiTenantInterpreter
Testing TestKernelMemoryPlanning
Output tensors not at index 0 are allocated from the persistent memory arena. Repeat calls will cause excess allocation!
Output tensors not at index 0 are allocated from the persistent memory arena. Repeat calls will cause excess allocation!
Output tensors not at index 0 are allocated from the persistent memory arena. Repeat calls will cause excess allocation!
Output tensors not at index 0 are allocated from the persistent memory arena. Repeat calls will cause excess allocation!
Output tensors not at index 0 are allocated from the persistent memory arena. Repeat calls will cause excess allocation!
Output tensors not at index 0 are allocated from the persistent memory arena. Repeat calls will cause excess allocation!
Testing TestVariableTensorReset
Testing TestIncompleteInitialization
Testing InterpreterWithProfilerShouldProfileOps
Testing TestIncompleteInitializationAllocationsWithSmallArena
Failed to allocate tail memory. Requested: 240, available 208, missing: 32
Failed to allocate memory for context->eval_tensors, 240 bytes required
Failed starting model allocation.

Testing TestInterpreterDoesNotAllocateUntilInvoke
[RecordingMicroAllocator] Arena allocation total 768 bytes
[RecordingMicroAllocator] Arena allocation head 32 bytes
[RecordingMicroAllocator] Arena allocation tail 736 bytes
[RecordingMicroAllocator] 'TfLiteEvalTensor data' used 240 bytes with alignment overhead (requested 240 bytes for 10 allocations)
[RecordingMicroAllocator] 'Persistent TfLiteTensor data' used 0 bytes with alignment overhead (requested 0 bytes for 0 tensors)
[RecordingMicroAllocator] 'Persistent TfLiteTensor quantization data' used 0 bytes with alignment overhead (requested 0 bytes for 0 allocations)
[RecordingMicroAllocator] 'TfLiteTensor variable buffer data' used 40 bytes with alignment overhead (requested 12 bytes for 3 allocations)
[RecordingMicroAllocator] 'NodeAndRegistration struct' used 168 bytes with alignment overhead (requested 168 bytes for 3 NodeAndRegistration structs)
[RecordingMicroAllocator] 'Operator runtime data' used 0 bytes with alignment overhead (requested 0 bytes for 0 OpData structs)
7/8 tests passed
~~~SOME TESTS FAILED~~~

Interpreter has 0 tensors and 2 nodes
Inputs: 0
Outputs: 2 3


Node   0 Operator Custom Name mock_custom
  Inputs: 0 1
  Outputs: 2
Node   1 Operator Custom Name mock_custom
  Inputs: 0 1
  Outputs: 3
make: *** [tensorflow/lite/micro/tools/make/Makefile:368: test_micro_interpreter_test] Error 1
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-689689559,keithm-xmos,2020-09-09 16:54:53,42964,[43109],Data bug,0,@nkreeger I applied your suggestion and I get the following: ``[code]``,0
"I ran with

> make -f tensorflow/lite/micro/tools/make/Makefile test_micro_interpreter_test

Here's my diff

```
diff --git a/tensorflow/lite/micro/micro_interpreter_test.cc b/tensorflow/lite/micro/micro_interpreter_test.cc
index a4a4143a2a..c5a13af8da 100644
--- a/tensorflow/lite/micro/micro_interpreter_test.cc
+++ b/tensorflow/lite/micro/micro_interpreter_test.cc
@@ -84,6 +84,7 @@ TF_LITE_MICRO_TEST(TestInterpreter) {
     TF_LITE_MICRO_EXPECT_LE(interpreter.arena_used_bytes(), 928 + 100);
     TF_LITE_MICRO_EXPECT_EQ(static_cast<size_t>(1), interpreter.inputs_size());
     TF_LITE_MICRO_EXPECT_EQ(static_cast<size_t>(2), interpreter.outputs_size());
+    TF_LITE_MICRO_EXPECT_GT(interpreter.tensors_size(), static_cast<size_t>(0));
 
     TfLiteTensor* input = interpreter.input(0);
     TF_LITE_MICRO_EXPECT_NE(nullptr, input);

```",IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-689690081,keithm-xmos,2020-09-09 16:55:48,42964,[43109],Data bug,0,I ran with > make -f tensorflow/lite/micro/tools/make/Makefile test_micro_interpreter_test Here's my diff ``[code]``,0
"@keithm-xmos sorry I had a bad vim buffer - yes this was accidentally regressed. I just opened https://github.com/tensorflow/tensorflow/pull/43109 to fix this -

Hopefully this isn't breaking you on anything right now - this API is mostly around for unit tests and inspecting of a model. I'd advise against looping through the graph on that API. Those values are now allocated from the ""persistent"" memory area of the arena. I have some documentation coming on those changes.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-690281291,nkreeger,2020-09-10 13:17:24,42964,[43109],Data bug,0,"@keithm-xmos sorry I had a bad vim buffer - yes this was accidentally regressed. I just opened [url] to fix this - Hopefully this isn't breaking you on anything right now - this API is mostly around for unit tests and inspecting of a model. I'd advise against looping through the graph on that API. Those values are now allocated from the ""persistent"" memory area of the arena. I have some documentation coming on those changes.",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42964"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42964"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-690715860,google-ml-butler[bot],2020-09-10 20:42:50,42964,[43109],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Should be fixed with this change: https://github.com/tensorflow/tensorflow/commit/ba071d416fc3d00b79021658c8d666b40b3fcb77,IssueComment,https://github.com/tensorflow/tensorflow/issues/42964#issuecomment-706170750,nkreeger,2020-10-09 13:08:34,42964,[43109],Data bug,0,Should be fixed with this change: [url],0
We'll have a look at this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42951#issuecomment-690021348,freddan80,2020-09-10 06:35:04,42951,[43484],Processor bug,0,We'll have a look at this issue.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42951"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42951"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42951#issuecomment-698543699,google-ml-butler[bot],2020-09-24 19:30:23,42951,[43484],Processor bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Awesome find Jan. If this is fixed then CMSIS-NN will work for images finally.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-683127762,kwagyeman,2020-08-28 20:14:24,42748,[43486],Algorithm design bug,0,Awesome find Jan. If this is fixed then CMSIS-NN will work for images finally.,4
"@kwagyeman Seems like it. I've written a patch and now have CMSIS-NN working with MobileNetV2, will open up a PR after the weekend.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-683146635,janjongboom,2020-08-28 21:06:43,42748,[43486],Algorithm design bug,0,"@kwagyeman Seems like it. I've written a patch and now have CMSIS-NN working with MobileNetV2, will open up a PR after the weekend.",4
@janjongboom Are there any other parts in the code where they allocate static buffers like this? It's kinda down right absurd in production code by ARM employees...,IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-683151273,kwagyeman,2020-08-28 21:19:14,42748,[43486],Algorithm design bug,0,@janjongboom Are there any other parts in the code where they allocate static buffers like this? It's kinda down right absurd in production code by ARM employees...,-3
Conv.cc and depthwiseconv.cc both have the issue. You need to fix both.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-683152387,kwagyeman,2020-08-28 21:22:09,42748,[43486],Algorithm design bug,0,Conv.cc and depthwiseconv.cc both have the issue. You need to fix both.,-2
"Hello @kwagyeman @janjongboom! 

I represent Arm. Some background; kMaxChannels is there for historical reasons - that's how the reference kernels used to be implemented as well. Some months back, the AllocatePersistentBuffer API was introduced in favor of the static buffers. Hence the ref kernels was updated to use that API. Our intention is to 'up-merge' changes, such as this one, to our CMSIS-NN kernels on a regular basis. However, we had to revert that change since we discovered an issue with the AllocatePersistentBuffer API, see https://github.com/tensorflow/tensorflow/pull/41121 for details. We're worked with the TFLu team to resolve this issue and it looks like this was fixed this(!) friday by https://github.com/tensorflow/tensorflow/commit/59d177d9acabe8e70bc33e554a364d2620bc6999#diff-7aab15c6eb5282359c2b928998bab743.

In the meanwhile, the quick fix is to bump kMaxChannels to the size it needs to be on your local fork.

I hope this gives some clarity to the issue.

@janjongboom thanks for the PR (https://github.com/tensorflow/tensorflow/pull/42770)! Let continue the technical discussion there.

Cheers!
Fredrik",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-683629183,freddan80,2020-08-31 08:01:10,42748,[43486],Algorithm design bug,0,"Hello @kwagyeman @janjongboom! I represent Arm. Some background; kMaxChannels is there for historical reasons - that's how the reference kernels used to be implemented as well. Some months back, the AllocatePersistentBuffer API was introduced in favor of the static buffers. Hence the ref kernels was updated to use that API. Our intention is to 'up-merge' changes, such as this one, to our CMSIS-NN kernels on a regular basis. However, we had to revert that change since we discovered an issue with the AllocatePersistentBuffer API, see [url] for details. We're worked with the TFLu team to resolve this issue and it looks like this was fixed this(!) friday by [url]#diff-7aab15c6eb5282359c2b928998bab743. In the meanwhile, the quick fix is to bump kMaxChannels to the size it needs to be on your local fork. I hope this gives some clarity to the issue. @janjongboom thanks for the PR ([url] Let continue the technical discussion there. Cheers! Fredrik",2
"@freddan80 Thanks for the update. I ran into the same issue on our 2.3.0 fork, and replaced the scratch buffer with a persistent one to get around that.

> In the meanwhile, the quick fix is to bump kMaxChannels to the size it needs to be on your local fork.

This adds 10K of RAM *per* convolutional layer, which won't fit on our targets.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-683652486,janjongboom,2020-08-31 08:48:59,42748,[43486],Algorithm design bug,0,"@freddan80 Thanks for the update. I ran into the same issue on our 2.3.0 fork, and replaced the scratch buffer with a persistent one to get around that. > In the meanwhile, the quick fix is to bump kMaxChannels to the size it needs to be on your local fork. This adds 10K of RAM *per* convolutional layer, which won't fit on our targets.",0
"@janjongboom thanks for the updated PR!

> This adds 10K of RAM per convolutional layer, which won't fit on our targets.

Make sense. Then your PR is the preferred solution.

However, allocating the memory using `AllocatePersistentBuffer` API will only move the memory claim from the BSS to the memory arena (which may well be located in BSS as well). It actually won't save memory, it's just putting it in a different part of the SRAM.

Cheers!


",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-683680736,freddan80,2020-08-31 09:49:53,42748,[43486],Algorithm design bug,0,"@janjongboom thanks for the updated PR! > This adds 10K of RAM per convolutional layer, which won't fit on our targets. Make sense. Then your PR is the preferred solution. However, allocating the memory using [code] API will only move the memory claim from the BSS to the memory arena (which may well be located in BSS as well). It actually won't save memory, it's just putting it in a different part of the SRAM. Cheers!",2
"The tensor arena is dynamically allocated and freed so memory can be used for other things until when itâ€™s needed for TF lite. Having it be dynamically allocated is a must.

I donâ€™t wish to be mean here, but, I have been consistently disappointed with ARMs lack of effort in support for these faster kernels... I would like to ask that future code released has more effort put into making it useful for a wider audience. Hard coded static buffers in code with max sizes without range checks is not production code.

Anyway, glad to see this getting fixed so we can enable it on the OpenMV Cam finally.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-683864888,kwagyeman,2020-08-31 15:50:46,42748,[43486],Algorithm design bug,0,"The tensor arena is dynamically allocated and freed so memory can be used for other things until when itâ€™s needed for TF lite. Having it be dynamically allocated is a must. I donâ€™t wish to be mean here, but, I have been consistently disappointed with ARMs lack of effort in support for these faster kernels... I would like to ask that future code released has more effort put into making it useful for a wider audience. Hard coded static buffers in code with max sizes without range checks is not production code. Anyway, glad to see this getting fixed so we can enable it on the OpenMV Cam finally.",-1
"@kwagyeman I believe there is some misunderstanding here. The TFLu feature to handle interleaved persistent memory request and arena scratch buffer requests, is only possible since the 28th of Aug 2020 (see 59d177d9acabe). We've been working with Google towards getting this TFLu feature so that it improves the usage of CMSIS-NN for wider audience like you.

Sorry that you feel that it wasn't given attention. Hope PR #42770 helps the case now and please reach out by a Github ticket, such as this one, for unsupported features or bugs, either in the TFLu or the CMSIS-NN repo. That way the issue is seen and known by a wider audience and thereby gain traction and leverage support from the entire community.

Cheers!",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-684470962,freddan80,2020-09-01 06:45:24,42748,[43486],Algorithm design bug,0,"@kwagyeman I believe there is some misunderstanding here. The TFLu feature to handle interleaved persistent memory request and arena scratch buffer requests, is only possible since the 28th of Aug 2020 (see 59d177d9acabe). We've been working with Google towards getting this TFLu feature so that it improves the usage of CMSIS-NN for wider audience like you. Sorry that you feel that it wasn't given attention. Hope PR #42770 helps the case now and please reach out by a Github ticket, such as this one, for unsupported features or bugs, either in the TFLu or the CMSIS-NN repo. That way the issue is seen and known by a wider audience and thereby gain traction and leverage support from the entire community. Cheers!",2
"> However, allocating the memory using AllocatePersistentBuffer API will only move the memory claim from the BSS to the memory arena (which may well be located in BSS as well). It actually won't save memory, it's just putting it in a different part of the SRAM.

Yep, but I only have one very large convolutional layer and a lot of smaller ones, so dynamically allocating it saves me a lot of memory. But great to see PRs being landed to mainline these types of issues. 

@freddan80 Q though (we can take this offline if you prefer): are there currently CI/CD pipelines set up for the CMSIS-NN kernels? E.g. we found this issue & https://github.com/tensorflow/tensorflow/issues/41816 through our own CI (and a bunch of debugging :-)), and we have currently automated tests for a wide variety of development boards that we run on real hardware for releases, both with the micro allocator and custom allocators, and with and without CMSIS-NN. But we don't follow mainline TensorFlow so we only find these issues once we upgrade. Perhaps it would be beneficial to share that with Arm?",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-684512954,janjongboom,2020-09-01 07:27:08,42748,[43486],Algorithm design bug,0,"> However, allocating the memory using AllocatePersistentBuffer API will only move the memory claim from the BSS to the memory arena (which may well be located in BSS as well). It actually won't save memory, it's just putting it in a different part of the SRAM. Yep, but I only have one very large convolutional layer and a lot of smaller ones, so dynamically allocating it saves me a lot of memory. But great to see PRs being landed to mainline these types of issues. @freddan80 Q though (we can take this offline if you prefer): are there currently CI/CD pipelines set up for the CMSIS-NN kernels? E.g. we found this issue & [url] through our own CI (and a bunch of debugging :-)), and we have currently automated tests for a wide variety of development boards that we run on real hardware for releases, both with the micro allocator and custom allocators, and with and without CMSIS-NN. But we don't follow mainline TensorFlow so we only find these issues once we upgrade. Perhaps it would be beneficial to share that with Arm?",2
"> @freddan80 Q though (we can take this offline if you prefer): are there currently CI/CD pipelines set up for the CMSIS-NN kernels? E.g. we found this issue & #41816 through our own CI (and a bunch of debugging :-)), and we have currently automated tests for a wide variety of development boards that we run on real hardware for releases, both with the micro allocator and custom allocators, and with and without CMSIS-NN. But we don't follow mainline TensorFlow so we only find these issues once we upgrade. Perhaps it would be beneficial to share that with Arm?

We have our internal CI, that tests TFLu-CMSIS-NN usecases on FPGAs and HW models with Cortex-M4 up to Cortex-M55 reference systems. We usually find issues related to CMSIS-NN quite soon. Unfortunately the networks we use did not have a reshape before FC as you encountered in #41816, or it would have been caught. Usually we create a kernel unit test case - in `fully_connected_test.cc` in this case - when we find issues such as the one in #41816, and then contribute that to avoid the same issue in the future. For the issue reported in this ticket, weâ€™ve been waiting for 59d177d to make a permanent fix (thanks again for you PR!). We had actually bumped `kMaxChannels` to 2048 in our internal tests (not being aware of the missing range check), but didnâ€™t want to deliver that since it increases the memory footprint unnecessarily for smaller network usecases.

Thatâ€™s some words about our internal CI. In parallel, we're working with the TFLu team to enable CMSIS-NN regression directly in the Tensorflow Github project, using Renode as target emulator (see `test_stm32f4_binary.sh`) to prevent breaking PRâ€™s being merged. Itâ€™s work ongoing and may take some time since there's an issue running this using Docker. However, I believe CMSIS-NN is tested using at least one of the targets in the internal TFLu tests, so there is some level of protection.

Itâ€™s awesome to hear that you have CMSIS-NN tests in you CI tests as well! Iâ€™d love to hear more about that. Perhaps some of your work can be upstreamed to the Tensorflow Github repo?

Cheers!
Fredrik",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-684838008,freddan80,2020-09-01 13:05:56,42748,[43486],Algorithm design bug,0,"> @freddan80 Q though (we can take this offline if you prefer): are there currently CI/CD pipelines set up for the CMSIS-NN kernels? E.g. we found this issue & #41816 through our own CI (and a bunch of debugging :-)), and we have currently automated tests for a wide variety of development boards that we run on real hardware for releases, both with the micro allocator and custom allocators, and with and without CMSIS-NN. But we don't follow mainline TensorFlow so we only find these issues once we upgrade. Perhaps it would be beneficial to share that with Arm? We have our internal CI, that tests TFLu-CMSIS-NN usecases on FPGAs and HW models with Cortex-M4 up to Cortex-M55 reference systems. We usually find issues related to CMSIS-NN quite soon. Unfortunately the networks we use did not have a reshape before FC as you encountered in #41816, or it would have been caught. Usually we create a kernel unit test case - in [code] in this case - when we find issues such as the one in #41816, and then contribute that to avoid the same issue in the future. For the issue reported in this ticket, weâ€™ve been waiting for 59d177d to make a permanent fix (thanks again for you PR!). We had actually bumped [code] to 2048 in our internal tests (not being aware of the missing range check), but didnâ€™t want to deliver that since it increases the memory footprint unnecessarily for smaller network usecases. Thatâ€™s some words about our internal CI. In parallel, we're working with the TFLu team to enable CMSIS-NN regression directly in the Tensorflow Github project, using Renode as target emulator (see [code]) to prevent breaking PRâ€™s being merged. Itâ€™s work ongoing and may take some time since there's an issue running this using Docker. However, I believe CMSIS-NN is tested using at least one of the targets in the internal TFLu tests, so there is some level of protection. Itâ€™s awesome to hear that you have CMSIS-NN tests in you CI tests as well! Iâ€™d love to hear more about that. Perhaps some of your work can be upstreamed to the Tensorflow Github repo? Cheers! Fredrik",3
"I can provide some additional context from the TF Micro side:

As you probably already know, the conv and depthwise_conv kernels use per-channel scale and zero-point quantization parameters. From the scale and zero points values, we calculate a multiplier and shift during the Prepare stage, which involves some computationally expensive double precision math as well as exponent calculations. Applying the multiplier and shift is a relatively cheap operation which occurs during the Eval stage. The storage required for these multipliers and shifts correlates to the number of channels along the quantized dimension (see the [TFLite quantization spec](https://www.tensorflow.org/lite/performance/quantization_spec#int8_quantized_operator_specifications) for more info).

Since we pre-calcualate shifts and multipliers during Prepare, we need to store the resulting values in persistent buffers, which means the memory cannot be re-used between kernel invocations (and the buffers must be allocated via context->AllocatePersistentBuffer). This is the price we pay for avoiding the large runtime overhead of calculating the multiplier and shift on-the-fly. Before we had a way to allocate persistent buffers in TF Micro, we implemented the conv and depthwise_conv kernels with a fixed-length buffer with 256 values. This issue seen here results from that previous implementation, and the fact not all of our kernels  have been updated to use dynamic allocation.

On a side note, it seems that there is increasing evidence that allowing models to use per-tensor quantization instead of per-channel for conv and depthwise_conv may be better for some TF Micro usecases. This is something we are aware of and discussing internally.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42748#issuecomment-688003409,njeffrie,2020-09-07 03:21:01,42748,[43486],Algorithm design bug,0,"I can provide some additional context from the TF Micro side: As you probably already know, the conv and depthwise_conv kernels use per-channel scale and zero-point quantization parameters. From the scale and zero points values, we calculate a multiplier and shift during the Prepare stage, which involves some computationally expensive double precision math as well as exponent calculations. Applying the multiplier and shift is a relatively cheap operation which occurs during the Eval stage. The storage required for these multipliers and shifts correlates to the number of channels along the quantized dimension (see the [TFLite quantization spec]([url]#int8_quantized_operator_specifications) for more info). Since we pre-calcualate shifts and multipliers during Prepare, we need to store the resulting values in persistent buffers, which means the memory cannot be re-used between kernel invocations (and the buffers must be allocated via context->AllocatePersistentBuffer). This is the price we pay for avoiding the large runtime overhead of calculating the multiplier and shift on-the-fly. Before we had a way to allocate persistent buffers in TF Micro, we implemented the conv and depthwise_conv kernels with a fixed-length buffer with 256 values. This issue seen here results from that previous implementation, and the fact not all of our kernels have been updated to use dynamic allocation. On a side note, it seems that there is increasing evidence that allowing models to use per-tensor quantization instead of per-channel for conv and depthwise_conv may be better for some TF Micro usecases. This is something we are aware of and discussing internally.",0
"Sorry for the confusion, 43545 is the correct PR",IssueComment,https://github.com/tensorflow/tensorflow/issues/43543#issuecomment-698407624,jenselofsson,2020-09-24 15:11:07,43543,[43545],Algorithm design bug,0,"Sorry for the confusion, 43545 is the correct PR",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43543"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43543"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43543#issuecomment-722336503,google-ml-butler[bot],2020-11-05 12:05:21,43543,[43545],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thanks but I think that it is hard to auto identify the ""real"" issue :wink: https://github.com/tensorflow/tensorflow/pull/43819",IssueComment,https://github.com/tensorflow/tensorflow/issues/43817#issuecomment-704255770,bhack,2020-10-06 13:06:39,43817,[43819],Code bug,0,"Thanks but I think that it is hard to auto identify the ""real"" issue :wink: [url]",1
"Thanks for your rapid answer @bhack.
I'm not sure to understand. Do you mean that the message provided by SonarCloud was not describing the problem properly? Or that I shouldn't have suggested a fix? I hesitated before doing it as I didn't want to introduce a bug with my suggestion.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43817#issuecomment-704289648,nicolas-harraudeau-sonarsource,2020-10-06 14:01:03,43817,[43819],Code bug,0,Thanks for your rapid answer @bhack. I'm not sure to understand. Do you mean that the message provided by SonarCloud was not describing the problem properly? Or that I shouldn't have suggested a fix? I hesitated before doing it as I didn't want to introduce a bug with my suggestion.,0
@nicolas-harraudeau-sonarsource No I just meant that it is a little bit more hard to automatically check that the required operation was on the 2nd arg (as hint). ,IssueComment,https://github.com/tensorflow/tensorflow/issues/43817#issuecomment-704294085,bhack,2020-10-06 14:08:03,43817,[43819],Code bug,0,@nicolas-harraudeau-sonarsource No I just meant that it is a little bit more hard to automatically check that the required operation was on the 2nd arg (as hint).,0
"@bhack Yes you are totally right. That's why the message says ""Correct **one of** the identical sub-expressions"". Sadly static code analyzers cannot provide fixes in many cases, developers will not be out of jobs soon ;)

Did you find the highlight on the second value confusing? We could highlight the whole `and` expression but it would create some confusions in cases such as `(a and b) and (a and b)`. Developers would not understand right away which `and` operand we are talking about. I'm open to any suggestion.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43817#issuecomment-704308221,nicolas-harraudeau-sonarsource,2020-10-06 14:29:06,43817,[43819],Code bug,0,"@bhack Yes you are totally right. That's why the message says ""Correct **one of** the identical sub-expressions"". Sadly static code analyzers cannot provide fixes in many cases, developers will not be out of jobs soon ;) Did you find the highlight on the second value confusing? We could highlight the whole [code] expression but it would create some confusions in cases such as [code]. Developers would not understand right away which [code] operand we are talking about. I'm open to any suggestion.",1
"I think it is ok, we will need advanced NLP models for this :wink: At some point Tensorflow models could generate this type of hints on its own code.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43817#issuecomment-704311850,bhack,2020-10-06 14:34:35,43817,[43819],Code bug,0,"I think it is ok, we will need advanced NLP models for this :wink: At some point Tensorflow models could generate this type of hints on its own code.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43817"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43817"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43817#issuecomment-704615063,google-ml-butler[bot],2020-10-07 00:02:25,43817,[43819],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
That's a good find. Please tag me in all similar issues from SonarSource.,IssueComment,https://github.com/tensorflow/tensorflow/issues/43818#issuecomment-704368181,mihaimaruseac,2020-10-06 15:48:19,43818,[43820],Test bug,0,That's a good find. Please tag me in all similar issues from SonarSource.,3
"Hi @mihaimaruseac and thank you.
Do you mean any issue found by SonarCloud? I recently reported #43817, #43813 and #43816.
I didn't report every issue our analyzer categorized as a bug because I didn't have time. You can take a look at the list of bugs [here](https://sonarcloud.io/project/issues?id=nicolas-harraudeau-sonarsource_tensorflow&languages=py&open=AXT60OurBMD9OHnI8qEG&resolved=false&types=BUG). It's quite short.

You might also be interested in some code smell issues such as:
* [this one](https://sonarcloud.io/project/issues?id=nicolas-harraudeau-sonarsource_tensorflow&issues=AXT60RJRBMD9OHnI8rFL&open=AXT60RJRBMD9OHnI8rFL), it looks to me like a classic [modification of a default argument](https://docs.python-guide.org/writing/gotchas/#mutable-default-arguments) which could lead to a bug one day.
* [or this one](https://sonarcloud.io/project/issues?id=nicolas-harraudeau-sonarsource_tensorflow&issues=AXT60Q4FBMD9OHnI8rCo&open=AXT60Q4FBMD9OHnI8rCo). I think that this is actually a bug. `len` cannot be called on an integer, so `len(len(...))` will fail.

We design our code analyzers to be quite conservative and avoid categorizing as bug things which might be code smells. That way developers are not disturbed with False Positives and trust our tools. The disadvantage is that some bugs are categorized as code smells.

At SonarSource we validate our static code analyzers using popular open source projects, such as Tensorflow, to make sure that we raise valuable issues and have no False Positives. This is how I saw these bugs.

As mentioned above, if you see any False Positives or if you have a question or feedback don't hesitate to share it [on the community forum](https://community.sonarsource.com/).",IssueComment,https://github.com/tensorflow/tensorflow/issues/43818#issuecomment-704556852,nicolas-harraudeau-sonarsource,2020-10-06 21:15:20,43818,[43820],Test bug,0,"Hi @mihaimaruseac and thank you. Do you mean any issue found by SonarCloud? I recently reported #43817, #43813 and #43816. I didn't report every issue our analyzer categorized as a bug because I didn't have time. You can take a look at the list of bugs [here]([url] It's quite short. You might also be interested in some code smell issues such as: * [this one]([url] it looks to me like a classic [modification of a default argument]([url]#mutable-default-arguments) which could lead to a bug one day. * [or this one]([url] I think that this is actually a bug. [code] cannot be called on an integer, so [code] will fail. We design our code analyzers to be quite conservative and avoid categorizing as bug things which might be code smells. That way developers are not disturbed with False Positives and trust our tools. The disadvantage is that some bugs are categorized as code smells. At SonarSource we validate our static code analyzers using popular open source projects, such as Tensorflow, to make sure that we raise valuable issues and have no False Positives. This is how I saw these bugs. As mentioned above, if you see any False Positives or if you have a question or feedback don't hesitate to share it [on the community forum]([url]",2
@mihaimaruseac Let me know. I can pick some of these.,IssueComment,https://github.com/tensorflow/tensorflow/issues/43818#issuecomment-704756157,bhack,2020-10-07 07:40:01,43818,[43820],Test bug,0,@mihaimaruseac Let me know. I can pick some of these.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43818"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43818"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43818#issuecomment-704966493,google-ml-butler[bot],2020-10-07 14:15:54,43818,[43820],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thank you @nicolas-harraudeau-sonarsource 

@bhack sure, thank you. I have so many things to do and team is severly downsized, so any help is great",IssueComment,https://github.com/tensorflow/tensorflow/issues/43818#issuecomment-705061860,mihaimaruseac,2020-10-07 16:47:55,43818,[43820],Test bug,0,"Thank you @nicolas-harraudeau-sonarsource @bhack sure, thank you. I have so many things to do and team is severly downsized, so any help is great",2
@mansnils @freddan80  what do you think?,IssueComment,https://github.com/tensorflow/tensorflow/issues/43743#issuecomment-702912483,advaitjain,2020-10-02 19:16:38,43743,[44015],Test bug,0,@mansnils @freddan80 what do you think?,0
"@advaitjain sounds like a good idea. I think the numbers were derived from the Bluepill target originally. The STM32M4 seem to support a wide range of memory configs: https://www.st.com/en/microcontrollers-microprocessors/stm32f4-series.html
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43743#issuecomment-703640571,freddan80,2020-10-05 13:42:05,43743,[44015],Test bug,0,@advaitjain sounds like a good idea. I think the numbers were derived from the Bluepill target originally. The STM32M4 seem to support a wide range of memory configs: [url],3
"I think the .ld should map the settings here:
https://github.com/renode/renode/blob/master/platforms/cpus/stm32f4.repl
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43743#issuecomment-703646657,freddan80,2020-10-05 13:52:17,43743,[44015],Test bug,0,I think the .ld should map the settings here: [url],0
"@mansnils can look at this next week. I think the only change needed is:

```
MEMORY { 
 RAM (xrw) : ORIGIN = 0x20000000, LENGTH = 256K 
 FLASH (rx) : ORIGIN = 0x8000000, LENGTH =  2048K
 } 

```
And perhaps remove the outdated comments in the top of the file:

```
/* Copied and modified from: tensorflow/lite/micro/tools/make/targets/bluepill/bluepill.lds

*/

/*
 * 0x00000000 - 0x07ffffff - aliased to flash or sys memory depending on BOOT jumpers.
 * 0x08000000 - 0x0801ffff - Flash.
 * 0x1ffff000 - 0x1ffff7ff - Boot firmware in system memory.
 * 0x1ffff800 - 0x1fffffff - Option bytes.
 * 0x20000000 - 0x20004fff - SRAM.
 * 0x40000000 - 0x40023400 - Peripherals
 */
```

@advaitjain let us know if you prefer us to fix this.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43743#issuecomment-703735945,freddan80,2020-10-05 16:16:34,43743,[44015],Test bug,0,@mansnils can look at this next week. I think the only change needed is: ``[code]`[code]`[code]`` @advaitjain let us know if you prefer us to fix this.,0
"yes, a PR from you guys would be excellent.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43743#issuecomment-706331278,advaitjain,2020-10-09 18:15:00,43743,[44015],Test bug,0,"yes, a PR from you guys would be excellent.",4
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43743"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43743"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43743#issuecomment-708864411,google-ml-butler[bot],2020-10-15 03:00:28,43743,[44015],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Let's create a PR to remove the link.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44525#issuecomment-720671357,mihaimaruseac,2020-11-02 19:15:24,44525,[44742],Documentation bug,0,Let's create a PR to remove the link.,0
"I removed the dead link but I am not able to merge 
#44757
Might you be able to please recommend how to merge this
",IssueComment,https://github.com/tensorflow/tensorflow/issues/44525#issuecomment-725269045,Sainithin-bit,2020-11-11 07:59:37,44525,[44742],Documentation bug,0,I removed the dead link but I am not able to merge #44757 Might you be able to please recommend how to merge this,0
"It first needs to be approved by a person working at Google. Then there is some CI and if all is green it gets imported inside Google were it waits for a new review round and more CI. If all is good then there is automation that merges it.

Looking at the Pr now.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44525#issuecomment-725646993,mihaimaruseac,2020-11-11 20:33:43,44525,[44742],Documentation bug,0,It first needs to be approved by a person working at Google. Then there is some CI and if all is green it gets imported inside Google were it waits for a new review round and more CI. If all is good then there is automation that merges it. Looking at the Pr now.,0
Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/31e386806706356954977ff2f431015e/44765.ipynb). Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/44765#issuecomment-725897723,amahendrakar,2020-11-12 07:36:16,44765,[44764],Documentation bug,0,Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here]([url] Thanks!,0
Please unlock the colab access permissions.,IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697276604,bhack,2020-09-23 10:28:03,43478,[45278],Deployment bug,0,Please unlock the colab access permissions.,0
"> Please unlock the colab access permissions.

https://colab.research.google.com/drive/17DI2N1L9EKSJ8-Ua88mcSnkmRT5adna3?usp=sharing
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697280215,Liu-Da,2020-09-23 10:36:02,43478,[45278],Deployment bug,0,> Please unlock the colab access permissions. [url],0
"Can you try to load with `custom_objects={""F1Score"": tfa.metrics.F1Score}`?
I've used: `!pip install --upgrade tensorflow tensorflow_addons` in your colab

/cc @marload",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697284593,bhack,2020-09-23 10:45:44,43478,[45278],Deployment bug,0,Can you try to load with [code]? I've used: [code] in your colab /cc @marload,0
"@Liu-Da,
As suggested by @bhack, by adding the `custom_objects={""F1Score"": tfa.metrics.F1Score}` argument I was able to load the model without any issues. Please check [this gist](https://colab.research.google.com/gist/amahendrakar/ae7bdd21b2917d2ec57757c648f0572a/43478.ipynb) for reference. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697306012,amahendrakar,2020-09-23 11:34:49,43478,[45278],Deployment bug,0,"@Liu-Da, As suggested by @bhack, by adding the [code] argument I was able to load the model without any issues. Please check [this gist]([url] for reference. Thanks!",5
"> @Liu-Da,
> As suggested by @bhack, by adding the `custom_objects={""F1Score"": tfa.metrics.F1Score}` argument I was able to load the model without any issues. Please check [this gist](https://colab.research.google.com/gist/amahendrakar/ae7bdd21b2917d2ec57757c648f0572a/43478.ipynb) for reference. Thanks!

Thanks @bhack and @amahendrakar. This does make the model load successfully.  

But the key to the problem is why the same code behaves differently in the tf2.0 and tf2.3.  

In addition, if I set `compile=False`,  why should we still care about the custom metric?",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697319002,Liu-Da,2020-09-23 12:04:09,43478,[45278],Deployment bug,0,"> @Liu-Da, > As suggested by @bhack, by adding the [code] argument I was able to load the model without any issues. Please check [this gist]([url] for reference. Thanks! Thanks @bhack and @amahendrakar. This does make the model load successfully. But the key to the problem is why the same code behaves differently in the tf2.0 and tf2.3. In addition, if I set [code], why should we still care about the custom metric?",0
I also found that the model trained and saved using tf2.0 can be loaded correctly by tf2.3. (set compile=False and dont need set custom_objects),IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697321056,Liu-Da,2020-09-23 12:08:24,43478,[45278],Deployment bug,0,I also found that the model trained and saved using tf2.0 can be loaded correctly by tf2.3. (set compile=False and dont need set custom_objects),3
I don't know if tf2.0 was going to save this custom object metrics. With the current code a think that the internal load doesn't care about the `compile` argument https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/saving/saved_model/load.py#L119-L120,IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697329703,bhack,2020-09-23 12:25:52,43478,[45278],Deployment bug,0,I don't know if tf2.0 was going to save this custom object metrics. With the current code a think that the internal load doesn't care about the [code] argument [url]#L119-L120,-2
"> I don't know if tf2.0 was going to save this custom object metrics. With the current code a think that the internal load doesn't care about the `compile` argument https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/saving/saved_model/load.py#L119-L120

As the model trained and saved using tf2.0 can be loaded correctly by tf2.3 without set any custom_objects, this situation may not be caused by tf.keras.model.load but by Model.save.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697337020,Liu-Da,2020-09-23 12:39:35,43478,[45278],Deployment bug,0,"> I don't know if tf2.0 was going to save this custom object metrics. With the current code a think that the internal load doesn't care about the [code] argument [url]#L119-L120 As the model trained and saved using tf2.0 can be loaded correctly by tf2.3 without set any custom_objects, this situation may not be caused by tf.keras.model.load but by Model.save.",0
"> I don't know if tf2.0 was going to save this custom object metrics. 

So if you don't save custom object metrics you don't have problem on load or not? As you was asking about loading with `compile=False`",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697338270,bhack,2020-09-23 12:41:44,43478,[45278],Deployment bug,0,> I don't know if tf2.0 was going to save this custom object metrics. So if you don't save custom object metrics you don't have problem on load or not? As you was asking about loading with [code],0
"E.g. If you save and load a non compiled model also with TF2.3 is ok you don't need to care about the custom_metrics:
```
import numpy as np
import tensorflow as tf
import tensorflow_addons as tfa

print(tf.__version__)

_input = tf.keras.layers.Input(shape=(500), name=""fbank"") # B*T*F*c
out = tf.keras.layers.Dense(50, activation=""tanh"")(_input)
probabilities = tf.keras.layers.Dense(2, activation=""softmax"")(out)
model = tf.keras.Model(inputs=_input, outputs=probabilities)

#model.compile(optimizer=""sgd"", loss=tf.keras.losses.CategoricalCrossentropy(), 
#              metrics= [""accuracy"", tfa.metrics.F1Score(num_classes=2, average=""micro"")])

model.summary()

x=np.random.rand(300,500)
y=np.random.rand(300,2)
#model.fit(x,y,batch_size=100, epochs=2)

path = 'saved_model/'
model.save(path, save_format='tf')

del model
model = tf.keras.models.load_model('saved_model', compile=False)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697346431,bhack,2020-09-23 12:56:35,43478,[45278],Deployment bug,0,E.g. If you save and load a non compiled model also with TF2.3 is ok you don't need to care about the custom_metrics: ``[code]``,0
"> E.g. If you save and load a non compiled model also with TF2.3 is ok you don't need to care about the custom_metrics:
> 
> ```
> import numpy as np
> import tensorflow as tf
> import tensorflow_addons as tfa
> 
> print(tf.__version__)
> 
> _input = tf.keras.layers.Input(shape=(500), name=""fbank"") # B*T*F*c
> out = tf.keras.layers.Dense(50, activation=""tanh"")(_input)
> probabilities = tf.keras.layers.Dense(2, activation=""softmax"")(out)
> model = tf.keras.Model(inputs=_input, outputs=probabilities)
> 
> #model.compile(optimizer=""sgd"", loss=tf.keras.losses.CategoricalCrossentropy(), 
> #              metrics= [""accuracy"", tfa.metrics.F1Score(num_classes=2, average=""micro"")])
> 
> model.summary()
> 
> x=np.random.rand(300,500)
> y=np.random.rand(300,2)
> #model.fit(x,y,batch_size=100, epochs=2)
> 
> path = 'saved_model/'
> model.save(path, save_format='tf')
> 
> del model
> model = tf.keras.models.load_model('saved_model', compile=False)
> ```

This code runs perfectly. 

> > I don't know if tf2.0 was going to save this custom object metrics.
> 
> So if you don't save custom object metrics you don't have problem on load or not? As you was asking about loading with `compile=False`

Yes, this code runs perfectly.   ",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697361592,Liu-Da,2020-09-23 13:24:05,43478,[45278],Deployment bug,0,"> E.g. If you save and load a non compiled model also with TF2.3 is ok you don't need to care about the custom_metrics: > > ``[code]`[code]compile=False` Yes, this code runs perfectly.",5
"![image](https://user-images.githubusercontent.com/24472521/94018474-3bbf0780-fde3-11ea-8ad7-1e08dbc7f464.png)

The official document says that if we use Savedmodel, we don't need to consider the issue of custom_object.

Model should been successfully loaded by `model =tf.keras.models.load_model('saved_model')`.

Even if there is a custom_object, it should not affect the loading model.

When we compile and train a model and then distribute it to others, we hope that the model can be successfully loaded without any source data sharing and inference can be performed correctly.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697369919,Liu-Da,2020-09-23 13:38:14,43478,[45278],Deployment bug,0,"![image]([url] The official document says that if we use Savedmodel, we don't need to consider the issue of custom_object. Model should been successfully loaded by [code]. Even if there is a custom_object, it should not affect the loading model. When we compile and train a model and then distribute it to others, we hope that the model can be successfully loaded without any source data sharing and inference can be performed correctly.",0
"I don't know if the exception is (/cc @k-w-w)
https://github.com/tensorflow/tensorflow/blob/0650101e05ef1ad56bfaadcd63ab775b25ecdd16/tensorflow/python/keras/saving/saved_model/metric_serialization.py#L44-L45",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-697537787,bhack,2020-09-23 15:24:34,43478,[45278],Deployment bug,0,I don't know if the exception is (/cc @k-w-w) [url]#L44-L45,0
"If someone only wants to load the model for prediction and inference, **without retraining**, I found a workaround solution.
Use this code before `model.save`
```
model.optimizer = None
model.compiled_loss = None
model.compiled_metrics = None
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-698753642,Liu-Da,2020-09-25 06:44:16,43478,[45278],Deployment bug,0,"If someone only wants to load the model for prediction and inference, **without retraining**, I found a workaround solution. Use this code before [code] ``[code]``",0
"> I don't know if the exception is (/cc @k-w-w)
> https://github.com/tensorflow/tensorflow/blob/0650101e05ef1ad56bfaadcd63ab775b25ecdd16/tensorflow/python/keras/saving/saved_model/metric_serialization.py#L44-L45

Can anyone familiar with this part of the code provide some help?",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-698754515,Liu-Da,2020-09-25 06:46:31,43478,[45278],Deployment bug,0,> I don't know if the exception is (/cc @k-w-w) > [url]#L44-L45 Can anyone familiar with this part of the code provide some help?,0
It is referencing an internal ticket. I've already mentioned @k-w-w ,IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-698861862,bhack,2020-09-25 10:49:00,43478,[45278],Deployment bug,0,It is referencing an internal ticket. I've already mentioned @k-w-w,0
"Was able to reproduce the issue. 

Code works with TF v2.0, throws an error stating 
`ValueError: Unable to restore custom object of type _tf_keras_metric currently. Please make sure that the layer implements get_config and from_config when saving. In addition, please use the custom_objects arg when calling load_model().` with TF v2.3. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/906edc47c0ce6ee03c40d8f3b8f0dc01/untitled0.ipynb#scrollTo=Hcdmx695RtxT). Thanks! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-699861748,amahendrakar,2020-09-28 08:28:23,43478,[45278],Deployment bug,0,"Was able to reproduce the issue. Code works with TF v2.0, throws an error stating [code] with TF v2.3. Please find the gist of it [here]([url]#scrollTo=Hcdmx695RtxT). Thanks!",0
"> If someone only wants to load the model for prediction and inference, **without retraining**, I found a workaround solution.
> Use this code before `model.save`
> 
> ```
> model.optimizer = None
> model.compiled_loss = None
> model.compiled_metrics = None
> ```
@Liu-Da I'm experiencing this problem as well. I'm using `from tensorflow.keras.callbacks import ModelCheckpoint` to save the model. Do you see an adjustment of your work-around when using `ModelCheckpoint`?",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-742660281,maxvfischer,2020-12-10 17:11:08,43478,[45278],Deployment bug,0,"> If someone only wants to load the model for prediction and inference, **without retraining**, I found a workaround solution. > Use this code before [code] > > ``[code]`[code]from tensorflow.keras.callbacks import ModelCheckpoint[code]ModelCheckpoint`?",0
"I submitted a fix for this issue in #45278, but it is still waiting for review.
I don't think there is an easy workaround for this currently other than only saving the weights in `ModelCheckpoint` or by adapting the callback itself to only save the model without the metrics.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-742665744,lgeiger,2020-12-10 17:20:09,43478,[45278],Deployment bug,0,"I submitted a fix for this issue in #45278, but it is still waiting for review. I don't think there is an easy workaround for this currently other than only saving the weights in [code] or by adapting the callback itself to only save the model without the metrics.",0
"@lgeiger I'm thinking about using @Liu-Da workaround together with `ModelCheckpoint`:

```python
...
callbacks = [
    ModelCheckpoint(
        filepath=arguments['model_output_path'],
        monitor=arguments['early_stopping_monitor'],
        verbose=0,
        save_best_only=True,
        save_weights_only=False,
        mode='max'
    )
]
model.fit(
    x=train_generator,
    steps_per_epoch=np.ceil(num_images_train / arguments['batch_size_train']),
    epochs=arguments['epochs'],
    validation_data=val_generator,
    validation_steps=np.ceil(num_images_val / arguments['batch_size_val']),
    callbacks=callbacks
)

model.optimizer = None
model.compiled_loss = None
model.compiled_metrics = None
model.save(arguments['model_output_path'])
```
Have I understood `ModelCheckpoint` correctly, that after `model.fit()`, the variable `model` will be the best model (because `save_best_only=True` in `ModelCheckpoint`)?",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-743081091,maxvfischer,2020-12-11 09:27:01,43478,[45278],Deployment bug,0,@lgeiger I'm thinking about using @Liu-Da workaround together with [code]: ``[code]`[code]ModelCheckpoint[code]model.fit()[code]model[code]save_best_only=True[code]ModelCheckpoint`)?,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43478"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43478"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-743450090,google-ml-butler[bot],2020-12-11 22:02:22,43478,[45278],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@Liu-Da Just ran in to this issue where I trained a model with a tensorflow_addon metric. In the file where I load the saved model, import both tensorflow and tensorflow_addons, then the saved model loads without issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-789184978,bendykstra94,2021-03-02 20:16:45,43478,[45278],Deployment bug,0,"@Liu-Da Just ran in to this issue where I trained a model with a tensorflow_addon metric. In the file where I load the saved model, import both tensorflow and tensorflow_addons, then the saved model loads without issue.",0
"For anyone subclassing a metric, see my [response](https://github.com/tensorflow/tensorflow/issues/34068#issuecomment-948208134) on another thread. Having to set the `custom_objects` keys to exactly the same name as the class isn't limited to just saving H5 models, but also TF models.",IssueComment,https://github.com/tensorflow/tensorflow/issues/43478#issuecomment-948210552,JakeTheSnake3p0,2021-10-21 03:00:44,43478,[45278],Deployment bug,0,"For anyone subclassing a metric, see my [response]([url]#issuecomment-948208134) on another thread. Having to set the [code] keys to exactly the same name as the class isn't limited to just saving H5 models, but also TF models.",0
"The following is a possible workaround:

```python
@tf.function
def graph_func(x):
    unique_input_ids, idx, counts = tf.raw_ops.UniqueWithCountsV2(x=x, axis=[0])
    idx = tf.reshape(idx, [-1])   # <<<<<<<<<<<<<<<<<<<<<
    idx = idx[:tf.shape(x)[0]]    # <<<<<<<<<<<<<<<<<<<<<
    tf.print('idx shape', tf.shape(idx), 'idx', idx)
    return x

_ = graph_func(c)
```
```
idx shape [4] idx [0 0 1 0]
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/44788#issuecomment-726115294,thierryherrmann,2020-11-12 14:34:13,44788,[45280],Data bug,1,The following is a possible workaround: ``[code]`[code]`[code]``,0
"Was able to reproduce the issue with TF v2.2, 2.3 and nightly versions. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/8868ab137c4c82e5ca07c08ee4802198/44788.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/44788#issuecomment-726201897,amahendrakar,2020-11-12 16:52:58,44788,[45280],Data bug,1,"Was able to reproduce the issue with TF v2.2, 2.3 and nightly versions. Please find the gist of it [here]([url] Thanks!",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44788"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44788"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/44788#issuecomment-743266868,google-ml-butler[bot],2020-12-11 15:39:54,44788,[45280],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I think it will be hard to expect a backport on 2.1.0.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-719760872,bhack,2020-10-30 19:46:17,44467,[45487],Version compatibility bug,1,I think it will be hard to expect a backport on 2.1.0.,-1
"the new h5py version just came out today: https://pypi.org/project/h5py/#history

Pinning it to a version <3.0.0 (or at least throwing a warning) is a very lightweight change with no risk.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-719839993,danzafar,2020-10-30 23:15:10,44467,[45487],Version compatibility bug,1,the new h5py version just came out today: [url]#history Pinning it to a version <3.0.0 (or at least throwing a warning) is a very lightweight change with no risk.,2
"> the new h5py version just came out today: https://pypi.org/project/h5py/#history
> 
> Pinning it to a version <3.0.0 (or at least throwing a warning) is a very lightweight change with no risk.

Yes but as you know generally we had very few patch releases (e.g. 2.1.x) so It Is quite hard to have wheels with these fixes on old versions.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-719843238,bhack,2020-10-30 23:28:13,44467,[45487],Version compatibility bug,1,> the new h5py version just came out today: [url]#history > > Pinning it to a version <3.0.0 (or at least throwing a warning) is a very lightweight change with no risk. Yes but as you know generally we had very few patch releases (e.g. 2.1.x) so It Is quite hard to have wheels with these fixes on old versions.,0
"@bhack I'm not going to add any more messages after this, but I think you can see based on these other issues the Keras API is essentially broken because h5py new release. I'm not sure why the version was not pinned as it is in master, but I strongly advise that you pin to h5py==2.10.0 this for all TF >= 2.1.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-719964088,danzafar,2020-10-31 17:33:37,44467,[45487],Version compatibility bug,1,"@bhack I'm not going to add any more messages after this, but I think you can see based on these other issues the Keras API is essentially broken because h5py new release. I'm not sure why the version was not pinned as it is in master, but I strongly advise that you pin to h5py==2.10.0 this for all TF >= 2.1.",-3
/cc @mihaimaruseac @angerson there are many Dockerfile and other file not constrained.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-719966136,bhack,2020-10-31 17:51:12,44467,[45487],Version compatibility bug,1,/cc @mihaimaruseac @angerson there are many Dockerfile and other file not constrained.,-2
"FWIW, I got a similar error message with h5py 3.0, and removing `.decode('utf-8')` from `tensorflow/python/keras/saving/hdf5_format.py` allows me to load Keras models as before.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-720042186,yan12125,2020-11-01 06:34:25,44467,[45487],Version compatibility bug,1,"FWIW, I got a similar error message with h5py 3.0, and removing [code] from [code] allows me to load Keras models as before.",1
"We cannot pin the versions without doing a patch release. We only do patch releases for security issues.

This issue has a quick workaround: `pip install tensorflow h5py<3.0.0`.

We are in the process of releasing TF 2.4 which should not be affected by this issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-720631688,mihaimaruseac,2020-11-02 17:58:47,44467,[45487],Version compatibility bug,1,We cannot pin the versions without doing a patch release. We only do patch releases for security issues. This issue has a quick workaround: [code]. We are in the process of releasing TF 2.4 which should not be affected by this issue.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44467"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44467"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-720631702,google-ml-butler[bot],2020-11-02 17:58:49,44467,[45487],Version compatibility bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thought it might be pertinent to link to the h5py repo:
This has been labeled as a bug in their 3.0.0 release (rather than a backwards incompatibility),
and is slated to be fixed in an upcoming release: https://github.com/h5py/h5py/issues/1732

edit:
Actually, there might be two separate but related issues here. The bug in the h5py thread occurs during the model-save codepath, but the bug in this TensorFlow thread is in the model-load codepath, which if I had to wildly guess _might_ require a typecheck/cast on TensorFlow's side",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-721991660,convoliution,2020-11-04 21:44:54,44467,[45487],Version compatibility bug,1,"Thought it might be pertinent to link to the h5py repo: This has been labeled as a bug in their 3.0.0 release (rather than a backwards incompatibility), and is slated to be fixed in an upcoming release: [url] edit: Actually, there might be two separate but related issues here. The bug in the h5py thread occurs during the model-save codepath, but the bug in this TensorFlow thread is in the model-load codepath, which if I had to wildly guess _might_ require a typecheck/cast on TensorFlow's side",0
"> there might be two separate but related issues here

That seems the case. I tried h5py 3.1.0, and the error `AttributeError: 'str' object has no attribute 'decode'` still happens.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-723399989,yan12125,2020-11-07 06:32:28,44467,[45487],Version compatibility bug,1,"> there might be two separate but related issues here That seems the case. I tried h5py 3.1.0, and the error [code] still happens.",-1
:laughing: Thanks!!,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-724957843,MarkSCQ,2020-11-10 20:48:52,44467,[45487],Version compatibility bug,1,:laughing: Thanks!!,5
`pip install 'h5py<3.0.0'`,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-725292443,elliotvilhelm,2020-11-11 08:52:12,44467,[45487],Version compatibility bug,1,[code],0
This error is also present in tensorflow 1.15: https://stackoverflow.com/questions/64795784/google-ai-platform-unexpected-error-when-loading-the-model-str-object-has-no,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-725829538,shivasuri,2020-11-12 04:32:01,44467,[45487],Version compatibility bug,1,This error is also present in tensorflow 1.15: [url],0
Is there a timeline for the fix/release? I am using Google AI Platform which unfortunately does not allow you to easily override the versions of its standard libraries including `h5py` ([stackoverflow](https://stackoverflow.com/questions/62816129/how-do-you-override-google-ai-platforms-standard-librarys-i-e-upgrade-scikit)),IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-726241167,shivasuri,2020-11-12 17:59:23,44467,[45487],Version compatibility bug,1,Is there a timeline for the fix/release? I am using Google AI Platform which unfortunately does not allow you to easily override the versions of its standard libraries including [code] ([stackoverflow]([url],0
"also incapable for tensorflow3.2.1
> update: I mean version 2.3.1",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-728920792,NIL-zhuang,2020-11-17 13:18:07,44467,[45487],Version compatibility bug,1,also incapable for tensorflow3.2.1 > update: I mean version 2.3.1,-2
"> also incapable for tensorflow3.2.1

of course, we cannot use tf3 right now unless you come from another universe",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-729122690,MarkSCQ,2020-11-17 18:37:16,44467,[45487],Version compatibility bug,1,"> also incapable for tensorflow3.2.1 of course, we cannot use tf3 right now unless you come from another universe",-3
"Please keep in mind that we don't update older branches unless for security reasons. So, because our bounds on dependencies were too large (our mistake, fixed now, but see also #44654), you will have to manually downgrade `h5py` in your installation.

You can do this in two ways:

* Either you install with an upper bound, a la:
    ```console
    $ pip install tensorflow 'h5py < 3.0.0'
    ```

* Or you install TF and then downgrade `h5py`, a la:

    ```console
    $ pip install tensorflow
    $ pip uninstall -y h5py
    $ pip install 'h5py < 3.0.0'
    ```

Alternatively, the issue should be fixed in nightly and in TF 2.4 RCs (in the sense that h5py is upper bounded to not get 3.0.0).

We will have people working on making TF work with `h5py >= 3` in the future, but this will only land in TF 2.5 or later.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-729300306,mihaimaruseac,2020-11-18 00:37:28,44467,[45487],Version compatibility bug,1,"Please keep in mind that we don't update older branches unless for security reasons. So, because our bounds on dependencies were too large (our mistake, fixed now, but see also #44654), you will have to manually downgrade [code] in your installation. You can do this in two ways: * Either you install with an upper bound, a la: ``[code]`[code]h5py[code]`[code]`[code]h5py >= 3` in the future, but this will only land in TF 2.5 or later.",-1
Has this been fixed yet for TF 2.3.1? ,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-732273085,rd16395p,2020-11-23 16:29:36,44467,[45487],Version compatibility bug,1,Has this been fixed yet for TF 2.3.1?,0
"Hate to reply with a link to a comment just above yours, but here it is: https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-729300306",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-732308364,mihaimaruseac,2020-11-23 17:26:48,44467,[45487],Version compatibility bug,1,"Hate to reply with a link to a comment just above yours, but here it is: [url]#issuecomment-729300306",-3
"My bad, I saw the issue was still open and assumed it was waiting on a fix. Thanks @mihaimaruseac ",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-732378492,rd16395p,2020-11-23 19:31:32,44467,[45487],Version compatibility bug,1,"My bad, I saw the issue was still open and assumed it was waiting on a fix. Thanks @mihaimaruseac",2
"The recommended fix of downgrading the h5py version:

` pip install 'h5py < 3.0.0'`

does not work on TensorFlow 2.3 because:

```
/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in load_weights(self, filepath, by_name, skip_mismatch, options)
   2202           'first, then load the weights.')
   2203     self._assert_weights_created()
-> 2204     with h5py.File(filepath, 'r') as f:
   2205       if 'layer_names' not in f.attrs and 'model_weights' in f:
   2206         f = f['model_weights']

AttributeError: module 'h5py' has no attribute 'File'
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-735487888,lakshmanok,2020-11-30 00:46:12,44467,[45487],Version compatibility bug,1,The recommended fix of downgrading the h5py version: [code] does not work on TensorFlow 2.3 because: ``[code]``,-2
"@danzafar 
Please update if this is still an issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-735574227,Saduf2019,2020-11-30 06:17:43,44467,[45487],Version compatibility bug,1,@danzafar Please update if this is still an issue.,0
Can you test if release candidate for TF 2.4 works?,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-735901736,mihaimaruseac,2020-11-30 16:42:15,44467,[45487],Version compatibility bug,1,Can you test if release candidate for TF 2.4 works?,0
I'll leave this to @bhack ,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-735908127,danzafar,2020-11-30 16:53:01,44467,[45487],Version compatibility bug,1,I'll leave this to @bhack,0
2.4.0-rc3 has `h5py~=2.10.0`,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-735977999,bhack,2020-11-30 18:59:35,44467,[45487],Version compatibility bug,1,2.4.0-rc3 has [code],0
Downgrading to h5py does not work for me.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-736699915,andcastillo,2020-12-01 17:24:29,44467,[45487],Version compatibility bug,1,Downgrading to h5py does not work for me.,-2
@mihaimaruseac Can you take a look at https://github.com/tensorflow/tensorflow/pull/45380 ?,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-738343165,bhack,2020-12-03 21:55:57,44467,[45487],Version compatibility bug,1,@mihaimaruseac Can you take a look at [url] ?,0
Downgrading to h5py worked some time ago. Now old h5py does not work and #40991 appears.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-739318917,yekm,2020-12-05 16:41:39,44467,[45487],Version compatibility bug,1,Downgrading to h5py worked some time ago. Now old h5py does not work and #40991 appears.,-3
Removing `.decode('utf-8')` on lines 176 and 190 in `/usr/lib/python3.9/site-packages/tensorflow/python/keras/saving/hdf5_format.py` worked for me.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-739320550,yekm,2020-12-05 16:55:38,44467,[45487],Version compatibility bug,1,Removing [code] on lines 176 and 190 in [code] worked for me.,2
We are now at 3.1.0 on master https://github.com/tensorflow/tensorflow/pull/45380,IssueComment,https://github.com/tensorflow/tensorflow/issues/44467#issuecomment-740221020,bhack,2020-12-07 22:32:27,44467,[45487],Version compatibility bug,1,We are now at 3.1.0 on master [url],0
"I have tried in colab with TF version 2.4, nightly version(`2.5.0-dev20201202`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/8d62aff3a12336dd515b4a18313efe27/untitled560.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/45324#issuecomment-737226305,ravikyram,2020-12-02 13:21:23,45324,[45613],Data bug,0,"I have tried in colab with TF version 2.4, nightly version([code]) and was able to reproduce the issue. Please, find the gist [here]([url]",0
Added a PR #45613 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/45324#issuecomment-743431559,yongtang,2020-12-11 21:17:36,45324,[45613],Data bug,0,Added a PR #45613 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45324"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45324"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/45324#issuecomment-779427925,google-ml-butler[bot],2021-02-15 20:12:03,45324,[45613],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45665"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45665"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/45665#issuecomment-745637448,google-ml-butler[bot],2020-12-15 23:45:49,45665,[45666],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@eiennohito,
I was able to run the code without any issues with a smaller value for `dense_shape`. 

Is there any specific reason you are using a tensor of such large dimensions? Thanks! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/45392#issuecomment-738804514,amahendrakar,2020-12-04 14:10:35,45392,[45675],Data bug,1,"@eiennohito, I was able to run the code without any issues with a smaller value for [code]. Is there any specific reason you are using a tensor of such large dimensions? Thanks!",2
"If you decrease dimensions of dense_shape so the number of elements fits into signed 64 bit integer the current implementation works. 

In my usage (I use sparse tensors to represent graphs with lots of attributes), tensors can have lots of dimensions (e.g. ~30), and it becomes impossible to use `reorder`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/45392#issuecomment-738833791,eiennohito,2020-12-04 15:05:19,45392,[45675],Data bug,1,"If you decrease dimensions of dense_shape so the number of elements fits into signed 64 bit integer the current implementation works. In my usage (I use sparse tensors to represent graphs with lots of attributes), tensors can have lots of dimensions (e.g. ~30), and it becomes impossible to use [code].",-2
"Was able to reproduce the issue with TF v2.3, TF v2.4.0rc4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/8b7f9c89274291823fb12136b89cc827/45392-tf-nightly.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/45392#issuecomment-739472260,amahendrakar,2020-12-06 08:30:33,45392,[45675],Data bug,1,"Was able to reproduce the issue with TF v2.3, TF v2.4.0rc4 and TF-nightly. Please find the gist of it [here]([url] Thanks!",0
"Added a PR #45675 to fix the issue, so that it is possible to gracefully return an error with error message.",IssueComment,https://github.com/tensorflow/tensorflow/issues/45392#issuecomment-744780560,yongtang,2020-12-14 23:15:30,45392,[45675],Data bug,1,"Added a PR #45675 to fix the issue, so that it is possible to gracefully return an error with error message.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45392"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45392"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/45392#issuecomment-752752492,google-ml-butler[bot],2020-12-30 20:43:53,45392,[45675],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/e97a3e0f3be52cfb7dbb5b4051d9d0fd/45975.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/45975#issuecomment-751698876,amahendrakar,2020-12-28 12:37:34,45975,[46013],Data bug,0,"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here]([url] Thanks!",1
Added a PR #46013 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/45975#issuecomment-751720718,yongtang,2020-12-28 13:56:58,45975,[46013],Data bug,0,Added a PR #46013 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45975"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45975"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/45975#issuecomment-753545469,google-ml-butler[bot],2021-01-02 23:54:09,45975,[46013],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #46040 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/45778#issuecomment-752072393,yongtang,2020-12-29 13:20:53,45778,[46040],Documentation bug,0,Added a PR #46040 for the fix.,0
Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/8dd49ffe9df3f1551d4f3f7a09941b7f/44092.ipynb) and [TF-nightly](dilation_rate). Please find the attached gist. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/44092#issuecomment-711862150,amahendrakar,2020-10-19 08:43:45,44092,[46063],Algorithm design bug,0,Was able to reproduce the issue with [TF v2.3]([url] and [TF-nightly](dilation_rate). Please find the attached gist. Thanks!,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44092"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44092"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/44092#issuecomment-756948636,google-ml-butler[bot],2021-01-08 19:22:07,44092,[46063],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46148"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46148"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46148#issuecomment-754763835,google-ml-butler[bot],2021-01-05 17:00:32,46148,[46149],Documentation bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Hi,

The current dilated conv rewriting pass only supports Conv2D:
https://github.com/tensorflow/tensorflow/blob/b422faa5e39f0ea2e9502ed5d974f23c36768894/tensorflow/compiler/mlir/lite/transforms/prepare_tf.cc#L629

If your model contains Conv1D, unfortunately that's not supported now.",IssueComment,https://github.com/tensorflow/tensorflow/issues/38638#issuecomment-616872985,haozha111,2020-04-21 00:04:14,38638,[46150],Deployment bug,0,"Hi, The current dilated conv rewriting pass only supports Conv2D: [url]#L629 If your model contains Conv1D, unfortunately that's not supported now.",-1
"Thank you for your interest,

But actually the model presents exactly a Conv2D op, as the Conv1D is converted to an ExpandDims -> Conv2D -> Squeeze sequence. So in the frozen graph there is exactly a SpaceToBatchND -> Expand -> Conv2D -> Squeeze -> BatchToSpaceND -> BiasAdd sequence which this comment states is supported
https://github.com/tensorflow/tensorflow/blob/adbacb4206cf440f3628e7240a53d8e0f12122b6/tensorflow/compiler/mlir/lite/transforms/dilated_conv.h#L50
The same comment cites Wavenet as a use case for this sequence, which is very similar to my model.",IssueComment,https://github.com/tensorflow/tensorflow/issues/38638#issuecomment-617016739,colluca,2020-04-21 07:53:06,38638,[46150],Deployment bug,0,"Thank you for your interest, But actually the model presents exactly a Conv2D op, as the Conv1D is converted to an ExpandDims -> Conv2D -> Squeeze sequence. So in the frozen graph there is exactly a SpaceToBatchND -> Expand -> Conv2D -> Squeeze -> BatchToSpaceND -> BiasAdd sequence which this comment states is supported [url]#L50 The same comment cites Wavenet as a use case for this sequence, which is very similar to my model.",0
"I took a look at your graph. And I think the pattern doesn't get matched because this line:
https://github.com/tensorflow/tensorflow/blob/adbacb4206cf440f3628e7240a53d8e0f12122b6/tensorflow/compiler/mlir/lite/transforms/dilated_conv.h#L284

For example, tensor name: tcn/residual_block_1_1/conv1D_1/SpaceToBatchND/block_shape only has 1 element '2', so the pattern got rejected since it's less than 2 elements.

Could you change your model code where you specify the `block_shape` argument for the SpaceToBatchND op? Assuming you want to apply dilation rate 2 on both the height and width, you can just pass in [2, 2] in this case.",IssueComment,https://github.com/tensorflow/tensorflow/issues/38638#issuecomment-618070225,haozha111,2020-04-22 22:19:51,38638,[46150],Deployment bug,0,"I took a look at your graph. And I think the pattern doesn't get matched because this line: [url]#L284 For example, tensor name: tcn/residual_block_1_1/conv1D_1/SpaceToBatchND/block_shape only has 1 element '2', so the pattern got rejected since it's less than 2 elements. Could you change your model code where you specify the [code] argument for the SpaceToBatchND op? Assuming you want to apply dilation rate 2 on both the height and width, you can just pass in [2, 2] in this case.",0
"Thank you.

The problem is that I didn't create the ExpandDims -> Conv2D -> Squeeze sequence explicitly, so I don't have direct access to them. I have dilated Conv1D layers in my model which are handled by TensorFlow this way. The complexity that TF introduces to handle Conv1D is actually quite surprising. So I think that the conversion should take care of supporting dilated Conv1D as it does dilated Conv2D. I could extend it myself in a pull request if that could help. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/38638#issuecomment-618209588,colluca,2020-04-23 06:39:06,38638,[46150],Deployment bug,0,"Thank you. The problem is that I didn't create the ExpandDims -> Conv2D -> Squeeze sequence explicitly, so I don't have direct access to them. I have dilated Conv1D layers in my model which are handled by TensorFlow this way. The complexity that TF introduces to handle Conv1D is actually quite surprising. So I think that the conversion should take care of supporting dilated Conv1D as it does dilated Conv2D. I could extend it myself in a pull request if that could help.",1
I see. I think the TF high level python API just rewrite the dilated conv into SpaceToBatch -> Conv -> BatchToSpace automatically. If you could help extend this pass by supporting Conv1D that will be great. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/38638#issuecomment-618509995,haozha111,2020-04-23 16:45:40,38638,[46150],Deployment bug,0,I see. I think the TF high level python API just rewrite the dilated conv into SpaceToBatch -> Conv -> BatchToSpace automatically. If you could help extend this pass by supporting Conv1D that will be great. Thanks!,3
"Hi @haozha111,

Unfortunately I cannot make it to work on this, is there a chance someone could solve this?
I kind of depend on it, but if this weren't possible I'd go with an ugly custom pass in my hardware delegates for turnaround time reasons.

I would be available to support with more information on how to reproduce the issue, etc.",IssueComment,https://github.com/tensorflow/tensorflow/issues/38638#issuecomment-654673787,colluca,2020-07-07 08:03:47,38638,[46150],Deployment bug,0,"Hi @haozha111, Unfortunately I cannot make it to work on this, is there a chance someone could solve this? I kind of depend on it, but if this weren't possible I'd go with an ugly custom pass in my hardware delegates for turnaround time reasons. I would be available to support with more information on how to reproduce the issue, etc.",-1
"Hi,

I wouldn't have much time working on support for dilated conv1d. Do you mind either file a github issue or write the custom pass on your own? I believe the work should be  very similar with the current 2d case with little modifications.",IssueComment,https://github.com/tensorflow/tensorflow/issues/38638#issuecomment-656257630,haozha111,2020-07-09 17:33:57,38638,[46150],Deployment bug,0,"Hi, I wouldn't have much time working on support for dilated conv1d. Do you mind either file a github issue or write the custom pass on your own? I believe the work should be very similar with the current 2d case with little modifications.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38638"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38638"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/38638#issuecomment-764969669,google-ml-butler[bot],2021-01-21 22:02:16,38638,[46150],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46020"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46020"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46020#issuecomment-756474261,google-ml-butler[bot],2021-01-08 00:41:57,46020,[46198],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46261"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46261"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46261#issuecomment-758279222,google-ml-butler[bot],2021-01-11 23:02:46,46261,[46265],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46297"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46297"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46297#issuecomment-758254412,google-ml-butler[bot],2021-01-11 22:05:34,46297,[46298],Code bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46347"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46347"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46347#issuecomment-758908328,google-ml-butler[bot],2021-01-12 20:09:27,46347,[46350],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I have tried in colab with TF 2.4, nightly version (`2.5.0-dev20201123`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/1f64705325efcbd92eb88f177bea626d/untitled534.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/45137#issuecomment-732695387,ravikyram,2020-11-24 06:58:32,45137,[46364],Data bug,0,"I have tried in colab with TF 2.4, nightly version ([code]) and was able to reproduce the issue.Please, find the gist [here]([url] Thanks!",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45137"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45137"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/45137#issuecomment-763094135,google-ml-butler[bot],2021-01-19 20:01:58,45137,[46364],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@darmac,
In order to expedite the trouble-shooting process, could you please fill in the below template and provide the exact sequence of commands / steps that you executed before running into the problem?

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-678296773,amahendrakar,2020-08-21 13:41:28,42545,[46643],Build bug,0,"@darmac, In order to expedite the trouble-shooting process, could you please fill in the below template and provide the exact sequence of commands / steps that you executed before running into the problem? - OS Platform and Distribution (e.g., Linux Ubuntu 16.04): - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: - TensorFlow installed from (source or binary): - TensorFlow version: - Python version: - Installed using virtualenv? pip? conda?: - Bazel version (if compiling from source): - GCC/Compiler version (if compiling from source): - CUDA/cuDNN version: - GPU model and memory: Thanks!",0
"OS Platform and Distribution: `CentOS Linux 8`
Mobile device if the issue happens on mobile device: `N/A (TaiShan2280 V2 Server)`
TensorFlow installed from (source or binary): `source`
TensorFlow version: `V2.2.0`
Python version: `3.6.3`
Installed using: `pip`
Bazel version (if compiling from source): `2.0.0`
GCC/Compiler version (if compiling from source): `8.2.1`
CUDA/cuDNN version: `N/A`
GPU model and memory: `N/A`",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-678571743,darmac,2020-08-22 01:06:36,42545,[46643],Build bug,0,OS Platform and Distribution: [code] Mobile device if the issue happens on mobile device: [code] TensorFlow installed from (source or binary): [code] TensorFlow version: [code] Python version: [code] Installed using: [code] Bazel version (if compiling from source): [code] GCC/Compiler version (if compiling from source): [code] CUDA/cuDNN version: [code] GPU model and memory: [code],0
"@darmac,
A similar issue [#39185](https://github.com/tensorflow/tensorflow/issues/39185), was fixed in TensorFlow v2.3. Could you please update TensorFlow to v2.3 and check if you are facing the same issue?

Also, please provide the exact sequence of commands or the code that you executed before running into the error? Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-679233947,amahendrakar,2020-08-24 16:30:56,42545,[46643],Build bug,0,"@darmac, A similar issue [#39185]([url] was fixed in TensorFlow v2.3. Could you please update TensorFlow to v2.3 and check if you are facing the same issue? Also, please provide the exact sequence of commands or the code that you executed before running into the error? Thanks!",1
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-683916540,google-ml-butler[bot],2020-08-31 17:22:15,42545,[46643],Build bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
"Got it, I have not test the latest version yet. Thanks.",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-684143094,darmac,2020-09-01 01:50:19,42545,[46643],Build bug,0,"Got it, I have not test the latest version yet. Thanks.",2
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-688906633,google-ml-butler[bot],2020-09-08 14:16:24,42545,[46643],Build bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
Got it.,IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-689233192,darmac,2020-09-09 00:58:21,42545,[46643],Build bug,0,Got it.,0
"> Got it, I have not test the latest version yet. Thanks.

@darmac,
In this case, can we close the issue. Please feel free to re-open the issue when you have updates regarding it. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-691172209,amahendrakar,2020-09-11 15:46:01,42545,[46643],Build bug,0,"> Got it, I have not test the latest version yet. Thanks. @darmac, In this case, can we close the issue. Please feel free to re-open the issue when you have updates regarding it. Thanks!",2
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-694969909,google-ml-butler[bot],2020-09-18 16:41:12,42545,[46643],Build bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
"Closing as stale. Please reopen if you'd like to work on this further.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-699148581,google-ml-butler[bot],2020-09-25 20:50:11,42545,[46643],Build bug,0,Closing as stale. Please reopen if you'd like to work on this further.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42545"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42545"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/42545#issuecomment-699148678,google-ml-butler[bot],2020-09-25 20:50:24,42545,[46643],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #36716 for the support.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46676#issuecomment-767997421,yongtang,2021-01-27 03:33:24,46676,[46716],Data bug,1,Added a PR #36716 for the support.,0
"I have tried in colab with TF version 2.4, Nightly version and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/e8b0133170d8664f10faae4097a00c76/untitled639.ipynb).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46676#issuecomment-768855316,ravikyram,2021-01-28 07:23:49,46676,[46716],Data bug,1,"I have tried in colab with TF version 2.4, Nightly version and was able to reproduce the issue. Please, find the gist [here]([url]",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46676"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46676"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46676#issuecomment-784362930,google-ml-butler[bot],2021-02-23 17:17:19,46676,[46716],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@ymodak 
I ran the code on tf 2.4 and nightly but colab crashes, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/0f6ab8c1a411eac72ae6e4502faed92b/untitled509.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/46700#issuecomment-768029433,Saduf2019,2021-01-27 04:53:43,46700,[46741],Data bug,0,"@ymodak I ran the code on tf 2.4 and nightly but colab crashes, please find the [gist here]([url]",-2
Added a PR #46741 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46700#issuecomment-768557934,yongtang,2021-01-27 20:31:23,46700,[46741],Data bug,0,Added a PR #46741 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46700"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46700"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46700#issuecomment-771118117,google-ml-butler[bot],2021-02-01 19:58:15,46700,[46741],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I ran the code on tf 2.4 and tf-nightly colab crashes, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/37011b0996cc4cebc25af92ee4fa1839/untitled509.ipynb)",IssueComment,https://github.com/tensorflow/tensorflow/issues/46698#issuecomment-768030495,Saduf2019,2021-01-27 04:56:49,46698,[46742],Data bug,0,"I ran the code on tf 2.4 and tf-nightly colab crashes, please find the [gist here]([url]",-2
Added a PR #46742 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46698#issuecomment-768585995,yongtang,2021-01-27 21:22:43,46698,[46742],Data bug,0,Added a PR #46742 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46698"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46698"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46698#issuecomment-771127572,google-ml-butler[bot],2021-02-01 20:13:51,46698,[46742],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Reopening as #46742 was rolled back,IssueComment,https://github.com/tensorflow/tensorflow/issues/46698#issuecomment-779370708,mihaimaruseac,2021-02-15 17:45:34,46698,[46742],Data bug,0,Reopening as #46742 was rolled back,-1
Was able to reproduce in Nightly version TF 2.6 and the colab crashes. Pease find the gist [here](https://colab.research.google.com/gist/saikumarchalla/5df7d4f625bc4be94b76698dd78a1517/untitled92.ipynb#scrollTo=UnuuCWdFJcbp). Thanks1,IssueComment,https://github.com/tensorflow/tensorflow/issues/46698#issuecomment-850765274,saikumarchalla,2021-05-29 04:07:40,46698,[46742],Data bug,0,Was able to reproduce in Nightly version TF 2.6 and the colab crashes. Pease find the gist [here]([url]#scrollTo=UnuuCWdFJcbp). Thanks1,0
Hi @DNXie ! I think this bug has been addressed now. I getting value error instead of [Colab ](https://colab.sandbox.google.com/gist/mohantym/69e5e1575579a85cc94199ca9f03da35/github_46698.ipynb)getting crashed. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/46698#issuecomment-1040190053,mohantym,2022-02-15 12:00:51,46698,[46742],Data bug,0,Hi @DNXie ! I think this bug has been addressed now. I getting value error instead of [Colab ]([url] crashed. Thanks!,3
"@mohantym It seems to be fixed in the nightly version also. Thanks!

",IssueComment,https://github.com/tensorflow/tensorflow/issues/46698#issuecomment-1041927801,DNXie,2022-02-16 17:47:07,46698,[46742],Data bug,0,@mohantym It seems to be fixed in the nightly version also. Thanks!,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46698"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46698"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46698#issuecomment-1041927889,google-ml-butler[bot],2022-02-16 17:47:13,46698,[46742],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46724"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46724"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46724#issuecomment-769989458,google-ml-butler[bot],2021-01-29 19:01:55,46724,[46749],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46656"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46656"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46656#issuecomment-774217774,google-ml-butler[bot],2021-02-05 18:44:09,46656,[46798],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@abattery - thank you, where can I see the fix? (running the gist with installing the latest tf-nightly still throws the same error)",IssueComment,https://github.com/tensorflow/tensorflow/issues/46656#issuecomment-774640279,AiaHaruv,2021-02-07 09:15:43,46656,[46798],Deployment bug,0,"@abattery - thank you, where can I see the fix? (running the gist with installing the latest tf-nightly still throws the same error)",1
@juanma9613 Please feel free to raise a PR to update the docs. You check the following [resource](https://www.tensorflow.org/community/contribute/code) to contribute to improve the docs. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/46492#issuecomment-763326603,jvishnuvardhan,2021-01-20 04:38:59,46492,[46893],Documentation bug,0,@juanma9613 Please feel free to raise a PR to update the docs. You check the following [resource]([url] to contribute to improve the docs. Thanks!,3
"Done, I will add the PR at the end of the week. Thanks.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46492#issuecomment-765614932,juanma9613,2021-01-22 18:48:14,46492,[46893],Documentation bug,0,"Done, I will add the PR at the end of the week. Thanks.",3
"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/3beaf907cf0caf938eefcab8d92def67/46891.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46891#issuecomment-773196216,amahendrakar,2021-02-04 10:18:08,46891,[46973],Data bug,1,"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here]([url] Thanks!",0
Added PR #46973 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46891#issuecomment-774526080,yongtang,2021-02-06 19:04:41,46891,[46973],Data bug,1,Added PR #46973 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46891"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46891"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46891#issuecomment-815057487,google-ml-butler[bot],2021-04-07 16:36:31,46891,[46973],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I also observed the following API aliases can cause the same issue in older versions of tensorflow.
Users should be cautious when using them on both CPU and GPU up to tensorflow 2.4.0 (v2.4.0-rc4-71-g582c8d236cb).

- `(tf.transpose)`, `tf.compat.v1.transpose`

<details>
  <summary>Code to reproduce the issue in <code>tf.compat.v1.transpose</code> in older versions</summary>

```python
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION, flush=True)
print(tf.config.list_physical_devices(), flush=True)


try:
    tf.compat.v1.transpose(conjugate=True, a=complex(1))
except Exception as e:
    print(""Error:"", str(e), flush=True)
print(""Success!"", flush=True)
```

On GPU, the Check failed error occurs:

```text
v2.4.0-rc4-71-g582c8d236cb 2.4.0
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2023-09-08 10:49:02.743006: F ./tensorflow/core/kernels/transpose_functor.h:169] Check failed: in.dims() >= 2 (0 vs. 2)
Aborted (core dumped)
```

This behavior is also reproducible on my CPU machine:

```text
v2.4.0-rc4-71-g582c8d236cb 2.4.0
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
2023-09-08 10:48:56.754273: F ./tensorflow/core/kernels/transpose_functor.h:169] Check failed: in.dims() >= 2 (0 vs. 2)
Aborted (core dumped)
```
</details>

It seems to be fixed in tensorflow 2.4.3 (v2.4.2-142-g72bb4c22adb) and later versions.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46891#issuecomment-1729310859,oawxkw,2023-09-21 10:39:57,46891,[46973],Data bug,1,"I also observed the following API aliases can cause the same issue in older versions of tensorflow. Users should be cautious when using them on both CPU and GPU up to tensorflow 2.4.0 (v2.4.0-rc4-71-g582c8d236cb). - [code], [code] <details> <summary>Code to reproduce the issue in <code>tf.compat.v1.transpose</code> in older versions</summary> ``[code]`[code]`[code]`[code]`[code]`` </details> It seems to be fixed in tensorflow 2.4.3 (v2.4.2-142-g72bb4c22adb) and later versions.",0
"@rmothukuru 
I ran the code shared on tf 2.4 and nightly, colab crashes, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/e258b6a130140d89c1fd3325317982bc/untitled520.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/46900#issuecomment-773030313,Saduf2019,2021-02-04 05:02:42,46900,[46974],Data bug,1,"@rmothukuru I ran the code shared on tf 2.4 and nightly, colab crashes, please find the [gist here]([url]",-2
According to documentation https://www.tensorflow.org/api_docs/python/tf/strings/substr an error should be thrown out gracefully (instead of a crash). Added a PR #46974 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46900#issuecomment-774538913,yongtang,2021-02-06 20:28:49,46900,[46974],Data bug,1,According to documentation [url] an error should be thrown out gracefully (instead of a crash). Added a PR #46974 for the fix.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46900"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46900"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46900#issuecomment-776116583,google-ml-butler[bot],2021-02-09 17:43:32,46900,[46974],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@chinya07,
Thank you for reporting the error. 

The change is being tracked in PR [#47003](https://github.com/tensorflow/tensorflow/pull/47003) and will reflect as soon as it gets merged.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46998#issuecomment-775036888,amahendrakar,2021-02-08 10:20:30,46998,[47003],Documentation bug,0,"@chinya07, Thank you for reporting the error. The change is being tracked in PR [#47003]([url] and will reflect as soon as it gets merged.",3
Confirmed. This currently breaks TPU models on colab compiled with tf.contrib.tpu.keras_to_tpu_model. ,IssueComment,https://github.com/tensorflow/tensorflow/issues/25086#issuecomment-456786645,indrasweb,2019-01-23 12:39:05,25086,[47011],Algorithm design bug,0,Confirmed. This currently breaks TPU models on colab compiled with tf.contrib.tpu.keras_to_tpu_model.,-3
@fchollet - could you please help take a look? Appreciate it!,IssueComment,https://github.com/tensorflow/tensorflow/issues/25086#issuecomment-456905046,sjain-stanford,2019-01-23 18:03:21,25086,[47011],Algorithm design bug,0,@fchollet - could you please help take a look? Appreciate it!,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25086"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25086"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/25086#issuecomment-786309891,google-ml-butler[bot],2021-02-25 23:51:30,25086,[47011],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@ghop02 Can you please try `experimental_new_converter` and let us know whether the issue persists with most recent converter. I had tried the converter for several complex layers and the converter is working well. I have added `experimental_new_converter` to your code. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/85eebf3e3df8471d9b87b70943b759d0/untitled715.ipynb). 

`converter.experimental_new_converter = True`

Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-567595618,jvishnuvardhan,2019-12-19 17:55:44,35199,[47012],Deployment bug,0,@ghop02 Can you please try [code] and let us know whether the issue persists with most recent converter. I had tried the converter for several complex layers and the converter is working well. I have added [code] to your code. Please check the [gist here]([url] [code] Thanks!,2
"Hi @jvishnuvardhan , thanks for the response!

![image](https://user-images.githubusercontent.com/1422280/71234090-acba1780-22c5-11ea-8f33-1ea7fc12a051.png)

I still get a similar result.  If you look at the [link above](https://github.com/tensorflow/tensorflow/blob/v2.1.0-rc1/tensorflow/python/keras/activations.py#L43-L79), the keras softmax is converting to:
```
  elif ndim > 2:
    e = math_ops.exp(x - math_ops.reduce_max(x, axis=axis, keepdims=True))
    s = math_ops.reduce_sum(e, axis=axis, keepdims=True)
    return e / s
```

I think removing that logic, and just always returning the tf.nn.softmax operation would work, since I believe that code was written before tensorflow had support for `ndim > 2`",IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-567803663,ghop02,2019-12-20 06:14:19,35199,[47012],Deployment bug,0,"Hi @jvishnuvardhan , thanks for the response! ![image]([url] I still get a similar result. If you look at the [link above]([url]#L43-L79), the keras softmax is converting to: ``[code]`[code]ndim > 2`",0
Seems reasonable though I don't have the full history behind the Keras implementation. @fchollet any thoughts (or somebody else who can chime in)?,IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-568076126,jdduke,2019-12-20 20:25:13,35199,[47012],Deployment bug,0,Seems reasonable though I don't have the full history behind the Keras implementation. @fchollet any thoughts (or somebody else who can chime in)?,0
Any additional thoughts on this? Just bumping in case it got lost during the holidays!,IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-574764077,ghop02,2020-01-15 17:21:30,35199,[47012],Deployment bug,0,Any additional thoughts on this? Just bumping in case it got lost during the holidays!,0
"Facing same issue with tf.keras(TF 2.1.0), when is use x=Activation(""softmax"")(ip).
The tflite conversion is successful; but the layers appear as shown by @ghop02 

![tfbug](https://user-images.githubusercontent.com/1130185/73448772-9b196480-4387-11ea-82bc-32e6b15e5820.png)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-580224026,anilsathyan7,2020-01-30 12:10:41,35199,[47012],Deployment bug,0,"Facing same issue with tf.keras(TF 2.1.0), when is use x=Activation(""softmax"")(ip). The tflite conversion is successful; but the layers appear as shown by @ghop02 ![tfbug]([url]",-2
"@anilsathyan7 if you're blocked, you should be able to make this change to sneak the softmax operator in:
```diff
- out = Activation(""softmax"")(in)
+ out = tf.keras.layers.Lambda(lambda x: tf.nn.softmax(x))(in)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-580354380,ghop02,2020-01-30 17:05:00,35199,[47012],Deployment bug,0,"@anilsathyan7 if you're blocked, you should be able to make this change to sneak the softmax operator in: ``[code]``",0
"@ghop2: If you want to submit a PR for updating the [Keras softmax behavior](https://github.com/tensorflow/tensorflow/blob/v2.1.0-rc1/tensorflow/python/keras/activations.py#L73), we'd be happy to approve. Thanks again for flagging the issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-580377977,jdduke,2020-01-30 17:59:17,35199,[47012],Deployment bug,0,"@ghop2: If you want to submit a PR for updating the [Keras softmax behavior]([url]#L73), we'd be happy to approve. Thanks again for flagging the issue.",3
"> @anilsathyan7 if you're blocked, you should be able to make this change to sneak the softmax operator in:
> 
> ```diff
> - out = Activation(""softmax"")(in)
> + out = tf.keras.layers.Lambda(lambda x: tf.nn.softmax(x))(in)
> ```

I will also add that TF2.1 works with conversion but TF2.2 does not, when using this method",IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-652072018,sinclairnick,2020-06-30 22:08:02,35199,[47012],Deployment bug,0,"> @anilsathyan7 if you're blocked, you should be able to make this change to sneak the softmax operator in: > > ``[code]`` I will also add that TF2.1 works with conversion but TF2.2 does not, when using this method",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35199"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35199"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/35199#issuecomment-791593577,google-ml-butler[bot],2021-03-05 18:14:19,35199,[47012],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I am able to replicate the issue reported on tf 2.4 and tf-nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/cdb1c001d0fc15d73735806bba9a2cbd/untitled522.ipynb).
Thanks!

",IssueComment,https://github.com/tensorflow/tensorflow/issues/46993#issuecomment-774866899,Saduf2019,2021-02-08 05:01:49,46993,[47017],Algorithm design bug,0,"I am able to replicate the issue reported on tf 2.4 and tf-nightly, please find the [gist here]([url] Thanks!",0
I think when `alpha=None` is passed a ValueError could be thrown. Added a PR #47017 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46993#issuecomment-775468511,yongtang,2021-02-08 21:18:14,46993,[47017],Algorithm design bug,0,I think when [code] is passed a ValueError could be thrown. Added a PR #47017 for the fix.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46993"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46993"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46993#issuecomment-776335071,google-ml-butler[bot],2021-02-10 00:18:15,46993,[47017],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46860"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46860"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46860#issuecomment-776350284,google-ml-butler[bot],2021-02-10 00:49:58,46860,[47018],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@smit-hinsu FYI this is related to 47060,IssueComment,https://github.com/tensorflow/tensorflow/issues/47057#issuecomment-777147432,miaout17,2021-02-11 01:15:34,47057,[47060],Deployment bug,0,@smit-hinsu FYI this is related to 47060,0
"Hi @WindQAQ 

Did you experience any real issues? or did you just observed this change in the TFLite model?

The `shape` attributes in TFLite models are optional for most tensors, expect inputs & constants. 
The TFLite runtime actually does shape propagation and recompute shape for the rest of the tensors. 
So practically this shouldn't cause any problem. 

Your pull request still makes sense for improving the compiler/converter code quality. I'm just wondering if there's real issues triggerd by this behavior. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/47057#issuecomment-777148023,miaout17,2021-02-11 01:17:42,47057,[47060],Deployment bug,0,"Hi @WindQAQ Did you experience any real issues? or did you just observed this change in the TFLite model? The [code] attributes in TFLite models are optional for most tensors, expect inputs & constants. The TFLite runtime actually does shape propagation and recompute shape for the rest of the tensors. So practically this shouldn't cause any problem. Your pull request still makes sense for improving the compiler/converter code quality. I'm just wondering if there's real issues triggerd by this behavior.",1
"Thanks for the reply. There is actually no issue triggered by `shape`, just an observation.",IssueComment,https://github.com/tensorflow/tensorflow/issues/47057#issuecomment-777156403,WindQAQ,2021-02-11 01:48:06,47057,[47060],Deployment bug,0,"Thanks for the reply. There is actually no issue triggered by [code], just an observation.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47057"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47057"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47057#issuecomment-779774129,google-ml-butler[bot],2021-02-16 11:24:57,47057,[47060],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I'm new to open source, but to clarify, are you calling or referencing the function directly? If you reference the function object rather than initialize a new one (i.e. `tf.keras.initializers.zeros` instead of `tf.keras.initializers.zeros()`) without calling it, it will not work.",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-776421859,MaanasArora,2021-02-10 03:57:43,47054,[47128],Deployment bug,0,"I'm new to open source, but to clarify, are you calling or referencing the function directly? If you reference the function object rather than initialize a new one (i.e. [code] instead of [code]) without calling it, it will not work.",0
"@fawazahmed0 
Please provide with minimal stand alone indented code to replicate the issue reported or if possible share a colab gist with the error.
The usage of these depends on the context they are used in,Zeros behavior is more suitable for including it inside models and serializing them.",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-776696437,Saduf2019,2021-02-10 13:12:25,47054,[47128],Deployment bug,0,"@fawazahmed0 Please provide with minimal stand alone indented code to replicate the issue reported or if possible share a colab gist with the error. The usage of these depends on the context they are used in,Zeros behavior is more suitable for including it inside models and serializing them.",0
"Well, I was going through, [timeseries forecasting tutorial](https://www.tensorflow.org/tutorials/structured_data/time_series) and when I tried to save the model it failed, I just had to change `tf.initializers.zeros` to `tf.initializers.zeros()` to make it working.

Here is the [colab](https://colab.research.google.com/drive/1E0P-aBU9B7RO_QUtDrlRDPcOWqd6UfkD?usp=sharing#scrollTo=weBjeZAFJOP4)

 ",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-776962458,fawazahmed0,2021-02-10 19:34:05,47054,[47128],Deployment bug,0,"Well, I was going through, [timeseries forecasting tutorial]([url] and when I tried to save the model it failed, I just had to change [code] to [code] to make it working. Here is the [colab]([url]#scrollTo=weBjeZAFJOP4)",0
"Minimal code sample which reproduces the error ([colab](https://colab.research.google.com/drive/1ehWxx6PaDKP6nFMaI2Nf84O3-Xyv3-Sm?usp=sharing) link):

```python
import tensorflow as tf   # issue was reproduced with tf.__version__ == 2.4.1

model = tf.keras.Sequential([
    tf.keras.layers.Reshape((-1, 784)),
    tf.keras.layers.Lambda(lambda x: tf.divide(tf.cast(x, tf.float32), 255.)),
    tf.keras.layers.Dense(256, activation='relu', bias_initializer=tf.initializers.zeros),
    tf.keras.layers.Dense(10, activation='softmax',)
])

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, validation_data=(x_test, y_test))
model.save('test')
```

exception:
```
TypeError                                 Traceback (most recent call last)
<...>

TypeError: get_config() missing 1 required positional argument: 'self'
```

The same code with tf.initializers.Zeros() would work fine `tf.initializers.Zeros()`, as @fawazahmed0 mentioned:

```python
import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Reshape((-1, 784)),
    tf.keras.layers.Lambda(lambda x: tf.divide(tf.cast(x, tf.float32), 255.)),
    tf.keras.layers.Dense(256, activation='relu', bias_initializer=tf.initializers.Zeros()),
    tf.keras.layers.Dense(10, activation='softmax',)
])

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, validation_data=(x_test, y_test))
model.save('test')
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-777644429,mishc9,2021-02-11 17:03:26,47054,[47128],Deployment bug,0,Minimal code sample which reproduces the error ([colab]([url] link): ``[code]`[code]`[code]`[code]tf.initializers.Zeros()[code]`[code]``,0
"I guess it could be simplified to the following gist ([colab](https://colab.research.google.com/drive/1jqONjLpZe1V6DYt9XulC9YFVifetUnFm?usp=sharing)):

```python
import tensorflow as tf

layer = tf.keras.layers.Dense(256, bias_initializer=tf.initializers.zeros)
layer.get_config()

Out: 
...
TypeError: get_config() missing 1 required positional argument: 'self'
```

But the following snippet works just fine:
```python
import tensorflow as tf

layer = tf.keras.layers.Dense(256, bias_initializer=tf.initializers.Zeros())
layer.get_config()
Out: 
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},,
 ...
 'units': 256,
 'use_bias': True}
```

The same logic holds for other initializers. For example, `tf.initializers.he_uniform` will fail with the same error if `get_config` is called, but  `tf.initializers.HeUniform` will not.

I'm not sure if it is a problem or it's by design. But it's at least confusing because models trained with ""`tf.initializers.zeros` - like"" initializers use them properly except for the model serialization.  
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-777668916,mishc9,2021-02-11 17:41:24,47054,[47128],Deployment bug,0,"I guess it could be simplified to the following gist ([colab]([url] ``[code]`[code]`[code]`[code]tf.initializers.he_uniform[code]get_config[code]tf.initializers.HeUniform[code]tf.initializers.zeros` - like"" initializers use them properly except for the model serialization.",0
"@mishc9 To me, it appears that the `tf.initializers.zeros` shortcut function was intended to be _called_ rather than referenced as-is, i.e. it generates an object of the `tf.keras.initializers.Zeros` class. The class and the shortcut function are exported with the same `@keras_export` decorator in the source code. 

If you run the colab with `tf.initializers.zeros()` in place of `tf.initializers.zeros`, it works just fine.",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-777713260,MaanasArora,2021-02-11 18:55:13,47054,[47128],Deployment bug,0,"@mishc9 To me, it appears that the [code] shortcut function was intended to be _called_ rather than referenced as-is, i.e. it generates an object of the [code] class. The class and the shortcut function are exported with the same [code] decorator in the source code. If you run the colab with [code] in place of [code], it works just fine.",0
"@MaanasArora you're right, it should be provided to the layer constructor as `tf.initializers.zeros()` (better way to do this), not  `tf.initializers.zeros`. But the strange thing is that it still would work even in the later case ([colab](https://colab.research.google.com/drive/1R1K3olMovqhX7z7qW1AwbmhbK12WeEjq#scrollTo=In65cIrYpBst)).

I think this behaviour should be treated as an issue if the way to provide an initializer in the form of `tf.initializers.zeros` is allowed and it initializers weights the right way (because it's the main purpose of initializers). 

On the other hand, if this way to use initializers is not a 'regular' way to use them and trained model could fail, there should be a warning (at least, may be exception) during the model build/compile stage in my opinion. Not sure about backward compatibility - raise an exception could break some old code. It is 'correct' way to initialize weights & biases in the [standalone](https://github.com/keras-team/keras) `keras` API. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-777772270,mishc9,2021-02-11 20:35:45,47054,[47128],Deployment bug,0,"@MaanasArora you're right, it should be provided to the layer constructor as [code] (better way to do this), not [code]. But the strange thing is that it still would work even in the later case ([colab]([url]#scrollTo=In65cIrYpBst)). I think this behaviour should be treated as an issue if the way to provide an initializer in the form of [code] is allowed and it initializers weights the right way (because it's the main purpose of initializers). On the other hand, if this way to use initializers is not a 'regular' way to use them and trained model could fail, there should be a warning (at least, may be exception) during the model build/compile stage in my opinion. Not sure about backward compatibility - raise an exception could break some old code. It is 'correct' way to initialize weights & biases in the [standalone]([url] [code] API.",0
"@mishc9 Yes, it oddly works in both cases and it's inconsistent because `tf.initializers.zeros` only creates issues during serialization.

Further, I noticed that when I passed `tf.initializers.Zeros` instead of `tf.initializers.Zeros`, it _also_ worked, and it also had the same error as `tf.initializers.zeros` when serializing the model. So I think that the issue is not with the shortcut function but that the class itself can be used directly without initializing an instance but breaks when serializing the model.

Looking at the source, I suspect that the class itself was not intended to be passed to the layer constructor. I will review the source further to be sure.",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-777789234,MaanasArora,2021-02-11 21:04:05,47054,[47128],Deployment bug,0,"@mishc9 Yes, it oddly works in both cases and it's inconsistent because [code] only creates issues during serialization. Further, I noticed that when I passed [code] instead of [code], it _also_ worked, and it also had the same error as [code] when serializing the model. So I think that the issue is not with the shortcut function but that the class itself can be used directly without initializing an instance but breaks when serializing the model. Looking at the source, I suspect that the class itself was not intended to be passed to the layer constructor. I will review the source further to be sure.",0
"@MaanasArora that is interesting. I looked here and there in the source code too and still do not understand what's the reason of this issue :( 
[Function](https://github.com/tensorflow/tensorflow/blob/132437408620c947aaa43db31ce442a2b30dec12/tensorflow/python/keras/initializers/__init__.py#L150) `initializers.get` dispatches initializers:

```python 
@keras_export('keras.initializers.get')
def get(identifier):
  if identifier is None:
    return None
  if isinstance(identifier, dict):
    return deserialize(identifier)
  elif isinstance(identifier, six.string_types):
    identifier = str(identifier)
    return deserialize(identifier)
  elif callable(identifier):
    return identifier
  else:
    raise ValueError('Could not interpret initializer identifier: ' +
                     str(identifier))
```

It is invoked [here](https://github.com/tensorflow/tensorflow/blob/132437408620c947aaa43db31ce442a2b30dec12/tensorflow/python/keras/layers/core.py#L1164) in `__init__` of the layer and later, during 'build' stage, in `add_weight` [method](https://github.com/tensorflow/tensorflow/blob/132437408620c947aaa43db31ce442a2b30dec12/tensorflow/python/keras/engine/base_layer.py#L591). But it should return the identity of the provided object, because the `tf.initializers.zeros`/`tf.initializers.Zeros` is callable. And we couldn't use this object to initialize weights - it is just initializer class. So perhaps I missed something, probably would use debugger to localise the error. 

**Edit**

Just found instantiation of type object initializer [here](https://github.com/tensorflow/tensorflow/blob/132437408620c947aaa43db31ce442a2b30dec12/tensorflow/python/keras/engine/base_layer_utils.py#L121):

```python
  else:
    # Instantiate initializer if provided initializer is a type object.
    if tf_inspect.isclass(initializer):
      initializer = initializer()
```

So, it seems like we could provide an initializer as a type object by design.

Frames (`tf` of the older version `2.2.1`, so lines could differ now):
<img width=""405"" alt=""image"" src=""https://user-images.githubusercontent.com/15159090/107704354-28e39b80-6cce-11eb-9d34-3150363dc18c.png"">
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-777798097,mishc9,2021-02-11 21:18:36,47054,[47128],Deployment bug,0,"@MaanasArora that is interesting. I looked here and there in the source code too and still do not understand what's the reason of this issue :( [Function]([url]#L150) [code] dispatches initializers: ``[code]`[code]__init__[code]add_weight[code]tf.initializers.zeros[code]tf.initializers.Zeros[code]`[code]`[code]tf[code]2.2.1`, so lines could differ now): <img width=""405"" alt=""image"" src=""[url]"">",-1
"@mishc9 Note that the variable is instantiated in the `add_weight` method, so when `get_config` is called, the initializer attribute of the layer object is still a class. So, the problem is that the `get_config` method is not accessing the object that is created in `add_weight`, but rather the (class type) attribute itself.

I'm not sure if it fits the design or function very well, but a possible solution would be to check if an attribute is a class during serialization and instantiate it if it is. Should I create a pull request with these changes?",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-778303000,MaanasArora,2021-02-12 16:38:25,47054,[47128],Deployment bug,0,"@mishc9 Note that the variable is instantiated in the [code] method, so when [code] is called, the initializer attribute of the layer object is still a class. So, the problem is that the [code] method is not accessing the object that is created in [code], but rather the (class type) attribute itself. I'm not sure if it fits the design or function very well, but a possible solution would be to check if an attribute is a class during serialization and instantiate it if it is. Should I create a pull request with these changes?",0
"@MaanasArora yes, exactly. In a layer object initializer is still a class, because `getter` function called in `add_weight` does not change the layer object itself. 

I've tested locally following changes to the function `initialisers.get`: 

```python
@keras_export('keras.initializers.get')
def get(identifier):
  if identifier is None:
    return None
  if isinstance(identifier, dict):
    return deserialize(identifier)
  elif isinstance(identifier, six.string_types):
    identifier = str(identifier)
    return deserialize(identifier)
  elif callable(identifier):
    if inspect.isclass(identifier):  # Additional check copied from the snippet above
      identifier = identifier()
    return identifier
  else:
    raise ValueError('Could not interpret initializer identifier: ' +
                     str(identifier))
```
and it worked. This function transforms type object initializer to the object initializer, as the `getter` in `add_weight` method does. 

I thought of changes in the serialisation function too. But it seems this solution could affect other serialised objects: activations, layers, regularizers etc. It's hards to handle all this cases carefully.  But `get` function is only for initializers. There's a cons to the `initializers.get` change too: type of provided argument will be changed implicitly. But it is true for `string` and `dict` initializers now.

I would make a PR with this change, but have had a problem with tensorflow local unit testing ðŸ¤·â€â™‚ï¸. Just could not run them. I would send PR without any additional unit tests covering this issue though. By the way, have you seen any additional intstructions how to dev & tests tensorflow on the local machine, except the contributing guidelines? Than would be great :) ",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-778379410,mishc9,2021-02-12 18:47:33,47054,[47128],Deployment bug,0,"@MaanasArora yes, exactly. In a layer object initializer is still a class, because [code] function called in [code] does not change the layer object itself. I've tested locally following changes to the function [code]: ``[code]`[code]getter[code]add_weight[code]get[code]initializers.get[code]string[code]dict` initializers now. I would make a PR with this change, but have had a problem with tensorflow local unit testing ðŸ¤·â€â™‚ï¸. Just could not run them. I would send PR without any additional unit tests covering this issue though. By the way, have you seen any additional intstructions how to dev & tests tensorflow on the local machine, except the contributing guidelines? Than would be great :)",0
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-783104944,google-ml-butler[bot],2021-02-22 05:52:16,47054,[47128],Deployment bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
"Closing as stale. Please reopen if you'd like to work on this further.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-787671750,google-ml-butler[bot],2021-03-01 06:06:06,47054,[47128],Deployment bug,0,Closing as stale. Please reopen if you'd like to work on this further.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47054"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47054"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47054#issuecomment-787671791,google-ml-butler[bot],2021-03-01 06:06:09,47054,[47128],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/88605d7199898f076e057b8ed35457c9/46539.ipynb#scrollTo=NRQ2tF_zk5qY). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46539#issuecomment-763717080,amahendrakar,2021-01-20 15:39:13,46539,[47135],Data bug,0,"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here]([url]#scrollTo=NRQ2tF_zk5qY). Thanks!",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46539"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46539"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46539#issuecomment-784297830,google-ml-butler[bot],2021-02-23 15:47:21,46539,[47135],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@OlafEichstaedt,
Thank you for reporting the issue.

The requested change is being tracked in PR [#47310](https://github.com/tensorflow/tensorflow/pull/47310). The link will be updated once the PR is merged. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/47305#issuecomment-783323421,amahendrakar,2021-02-22 11:58:18,47305,[47310],Documentation bug,0,"@OlafEichstaedt, Thank you for reporting the issue. The requested change is being tracked in PR [#47310]([url] The link will be updated once the PR is merged. Thanks!",3
"The reason is in `_zero_initialize_bss_data` (tensorflow/lite/micro/tools/make/downloads/stm32_bare_lib/source/startup.c). It initializes the BSS data with DEADBEEF.

To verify that:

Build with debug info
```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill BUILD_TYPE=debug test_renode -j`nproc`
```

Run in Renode:
```
include @tensorflow/lite/micro/testing/bluepill_nontest.resc; sysbus LoadELF @tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3_debug/bin/test_renode; machine StartGdbServer 3333
```

Start GDB:
```
tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/arm-none-eabi-gdb tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3_debug/bin/test_renode
```

In GDB:
```
tar rem :3333
watch *0x20000008
mon s
c
```

It will break in the code that actually writes this data.

Now why do they go to bss instead of data? I don't know.

Here's an excerpt from the objdump:

```
Disassembly of section .data:

20000000 <a>:                        <- OK
20000000:   0000002d    andeq   r0, r0, sp, lsr #32

20000004 <init_to_true>:                        <- OK
20000004:   00000001    andeq   r0, r0, r1

Disassembly of section .bss: 

20000008 <init_to_false>:                        <- NOT OK
20000008:   00000000    andeq   r0, r0, r0

2000000c <init_to_nullptr>:                        <- NOT OK
2000000c:   00000000    andeq   r0, r0, r0

20000010 <g_tick_count>:                        <- NOT OK
20000010:   00000000    andeq   r0, r0, r0

Disassembly of section ._user_heap_stack:

20000014 <._user_heap_stack>:
    ...   
```

For the record, this is HAL specific, so it should behave the same way on HW, not only in Renode.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46937#issuecomment-784994556,PiotrZierhoffer,2021-02-24 11:00:14,46937,[47382],Code bug,1,"The reason is in [code] (tensorflow/lite/micro/tools/make/downloads/stm32_bare_lib/source/startup.c). It initializes the BSS data with DEADBEEF. To verify that: Build with debug info ``[code]nproc[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`` For the record, this is HAL specific, so it should behave the same way on HW, not only in Renode.",0
Changing 0xDEADBEEF to 0 of course fixes the problem,IssueComment,https://github.com/tensorflow/tensorflow/issues/46937#issuecomment-785050816,PiotrZierhoffer,2021-02-24 12:46:29,46937,[47382],Code bug,1,Changing 0xDEADBEEF to 0 of course fixes the problem,0
"Your example @advaitjain has similar results on `stm32f4` also built with `stm32_bare_lib` that causes the problem.

The `-559038737` number that is printed as `init_to_nullptr` is exactly a signed int value for `0xDEADBEEF`. The `239` in `init_to_false` is the ending `0xEF` byte.

I remember stumbling upon an issue with this BSS initialization when code from such an `if` was never executed:
```
static TYPE* some_pointer = nullptr;
if (!some_pointer){
    // Code never called
}
```
The compiler simply assumed a static pointer is always `nullptr` (`0x0`) right after declaration and skipped the ""additional"" `nullptr` initialization while it was `0xDEADBEEF` instead.

Now I can see there's no such problem anymore so perhaps the compiler has been fixed.

Nevertheless, this issue made me wonder again about what the purpose of that `0xDEADBEEF` initialization is. The binaries work well without it. Perhaps it could be simply disabled @aselle @petewarden? https://github.com/google/stm32_bare_lib/blob/55bf49816f1a9dc7d9e35951c135e852ce7a98df/source/startup.c#L114",IssueComment,https://github.com/tensorflow/tensorflow/issues/46937#issuecomment-785339466,ajelinski,2021-02-24 20:06:22,46937,[47382],Code bug,1,Your example @advaitjain has similar results on [code] also built with [code] that causes the problem. The [code] number that is printed as [code] is exactly a signed int value for [code]. The [code] in [code] is the ending [code] byte. I remember stumbling upon an issue with this BSS initialization when code from such an [code] was never executed: ``[code]`[code]nullptr[code]0x0[code]nullptr[code]0xDEADBEEF[code]0xDEADBEEF` initialization is. The binaries work well without it. Perhaps it could be simply disabled @aselle @petewarden? [url]#L114,0
"Thanks for the debugging @PiotrZierhoffer.

@ajelinski, I'm not sure about the thinking behind the decision to go with not zero initializing the .bss -- it does seem non-standard.

I have made https://github.com/tensorflow/tensorflow/pull/47382 that fixes this issue independent of upstream changes to STM32 Bare Lib and also answers @PiotrZierhoffer's comment about why the variables are ending up in .bss instead of .data

This link has some useful info as well: https://stackoverflow.com/q/8721475
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46937#issuecomment-785414007,advaitjain,2021-02-24 22:02:06,46937,[47382],Code bug,1,"Thanks for the debugging @PiotrZierhoffer. @ajelinski, I'm not sure about the thinking behind the decision to go with not zero initializing the .bss -- it does seem non-standard. I have made [url] that fixes this issue independent of upstream changes to STM32 Bare Lib and also answers @PiotrZierhoffer's comment about why the variables are ending up in .bss instead of .data This link has some useful info as well: [url]",1
"Talked to @petewarden and we decided that changine STM32 Bare Lib is the way to go.

> 
> I have made #47382 that fixes this issue independent of upstream changes to STM32 Bare Lib and also answers @PiotrZierhoffer's comment about why the variables are ending up in .bss instead of .data
> 
> This link has some useful info as well: [stackoverflow.com/q/8721475](https://stackoverflow.com/q/8721475)

#47382 originally added `-fno-zero-initialized-in-bss` and verified that the globals were in the .data section instead of .bss using the tips from https://stackoverflow.com/q/8721475

It has since been updated to simply pull in an updated version of STM32 Bare Lib (with the zero initialization of .bss)",IssueComment,https://github.com/tensorflow/tensorflow/issues/46937#issuecomment-785431018,advaitjain,2021-02-24 22:37:57,46937,[47382],Code bug,1,Talked to @petewarden and we decided that changine STM32 Bare Lib is the way to go. > > I have made #47382 that fixes this issue independent of upstream changes to STM32 Bare Lib and also answers @PiotrZierhoffer's comment about why the variables are ending up in .bss instead of .data > > This link has some useful info as well: [stackoverflow.com/q/8721475]([url] #47382 originally added [code] and verified that the globals were in the .data section instead of .bss using the tips from [url] It has since been updated to simply pull in an updated version of STM32 Bare Lib (with the zero initialization of .bss),0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46937"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46937"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46937#issuecomment-785483084,google-ml-butler[bot],2021-02-25 00:22:28,46937,[47382],Code bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@dd1923 

Will it be possible to share the colab link or simple standalone code to reproduce the issue reported here.It helps us in localizing the issue faster.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/39230#issuecomment-625058236,ravikyram,2020-05-07 06:33:04,39230,[47412],Algorithm design bug,0,@dd1923 Will it be possible to share the colab link or simple standalone code to reproduce the issue reported here.It helps us in localizing the issue faster.Thanks!,3
@ravikyram Did you read the post above? What do you want to reproduce? The documentation and the code link I mentioned clearly shows it. This is a case of bad api design.,IssueComment,https://github.com/tensorflow/tensorflow/issues/39230#issuecomment-625329517,dsuthar-nvidia,2020-05-07 15:35:19,39230,[47412],Algorithm design bug,0,@ravikyram Did you read the post above? What do you want to reproduce? The documentation and the code link I mentioned clearly shows it. This is a case of bad api design.,-3
@pavithrasv ,IssueComment,https://github.com/tensorflow/tensorflow/issues/39230#issuecomment-629509681,dsuthar-nvidia,2020-05-15 21:47:28,39230,[47412],Algorithm design bug,0,@pavithrasv,0
@jhseu @pavithrasv when do you think this would be assigned to someone?,IssueComment,https://github.com/tensorflow/tensorflow/issues/39230#issuecomment-631800022,dsuthar-nvidia,2020-05-21 00:01:39,39230,[47412],Algorithm design bug,0,@jhseu @pavithrasv when do you think this would be assigned to someone?,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39230"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39230"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39230#issuecomment-857919115,google-ml-butler[bot],2021-06-09 17:59:32,39230,[47412],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
PR is #47521 ,IssueComment,https://github.com/tensorflow/tensorflow/issues/47520#issuecomment-789562732,brychcy,2021-03-03 09:15:23,47520,[47521],Visualization bug,0,PR is #47521,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47520"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47520"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47520#issuecomment-816090491,google-ml-butler[bot],2021-04-08 19:23:08,47520,[47521],Visualization bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I can help to fix if my judgement is correct. That would be my first code contribution to TF :) ,IssueComment,https://github.com/tensorflow/tensorflow/issues/47464#issuecomment-787512945,CyangXu,2021-02-28 20:02:02,47464,[47567],Code bug,0,I can help to fix if my judgement is correct. That would be my first code contribution to TF :),3
@ymodak I sent in a pull request which must solve this.,IssueComment,https://github.com/tensorflow/tensorflow/issues/47464#issuecomment-790817185,around-star,2021-03-04 18:06:51,47464,[47567],Code bug,0,@ymodak I sent in a pull request which must solve this.,2
I expected that I could become the assignee and fixed it. Why not give a newbie an opportunity? So sad. ,IssueComment,https://github.com/tensorflow/tensorflow/issues/47464#issuecomment-790832313,CyangXu,2021-03-04 18:30:04,47464,[47567],Code bug,0,I expected that I could become the assignee and fixed it. Why not give a newbie an opportunity? So sad.,-3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47464"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47464"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47464#issuecomment-791566362,google-ml-butler[bot],2021-03-05 17:27:49,47464,[47567],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@CyangXu Thanks for your issue. Assignee's generally facilitate the PR merging process, you may want to raise PR as an author to fix issue/add new feature. I am sorry you missed this opportunity however feel free to raise PR to address any other issue of your choice and we can help merge it. Contributions from the community are highly encouraged and welcomed. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/47464#issuecomment-791829913,ymodak,2021-03-06 01:30:07,47464,[47567],Code bug,0,"@CyangXu Thanks for your issue. Assignee's generally facilitate the PR merging process, you may want to raise PR as an author to fix issue/add new feature. I am sorry you missed this opportunity however feel free to raise PR to address any other issue of your choice and we can help merge it. Contributions from the community are highly encouraged and welcomed. Thanks!",3
@ymodak Thank you for explanation!,IssueComment,https://github.com/tensorflow/tensorflow/issues/47464#issuecomment-798809551,CyangXu,2021-03-14 00:50:23,47464,[47567],Code bug,0,@ymodak Thank you for explanation!,3
"Are you satisfied with the resolution of your issue?
[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)
[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)",IssueComment,https://github.com/tensorflow/tensorflow/issues/47464#issuecomment-798836472,ymodak,2021-03-14 05:29:59,47464,[47567],Code bug,0,Are you satisfied with the resolution of your issue? [Yes]([url] [No]([url],0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47575"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47575"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47575#issuecomment-793186637,google-ml-butler[bot],2021-03-09 00:01:52,47575,[47653],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46453"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46453"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-760803862,google-ml-butler[bot],2021-01-15 10:16:57,46453,[47698],Deployment bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to run the code without any issues on [TF v2.4](https://colab.research.google.com/gist/amahendrakar/7f400de432bddbf6b4e47a0feb33ed7a/46453.ipynb).

However, session crashes on running the code with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/be033a6c68b0028f5522924ef378e66b/46453-tf-nightly.ipynb#scrollTo=rdbO5RSdFM6a) (i.e. v2.5.0-dev20210114). Please check the linked gist for reference. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-761084482,amahendrakar,2021-01-15 17:44:59,46453,[47698],Deployment bug,1,"Was able to run the code without any issues on [TF v2.4]([url] However, session crashes on running the code with [TF-nightly]([url]#scrollTo=rdbO5RSdFM6a) (i.e. v2.5.0-dev20210114). Please check the linked gist for reference. Thanks!",-1
"I can successfully convert, build, and then load back the model in `2.4.0`. But if I include `tf.image.combined_non_max_suppression` op for conversion, I get totally wrong predictions from the converted model. 

The same code fails in nightly `dev20210114`.


For reference, this is how i call `tf.image.combined_non_max_suppression`

```python
def call(self, predictions):
    box_predictions, class_predictions = predictions

    class_predictions = tf.cast(class_predictions, dtype=tf.float32)
    box_predictions = tf.cast(box_predictions, dtype=tf.float32)

    class_predictions = tf.nn.sigmoid(class_predictions)  #  [batch_size, num_anchors, num_classes]
    boxes = self._decode_box_predictions(self._anchors.boxes[None, ...],
                                         box_predictions)   #  [batch_size, num_anchors, 4]; (absolute coordinates)

    if self.pre_nms_top_k > 0:  #  This condition return false because `pre_nms_top_k` is -1 always
        top_k_class_predictions, top_k_boxes = self._filter_top_k(
            class_predictions, boxes)

    else:
        top_k_boxes = tf.expand_dims(boxes, axis=2)   #  [batch_size, num_anchors, 1, 4]; (absolute coordinates)
        top_k_class_predictions = class_predictions #  [batch_size, num_anchors, num_classes]

    return tf.image.combined_non_max_suppression(
        top_k_boxes,
        top_k_class_predictions,
        self.max_detections_per_class,  #  100
        self.max_detections,  #  100
        self.nms_iou_threshold,  #  0.5
        self.confidence_threshold,  #  0.05
        clip_boxes=False,
    )
```

**EDIT 1**: I could fix the wrong predictions issue (after conversion) by using normalized coordinates (when x1, y1, x2, y2 lie in [0, 1])
But according to [the documentation](https://www.tensorflow.org/api_docs/python/tf/image/combined_non_max_suppression), both normalized and absolute coordinates should work. I think the TRT plugin only supports normalized coordinates.
```
... ""Bounding boxes are supplied as [y1, x1, y2, x2], where (y1, x1) and (y2, x2) 
are the coordinates of any diagonal pair of box corners and the coordinates can
be provided as normalized (i.e., lying in the interval [0, 1]) or absolute""...
```

**EDIT 2**
Looks like this is the reason why we always send normalized coordinates to TRT plugin
https://github.com/tensorflow/tensorflow/blob/4fa4184a5a454eceb5b567c8b3c4fce46faf2de8/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5911-L5917",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-761130922,srihari-humbarwadi,2021-01-15 19:07:55,46453,[47698],Deployment bug,1,"I can successfully convert, build, and then load back the model in [code]. But if I include [code] op for conversion, I get totally wrong predictions from the converted model. The same code fails in nightly [code]. For reference, this is how i call [code] ``[code]pre_nms_top_k[code]`[code]`[code]`` **EDIT 2** Looks like this is the reason why we always send normalized coordinates to TRT plugin [url]#L5911-L5917",-2
@bixia1 what do you think?  Is [this](https://github.com/tensorflow/tensorflow/blob/4fa4184a5a454eceb5b567c8b3c4fce46faf2de8/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5914) correct?,IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-765017721,sanjoy,2021-01-21 23:58:34,46453,[47698],Deployment bug,1,@bixia1 what do you think? Is [this]([url]#L5914) correct?,0
"The [PR in question](https://github.com/tensorflow/tensorflow/pull/40062) (merged on 1/13/2021) doesnâ€™t make any change in terms of always use normalized coordinate in TF-TRT.

The [TF document](https://www.tensorflow.org/api_docs/python/tf/image/combined_non_max_suppression) says the bounding box coordinates can be normalized or absolute values. But I couldn't tell how the operation representation indicate whether the coordinates are normalized or absolute values.  I looked at [the implement of the compute method for the operation](https://github.com/tensorflow/tensorflow/blob/9045dcaf276cb7b24fde33da09165cb38d157a5e/tensorflow/core/kernels/image/non_max_suppression_op.cc#L916) and couldn't figure out this either. I am asking for information about this in an internal channel.

",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-765069987,bixia1,2021-01-22 02:25:50,46453,[47698],Deployment bug,1,The [PR in question]([url] (merged on 1/13/2021) doesnâ€™t make any change in terms of always use normalized coordinate in TF-TRT. The [TF document]([url] says the bounding box coordinates can be normalized or absolute values. But I couldn't tell how the operation representation indicate whether the coordinates are normalized or absolute values. I looked at [the implement of the compute method for the operation]([url]#L916) and couldn't figure out this either. I am asking for information about this in an internal channel.,0
@tfeher ,IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-765071602,bixia1,2021-01-22 02:31:04,46453,[47698],Deployment bug,1,@tfeher,0
"I got an answer from the TensorFlow people which help me understand the situation. The TensorFlow implementation for the operation is the same regardless whether the coordinates are normalized or absolute values. On the other hand, the TensorRT implementation requires a parameter that specifies whether the coordinates are normalized or not, see code [here](https://github.com/tensorflow/tensorflow/blob/ab9eb3d10400c92b15bfae62b284bf9937cb1845/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5951-L5952). If this field is indeed used in the TensorRT implementation, then we have a problem here. Now the question is why it was working before the  [PR in question](https://github.com/tensorflow/tensorflow/pull/40062)? I will let @tfeher and @DEKHTIARJonathan take care of this.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-765173745,bixia1,2021-01-22 06:42:09,46453,[47698],Deployment bug,1,"I got an answer from the TensorFlow people which help me understand the situation. The TensorFlow implementation for the operation is the same regardless whether the coordinates are normalized or absolute values. On the other hand, the TensorRT implementation requires a parameter that specifies whether the coordinates are normalized or not, see code [here]([url]#L5951-L5952). If this field is indeed used in the TensorRT implementation, then we have a problem here. Now the question is why it was working before the [PR in question]([url] I will let @tfeher and @DEKHTIARJonathan take care of this.",0
"@bixia1 There are two issues here, 
 - Conversion of `tf.image.combined_non_max_suppression` in nightly fails. But works in `2.4.0`
 - Reading the comments [here](https://github.com/tensorflow/tensorflow/blob/4fa4184a5a454eceb5b567c8b3c4fce46faf2de8/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5911-L5917), calculation of width/height differs in tensorrt vs tensorflow op. To avoid this, the converter always assumes the users are sending normalized coordinates [here](https://github.com/tensorflow/tensorflow/blob/4fa4184a5a454eceb5b567c8b3c4fce46faf2de8/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5918).

Hence, if the users want to export `tf.image.combined_non_max_suppression` to tensorrt, they should make sure that they are sending normalized coordinates. But the documentation fails to warn the user about this.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-765386586,srihari-humbarwadi,2021-01-22 13:11:18,46453,[47698],Deployment bug,1,"@bixia1 There are two issues here, - Conversion of [code] in nightly fails. But works in [code] - Reading the comments [here]([url]#L5911-L5917), calculation of width/height differs in tensorrt vs tensorflow op. To avoid this, the converter always assumes the users are sending normalized coordinates [here]([url]#L5918). Hence, if the users want to export [code] to tensorrt, they should make sure that they are sending normalized coordinates. But the documentation fails to warn the user about this.",-2
"> The TensorFlow implementation for the operation is the same regardless whether the coordinates are normalized or absolute values. On the other hand, the TensorRT implementation requires a parameter that specifies whether the coordinates are normalized or not

TensorRT indeed has two implementation for the IOU calculation one for coordinates that should be interpreted as [pixels](https://github.com/NVIDIA/TensorRT/blob/183f891191f08fd016216fd0b94bc9c8c52d0ac2/plugin/common/kernels/allClassNMS.cu#L142-L143), and one otherwise (activated by[ isNormalized=true](https://github.com/NVIDIA/TensorRT/blob/183f891191f08fd016216fd0b94bc9c8c52d0ac2/plugin/common/kernels/allClassNMS.cu#L135-L139)). Note that `isNormalized` is an unfortunate name for the option, what it does is simply switching between these two modes. The latter implementation agrees with the [TF implementation](https://github.com/tensorflow/tensorflow/blob/508374a893df7999633d9ebbe55e94d92eef7280/tensorflow/core/kernels/image/non_max_suppression_op.cc#L123-L134), therefore the converter uses only that mode [mode of the TRT plugin](https://github.com/tensorflow/tensorflow/blob/ac4b2997b6c47e06a4f689355c08418856905594/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5911-L5918). We do have an unit test which checks that the converter works for non-normalized coordinates. 

To summarize, the TF-TRT converted combinedNMS op should work with not-normalized coordinates. #40062 did not touch this. Among other things, the handling of the `clib_boxes` attribute was corrected in that PR, but not sure if that is relevant here.

I will have a closer look at the problem and report back.



",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-765437173,tfeher,2021-01-22 14:26:28,46453,[47698],Deployment bug,1,"> The TensorFlow implementation for the operation is the same regardless whether the coordinates are normalized or absolute values. On the other hand, the TensorRT implementation requires a parameter that specifies whether the coordinates are normalized or not TensorRT indeed has two implementation for the IOU calculation one for coordinates that should be interpreted as [pixels]([url]#L142-L143), and one otherwise (activated by[ isNormalized=true]([url]#L135-L139)). Note that [code] is an unfortunate name for the option, what it does is simply switching between these two modes. The latter implementation agrees with the [TF implementation]([url]#L123-L134), therefore the converter uses only that mode [mode of the TRT plugin]([url]#L5911-L5918). We do have an unit test which checks that the converter works for non-normalized coordinates. To summarize, the TF-TRT converted combinedNMS op should work with not-normalized coordinates. #40062 did not touch this. Among other things, the handling of the [code] attribute was corrected in that PR, but not sure if that is relevant here. I will have a closer look at the problem and report back.",0
"I could reproduce the bug. The TRT engine throws a segfault when we call [enqueue](https://github.com/tensorflow/tensorflow/blob/3db793ee031f2abede180043b016c085f1d8c26b/tensorflow/compiler/tf2tensorrt/utils/trt_engine_utils.cc#L280). The problem indeed happens after the converter was changed in #40062, if I revert the changes then the segfault disappears. It still needs to be clarified whether we make an error on TF-TRT side while setting up the TRT NMS plugin parameters, or it is a bug in TRT.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-768529059,tfeher,2021-01-27 19:39:37,46453,[47698],Deployment bug,1,"I could reproduce the bug. The TRT engine throws a segfault when we call [enqueue]([url]#L280). The problem indeed happens after the converter was changed in #40062, if I revert the changes then the segfault disappears. It still needs to be clarified whether we make an error on TF-TRT side while setting up the TRT NMS plugin parameters, or it is a bug in TRT.",-1
"The issue is caused by the change in handling the `top_k` parameter for the plugin. The value that we are passing (5000) is larger than what TRT can handle (4096). There are two options to fix this:
- Cap top_k to 4096. We have to check whether this leads to incompatibility between the TF and TRT results.
- Mark node as incompatible, this is always safe but bad for performance.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-772780658,tfeher,2021-02-03 19:55:57,46453,[47698],Deployment bug,1,"The issue is caused by the change in handling the [code] parameter for the plugin. The value that we are passing (5000) is larger than what TRT can handle (4096). There are two options to fix this: - Cap top_k to 4096. We have to check whether this leads to incompatibility between the TF and TRT results. - Mark node as incompatible, this is always safe but bad for performance.",0
"> > The TensorFlow implementation for the operation is the same regardless whether the coordinates are normalized or absolute values. On the other hand, the TensorRT implementation requires a parameter that specifies whether the coordinates are normalized or not
> 
> TensorRT indeed has two implementation for the IOU calculation one for coordinates that should be interpreted as [pixels](https://github.com/NVIDIA/TensorRT/blob/183f891191f08fd016216fd0b94bc9c8c52d0ac2/plugin/common/kernels/allClassNMS.cu#L142-L143), and one otherwise (activated by[ isNormalized=true](https://github.com/NVIDIA/TensorRT/blob/183f891191f08fd016216fd0b94bc9c8c52d0ac2/plugin/common/kernels/allClassNMS.cu#L135-L139)). Note that `isNormalized` is an unfortunate name for the option, what it does is simply switching between these two modes. The latter implementation agrees with the [TF implementation](https://github.com/tensorflow/tensorflow/blob/508374a893df7999633d9ebbe55e94d92eef7280/tensorflow/core/kernels/image/non_max_suppression_op.cc#L123-L134), therefore the converter uses only that mode [mode of the TRT plugin](https://github.com/tensorflow/tensorflow/blob/ac4b2997b6c47e06a4f689355c08418856905594/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5911-L5918). We do have an unit test which checks that the converter works for non-normalized coordinates.
> 
> To summarize, the TF-TRT converted combinedNMS op should work with not-normalized coordinates. #40062 did not touch this. Among other things, the handling of the `clib_boxes` attribute was corrected in that PR, but not sure if that is relevant here.
> 
> I will have a closer look at the problem and report back.

@tfeher 
https://github.com/tensorflow/tensorflow/blob/a6f927400dfa09f445faee953e5694512226eed5/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5980-L5987
Can you please clarify: Since `is_normalized` explicitly being set to `true`, does this mean that the converter expects the coordinates to be normalized `[0, 1]`?. When I tried passing unnormalized coordinates, I did not get correct results.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-772841339,srihari-humbarwadi,2021-02-03 21:37:42,46453,[47698],Deployment bug,1,"> > The TensorFlow implementation for the operation is the same regardless whether the coordinates are normalized or absolute values. On the other hand, the TensorRT implementation requires a parameter that specifies whether the coordinates are normalized or not > > TensorRT indeed has two implementation for the IOU calculation one for coordinates that should be interpreted as [pixels]([url]#L142-L143), and one otherwise (activated by[ isNormalized=true]([url]#L135-L139)). Note that [code] is an unfortunate name for the option, what it does is simply switching between these two modes. The latter implementation agrees with the [TF implementation]([url]#L123-L134), therefore the converter uses only that mode [mode of the TRT plugin]([url]#L5911-L5918). We do have an unit test which checks that the converter works for non-normalized coordinates. > > To summarize, the TF-TRT converted combinedNMS op should work with not-normalized coordinates. #40062 did not touch this. Among other things, the handling of the [code] attribute was corrected in that PR, but not sure if that is relevant here. > > I will have a closer look at the problem and report back. @tfeher [url]#L5980-L5987 Can you please clarify: Since [code] explicitly being set to [code], does this mean that the converter expects the coordinates to be normalized [code]?. When I tried passing unnormalized coordinates, I did not get correct results.",0
"As I have described above, the combinedNMS op is expected to work with not normalized coordinates. And yes, we need to set `is_normalized = true` even if we have not normalied coordinates. TRT's naming of the argument is somewhat unfortunate. I have confirmed with a TRT engineer that the `isNormalized` arg only switches modes of IOU calculation, it does not require us to provide normalized coordinates.

Note that TRT has an option `clipBoxes` with the following meaning:

> Forcibly restrict bounding boxes to the normalized range [0,1]. Only applicable if isNormalized is also true. Defaults to true.

If it is set to false, then the conversion should work with unnormalized coordinates.

Now the problem is, that before #40062, the `clipBoxes` arg was not set by the converter, so it defaulted to truncating the box coordinates. This is one of the things which was fixed by #40062. 

The question is, which version of TF are you using  when you get the incorrect results?",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-772879525,tfeher,2021-02-03 22:48:01,46453,[47698],Deployment bug,1,"As I have described above, the combinedNMS op is expected to work with not normalized coordinates. And yes, we need to set [code] even if we have not normalied coordinates. TRT's naming of the argument is somewhat unfortunate. I have confirmed with a TRT engineer that the [code] arg only switches modes of IOU calculation, it does not require us to provide normalized coordinates. Note that TRT has an option [code] with the following meaning: > Forcibly restrict bounding boxes to the normalized range [0,1]. Only applicable if isNormalized is also true. Defaults to true. If it is set to false, then the conversion should work with unnormalized coordinates. Now the problem is, that before #40062, the [code] arg was not set by the converter, so it defaulted to truncating the box coordinates. This is one of the things which was fixed by #40062. The question is, which version of TF are you using when you get the incorrect results?",0
"@tfeher, I guess this explains the behaviour. I was successfully able to convert the models in `2.4.0` but the output boxes were being clipped to 1 for the converted model. 
> clipBoxes arg was not set by the converter",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-772883549,srihari-humbarwadi,2021-02-03 22:56:39,46453,[47698],Deployment bug,1,"@tfeher, I guess this explains the behaviour. I was successfully able to convert the models in [code] but the output boxes were being clipped to 1 for the converted model. > clipBoxes arg was not set by the converter",0
"@tfeher, we encountered similar crash for a google internal customer and verified that setting top_k to 4096 fix the problem. For their case, num_boxes is 70K+. 

I think we probably misunderstand the relationship between num_boxes and top_k in [this code block](https://github.com/tensorflow/tensorflow/blob/ed22f400428a669c1c6e4553cd7f4900abeaf954/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5999-L6002).  top_k in the plugin is more like the num of top values we keep in the internal of the algorithm, in order to support the selection of keep_top_k as output, is it?

I think we should fix this to something like this:
if (keep_top_k > 4096) return ""tensorrt not support"" else top_k = 4096 (or top_k = keep_top_k?)

They also help me check the performance for these two ways of setting top_k:
     top_k = keep_top_k
     top_k = 4096
and didn't see any perf diff for their app.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-774210267,bixia1,2021-02-05 18:33:19,46453,[47698],Deployment bug,1,"@tfeher, we encountered similar crash for a google internal customer and verified that setting top_k to 4096 fix the problem. For their case, num_boxes is 70K+. I think we probably misunderstand the relationship between num_boxes and top_k in [this code block]([url]#L5999-L6002). top_k in the plugin is more like the num of top values we keep in the internal of the algorithm, in order to support the selection of keep_top_k as output, is it? I think we should fix this to something like this: if (keep_top_k > 4096) return ""tensorrt not support"" else top_k = 4096 (or top_k = keep_top_k?) They also help me check the performance for these two ways of setting top_k: top_k = keep_top_k top_k = 4096 and didn't see any perf diff for their app.",0
"See cloud_tpu is setting top_k to 5000 [here](https://github.com/tensorflow/tpu/blob/d4daff70a8a17625cb43386b2a564cb0e0e0e130/models/official/detection/ops/postprocess_ops.py#L60-L80)
Here is their definition of top_k: 
pre_nms_num_boxes: an int number of top candidate detections per class
      before NMS",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-774214260,bixia1,2021-02-05 18:37:21,46453,[47698],Deployment bug,1,See cloud_tpu is setting top_k to 5000 [here]([url]#L60-L80) Here is their definition of top_k: pre_nms_num_boxes: an int number of top candidate detections per class before NMS,0
"@bixia1 pre_nms_top_k is used in models like RetinaNet, EfficientDet and other similar models. And in most of the cases, the literature asks us to pick the top 5000 boxes (depending on the score), this is where the number 5000 comes from.

But what troubles me is there is no way in which the user can set this value when calling `combined_non_max_suppression`. I feel that since tensorrt plugin already has this field, it would be beneficial to expose this param in `tf.image.combined_non_max_suppression`

```python
tf.image.combined_non_max_suppression(
    boxes, scores, max_output_size_per_class, max_total_size, iou_threshold=0.5,
    score_threshold=float('-inf'), pad_per_class=False, clip_boxes=True,
    name=None
)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-774227477,srihari-humbarwadi,2021-02-05 19:02:59,46453,[47698],Deployment bug,1,"@bixia1 pre_nms_top_k is used in models like RetinaNet, EfficientDet and other similar models. And in most of the cases, the literature asks us to pick the top 5000 boxes (depending on the score), this is where the number 5000 comes from. But what troubles me is there is no way in which the user can set this value when calling [code]. I feel that since tensorrt plugin already has this field, it would be beneficial to expose this param in [code] ``[code]``",-1
"Hi, Tama's PR is going to fix this by introducing an environment for you to overwrite the default behavior. With his PR, the default behavior won't be changed, that is, we still reject the case where top_k > 4096 as we do currently unless you explicit request to change this behavior through providing the environment variable. We need your feedback on this solution.",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-796002531,bixia1,2021-03-10 19:59:28,46453,[47698],Deployment bug,1,"Hi, Tama's PR is going to fix this by introducing an environment for you to overwrite the default behavior. With his PR, the default behavior won't be changed, that is, we still reject the case where top_k > 4096 as we do currently unless you explicit request to change this behavior through providing the environment variable. We need your feedback on this solution.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46453"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46453"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-797157576,google-ml-butler[bot],2021-03-12 00:56:33,46453,[47698],Deployment bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
I sent a pull request which should fix this issue,IssueComment,https://github.com/tensorflow/tensorflow/issues/47789#issuecomment-798809063,CyangXu,2021-03-14 00:44:38,47789,[47788],Code bug,0,I sent a pull request which should fix this issue,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47789"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47789"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47789#issuecomment-815183587,google-ml-butler[bot],2021-04-07 19:52:43,47789,[47788],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I am able to replicate the issue reported on tf 2.3,2.4 and nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/e701dd589462a69a246c57135c1e6920/untitled567.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/47970#issuecomment-803915678,Saduf2019,2021-03-22 09:37:03,47970,[47986],Data bug,0,"I am able to replicate the issue reported on tf 2.3,2.4 and nightly, please find the [gist here]([url]",0
"Opened #47986 with a fix.

As a temporary workaround you can use `tf.config.optimizer.set_experimental_options({""constant_folding"": False})` although that could slightly reduce performance in some cases.",IssueComment,https://github.com/tensorflow/tensorflow/issues/47970#issuecomment-804369420,lgeiger,2021-03-22 20:24:30,47970,[47986],Data bug,0,Opened #47986 with a fix. As a temporary workaround you can use [code] although that could slightly reduce performance in some cases.,2
"It works for me if I do `experimental_compile=True` (since I anyways want to do that for performance). I'm wondering though, doesn't experimental compile constant fold too?",IssueComment,https://github.com/tensorflow/tensorflow/issues/47970#issuecomment-804711487,deluksic,2021-03-23 08:21:47,47970,[47986],Data bug,0,"It works for me if I do [code] (since I anyways want to do that for performance). I'm wondering though, doesn't experimental compile constant fold too?",1
"> I'm wondering though, doesn't experimental compile constant fold too?

experimental compile does constant folding too, but uses a different code path as far as I know which doesn't have this bug.",IssueComment,https://github.com/tensorflow/tensorflow/issues/47970#issuecomment-804802986,lgeiger,2021-03-23 10:48:28,47970,[47986],Data bug,0,"> I'm wondering though, doesn't experimental compile constant fold too? experimental compile does constant folding too, but uses a different code path as far as I know which doesn't have this bug.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47970"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47970"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47970#issuecomment-817047414,google-ml-butler[bot],2021-04-10 01:13:49,47970,[47986],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Hi,

I created a PR with a fix [(48144)](https://github.com/tensorflow/tensorflow/pull/48144).

Apologies if did not respecting your contributing guidelines this time.

Cheers",IssueComment,https://github.com/tensorflow/tensorflow/issues/48145#issuecomment-809200524,dmpiergiacomo,2021-03-29 08:55:16,48145,[48144],Deployment bug,0,"Hi, I created a PR with a fix [(48144)]([url] Apologies if did not respecting your contributing guidelines this time. Cheers",2
"Hi, could you please tell me how big is your libtensorflow-microlite.a?",IssueComment,https://github.com/tensorflow/tensorflow/issues/48145#issuecomment-810036183,napoleonwar,2021-03-30 08:43:31,48145,[48144],Deployment bug,0,"Hi, could you please tell me how big is your libtensorflow-microlite.a?",0
"> Hi, could you please tell me how big is your libtensorflow-microlite.a?

Hi @napoleonwar, my `libtensorflow-microlite.a` seems to be 1.0 MB on my host. I currently don't know the size on the target though.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48145#issuecomment-810055831,dmpiergiacomo,2021-03-30 09:11:34,48145,[48144],Deployment bug,0,"> Hi, could you please tell me how big is your libtensorflow-microlite.a? Hi @napoleonwar, my [code] seems to be 1.0 MB on my host. I currently don't know the size on the target though.",0
"> Hi @napoleonwar, my `libtensorflow-microlite.a` seems to be 1.0 MB on my host. I currently don't know the size on the target though.

Ok Thanks! I am wondering how big is it after you compiling the hello world example if you did before. Because in my case, the binary file is 350KB for this simplest example, it will become bigger for more complex cases. Did you get some result whose size is under 100KB by using TFLM?",IssueComment,https://github.com/tensorflow/tensorflow/issues/48145#issuecomment-810188208,napoleonwar,2021-03-30 12:35:53,48145,[48144],Deployment bug,0,"> Hi @napoleonwar, my [code] seems to be 1.0 MB on my host. I currently don't know the size on the target though. Ok Thanks! I am wondering how big is it after you compiling the hello world example if you did before. Because in my case, the binary file is 350KB for this simplest example, it will become bigger for more complex cases. Did you get some result whose size is under 100KB by using TFLM?",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46854"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46854"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46854#issuecomment-817019936,google-ml-butler[bot],2021-04-09 23:12:45,46854,[48182],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I have tried in colab with TF version 2.2, 2.3 and nightly version(`2.5.0-dev20201116`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/08c4a080d0ab6b9451e0ec9536747bfb/untitled519.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-728708182,ravikyram,2020-11-17 06:06:39,44906,[48207],Algorithm design bug,0,"I have tried in colab with TF version 2.2, 2.3 and nightly version([code]) and was able to reproduce the issue.Please, find the gist [here]([url] Thanks!",0
"@Lescurel Do you like a better error message?

Extracted from the doc https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer?version=nightly
>dynamic: Set this to True if your layer should only be run eagerly, and should not be used to generate a static computation graph. This would be the case for a Tree-RNN or a recursive network, for example, or generally for any layer that manipulates tensors using Python control flow. If False, we assume that the layer can safely be used to generate a static computation graph. 

If you run a similar example you can check:
```
import tensorflow as tf
inp = tf.keras.Input(shape=(10,))
def my_lambda_func(x):
    print(tf.executing_eagerly())
x = tf.keras.layers.Lambda(my_lambda_func)(inp)
```

",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-728990516,bhack,2020-11-17 15:08:22,44906,[48207],Algorithm design bug,0,"@Lescurel Do you like a better error message? Extracted from the doc [url] >dynamic: Set this to True if your layer should only be run eagerly, and should not be used to generate a static computation graph. This would be the case for a Tree-RNN or a recursive network, for example, or generally for any layer that manipulates tensors using Python control flow. If False, we assume that the layer can safely be used to generate a static computation graph. If you run a similar example you can check: ``[code]``",1
"@bhack If passing `dynamic=True` to a Lambda layer is indeed impossible, then yes, I would have expected a better error message. 

But I don't really see why it would be impossible. It feels to me that it is more likely to end up  writing Python control flow code in a Lambda layer than in any other layer. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-729729781,Lescurel,2020-11-18 14:51:08,44906,[48207],Algorithm design bug,0,"@bhack If passing [code] to a Lambda layer is indeed impossible, then yes, I would have expected a better error message. But I don't really see why it would be impossible. It feels to me that it is more likely to end up writing Python control flow code in a Lambda layer than in any other layer.",-1
"It Is ok to me to keep this open for a better error message.
As you can see with my print in lambda you are no more in eager mode this match with documentation.",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-729739292,bhack,2020-11-18 15:05:38,44906,[48207],Algorithm design bug,0,It Is ok to me to keep this open for a better error message. As you can see with my print in lambda you are no more in eager mode this match with documentation.,0
"To add a bit of context, I ended finding that ""bug"" in a more complex program that ended up throwing that Traceback : 

[traceback.log](https://github.com/tensorflow/tensorflow/files/5560985/traceback.log)

In that Traceback, the first error I saw was : 

> OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.

Which I ignored, given that the function was already decorated with `@tf.function`. (This is also a strange behaviour, but I can't reproduce it)

The second error is: 

> TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.

The problem is that apparently, those two suggestions are incompatible with each other, if I believe your example. 
",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-729747114,Lescurel,2020-11-18 15:16:19,44906,[48207],Algorithm design bug,0,"To add a bit of context, I ended finding that ""bug"" in a more complex program that ended up throwing that Traceback : [traceback.log]([url] In that Traceback, the first error I saw was : > OperatorNotAllowedInGraphError: iterating over [code] is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function. Which I ignored, given that the function was already decorated with [code]. (This is also a strange behaviour, but I can't reproduce it) The second error is: > TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass [code] to the class constructor. The problem is that apparently, those two suggestions are incompatible with each other, if I believe your example.",-2
I cannot see your context with the current code.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-729764493,bhack,2020-11-18 15:42:25,44906,[48207],Algorithm design bug,0,I cannot see your context with the current code.,-1
"Sorry, I forgot to add that the error was caused by a Lambda layer. Basically something like the example below caused the error. However, I have been unable to reproduce with a minimal example, so the example below is completely functional. 

```python
import tensorflow as tf

@tf.function
def python_control_flow_fn(tensor):
    return tf.concat([t for t in tensor],axis=0)

inp = tf.keras.Input(shape=(10,))
layer = tf.keras.layers.Lambda(python_control_flow_fn)(inp)
```

The traceback seems to suggest that I can either add `@tf.function` to my Python control flow function, or add `dynamic=True` to the layer.  ",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-729781477,Lescurel,2020-11-18 16:07:34,44906,[48207],Algorithm design bug,0,"Sorry, I forgot to add that the error was caused by a Lambda layer. Basically something like the example below caused the error. However, I have been unable to reproduce with a minimal example, so the example below is completely functional. ``[code]`[code]@tf.function[code]dynamic=True` to the layer.",0
"> OperatorNotAllowedInGraphError: iterating over tf.Tensor is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.

This is not related to lambda:
````python
@tf.function
def python_control_flow_fn(tensor):
    return tf.concat([t for t in tensor],axis=0)

inp = tf.keras.Input(shape=(10,))
python_control_flow_fn(inp)",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-729868988,bhack,2020-11-18 18:24:47,44906,[48207],Algorithm design bug,0,"> OperatorNotAllowedInGraphError: iterating over tf.Tensor is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function. This is not related to lambda: ````python @tf.function def python_control_flow_fn(tensor): return tf.concat([t for t in tensor],axis=0) inp = tf.keras.Input(shape=(10,)) python_control_flow_fn(inp)",0
"Adding the `contributions welcome` label to this issue for further investigation by the community. If you are interested in working on this issue, please leave a comment and I will assign it to you. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-799466566,nikitamaia,2021-03-15 14:30:48,44906,[48207],Algorithm design bug,0,"Adding the [code] label to this issue for further investigation by the community. If you are interested in working on this issue, please leave a comment and I will assign it to you. Thanks!",3
"Hi,
this error happens even in eager mode (tf 2.4.1):

```python

import tensorflow as tf

tf.config.run_functions_eagerly(True)

input = tf.keras.Input(shape=())

@tf.function
def fn(x):
    return x

output = tf.keras.layers.Lambda(fn, dynamic=True)(input)
tf.keras.Model(inputs=input, outputs=output)
```
throws:

`RecursionError: maximum recursion depth exceeded while calling a Python object`",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-802123410,nicolaspi,2021-03-18 17:06:39,44906,[48207],Algorithm design bug,0,"Hi, this error happens even in eager mode (tf 2.4.1): ``[code]`[code]RecursionError: maximum recursion depth exceeded while calling a Python object`",-2
@nikitamaia Can you assign this to @fsx950223 he has already a submitted PR.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-818998702,bhack,2021-04-13 19:31:18,44906,[48207],Algorithm design bug,0,@nikitamaia Can you assign this to @fsx950223 he has already a submitted PR.,0
"Thanks for the heads up @bhack!

@fsx950223 can you leave a comment on this thread requesting to be assigned? Github settings won't let me assign someone unless they have commented on the thread :)",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-819006731,nikitamaia,2021-04-13 19:45:49,44906,[48207],Algorithm design bug,0,Thanks for the heads up @bhack! @fsx950223 can you leave a comment on this thread requesting to be assigned? Github settings won't let me assign someone unless they have commented on the thread :),2
Please assign the issue to me.,IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-819233796,fsx950223,2021-04-14 05:15:53,44906,[48207],Algorithm design bug,0,Please assign the issue to me.,2
"Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210602, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/4b23f0c1e384137b1666c3a22a4c4ddf/44906.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-853691838,sachinprasadhs,2021-06-03 08:34:25,44906,[48207],Algorithm design bug,0,"Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210602, please find the gist [here]([url] Thanks!",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44906"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44906"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-857847803,google-ml-butler[bot],2021-06-09 16:25:12,44906,[48207],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I also observed the following alternative names of the API have the same behavior that causes the `RecursionError` Exception:

- `(tf.keras.layers.Lambda)`, `tf.compat.v1.keras.layers.Lambda`

This behavior still exists in tensorflow nightly (2.15.0-dev20230920), and users should be cautious when using them on both CPU and GPU.

<details>
  <summary>Code to reproduce the issue in <code>tf.compat.v1.keras.layers.Lambda</code></summary>

```python
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION, flush=True)
print(tf.config.list_physical_devices(), flush=True)


inp = tf.keras.Input(shape=(10,))
out = tf.compat.v1.keras.layers.Lambda(
        lambda x_input: x_input,
        dynamic=True,
)(inp)
model = tf.keras.Model(inputs=inp, outputs=out)
```

On my GPU machine, the above code produces the following output, and the `RecursionError` Exception is raised.

```text
v2.14.0-rc0-34-gdd01672d9a9 2.14.0-rc1
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Traceback (most recent call last):
  File ""/tmp/analyze/44906-4-s/tf.compat.v1.keras.layers.Lambda.py"", line 7, in <module>
    out = tf.compat.v1.keras.layers.Lambda(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/lib/python3.11/inspect.py"", line 3272, in signature
    return Signature.from_callable(obj, follow_wrapped=follow_wrapped,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/inspect.py"", line 3020, in from_callable
    return _signature_from_callable(obj, sigcls=cls,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/inspect.py"", line 2457, in _signature_from_callable
    obj = unwrap(obj, stop=(lambda f: hasattr(f, ""__signature__"")))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/inspect.py"", line 760, in unwrap
    memo = {id(f): f}
            ^^^^^
RecursionError: maximum recursion depth exceeded while calling a Python object
```

This behavior is also reproducible on my CPU machine:

```text
v2.14.0-rc0-34-gdd01672d9a9 2.14.0-rc1
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Traceback (most recent call last):
  File ""/tmp/analyze/44906-4-s/tf.compat.v1.keras.layers.Lambda.py"", line 7, in <module>
    out = tf.compat.v1.keras.layers.Lambda(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/lib/python3.11/inspect.py"", line 3272, in signature
    return Signature.from_callable(obj, follow_wrapped=follow_wrapped,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/inspect.py"", line 3020, in from_callable
    return _signature_from_callable(obj, sigcls=cls,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/inspect.py"", line 2457, in _signature_from_callable
    obj = unwrap(obj, stop=(lambda f: hasattr(f, ""__signature__"")))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.11/inspect.py"", line 760, in unwrap
    memo = {id(f): f}
            ^^^^^
RecursionError: maximum recursion depth exceeded while calling a Python object
```
</details>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/44906#issuecomment-1729371626,oawxkw,2023-09-21 11:22:48,44906,[48207],Algorithm design bug,0,"I also observed the following alternative names of the API have the same behavior that causes the [code] Exception: - [code], [code] This behavior still exists in tensorflow nightly (2.15.0-dev20230920), and users should be cautious when using them on both CPU and GPU. <details> <summary>Code to reproduce the issue in <code>tf.compat.v1.keras.layers.Lambda</code></summary> ``[code]`[code]RecursionError[code]`[code]`[code]`[code]`` </details>",-2
"@jeongukjae 
Created a PR to fix this issue, this issue will be closed once the [PR](https://github.com/tensorflow/tensorflow/pull/48215) is merged.

Thanks!.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48189#issuecomment-810976195,Saduf2019,2021-03-31 11:01:23,48189,[48215],Visualization bug,0,"@jeongukjae Created a PR to fix this issue, this issue will be closed once the [PR]([url] is merged. Thanks!.",3
"Yes. ""Example"" would be a slightly better fit. ""Sample"" is used in the sense ""sample from a probability distribution"", we often think of datasets as sample from a distribution, an ""example"" is a ""sample of size 1"".

If you send a PR I'll approve it.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48298#issuecomment-813564824,MarkDaoust,2021-04-05 18:36:15,48298,[48318],Documentation bug,0,"Yes. ""Example"" would be a slightly better fit. ""Sample"" is used in the sense ""sample from a probability distribution"", we often think of datasets as sample from a distribution, an ""example"" is a ""sample of size 1"". If you send a PR I'll approve it.",3
"Here's a brief about the issue...
In this repo (tensorflow/tensorflow/examples) the README is enough with examples and all other things, but still it has a statement ""This directory is not actively maintained"" which is fine, but I feel a statement must be included along with it... ""Refer this repo for other examples"" so that newcomers will know and refer to that link",IssueComment,https://github.com/tensorflow/tensorflow/issues/48394#issuecomment-815496269,alphaX86,2021-04-08 06:46:25,48394,[48398],Documentation bug,0,"Here's a brief about the issue... In this repo (tensorflow/tensorflow/examples) the README is enough with examples and all other things, but still it has a statement ""This directory is not actively maintained"" which is fine, but I feel a statement must be included along with it... ""Refer this repo for other examples"" so that newcomers will know and refer to that link",1
"And TF community, please assign me this issue, I want to work on it! :)",IssueComment,https://github.com/tensorflow/tensorflow/issues/48394#issuecomment-815496536,alphaX86,2021-04-08 06:46:50,48394,[48398],Documentation bug,0,"And TF community, please assign me this issue, I want to work on it! :)",5
"@alphaX86 
 Please feel free to submit a PR.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/48394#issuecomment-815505841,Saduf2019,2021-04-08 07:02:19,48394,[48398],Documentation bug,0,@alphaX86 Please feel free to submit a PR.Thanks!,3
[colab link](https://colab.research.google.com/gist/eli-osherovich/591f0e7a44b9b912fd9fcf52711a09dd/untitled1.ipynb),IssueComment,https://github.com/tensorflow/tensorflow/issues/47954#issuecomment-803589333,eli-osherovich,2021-03-21 14:16:35,47954,[48434],Data bug,0,[colab link]([url],0
"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/acad508bce039cd9db9209532dd88d83/47954.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/47954#issuecomment-804038672,amahendrakar,2021-03-22 12:55:01,47954,[48434],Data bug,0,"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here]([url] Thanks!",0
Any response?,IssueComment,https://github.com/tensorflow/tensorflow/issues/47954#issuecomment-812632621,eli-osherovich,2021-04-02 17:35:04,47954,[48434],Data bug,0,Any response?,0
/cc @nikitamaia ,IssueComment,https://github.com/tensorflow/tensorflow/issues/47954#issuecomment-819119841,bhack,2021-04-13 23:41:53,47954,[48434],Data bug,0,/cc @nikitamaia,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47954"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47954"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/47954#issuecomment-848252978,google-ml-butler[bot],2021-05-25 20:49:14,47954,[48434],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@atn832 ,
Can you please share us the exact link where **`embeddings_metadata`** was located, so that we can fix it? Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/48174#issuecomment-812768717,rmothukuru,2021-04-03 00:57:28,48174,[48457],Visualization bug,0,"@atn832 , Can you please share us the exact link where **[code]** was located, so that we can fix it? Thanks!",2
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48174#issuecomment-817052009,google-ml-butler[bot],2021-04-10 01:52:09,48174,[48457],Visualization bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
"@scarlehoff 
Created pr #48536 to fix this issue, once the pr is merged this issue will be automatically closed.
Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/48473#issuecomment-820236488,Saduf2019,2021-04-15 08:37:52,48473,[48536],Documentation bug,0,"@scarlehoff Created pr #48536 to fix this issue, once the pr is merged this issue will be automatically closed. Thanks!",3
"I have tried in colab with TF v2.4,TF v2.5.0rc0, TF-nightly and noticed that session is being crashed.Please find the [gist](https://colab.research.google.com/gist/tilakrayal/0320e88d57e19455caae287cb8e0a208/48470.ipynb) here",IssueComment,https://github.com/tensorflow/tensorflow/issues/48470#issuecomment-817885326,tilakrayal,2021-04-12 15:01:22,48470,[48566],Algorithm design bug,0,"I have tried in colab with TF v2.4,TF v2.5.0rc0, TF-nightly and noticed that session is being crashed.Please find the [gist]([url] here",-2
Thanks for the report. I would suggest raising `ValueError` for all conv layers in case `filters` is `0`. Would you be able to open a PR implementing this change (including tests)?,IssueComment,https://github.com/tensorflow/tensorflow/issues/48470#issuecomment-819874154,fchollet,2021-04-14 21:56:44,48470,[48566],Algorithm design bug,0,Thanks for the report. I would suggest raising [code] for all conv layers in case [code] is [code]. Would you be able to open a PR implementing this change (including tests)?,2
"Thanks @fchollet . I agree that `ValueError` should be raised whenever `filters` is `0`. 
I noticed that the following functions also crash when `filters`=`0`.
```
Conv1DTranspose
Conv3DTranspose
ConvLSTM2D
```

while these run silently, but exception should be raised actually.
```
Conv1D
Conv3D
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48470#issuecomment-821033846,lugalUrim,2021-04-16 09:04:13,48470,[48566],Algorithm design bug,0,Thanks @fchollet . I agree that [code] should be raised whenever [code] is [code]. I noticed that the following functions also crash when [code]=[code]. ``[code]`[code]`[code]``,1
@fchollet I'll open a PR for this issue implementing the change.,IssueComment,https://github.com/tensorflow/tensorflow/issues/48470#issuecomment-821212786,around-star,2021-04-16 14:21:45,48470,[48566],Algorithm design bug,0,@fchollet I'll open a PR for this issue implementing the change.,3
/cc @nikitamaia (Assign/In progress),IssueComment,https://github.com/tensorflow/tensorflow/issues/48470#issuecomment-821847273,bhack,2021-04-17 16:12:44,48470,[48566],Algorithm design bug,0,/cc @nikitamaia (Assign/In progress),0
"@nikitamaia , @fchollet , @bhack I have sent in a [PR](https://github.com/tensorflow/tensorflow/pull/48566) for this issue. Can you please review it ?",IssueComment,https://github.com/tensorflow/tensorflow/issues/48470#issuecomment-822564013,around-star,2021-04-19 15:33:55,48470,[48566],Algorithm design bug,0,"@nikitamaia , @fchollet , @bhack I have sent in a [PR]([url] for this issue. Can you please review it ?",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48470"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48470"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48470#issuecomment-823514830,google-ml-butler[bot],2021-04-20 18:42:35,48470,[48566],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48606"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48606"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48606#issuecomment-843300164,google-ml-butler[bot],2021-05-18 16:02:26,48606,[48595],Visualization bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@lugalUrim 
When you make a model and compile, it gives the expected error.
Example:
```python
model = tf.keras.Sequential()
model.add(tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding=padding))
model.add(tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding=padding))
model.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])
model.fit(np.random.rand(10, 1, 1, 3))
```
Error trace:
```
ValueError: in user code:

    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step
        y_pred = self(x, training=True)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:389 call
        outputs = layer(inputs, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/convolutional.py:248 call
        outputs = self._convolution_op(inputs, self.kernel)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:1020 convolution_v2
        name=name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:1150 convolution_internal
        name=name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:2604 _conv2d_expanded_batch
        name=name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py:973 conv2d
        data_format=data_format, dilations=dilations, name=name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal
        compute_device)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal
        op_def=op_def)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:2016 __init__
        control_input_ops, op_def)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1856 _create_c_op
        raise ValueError(str(e))

    ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node sequential_1/conv2d_5/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=""VALID"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](IteratorGetNext, sequential_1/conv2d_5/Conv2D/ReadVariableOp)' with input shapes: [?,1,1,3], [2,2,3,3].

```

Please close this issue if the query is resolved.
Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-821833925,AdityaKane2001,2021-04-17 14:46:10,48589,[48610],Algorithm design bug,0,"@lugalUrim When you make a model and compile, it gives the expected error. Example: ``[code]`[code]`[code]`` Please close this issue if the query is resolved. Thanks",0
"Thanks @AdityaKane2001 . When I make a model, it raises a `ValueError` indeed.

As far as I am concerned, it would be better if the error can also be raised when building a layer for invalid input. 

 - Image this case: One breaks the model into multiple blocks to debug, and every single block (consisting of one or more layers) works fine with some input, but when putting them altogether into a model, it gives some error. It is a bit confusing, right.

 - This bug leads to future crash when taking gradient.
First, build a layer. (Executes successfully)
```
import tensorflow as tf
import numpy as np

filters, kernel_size, strides, padding = 3, [2, 2], 2, 'valid'
data = np.random.rand(1, 1, 1, 1)
layer = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding=padding)
print(layer(data).shape)
```
Second, take the gradient. (**Session crashes**.)
```
with tf.GradientTape() as tape:
  out = layer(data)
  loss = tf.reduce_sum(out)
  layer_variables = layer.trainable_variables
  grads = tape.gradient(loss, layer_variables)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-822010915,lugalUrim,2021-04-18 15:35:43,48589,[48610],Algorithm design bug,0,"Thanks @AdityaKane2001 . When I make a model, it raises a [code] indeed. As far as I am concerned, it would be better if the error can also be raised when building a layer for invalid input. - Image this case: One breaks the model into multiple blocks to debug, and every single block (consisting of one or more layers) works fine with some input, but when putting them altogether into a model, it gives some error. It is a bit confusing, right. - This bug leads to future crash when taking gradient. First, build a layer. (Executes successfully) ``[code]`[code]`[code]``",0
"@lugalUrim 
The thing is, mostly one does not execute a layer like this without putting it into a model, for obvious reasons. But yes, it's a valid thing to expect, and we can perhaps implement it.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-822012050,AdityaKane2001,2021-04-18 15:42:43,48589,[48610],Algorithm design bug,0,"@lugalUrim The thing is, mostly one does not execute a layer like this without putting it into a model, for obvious reasons. But yes, it's a valid thing to expect, and we can perhaps implement it.",2
/cc  @nikitamaia Assign/Inprogress,IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-822626803,bhack,2021-04-19 17:00:43,48589,[48610],Algorithm design bug,0,/cc @nikitamaia Assign/Inprogress,0
"Requesting to close, solved in #48610 
Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-840681863,AdityaKane2001,2021-05-13 16:37:49,48589,[48610],Algorithm design bug,0,"Requesting to close, solved in #48610 Thanks",3
"Yes, as a suggestion please use a valid pattern in the PR next time for autolinking https://docs.github.com/en/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword",IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-840689999,bhack,2021-05-13 16:51:25,48589,[48610],Algorithm design bug,0,"Yes, as a suggestion please use a valid pattern in the PR next time for autolinking [url]#linking-a-pull-request-to-an-issue-using-a-keyword",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48589"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48589"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-840707475,google-ml-butler[bot],2021-05-13 17:20:50,48589,[48610],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Thank you @AdityaKane2001 @bhack closed this as the PR got merged,IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-840707940,rthadur,2021-05-13 17:21:40,48589,[48610],Algorithm design bug,0,Thank you @AdityaKane2001 @bhack closed this as the PR got merged,5
"> Yes, as a suggestion please use a valid pattern in the PR next time for autolinking https://docs.github.com/en/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword

Sure, would do",IssueComment,https://github.com/tensorflow/tensorflow/issues/48589#issuecomment-840716088,AdityaKane2001,2021-05-13 17:35:50,48589,[48610],Algorithm design bug,0,"> Yes, as a suggestion please use a valid pattern in the PR next time for autolinking [url]#linking-a-pull-request-to-an-issue-using-a-keyword Sure, would do",1
related PR has been approved and will be merged soon. Thank you ,IssueComment,https://github.com/tensorflow/tensorflow/issues/48627#issuecomment-830280170,rthadur,2021-04-30 18:26:32,48627,[48626],Documentation bug,0,related PR has been approved and will be merged soon. Thank you,4
Adding @pedro-r-marques who wrote the code.,IssueComment,https://github.com/tensorflow/tensorflow/issues/48609#issuecomment-822085350,foxik,2021-04-18 23:33:57,48609,[48634],Algorithm design bug,0,Adding @pedro-r-marques who wrote the code.,0
Was able to reproduce the issue in TF 2.4.1 and nightly versions. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/17a0a4e7dd419bf42f096ccb9db1fca1/raggedsparsecategoricalcrossentropybug.ipynb). Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/48609#issuecomment-823017239,saikumarchalla,2021-04-20 06:42:49,48609,[48634],Algorithm design bug,0,Was able to reproduce the issue in TF 2.4.1 and nightly versions. Please find the gist [here]([url] Thanks!,1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48609"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48609"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48609#issuecomment-824287925,google-ml-butler[bot],2021-04-21 19:01:08,48609,[48634],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"That's how ""ReLU"" looks like if we obey 
```
  f(x) = max_value if x >= max_value
  f(x) = x if threshold <= x < max_value
  f(x) = negative_slope * (x - threshold) otherwise

negative_slope = 1
threshold = -1
max_value = 1
```
![image](https://user-images.githubusercontent.com/37601244/115468201-07091680-a233-11eb-9567-796d263a6ad5.png)

It does not look like ""**Re**ctified **L**inear **U**nit anymore so I think it's no point to fix it and I recommend modifying the docs. (https://github.com/tensorflow/tensorflow/pull/48654)",IssueComment,https://github.com/tensorflow/tensorflow/issues/48646#issuecomment-823623999,szutenberg,2021-04-20 21:52:50,48646,[48654],Algorithm design bug,0,"That's how ""ReLU"" looks like if we obey ``[code]`` ![image]([url] It does not look like ""**Re**ctified **L**inear **U**nit anymore so I think it's no point to fix it and I recommend modifying the docs. ([url]",-1
"@szutenberg 
>   f(x) = negative_slope * (x - threshold) otherwise

Can we do
` f(x) =   negative_slope * (x - threshold) + threshold `

This will work for the general case as `f(x) .= x for x = threshold` ",IssueComment,https://github.com/tensorflow/tensorflow/issues/48646#issuecomment-823772531,AdityaKane2001,2021-04-21 04:46:51,48646,[48654],Algorithm design bug,0,@szutenberg > f(x) = negative_slope * (x - threshold) otherwise Can we do [code] This will work for the general case as [code],0
"@szutenberg 
Also, there's something more weird going on with `tf.keras.backend.relu` function. Here's how it works:
```python
a = np.array( [ [0.5,2] , [-1.5,-0.5] ])
# array([[ 0.5,  2. ],
#       [-1.5, -0.5]])
print(tf.keras.backend.relu(a, alpha = 1, max_value = 1, threshold=-1)) 
# Output :
# tf.Tensor(
# [[ 0.5  1. ]
# [-0.5  0. ]], shape=(2, 2), dtype=float64)
```

According to your graph the (1,1) entry should be -0.5. 
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48646#issuecomment-823824201,AdityaKane2001,2021-04-21 06:54:16,48646,[48654],Algorithm design bug,0,"@szutenberg Also, there's something more weird going on with [code] function. Here's how it works: ``[code]`` According to your graph the (1,1) entry should be -0.5.",-1
"@AdityaKane2001 

Yes, it does not match my graph because I drew it by following:
```
  f(x) = max_value if x >= max_value
  f(x) = x if threshold <= x < max_value
  f(x) = negative_slope * (x - threshold) otherwise
```

That's why I propose PR https://github.com/tensorflow/tensorflow/pull/48654 which solves the problem (negative threshold is simply not supported).

I tried to understand why the threshold parameter was introduced. I found commit https://github.com/tensorflow/tensorflow/commit/0cf2c612e5e6ff8c5026011e8186056801def747 . I don't understand what is the point to introduce such consolidation. Any ideas?

Note that in [keras.layers.ThresholdedReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ThresholdedReLU) `theta >= 0` (`theta` is equivalent to `threshold` in ReLU).

We should not replace `f(x) = negative_slope * (x - threshold)` with `f(x) = negative_slope * (x - threshold) + threshold` because it would break compatibility with [keras.layers.ThresholdedReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ThresholdedReLU) by modifying behaviour for positive theshold value (f(x) would return threshold instead of 0).",IssueComment,https://github.com/tensorflow/tensorflow/issues/48646#issuecomment-826310481,szutenberg,2021-04-25 11:45:11,48646,[48654],Algorithm design bug,0,"@AdityaKane2001 Yes, it does not match my graph because I drew it by following: ``[code]`[code]theta >= 0[code]theta[code]threshold[code]f(x) = negative_slope * (x - threshold)[code]f(x) = negative_slope * (x - threshold) + threshold` because it would break compatibility with [keras.layers.ThresholdedReLU]([url] by modifying behaviour for positive theshold value (f(x) would return threshold instead of 0).",0
"@szutenberg 
Fair enough. But then should we modify the relu function itself, asserting that we do have a non-negative threshold? It will remove any ambiguity for the user in case the user tries to enter a negative threshold value.

However, even though the use case is extremely rare, it is perhaps best to keep it like that and clear bugs, if any, because it gives more flexibility, as `ThresholdedReLU` only allows a normal ReLU to be used with a threshold, and not some custom variant of it.

So, another possible solution may be to resolve those errors and bugs in the relu function, and eliminate `ThresholdedReLU` as it will be sort of a duplicate.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48646#issuecomment-826316232,AdityaKane2001,2021-04-25 12:26:56,48646,[48654],Algorithm design bug,0,"@szutenberg Fair enough. But then should we modify the relu function itself, asserting that we do have a non-negative threshold? It will remove any ambiguity for the user in case the user tries to enter a negative threshold value. However, even though the use case is extremely rare, it is perhaps best to keep it like that and clear bugs, if any, because it gives more flexibility, as [code] only allows a normal ReLU to be used with a threshold, and not some custom variant of it. So, another possible solution may be to resolve those errors and bugs in the relu function, and eliminate [code] as it will be sort of a duplicate.",0
"@AdityaKane2001 I added additional asserts to ReLU.

From the graph I drew, we can see that such scenario **probably** does not make any sense. It's not continuous at -1, this sudden change may break gradient descent.

I don't understand what is the idea behind https://github.com/tensorflow/tensorflow/commit/0cf2c612e5e6ff8c5026011e8186056801def747 and I'd rather revert it than eliminate ThresholdedReLU. People use ThresholdedReLU: [example 1](https://github.com/gao-lab/REVA-Data_Source_Code/blob/9da1a9fcfa04663b6a09a9c2549af9dddcc9848a/Variant_annotation/CNNs/model_structures.py#L17), [example 2](https://github.com/tincochan/vGame_bgm_remix/blob/4135b1a5ff9f1de9107facb8623d586200c0246e/rnn-cnn-gan-enhancer.py#L66)

For very rare use cases users can implement their own layers.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48646#issuecomment-826327078,szutenberg,2021-04-25 13:44:32,48646,[48654],Algorithm design bug,0,"@AdityaKane2001 I added additional asserts to ReLU. From the graph I drew, we can see that such scenario **probably** does not make any sense. It's not continuous at -1, this sudden change may break gradient descent. I don't understand what is the idea behind [url] and I'd rather revert it than eliminate ThresholdedReLU. People use ThresholdedReLU: [example 1]([url]#L17), [example 2]([url]#L66) For very rare use cases users can implement their own layers.",-2
"@szutenberg 
I agree with you. The use case is very (very) small..",IssueComment,https://github.com/tensorflow/tensorflow/issues/48646#issuecomment-826343202,AdityaKane2001,2021-04-25 15:32:16,48646,[48654],Algorithm design bug,0,@szutenberg I agree with you. The use case is very (very) small..,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48646"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48646"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48646#issuecomment-840888841,google-ml-butler[bot],2021-05-13 23:17:50,48646,[48654],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48961"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48961"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48961#issuecomment-840763389,google-ml-butler[bot],2021-05-13 18:55:33,48961,[48962],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Thanks.. Can you submit a small PR?,IssueComment,https://github.com/tensorflow/tensorflow/issues/49046#issuecomment-836782156,bhack,2021-05-10 14:39:45,49046,[49049],Code bug,0,Thanks.. Can you submit a small PR?,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49046"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49046"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49046#issuecomment-840773527,google-ml-butler[bot],2021-05-13 19:12:52,49046,[49049],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@ashahab 
I was able to reproduce the issue in  TF v2.4.1, TF2.5rc1 and TF-nightly(2.6.0) with no errors Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/ee62c3dfdc40f543b17a6cc2f6431e8d/-48903.ipynb) here and let us know if it helps. Thanks!

",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-832539407,UsharaniPagadala,2021-05-05 09:13:31,48903,[49121],Data bug,1,"@ashahab I was able to reproduce the issue in TF v2.4.1, TF2.5rc1 and TF-nightly(2.6.0) with no errors Please find the [gist]([url] here and let us know if it helps. Thanks!",3
"@UsharaniPagadala I think this is a race condition. I don't know about the execution environment of the notebook and whether it allows true multi-threading.
Here are the steps I followed on a 12-core Azure nv12 box:
```bash
$pip install tensorflow==2.4.1
$python segfault.py
...
2021-05-05 04:57:51.915818: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-05 04:57:51.915930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-05 04:57:51.915948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]
2021-05-05 04:57:51.966764: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-05 04:57:51.967255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2596985000 Hz
Segmentation fault (core dumped)
```

Let me know if you follow the above steps you don't see the segfault.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-832642106,ashahab,2021-05-05 12:19:23,48903,[49121],Data bug,1,@UsharaniPagadala I think this is a race condition. I don't know about the execution environment of the notebook and whether it allows true multi-threading. Here are the steps I followed on a 12-core Azure nv12 box: ``[code]`` Let me know if you follow the above steps you don't see the segfault.,0
"@jvishnuvardhan 
I was able to run the code in tf2.4, tf2.5rc1 and tf-nightly .Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/ee62c3dfdc40f543b17a6cc2f6431e8d/-48903.ipynb) here.Thanks",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-832682756,UsharaniPagadala,2021-05-05 13:22:18,48903,[49121],Data bug,1,"@jvishnuvardhan I was able to run the code in tf2.4, tf2.5rc1 and tf-nightly .Please find the [gist]([url] here.Thanks",5
Thanks for the link. I can also reproduce the issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-832859942,yangustc07,2021-05-05 17:05:31,48903,[49121],Data bug,1,Thanks for the link. I can also reproduce the issue.,1
@yangustc07  Were you able to see the segmentation fault?,IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-832937461,ashahab,2021-05-05 19:05:46,48903,[49121],Data bug,1,@yangustc07 Were you able to see the segmentation fault?,0
"Yes, I can see the segmentation fault and I'm working on a fix. Inputs are welcome if you have more information.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-832941742,yangustc07,2021-05-05 19:12:31,48903,[49121],Data bug,1,"Yes, I can see the segmentation fault and I'm working on a fix. Inputs are welcome if you have more information.",2
"@yangustc07 Thanks for reproducing the issue.
Yes I have more inputs.
This is caused only when we combine these five: snapshot, shuffle, batch, repeat, and prefetch. I have been unsuccessful in removing any of these to narrow the problem.

I added some logging where snapshot Reader was getting an input reference: `input_->Ref()` and where it was returning the reference: `input_->UnRef()`. 
All threads except one will first execute `input_->Ref()` and then execute `input_->UnRef()` (I logged the thread ids). However, the last thread invokes `input_->UnRef()` without doing the prior `input_->Ref()`. It's trying to invoke `input_->UnRef()` on a null(0) `input_`.



",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-832952490,ashahab,2021-05-05 19:31:00,48903,[49121],Data bug,1,"@yangustc07 Thanks for reproducing the issue. Yes I have more inputs. This is caused only when we combine these five: snapshot, shuffle, batch, repeat, and prefetch. I have been unsuccessful in removing any of these to narrow the problem. I added some logging where snapshot Reader was getting an input reference: [code] and where it was returning the reference: [code]. All threads except one will first execute [code] and then execute [code] (I logged the thread ids). However, the last thread invokes [code] without doing the prior [code]. It's trying to invoke [code] on a null(0) [code].",0
"Tried to debug more. The reason one thread does not call `input_->Ref()` is `SnapshotDatasetV2Op::Dataset::Iterator::Reader::Initialize` returns a cancelled error somewhere. In that case, the destructor shouldn't call `input_->UnRef()`, and there shouldn't be any calls to `Reader::GetNextInternal()`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833158741,yangustc07,2021-05-06 01:28:20,48903,[49121],Data bug,1,"Tried to debug more. The reason one thread does not call [code] is [code] returns a cancelled error somewhere. In that case, the destructor shouldn't call [code], and there shouldn't be any calls to [code].",0
"Yang, your earlier solution of commenting out ref and unref does not seem
safe to me, and may result in memory leaks.

On Wed, May 5, 2021 at 6:28 PM Yang Chen ***@***.***> wrote:

> Tried to debug more. The reason one thread does not call input_->Ref() is
> SnapshotDatasetV2Op::Dataset::Iterator::Reader::Initialize returns a
> cancelled error somewhere. In that case, the destructor shouldn't call
> input_->UnRef(), and there shouldn't be any calls to
> Reader::GetNextInternal().
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833158741>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAFISPOVBXPH7F5DAKPRRRDTMHWENANCNFSM44DJOMUA>
> .
>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833187909,ashahab,2021-05-06 02:57:37,48903,[49121],Data bug,1,"Yang, your earlier solution of commenting out ref and unref does not seem safe to me, and may result in memory leaks. On Wed, May 5, 2021 at 6:28 PM Yang Chen ***@***.***> wrote: > Tried to debug more. The reason one thread does not call input_->Ref() is > SnapshotDatasetV2Op::Dataset::Iterator::Reader::Initialize returns a > cancelled error somewhere. In that case, the destructor shouldn't call > input_->UnRef(), and there shouldn't be any calls to > Reader::GetNextInternal(). > > â€” > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub > <[url]#issuecomment-833158741>, > or unsubscribe > <[url] > . >",-2
"Yes, thanks for the note. I have updated the comment earlier. I have a better fix now.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833188464,yangustc07,2021-05-06 02:59:30,48903,[49121],Data bug,1,"Yes, thanks for the note. I have updated the comment earlier. I have a better fix now.",3
"Yeah I think the fix can handle the cancellation.

On Wed, May 5, 2021 at 7:59 PM Yang Chen ***@***.***> wrote:

> Yes, I have updated the comment earlier. I have a better fix now.
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833188464>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAFISPKJQLJYY7EPEZCHVJDTMIA2LANCNFSM44DJOMUA>
> .
>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833194034,ashahab,2021-05-06 03:17:50,48903,[49121],Data bug,1,"Yeah I think the fix can handle the cancellation. On Wed, May 5, 2021 at 7:59 PM Yang Chen ***@***.***> wrote: > Yes, I have updated the comment earlier. I have a better fix now. > > â€” > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub > <[url]#issuecomment-833188464>, > or unsubscribe > <[url] > . >",2
@yangustc07 do you have a fix?,IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833795753,ashahab,2021-05-06 19:19:48,48903,[49121],Data bug,1,@yangustc07 do you have a fix?,0
"Yes, I just submitted https://github.com/tensorflow/tensorflow/commit/858a5698a7b4ee95befa2e9c3d7aaa0a8170ec54. I'm trying to see why it changed my commit message to ""internal change."" The original description was:

```
[tf.data] Fix snapshot segfault when using repeat and prefetch.

Fixes: https://github.com/tensorflow/tensorflow/issues/48903.

`input_->MakeIterator` refs the dataset in
https://github.com/tensorflow/tensorflow/blob/a9cf3a0e4b419630f0183b0cc4e48e0641a62721/tensorflow/core/framework/dataset.cc#L679. So
we don't need to call `input_->Ref()`. Otherwise, if
`SnapshotDatasetV2Op::Dataset::Iterator::Reader::Initialize` returns an error,
`input_->Ref()` isn't called, but the destructor still calls `input_->Unref()`.

If `InitializeIterator` returns an error, the iterator_ needs to be reset to
nullptr. Otherwise, if GetNextInternal is called a second time,
`iterator_->GetNext` may dereference a null `input_impl_`.

```",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833797982,yangustc07,2021-05-06 19:23:40,48903,[49121],Data bug,1,"Yes, I just submitted [url] I'm trying to see why it changed my commit message to ""internal change."" The original description was: ``[code]input_->MakeIterator[code]input_->Ref()[code]SnapshotDatasetV2Op::Dataset::Iterator::Reader::Initialize[code]input_->Ref()[code]input_->Unref()[code]InitializeIterator[code]iterator_->GetNext[code]input_impl_[code]``",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48903"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48903"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833798291,google-ml-butler[bot],2021-05-06 19:24:11,48903,[49121],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@trentlo @chsigg Any idea what's going on?,IssueComment,https://github.com/tensorflow/tensorflow/issues/48869#issuecomment-831647638,sanjoy,2021-05-04 02:21:52,48869,[49173],Processor bug,0,@trentlo @chsigg Any idea what's going on?,0
"> @trentlo @chsigg Any idea what's going on?

This is a known issue that we mention to you in the last meeting.

@nouiz is back. He knows more. (@bas-aarts FYI.)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48869#issuecomment-831651371,trentlo,2021-05-04 02:39:13,48869,[49173],Processor bug,0,> @trentlo @chsigg Any idea what's going on? This is a known issue that we mention to you in the last meeting. @nouiz is back. He knows more. (@bas-aarts FYI.),0
"This diff fix at least part of the problem:
```
diff --git a/tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.h b/tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.h
index 8c7613992ea..b04c592046e 100644
--- a/tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.h
+++ b/tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.h
@@ -67,7 +67,7 @@ class GpuCudaMallocAsyncAllocator : public Allocator {
   explicit GpuCudaMallocAsyncAllocator(PlatformDeviceId platform_device_id,
                                        size_t pool_size,
                                        bool reserve_memory = false,
-                                       bool compute_stats = false);
+                                       bool compute_stats = true);
   ~GpuCudaMallocAsyncAllocator() override;
   string Name() override { return name_; }
   void* AllocateRaw(size_t alignment, size_t num_bytes) override;
```

But I have problems building upstream TF in our container. So I have difficulty investigating this. Here is the error in case you have an idea what is going on:

```
Execution platform: @local_execution_config_platform//:platform
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor
flow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: /root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/t
ensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow7functor12UnaryFunctorIN5Eigen9GpuDeviceENS0_3negINS2_4halfEEEEclERKS3_NS2_9TensorMapINS2_6TensorIS5_Li1ELi1ElEELi16ENS2_11MakePointerEEENSA_
INSB_IKS5_Li1ELi1ElEELi16ESD_EE

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor
flow/python/tools/api/generator/create_python_api.py"", line 26, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor
flow/python/__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor
flow/python/eager/context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor
flow/python/pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor
flow/python/pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor
flow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: /root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/t
ensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow7functor12UnaryFunctorIN5Eigen9GpuDeviceENS0_3negINS2_4halfEEEEclERKS3_NS2_9TensorMapINS2_6TensorIS5_Li1ELi1ElEELi16ENS2_11MakePointerEEENSA_
INSB_IKS5_Li1ELi1ElEELi16ESD_EE
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48869#issuecomment-831955653,nouiz,2021-05-04 13:47:42,48869,[49173],Processor bug,0,This diff fix at least part of the problem: ``[code]`[code]`[code]``,1
"I fixed the above link error. But now compiling TF is way longer... So I'm still blocked. See this new nvbug:
https://github.com/tensorflow/tensorflow/issues/48966",IssueComment,https://github.com/tensorflow/tensorflow/issues/48869#issuecomment-834725018,nouiz,2021-05-07 19:38:43,48869,[49173],Processor bug,0,I fixed the above link error. But now compiling TF is way longer... So I'm still blocked. See this new nvbug: [url],-3
"There is more ( maybe it helps): I trained a model on images data using tensorflow 2.5.0-rc3.  when making predicitnons, it resulted in Out of Memory error.  Then i downgraded to 2.4.1, loading the same pre-trainned model and data ( same batch_size,etc). The predicitons were just fine, using at least, 1.5GB less of my GPU memory ( it has 8GB).  ",IssueComment,https://github.com/tensorflow/tensorflow/issues/48869#issuecomment-837310457,rpsantosa,2021-05-10 20:43:54,48869,[49173],Processor bug,0,"There is more ( maybe it helps): I trained a model on images data using tensorflow 2.5.0-rc3. when making predicitnons, it resulted in Out of Memory error. Then i downgraded to 2.4.1, loading the same pre-trainned model and data ( same batch_size,etc). The predicitons were just fine, using at least, 1.5GB less of my GPU memory ( it has 8GB).",-1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48869"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48869"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48869#issuecomment-862913476,google-ml-butler[bot],2021-06-17 04:27:04,48869,[49173],Processor bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thanks, can you open a PR with tests?",IssueComment,https://github.com/tensorflow/tensorflow/issues/49214#issuecomment-841803908,bhack,2021-05-16 11:25:12,49214,[49222],Code bug,0,"Thanks, can you open a PR with tests?",2
"Yes, I'm going to prepare some simple code for reproduction and unit tests.",IssueComment,https://github.com/tensorflow/tensorflow/issues/49214#issuecomment-841804711,bzamecnik,2021-05-16 11:33:07,49214,[49222],Code bug,0,"Yes, I'm going to prepare some simple code for reproduction and unit tests.",3
"It looks that there's an existing test in [cudnn_recurrent_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/cudnn_recurrent_test.py#L274
) but for some reason has been [disabled](https://github.com/tensorflow/tensorflow/commit/8d25e4bf616b7ae4ed101c580a23421616bf674c). It was done just before v2.3.0-rc0 so it's likely caused by the bug described above.

```
  # TODO(b/156439419): Reenable after the bug is fixed.
  @parameterized.named_parameters(
      *testing_utils.generate_combinations_with_testcase_name(
          rnn_type=['LSTM', 'GRU'], to_cudnn=[True, False],
          bidirectional=[True, False], implementation=[1, 2],
          model_nest_level=[1, 2], model_type=['seq', 'func']))
  @test_util.run_v1_only('b/120911602, b/112083752')
  @test_util.run_gpu_only
  def DISALBED_test_load_weights_between_noncudnn_rnn(
```
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49214#issuecomment-841849915,bzamecnik,2021-05-16 17:38:18,49214,[49222],Code bug,0,It looks that there's an existing test in [cudnn_recurrent_test.py]([url]#L274 ) but for some reason has been [disabled]([url] It was done just before v2.3.0-rc0 so it's likely caused by the bug described above. ``[code]``,0
"A workaround to patch the module before the new Tensorflow is released (or for older TF 2 installations):

```
import importlib
from tensorflow.python.keras.saving import hdf5_format

filename = hdf5_format.__file__
with open(filename, 'r') as f:
    content = f.read()
if ""['Model', 'Sequential']"" in content:
    print(f'Patching {filename} to support nested Functional model...')
    content = content.replace(""['Model', 'Sequential']"", ""['Model', 'Sequential', 'Functional']"")
    with open(filename, 'w') as f:
        f.write(content)

    importlib.reload(hdf5_format)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/49214#issuecomment-841878661,bzamecnik,2021-05-16 21:14:31,49214,[49222],Code bug,0,A workaround to patch the module before the new Tensorflow is released (or for older TF 2 installations): ``[code]``,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49214"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49214"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49214#issuecomment-847126361,google-ml-butler[bot],2021-05-24 15:35:07,49214,[49222],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@tsbertalan - Thank you so much for mentioning this, and for creating a gist as an example. I agree that the API documentation for `tf.custom_gradient` could be improved, and this is a great start. ðŸ™‚ 

**A few things:**

- Would you like to make a PR to **update the documentation** for `tf.custom_gradient`? If yes, I'd be happy to point you to where to get started!

- Would you be interested in **converting your [gist example](https://gist.github.com/tsbertalan/b6c02bf6e39116d8446faa0159a011af) to TensorFlow 2.0 style** (ping @alextp), and including it as an example in [`tensorflow/examples`](http://www.github.com/tensorflow/examples)?

- I noticed that you're a post-doc at MIT; congratulations! Would you be interested in working on similar efforts as a [Google Summer of Code project](https://summerofcode.withgoogle.com/organizations/6137730124218368/)? TensorFlow has recently been added as a mentoring organization, and **updating the API docs with detailed technical examples** would be a great project.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-468965752,dynamicwebpaige,2019-03-02 22:17:50,26270,[49488],Documentation bug,0,"@tsbertalan - Thank you so much for mentioning this, and for creating a gist as an example. I agree that the API documentation for [code] could be improved, and this is a great start. ðŸ™‚ **A few things:** - Would you like to make a PR to **update the documentation** for [code]? If yes, I'd be happy to point you to where to get started! - Would you be interested in **converting your [gist example]([url] to TensorFlow 2.0 style** (ping @alextp), and including it as an example in [[code]]([url] - I noticed that you're a post-doc at MIT; congratulations! Would you be interested in working on similar efforts as a [Google Summer of Code project]([url] TensorFlow has recently been added as a mentoring organization, and **updating the API docs with detailed technical examples** would be a great project.",5
Can i also work on updation of docs for tf.custom_gradient !?,IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-469106001,Shashankjain12,2019-03-04 03:27:00,26270,[49488],Documentation bug,0,Can i also work on updation of docs for tf.custom_gradient !?,2
"Thanks for the comments! I'd love to have improved documentation for tf.custom_gradient, and would love to review such a pull request.

One minor nit though is that when you say ""the sum of the gradient over examples is not ""the gradient""--only the per-example gradient truly deserves that name"" I do not quite agree; TensorFlow only differentiates scalar loss functions, so ""the gradient"" is shorthand for ""the gradient of the sum / average of per-example losses"" and then because the gradient of a sum is the sum of the gradients then I think the text there is mostly correct.

That said I agree with you that correct is not enough and that we need to clarify these comments so others don't make the same mistake.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-469324724,alextp,2019-03-04 16:45:55,26270,[49488],Documentation bug,0,"Thanks for the comments! I'd love to have improved documentation for tf.custom_gradient, and would love to review such a pull request. One minor nit though is that when you say ""the sum of the gradient over examples is not ""the gradient""--only the per-example gradient truly deserves that name"" I do not quite agree; TensorFlow only differentiates scalar loss functions, so ""the gradient"" is shorthand for ""the gradient of the sum / average of per-example losses"" and then because the gradient of a sum is the sum of the gradients then I think the text there is mostly correct. That said I agree with you that correct is not enough and that we need to clarify these comments so others don't make the same mistake.",3
"My original post is below, this is only because it might help others trying to get custom_gradient to work with keras in more complicated situations...

OK, might be a documentation issue, but probably I was not reading enough documentation at all. If you use custom_gradient you are only allowed to use limited python statements, mainly tensorflow operations:
this gradient seems to work at least, maybe it helps others:
```

@tf.custom_gradient
def select_subnet_layer(x):
    # the last in x are the select, before is divided into parts
    x_select = x[:,:,-args.lstm_num:]
    x_data = x[:,:,:-args.lstm_num]
    print(""x_select"",x_select.shape)
    size_of_out = x_data.shape[2] // args.lstm_num
    out = x_data[:,:,:size_of_out]
    out = 0 * out
    for i in range(args.lstm_num):
        out += x_data[:,:,(i * size_of_out):((i+1)*size_of_out)]* x_select[:,:,i:i+1]
    print(""out"",out.shape)
    print(""x"",x.shape)
    def custom_grad(dy):
        size_of_out = (x.shape[2]-args.lstm_num) // args.lstm_num
        gg = []
        gs = []
        for i in range(args.lstm_num):
            gg.append(  x[:,:,size_of_out * args.lstm_num +i:size_of_out * args.lstm_num + i + 1] * dy)
            tmp =  x[:,:,size_of_out * i:size_of_out * (i+1)] * dy
            gs.append(keras.backend.sum(tmp, axis = 2, keepdims = True))
        grad = keras.backend.concatenate(gg + gs)
        print(gg,gs,grad)
        return grad # keras.backend.clip(grad,-1,1)
    return out, custom_grad

```


I am not sure, if I have a documentation related issue, or maybe it is a bug.

I created a custom layer and I need to add a custom gradient:

The problem is: My layer is included in a LSTM network and therefore has changing input and output shapes. Initially it has e.g.  (?,?,153) e.g. which is (1, variable size, 153) during calculation.

my keras layer is defined as:

```
@tf.custom_gradient
def select_subnet_layer(x):
    global ssss
    # the last in x are the select, before is divided into parts
    x_select = x[:,:,-args.lstm_num:]
    x_data = x[:,:,:-args.lstm_num]
    print(""x_select"",x_select.shape)
    size_of_out = x_data.shape[2] // args.lstm_num
    out = x_data[:,:,:size_of_out]
    out = 0 * out
    for i in range(args.lstm_num):
        out += x_data[:,:,(i * size_of_out):((i+1)*size_of_out)]* x_select[:,:,i:i+1]
    print(""out"",out.shape)
    print(""x"",x.shape)
    def custom_grad(dy):
        print('debugging',dy)
        s1 = dy.shape.as_list()[0]
        s2 = dy.shape.as_list()[1]
        print(dy,[dy])
        if s1 is None:
            return tf.fill((1, 324, size_of_out*args.lstm_num + args.lstm_num), 1.0)
        grad_nump = np.ones([s1,s2,153], dtype='float32')
        if x.shape.as_list()[0] is not None:
            for i in range(args.lstm_num):
                print('???',args.lstm_num)
                grad_nump[:,:, size_of_out*i : size_of_out*(i+1)] = x[:,:,size_of_out * args.lstm_num + i]
                grad_nump[:,:,size_of_out * args + i] = np.sum(x[:,:,size_of_out*i : size_of_out*(i+1)])
        grad = tf.convert_to_tensor(grad_nump)
        return grad
    return out, custom_grad

class CustomLayer(Layer):

    def __init__(self, **kwargs):

        super(CustomLayer, self).__init__(**kwargs)

    def call(self, x):
        return select_subnet_layer(x[:,:])  # you don't need to explicitly define the custom gradient

    def compute_output_shape(self, input_shape):
        print(input_shape[2])
        return (input_shape[0], input_shape[1], (int(input_shape[2]) - args.lstm_num ) // args.lstm_num)

```
if s1 is None:     is not what I want. I tried to return a tf tensor placeholder with correct dimensions, but this dimension is not changed to a correct one during evaluation of the net too.

Later it does not change the shape?! Therefore I get the Error

InvalidArgumentError: shape of dy was [1,324,153] instead of [1,262,153]
	 [[{{node training_1/RMSprop/gradients/custom_layer_3/strided_slice_grad/StridedSliceGrad}}]]
	 [[loss_2/mul/_183]]

when I do have a changed dimension in one training example.

I have the full source of the file on github:
https://github.com/dsmic/LearnMultiplyByHand/blob/5e550ae6435c623c325889d8d5a28d65a12a092a/learnmultiply_schriftlich_limit_traindata_subnets.py

I would love to get any suggestion what the problem might be, and of cause would help in case it is a bug to fix. 
",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-519460815,dsmic,2019-08-08 10:22:29,26270,[49488],Documentation bug,0,"My original post is below, this is only because it might help others trying to get custom_gradient to work with keras in more complicated situations... OK, might be a documentation issue, but probably I was not reading enough documentation at all. If you use custom_gradient you are only allowed to use limited python statements, mainly tensorflow operations: this gradient seems to work at least, maybe it helps others: ``[code]`[code]`[code]`` if s1 is None: is not what I want. I tried to return a tf tensor placeholder with correct dimensions, but this dimension is not changed to a correct one during evaluation of the net too. Later it does not change the shape?! Therefore I get the Error InvalidArgumentError: shape of dy was [1,324,153] instead of [1,262,153] [[{{node training_1/RMSprop/gradients/custom_layer_3/strided_slice_grad/StridedSliceGrad}}]] [[loss_2/mul/_183]] when I do have a changed dimension in one training example. I have the full source of the file on github: [url] I would love to get any suggestion what the problem might be, and of cause would help in case it is a bug to fix.",0
"Is this still open? If so, I would like to take on this. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-547355732,lsgrep,2019-10-29 10:31:17,26270,[49488],Documentation bug,0,"Is this still open? If so, I would like to take on this.",3
"For me it is closed, I learned to use only limited python statements, but did not find any detailed documentation, what is allowed....",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-547389860,dsmic,2019-10-29 12:10:22,26270,[49488],Documentation bug,0,"For me it is closed, I learned to use only limited python statements, but did not find any detailed documentation, what is allowed....",-2
"@tsbertalan @dynamicwebpaige Has the issue been resolved?
If not I would like to improve it",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-552113412,bharatnishant,2019-11-09 16:07:27,26270,[49488],Documentation bug,0,@tsbertalan @dynamicwebpaige Has the issue been resolved? If not I would like to improve it,2
"@bharatnishant I think, actually, the documentation that needs this clarification first is that for the regular `tf.gradients` function. It does claim, from the very start, that it's for computing ""symbolic derivatives of sum of `ys` w.r.t. `x` in `xs`."" However, there appear to be cases in which this is not enforced, with confusing interactions between the presense of a batch dimension in either `ys` or `xs`.  

I'd prefer more predictable behavior, with an exception raised rather than an automatic sum in the cases where a Jacobian-like computation is not possible, but, failing that, it seems reasonable at least to have documentation of when to expect that such an automatic sum will be added silently. As with convolution, we should be able to predict a-priori the shape of the gradient tensor(s) for all the possible input shapes for `x`(s) and `ys`, including batch dimensions in either.

@alextp I get your point about how `tf.gradients` is only really intended for scalar functions. There would be no need for this to even be a shorthand in my ideal world where exceptions were raised when `ys` was not a scalar. However, in reality, there appear to be circumstances where the resulting tensor will provide unaggregated gradients $dL_i/d\theta_j$, where $i$ is the batch index, and $j$ is the index across this particular parameter vector.

I think that a distinction should be made (and, in some fashion, is made) between a batch index and a true index, where computation for each batch index value is conceptually independent (except for some final aggregation), whereas true indices interact in everyday linear algebraic computations. I think the point about `tf.gradients` being for scalars applies more to the second type of index than the first--a reasonable terminology would be to speak of unaggregated gradients (which are d/dtheta of a scalar, evaluated per-entry in some dataset), and then change to the term ""(un)aggregated Jacobians"" when discussing derivatives of vectors per-datum. Also, note here, that I think it makes sense to describe tensors with shapes of both `()` and `(None,)` as ""scalar"".

For that matter, it would be nice to know what the real performance tradeoffs are for computing a Jacobian. [Another issue 
](https://github.com/tensorflow/tensorflow/issues/675) discusses some methods for doing that, but do these scale, say, linearly in the output dimension `M`? That is, if you formulate this is the stacking of the gradients of `M` several scalar-valued functions, does it in fact just take `M` times longer to compute that? How does this change if you use the experimental `tf.python.ops.parallel_for.gradients.jacobian`? I believe it does raise warnings about space usage, and, in some circumstances, the ""Jacobian"" returned can have *two* batch dimensions `i` and `j`, and an enormous number of zero entries for all the cases where `i!=j`.

As for clarification of the `tf.custom_gradients` documentation, I understand that, in deriving backpropagation as the chain rule, several Jacobian-vector products emerge that can can be computed more efficiently as such rather than as explicit full Jacobian evaluations followed by matrix-vector products. However, it is not totally clear to me how this squares with the terminology of ""initial value gradients"", ""received gradients"", or sometimes ""upstream gradients"" that is used to refer to the argument of the wrapped function. A more mathematical treatment would be very welcome, showing the complete chain rule for a simple expression with proper equivalences drawn between the mathematical expressions and the code objects/arguments.

I also see now that this is tagged as API v 2, though I'm still using the 1.x versions. I think that `tf.gradients` and `tf.custom_gradient` at least have similar documentation between the two versions, but in v2, there might be additional complications surrounding the ""gradient tape"" paradigm.

Sorry for the long-winded response. TensorFlow has been in a confusing state of flux over the past few versions, and so I (obviously) have many points of confusion on this.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-553177520,tsbertalan,2019-11-13 00:14:32,26270,[49488],Documentation bug,0,"@bharatnishant I think, actually, the documentation that needs this clarification first is that for the regular [code] function. It does claim, from the very start, that it's for computing ""symbolic derivatives of sum of [code] w.r.t. [code] in [code]."" However, there appear to be cases in which this is not enforced, with confusing interactions between the presense of a batch dimension in either [code] or [code]. I'd prefer more predictable behavior, with an exception raised rather than an automatic sum in the cases where a Jacobian-like computation is not possible, but, failing that, it seems reasonable at least to have documentation of when to expect that such an automatic sum will be added silently. As with convolution, we should be able to predict a-priori the shape of the gradient tensor(s) for all the possible input shapes for [code](s) and [code], including batch dimensions in either. @alextp I get your point about how [code] is only really intended for scalar functions. There would be no need for this to even be a shorthand in my ideal world where exceptions were raised when [code] was not a scalar. However, in reality, there appear to be circumstances where the resulting tensor will provide unaggregated gradients $dL_i/d\theta_j$, where $i$ is the batch index, and $j$ is the index across this particular parameter vector. I think that a distinction should be made (and, in some fashion, is made) between a batch index and a true index, where computation for each batch index value is conceptually independent (except for some final aggregation), whereas true indices interact in everyday linear algebraic computations. I think the point about [code] being for scalars applies more to the second type of index than the first--a reasonable terminology would be to speak of unaggregated gradients (which are d/dtheta of a scalar, evaluated per-entry in some dataset), and then change to the term ""(un)aggregated Jacobians"" when discussing derivatives of vectors per-datum. Also, note here, that I think it makes sense to describe tensors with shapes of both [code] and [code] as ""scalar"". For that matter, it would be nice to know what the real performance tradeoffs are for computing a Jacobian. [Another issue ]([url] discusses some methods for doing that, but do these scale, say, linearly in the output dimension [code]? That is, if you formulate this is the stacking of the gradients of [code] several scalar-valued functions, does it in fact just take [code] times longer to compute that? How does this change if you use the experimental [code]? I believe it does raise warnings about space usage, and, in some circumstances, the ""Jacobian"" returned can have *two* batch dimensions [code] and [code], and an enormous number of zero entries for all the cases where [code]. As for clarification of the [code] documentation, I understand that, in deriving backpropagation as the chain rule, several Jacobian-vector products emerge that can can be computed more efficiently as such rather than as explicit full Jacobian evaluations followed by matrix-vector products. However, it is not totally clear to me how this squares with the terminology of ""initial value gradients"", ""received gradients"", or sometimes ""upstream gradients"" that is used to refer to the argument of the wrapped function. A more mathematical treatment would be very welcome, showing the complete chain rule for a simple expression with proper equivalences drawn between the mathematical expressions and the code objects/arguments. I also see now that this is tagged as API v 2, though I'm still using the 1.x versions. I think that [code] and [code] at least have similar documentation between the two versions, but in v2, there might be additional complications surrounding the ""gradient tape"" paradigm. Sorry for the long-winded response. TensorFlow has been in a confusing state of flux over the past few versions, and so I (obviously) have many points of confusion on this.",-1
"I think this issue is still open. If it is, I would like to work on it and improve the documentation.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-559148167,tanmoyio,2019-11-27 16:00:05,26270,[49488],Documentation bug,0,"I think this issue is still open. If it is, I would like to work on it and improve the documentation.",3
"@tsbertalan @dynamicwebpaige @alextp Since the issue is still open, can I work on it and do the required changes in documentation?",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-570554823,Saumil-Agarwal,2020-01-03 12:05:41,26270,[49488],Documentation bug,0,"@tsbertalan @dynamicwebpaige @alextp Since the issue is still open, can I work on it and do the required changes in documentation?",2
"Sure, please send a PR!

On Fri, Jan 3, 2020 at 4:05 AM Saumil-Agarwal <notifications@github.com>
wrote:

> @tsbertalan <https://github.com/tsbertalan> @dynamicwebpaige
> <https://github.com/dynamicwebpaige> @alextp <https://github.com/alextp>
> Since the issue is still open, can I work on it and do the required changes
> in documentation?
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/26270?email_source=notifications&email_token=AAABHRO2AEAY7EZOOOUAH7DQ34SZVA5CNFSM4G3ICUN2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIA7TRY#issuecomment-570554823>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAABHROYGTKNGE2RREF4AGDQ34SZVANCNFSM4G3ICUNQ>
> .
>


-- 
 - Alex
",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-570988029,alextp,2020-01-06 03:17:58,26270,[49488],Documentation bug,0,"Sure, please send a PR! On Fri, Jan 3, 2020 at 4:05 AM Saumil-Agarwal <[email]> wrote: > @tsbertalan <[url] @dynamicwebpaige > <[url] @alextp <[url] > Since the issue is still open, can I work on it and do the required changes > in documentation? > > â€” > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub > <[url]#issuecomment-570554823>, > or unsubscribe > <[url] > . > -- - Alex",3
bump,IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-596551952,ziofil,2020-03-09 14:15:36,26270,[49488],Documentation bug,0,bump,0
is this issues still occur?,IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-670505284,hfahrudin,2020-08-07 13:02:53,26270,[49488],Documentation bug,0,is this issues still occur?,0
"Hello, it's been quite some time since the issue has been open and looks like there aren't any active linked PR. If this issue is still open I will begin to work on it.
I'm not too aware of the functionality of the custom_gradient function. However, judging by the comments made by @tsbertalan and @alextp the following changes have to be made to the documentation:
- The document should clarify that under certain ""cases an automatic sum will be added silently"".
- Clearing up the differences between ""a batch index and a true index""

Feel free to correct me if I'm wrong as my knowledge of gradients is fairly limited. Since it is also my first time working on an open-source issue I would greatly appreciate it if anyone could point me towards the guidelines for PR and making documentation changes.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-674123690,Harsh188,2020-08-14 15:15:24,26270,[49488],Documentation bug,0,"Hello, it's been quite some time since the issue has been open and looks like there aren't any active linked PR. If this issue is still open I will begin to work on it. I'm not too aware of the functionality of the custom_gradient function. However, judging by the comments made by @tsbertalan and @alextp the following changes have to be made to the documentation: - The document should clarify that under certain ""cases an automatic sum will be added silently"". - Clearing up the differences between ""a batch index and a true index"" Feel free to correct me if I'm wrong as my knowledge of gradients is fairly limited. Since it is also my first time working on an open-source issue I would greatly appreciate it if anyone could point me towards the guidelines for PR and making documentation changes.",3
"@Harsh188 I am open for this or any other type of work that needs improvement. I am just begining out my journey as an open-source cotributor and hence I would appreciate any pointers or useful tips in order to get started as a contributor.

Please connect with me if you find a suitable time for the same.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-710075130,AmitSharma1127,2020-10-16 14:16:49,26270,[49488],Documentation bug,0,@Harsh188 I am open for this or any other type of work that needs improvement. I am just begining out my journey as an open-source cotributor and hence I would appreciate any pointers or useful tips in order to get started as a contributor. Please connect with me if you find a suitable time for the same.,3
"Same here, I am also a beginner and would like to contribute. Is there any places where I can help?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-716664127,ghost,2020-10-26 16:26:00,26270,[49488],Documentation bug,0,"Same here, I am also a beginner and would like to contribute. Is there any places where I can help?",3
"Hey there,
I am new to open source environment,and i would like to contribute.Can anybody explain me 'How to get started?'",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-719159336,suryagowda,2020-10-30 04:08:41,26270,[49488],Documentation bug,0,"Hey there, I am new to open source environment,and i would like to contribute.Can anybody explain me 'How to get started?'",3
"I'm not sure if this is what you're looking for, but the first thing is to clone the repository (`git clone [url of repo]`). Then you make a new branch in which you will develop a new feature or fix a bug. Finally, when the work is done you open a pull request here on GitHub to have the new code reviewed and eventually merged.",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-719504216,ziofil,2020-10-30 11:40:34,26270,[49488],Documentation bug,0,"I'm not sure if this is what you're looking for, but the first thing is to clone the repository ([code]). Then you make a new branch in which you will develop a new feature or fix a bug. Finally, when the work is done you open a pull request here on GitHub to have the new code reviewed and eventually merged.",0
"hey is this issue still open want to work on it and I am new to tensorflow community.
 @dynamicwebpaige  @ziofil ",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-736995068,sparkingdark,2020-12-02 05:13:04,26270,[49488],Documentation bug,0,hey is this issue still open want to work on it and I am new to tensorflow community. @dynamicwebpaige @ziofil,3
"Hey, I am new to the open-source community and I would like to contribute, I have gone through the CONTRIBUTION.md file and gone through the good first issue and every possible thing I have gone, but still not getting where to start, can anyone help me out, where to start with?
@dynamicwebpaige @alextp ",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-738638452,devkumar24,2020-12-04 08:20:25,26270,[49488],Documentation bug,0,"Hey, I am new to the open-source community and I would like to contribute, I have gone through the CONTRIBUTION.md file and gone through the good first issue and every possible thing I have gone, but still not getting where to start, can anyone help me out, where to start with? @dynamicwebpaige @alextp",1
"Hello!
I am newbie to open source contribution and really interested to contribute!! . But I have very very less knowledge about it . Can anyone help me please?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-748419253,Aditya-Komaravolu,2020-12-19 04:54:53,26270,[49488],Documentation bug,0,Hello! I am newbie to open source contribution and really interested to contribute!! . But I have very very less knowledge about it . Can anyone help me please?,2
I have no clue in programming and i am looking for someone who can write script and programme,IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-768176559,jacksondouglas1010,2021-01-27 10:05:50,26270,[49488],Documentation bug,0,I have no clue in programming and i am looking for someone who can write script and programme,0
Is there anyone who can help me to create Program rock paper scissors game play with NAO robot? ,IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-830480743,mahidurrahman251,2021-05-01 01:11:18,26270,[49488],Documentation bug,0,Is there anyone who can help me to create Program rock paper scissors game play with NAO robot?,0
"Hey there! 
@dynamicwebpaige @tsbertalan I have experience in TensorFlow, but I'm new to open source. I see you would like to have some examples, could you please explain more?ðŸ˜…",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-837222608,a-ma-n,2021-05-10 19:44:58,26270,[49488],Documentation bug,0,"Hey there! @dynamicwebpaige @tsbertalan I have experience in TensorFlow, but I'm new to open source. I see you would like to have some examples, could you please explain more?ðŸ˜…",2
"Yeah, I had a project about NAO robot to play rock paper scissors games.
And i did that in choregraphe. If you think that i can help you then leet
me know.

On Fri, 11 Jun 2021 at 00:37, copybara-service[bot] <
***@***.***> wrote:

> Closed #26270 <https://github.com/tensorflow/tensorflow/issues/26270> via
> #49488 <https://github.com/tensorflow/tensorflow/pull/49488>.
>
> â€”
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/26270#event-4872614385>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ATZUPVX67BUQN6CQIG3QAW3TSDS5HANCNFSM4G3ICUNQ>
> .
>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/26270#issuecomment-860059013,mahidurrahman251,2021-06-12 14:11:50,26270,[49488],Documentation bug,0,"Yeah, I had a project about NAO robot to play rock paper scissors games. And i did that in choregraphe. If you think that i can help you then leet me know. On Fri, 11 Jun 2021 at 00:37, copybara-service[bot] < ***@***.***> wrote: > Closed #26270 <[url] via > #49488 <[url] > > â€” > You are receiving this because you commented. > Reply to this email directly, view it on GitHub > <[url]#event-4872614385>, > or unsubscribe > <[url] > . >",2
I don't see any errors (or anything involving ragged tensors or reduce_variance) in the attached gist.  Did you link the right one?,IssueComment,https://github.com/tensorflow/tensorflow/issues/49606#issuecomment-847882166,edloper,2021-05-25 13:43:26,49606,[49609],Data bug,0,I don't see any errors (or anything involving ragged tensors or reduce_variance) in the attached gist. Did you link the right one?,0
"I was able to reproduce this problem with:

```
import tensorflow as tf
x = tf.ragged.constant([[1., 2, 3], [4, 5], [6, 7, 8, 9]])
print(tf.math.reduce_variance(x, axis=1))  # succeeds
print(tf.math.reduce_variance(x, axis=0))  # fails
```

The problem arises because the current dispatch mechanism is reactive, not proactive.  In particular, the current dispatch mechanism is a fallback that gets used when the ""normal"" implementation raises an error.  This design was used to ensure that dispatch didn't add overhead to existing operations, but we have plans to change it to a proactive mechanism, which checks the types of arguments before running the operation.

So the long term fix is to update the dispatch to be proactive, and not a fallback mechanism.

But until we've finished that update, a shorter-term solution is to update reduce_variance to call convert_to_tensor on its input.  Almost all TensorFlow ops call convert_to_tensor on their inputs before processing them.  This ensures that we can pass in non-tensor values, such as numpy arrays or python lists.  The fact that (almost) all TensorFlow ops call convert_to_tensor is what makes the dispatch fallback mechanism work, since this will fail for types such as RaggedTensor.

If we look at some of the other reduce operations in math_ops.py, such as reduce_logsumexp, they do call convert_to_tensor on their input.  I believe that the following change should make dispatch work correctly (though I haven't actually tested it yet):

```
  with ops.name_scope(name):
    input_tensor = ops.convert_to_tensor(input_tensor)       # NEW
    means = reduce_mean(input_tensor, axis=axis, keepdims=True)
```

This change will also have the side benefit that input_tensor won't get converted to a tensor twice.  (In the current code, if input_tensor is a python list or other non-tensor value, then it will get converted twice: once when we call reduce_mean, and again in the expression `input_tensor - means`).

I'd be happy to make that fix if you like; or if you'd prefer to contribute the fix, that would be fine too.",IssueComment,https://github.com/tensorflow/tensorflow/issues/49606#issuecomment-847895341,edloper,2021-05-25 14:00:10,49606,[49609],Data bug,0,"I was able to reproduce this problem with: ``[code]`[code]`[code]`[code]input_tensor - means`). I'd be happy to make that fix if you like; or if you'd prefer to contribute the fix, that would be fine too.",3
"@edloper , apologies. I have updated [gist](https://colab.research.google.com/gist/ashutosh1919/b0591ddb485107187b982a08276712be/untitled550.ipynb)",IssueComment,https://github.com/tensorflow/tensorflow/issues/49606#issuecomment-847895603,ashutosh1919,2021-05-25 14:00:27,49606,[49609],Data bug,0,"@edloper , apologies. I have updated [gist]([url]",2
The issue will move to closed status once the PR is merged.,IssueComment,https://github.com/tensorflow/tensorflow/issues/49606#issuecomment-849308242,tilakrayal,2021-05-27 04:23:07,49606,[49609],Data bug,0,The issue will move to closed status once the PR is merged.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49606"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49606"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49606#issuecomment-858038343,google-ml-butler[bot],2021-06-09 19:36:14,49606,[49609],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@aliencaocao,
I have linked [your PR](https://github.com/tensorflow/tensorflow/pull/49825) to this issue. Meanwhile, can you please provide a reproducible code demonstrating the bug so that community can understand it clearly? Thanks! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/49724#issuecomment-849552697,rmothukuru,2021-05-27 11:23:41,49724,[49825],Code bug,0,"@aliencaocao, I have linked [your PR]([url] to this issue. Meanwhile, can you please provide a reproducible code demonstrating the bug so that community can understand it clearly? Thanks!",2
"Sure. But bfore the code itself, I would just like to remind that this is possibly just a typo and not really a program bug. The stack trace is provided in case of any use, but in this case I doubt if it will be useful.

On a side note, if anyone can suggest a way for me to convert a tensor into numpy array in this particular use case (inside a tf.data mapped function), please advise me as I desperately need to do this. I did try the suggested `tf.data.experimental.enable_debug_mode()` (I corrected the typo here), but it still gives the same 'AttributeError: 'Tensor' object has no attribute 'numpy'' error.

```
import tensorflow as tf
import tensorflow_datasets as tfds

ds = tfds.load('oxford_iiit_pet', split='train')
tf.config.run_functions_eagerly(True)

def preprocess(datapoint):
    mask = datapoint['segmentation_mask']
    mask.numpy()
    return mask

ds.map(preprocess)
```

Running this will give me a warning:

```
C:\Program Files\Python38\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.
  warnings.warn(
```
The suggested `tf.data.experimental.enable.debug_mode()` is the typo, and should be corrected to `tf.data.experimental.enable_debug_mode()`

full stack trace:

```
AttributeError                            Traceback (most recent call last)

<ipython-input-1-16c739303191> in <module>
     10     return mask
     11 
---> 12 ds.map(preprocess)

C:\Program Files\Python38\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in map(self, map_func, num_parallel_calls, deterministic)
   1923         warnings.warn(""The `deterministic` argument has no effect unless the ""
   1924                       ""`num_parallel_calls` argument is specified."")
-> 1925       return MapDataset(self, map_func, preserve_cardinality=True)
   1926     else:
   1927       return ParallelMapDataset(

C:\Program Files\Python38\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in __init__(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)
   4481     self._use_inter_op_parallelism = use_inter_op_parallelism
   4482     self._preserve_cardinality = preserve_cardinality
-> 4483     self._map_func = StructuredFunctionWrapper(
   4484         map_func,
   4485         self._transformation_name(),

C:\Program Files\Python38\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)
   3710     resource_tracker = tracking.ResourceTracker()
   3711     with tracking.resource_tracker_scope(resource_tracker):
-> 3712       self._function = fn_factory()
   3713       # There is no graph to add in eager mode.
   3714       add_to_graph &= not context.executing_eagerly()

C:\Program Files\Python38\lib\site-packages\tensorflow\python\eager\function.py in get_concrete_function(self, *args, **kwargs)
   3132          or `tf.Tensor` or `tf.TensorSpec`.
   3133     """"""
-> 3134     graph_function = self._get_concrete_function_garbage_collected(
   3135         *args, **kwargs)
   3136     graph_function._garbage_collector.release()  # pylint: disable=protected-access

C:\Program Files\Python38\lib\site-packages\tensorflow\python\eager\function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)
   3098       args, kwargs = None, None
   3099     with self._lock:
-> 3100       graph_function, _ = self._maybe_define_function(args, kwargs)
   3101       seen_names = set()
   3102       captured = object_identity.ObjectIdentitySet(

C:\Program Files\Python38\lib\site-packages\tensorflow\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   3442 
   3443           self._function_cache.missed.add(call_context_key)
-> 3444           graph_function = self._create_graph_function(args, kwargs)
   3445           self._function_cache.primary[cache_key] = graph_function
   3446 

C:\Program Files\Python38\lib\site-packages\tensorflow\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3277     arg_names = base_arg_names + missing_arg_names
   3278     graph_function = ConcreteFunction(
-> 3279         func_graph_module.func_graph_from_py_func(
   3280             self._name,
   3281             self._python_function,

C:\Program Files\Python38\lib\site-packages\tensorflow\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    997         _, original_func = tf_decorator.unwrap(python_func)
    998 
--> 999       func_outputs = python_func(*func_args, **func_kwargs)
   1000 
   1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

C:\Program Files\Python38\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in wrapped_fn(*args)
   3685           attributes=defun_kwargs)
   3686       def wrapped_fn(*args):  # pylint: disable=missing-docstring
-> 3687         ret = wrapper_helper(*args)
   3688         ret = structure.to_tensor_list(self._output_structure, ret)
   3689         return [ops.convert_to_tensor(t) for t in ret]

C:\Program Files\Python38\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in wrapper_helper(*args)
   3615       if not _should_unpack(nested_args):
   3616         nested_args = (nested_args,)
-> 3617       ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)
   3618       if _should_pack(ret):
   3619         ret = tuple(ret)

C:\Program Files\Python38\lib\site-packages\tensorflow\python\autograph\impl\api.py in wrapper(*args, **kwargs)
    693       except Exception as e:  # pylint:disable=broad-except
    694         if hasattr(e, 'ag_error_metadata'):
--> 695           raise e.ag_error_metadata.to_exception(e)
    696         else:
    697           raise

AttributeError: in user code:

    <ipython-input-1-16c739303191>:9 preprocess  *
        mask.numpy()
    C:\Program Files\Python38\lib\site-packages\tensorflow\python\framework\ops.py:401 __getattr__
        self.__getattribute__(name)

    AttributeError: 'Tensor' object has no attribute 'numpy'
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/49724#issuecomment-849586089,aliencaocao,2021-05-27 12:21:29,49724,[49825],Code bug,0,"Sure. But bfore the code itself, I would just like to remind that this is possibly just a typo and not really a program bug. The stack trace is provided in case of any use, but in this case I doubt if it will be useful. On a side note, if anyone can suggest a way for me to convert a tensor into numpy array in this particular use case (inside a tf.data mapped function), please advise me as I desperately need to do this. I did try the suggested [code] (I corrected the typo here), but it still gives the same 'AttributeError: 'Tensor' object has no attribute 'numpy'' error. ``[code]`[code]`[code]tf.config.experimental_run_functions_eagerly[code]tf.data.experimental.enable.debug_mode()[code]`[code]tf.data.experimental.enable.debug_mode()[code]tf.data.experimental.enable_debug_mode()[code]`[code]deterministic[code]num_parallel_calls[code]tf.Tensor[code]tf.TensorSpec[code]func_outputs[code]``",-1
@aliencaocao I noticed that your PR got approved but some errors are blocking it from merging. We will look into it. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/49724#issuecomment-853333917,jvishnuvardhan,2021-06-02 19:42:03,49724,[49825],Code bug,0,@aliencaocao I noticed that your PR got approved but some errors are blocking it from merging. We will look into it. Thanks!,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49724"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49724"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49724#issuecomment-854229462,google-ml-butler[bot],2021-06-03 22:34:37,49724,[49825],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Was able to reproduce the issue in TF 2.4 and Nightly version as well. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/5bbf7fed3fe931f4cc07306c91276f88/convert_image_dtype.ipynb).,IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-825787816,saikumarchalla,2021-04-23 16:54:46,48701,[49868],Data bug,0,Was able to reproduce the issue in TF 2.4 and Nightly version as well. Please find the gist [here]([url],0
Thanks for reporting the issue!,IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-833771449,kkimdev,2021-05-06 18:46:41,48701,[49868],Data bug,0,Thanks for reporting the issue!,3
"Hi, Can I take this issue?",IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-847744585,pointhex,2021-05-25 10:17:12,48701,[49868],Data bug,0,"Hi, Can I take this issue?",3
"Yes, please feel free to do so.",IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-848013152,kkimdev,2021-05-25 16:13:50,48701,[49868],Data bug,0,"Yes, please feel free to do so.",3
"@kkimdev thank you. I did changes and try to check it by unit test, but have one small problem. Could you please tell me or send the link where I can find how to start the exact unit test? e.g ConvertImageTest.testNoConvert.
Could you also tell me please how to check what tests failed because of me? And do you have something like Jenkins or whatever where I can check that I don't break something?",IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-850470833,pointhex,2021-05-28 14:45:40,48701,[49868],Data bug,0,"@kkimdev thank you. I did changes and try to check it by unit test, but have one small problem. Could you please tell me or send the link where I can find how to start the exact unit test? e.g ConvertImageTest.testNoConvert. Could you also tell me please how to check what tests failed because of me? And do you have something like Jenkins or whatever where I can check that I don't break something?",0
"@pointhex I think you can put unit test here https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/ops/image_ops_test.py and once you open a Github PR, it will kick off pre-submit testings.  Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-850554683,kkimdev,2021-05-28 17:08:53,48701,[49868],Data bug,0,"@pointhex I think you can put unit test here [url] and once you open a Github PR, it will kick off pre-submit testings. Thanks!",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48701"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48701"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-923477552,google-ml-butler[bot],2021-09-21 00:27:58,48701,[49868],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
The issue is still not resolved in TF master branch. It seems that PR https://github.com/tensorflow/tensorflow/pull/49868 was not merged.,IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-984311988,shkarupa-alex,2021-12-02 05:43:45,48701,[49868],Data bug,0,The issue is still not resolved in TF master branch. It seems that PR [url] was not merged.,-2
Here is a commit where this issue fix was removed https://github.com/tensorflow/tensorflow/commit/56ab2308f72da337865cf765a1844ed9e990d02e#diff-a5a22434f0c18768fc2e10c0e0420ac6f111a5802f67e3df54f155bfefc7094f,IssueComment,https://github.com/tensorflow/tensorflow/issues/48701#issuecomment-986513332,shkarupa-alex,2021-12-06 07:38:36,48701,[49868],Data bug,0,Here is a commit where this issue fix was removed [url]#diff-a5a22434f0c18768fc2e10c0e0420ac6f111a5802f67e3df54f155bfefc7094f,0
Please close this issue once related PR is merged.Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/49941#issuecomment-852189377,tilakrayal,2021-06-01 14:50:51,49941,[49942],Data bug,0,Please close this issue once related PR is merged.Thanks!,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49941"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49941"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49941#issuecomment-857968188,google-ml-butler[bot],2021-06-09 18:41:33,49941,[49942],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
The issue will move to closed status once the PR is merged.,IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-856822598,tilakrayal,2021-06-08 14:34:40,50145,[50179],Build bug,0,The issue will move to closed status once the PR is merged.,0
"@eli-osherovich ,

Please free feel to move this issue to closed status.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-857456862,tilakrayal,2021-06-09 07:26:34,50145,[50179],Build bug,0,"@eli-osherovich , Please free feel to move this issue to closed status.Thanks!",3
"@tilakrayal 
Original PR messed up after a rebase.
Re-created it.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-857897422,eli-osherovich,2021-06-09 17:36:35,50145,[50179],Build bug,0,@tilakrayal Original PR messed up after a rebase. Re-created it.,0
"@eli-osherovich, @tilakrayal, Intel is also seeing this build issue and investigating for solution. As a workaround before any fix, please try with adding this build option,  **--spawn_strategy=standalone** , to the build command and this should temporarily fix the build failure.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-858086858,yimeisun123,2021-06-09 20:43:20,50145,[50179],Build bug,0,"@eli-osherovich, @tilakrayal, Intel is also seeing this build issue and investigating for solution. As a workaround before any fix, please try with adding this build option, **--spawn_strategy=standalone** , to the build command and this should temporarily fix the build failure.",1
"Tensorflow has reverted a change that causes the build failure, there is no need to use the additional option mentioned above if you sync the project today which has this commit https://github.com/tensorflow/tensorflow/commit/763ae9bed64834d6a9a2e18d9eead0d8763df079 (the commit message is incorrect).",IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-858316038,yimeisun123,2021-06-10 05:31:26,50145,[50179],Build bug,0,"Tensorflow has reverted a change that causes the build failure, there is no need to use the additional option mentioned above if you sync the project today which has this commit [url] (the commit message is incorrect).",0
"@yimeisun123 
The above change just puts standalone into config. My fix is better - it keeps the usual build",IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-858327247,eli-osherovich,2021-06-10 05:53:42,50145,[50179],Build bug,0,@yimeisun123 The above change just puts standalone into config. My fix is better - it keeps the usual build,-1
"@eli-osherovich - tried your earlier PR#50143, and still has build failure. I see that you pushed a new PR#50179, will check. Thanks.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-858332109,yimeisun123,2021-06-10 06:02:15,50145,[50179],Build bug,0,"@eli-osherovich - tried your earlier PR#50143, and still has build failure. I see that you pushed a new PR#50179, will check. Thanks.",0
"@yimeisun123  it definitely works for me.

By the way, if you are working on TF inside Intel, have a look at this issue: #50176 . There is a weird  problem inside Intel's code with GCC 11. While trivial code changes can solve it, the problem is quite interesting. Probably worth solving without code changes. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-858946622,eli-osherovich,2021-06-10 19:21:13,50145,[50179],Build bug,0,"@yimeisun123 it definitely works for me. By the way, if you are working on TF inside Intel, have a look at this issue: #50176 . There is a weird problem inside Intel's code with GCC 11. While trivial code changes can solve it, the problem is quite interesting. Probably worth solving without code changes.",2
@tilakrayal  can we move forward with this?,IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-861754798,eli-osherovich,2021-06-15 18:58:22,50145,[50179],Build bug,0,@tilakrayal can we move forward with this?,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50145"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50145"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/50145#issuecomment-863360015,google-ml-butler[bot],2021-06-17 15:55:07,50145,[50179],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@sebltm ,

Every TensorFlow release is compatible with a certain version, for more information please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu).In this case, can you please try installing TensorFlow v2.5 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/50669#issuecomment-876451760,tilakrayal,2021-07-08 13:44:53,50669,[50961],Processor bug,0,"@sebltm , Every TensorFlow release is compatible with a certain version, for more information please take a look at the [tested build configurations]([url]#gpu).In this case, can you please try installing TensorFlow v2.5 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Thanks!",2
"Works with TF 2.5 / CUDA 11.2 / cuDNN 8.1, however this only half solves my problem, since my reason for trying another version of CUDA / cuDNN is that I was getting frequent segmentation faults with this combination, which disappeared after migrating to CUDA 11.4 / cuDNN 8.2.2",IssueComment,https://github.com/tensorflow/tensorflow/issues/50669#issuecomment-878941564,sebltm,2021-07-13 09:45:32,50669,[50961],Processor bug,0,"Works with TF 2.5 / CUDA 11.2 / cuDNN 8.1, however this only half solves my problem, since my reason for trying another version of CUDA / cuDNN is that I was getting frequent segmentation faults with this combination, which disappeared after migrating to CUDA 11.4 / cuDNN 8.2.2",-1
"CC @nouiz 

> since my reason for trying another version of CUDA / cuDNN is that I was getting frequent segmentation faults with this combination

Is there a GH issue about these segfaults?",IssueComment,https://github.com/tensorflow/tensorflow/issues/50669#issuecomment-885946764,sanjoy,2021-07-23 22:36:45,50669,[50961],Processor bug,0,CC @nouiz > since my reason for trying another version of CUDA / cuDNN is that I was getting frequent segmentation faults with this combination Is there a GH issue about these segfaults?,-2
"The ""No allocator statistics"" was fixed about a mount ago (#49173), but it got reverted and i just saw this today.
I'll take a look at this.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50669#issuecomment-886973134,nouiz,2021-07-26 19:37:48,50669,[50961],Processor bug,0,"The ""No allocator statistics"" was fixed about a mount ago (#49173), but it got reverted and i just saw this today. I'll take a look at this.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50669"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50669"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/50669#issuecomment-908273659,google-ml-butler[bot],2021-08-30 11:45:32,50669,[50961],Processor bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"The fix was merged a few hours ago.
Can you wait 24h and try TF nightly build to be sure that it also works for you?
If you have any comments on that new features, please share with us.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50669#issuecomment-908411754,nouiz,2021-08-30 14:55:19,50669,[50961],Processor bug,0,"The fix was merged a few hours ago. Can you wait 24h and try TF nightly build to be sure that it also works for you? If you have any comments on that new features, please share with us.",3
"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c767ecbb5d79e0cfdda8bebb6fa4582e/46911.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46911#issuecomment-773430437,amahendrakar,2021-02-04 16:20:20,46911,[51138],Data bug,1,"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here]([url] Thanks!",0
Colab crashes in TF 2.6 as well.Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/b6bdaeacb30114dcac93f2325c54dfd2/copy-of-untitled92.ipynb).Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/46911#issuecomment-850766652,saikumarchalla,2021-05-29 04:21:38,46911,[51138],Data bug,1,Colab crashes in TF 2.6 as well.Please find the gist [here]([url],-2
Added PR #51138 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46911#issuecomment-892331205,yongtang,2021-08-04 03:23:44,46911,[51138],Data bug,1,Added PR #51138 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46911"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46911"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46911#issuecomment-923513186,google-ml-butler[bot],2021-09-21 01:51:59,46911,[51138],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@rmothukuru 
I ran the code shared on tf 2.4 and nightly, colab crashes. Please find the [gist here](https://colab.research.google.com/gist/Saduf2019/a19ece73799cb1d602387e840fe98574/untitled520.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/46913#issuecomment-773028965,Saduf2019,2021-02-04 04:58:45,46913,[51359],Data bug,1,"@rmothukuru I ran the code shared on tf 2.4 and nightly, colab crashes. Please find the [gist here]([url]",-2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46913"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46913"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46913#issuecomment-782416907,google-ml-butler[bot],2021-02-19 22:31:34,46913,[51359],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"BTW, tf.keras.layers.RepeatVector thorws segmentation fault when data is empty:
~~~python
import tensorflow as tf
import numpy as np
tf.keras.layers.RepeatVector(n=9223372036854775807)(np.ones((0,0)))
~~~

Output:
~~~python
Segmentation fault (core dumped)
~~~",IssueComment,https://github.com/tensorflow/tensorflow/issues/46913#issuecomment-782418845,DNXie,2021-02-19 22:35:20,46913,[51359],Data bug,1,"BTW, tf.keras.layers.RepeatVector thorws segmentation fault when data is empty: ~~~python import tensorflow as tf import numpy as np tf.keras.layers.RepeatVector(n=9223372036854775807)(np.ones((0,0))) ~~~ Output: ~~~python Segmentation fault (core dumped) ~~~",-2
Colab crashes in TF 2.6 as well. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/4ef0fe758f11af629a9485dbfaa17e17/untitled93.ipynb).,IssueComment,https://github.com/tensorflow/tensorflow/issues/46913#issuecomment-850771343,saikumarchalla,2021-05-29 05:06:49,46913,[51359],Data bug,1,Colab crashes in TF 2.6 as well. Please find the gist [here]([url],-2
Added a PR #51359 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46913#issuecomment-894682013,yongtang,2021-08-07 17:25:43,46913,[51359],Data bug,1,Added a PR #51359 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46913"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46913"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46913#issuecomment-901200824,google-ml-butler[bot],2021-08-18 15:16:01,46913,[51359],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"This second input still crashes in the nightly version, see [gist](https://colab.research.google.com/drive/1eGLreialnwDETqk5LipkD1mLd7v5N9vP?usp=sharing) @yongtang 

```
import tensorflow as tf
import numpy as np
tf.keras.layers.RepeatVector(n=9223372036854775807)(np.ones((0,0)))
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/46913#issuecomment-1118661417,DNXie,2022-05-05 14:59:22,46913,[51359],Data bug,1,"This second input still crashes in the nightly version, see [gist]([url] @yongtang ``[code]``",-3
"@Sur3 ,

I was able to execute the code in tf v2.5 without any issues.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/4c8ea2462baf883bc635544e24aef422/classification.ipynb).Also could you please create a virtual environment and test your code again. It helps. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-871952500,tilakrayal,2021-07-01 06:12:32,50545,[51450],Code bug,0,"@Sur3 , I was able to execute the code in tf v2.5 without any issues.Please find the gist of it [here]([url] could you please create a virtual environment and test your code again. It helps. Thanks!",3
"I'm able to reproduce this. I suspect it came from this commit https://github.com/tensorflow/tensorflow/commit/f599aed5d8d73d45991f74ba4c62db92bf716eba, as when I reorder the lines

```
from tensorflow.python.eager import context
from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
```

to


```
from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
from tensorflow.python.eager import context
```

the problem goes away.

Working on testing this in a docker container for reproducibility.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-872229474,sclarkson,2021-07-01 13:04:25,50545,[51450],Code bug,0,I'm able to reproduce this. I suspect it came from this commit [url] as when I reorder the lines ``[code]`[code]`[code]`` the problem goes away. Working on testing this in a docker container for reproducibility.,0
"What do you mean with creating a virtual environment and how would that help?
I'm using Gentoo Linux; when tensorflow-2.5 is installed the code doesn't work, but when I downgrade that package to tensorflow-2.4 it works. Therefore there must be something wrong with the tensorflow-2.5 code.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-872254007,Sur3,2021-07-01 13:36:15,50545,[51450],Code bug,0,"What do you mean with creating a virtual environment and how would that help? I'm using Gentoo Linux; when tensorflow-2.5 is installed the code doesn't work, but when I downgrade that package to tensorflow-2.4 it works. Therefore there must be something wrong with the tensorflow-2.5 code.",-2
"@tilakrayal 

Needs this patch to compile with a local protobuf https://github.com/tensorflow/tensorflow/commit/95abf88e4c117f8445308c3174cc42795a6694e6 which I very hackily applied in the Dockerfile below.

```
FROM ubuntu:20.04

ARG bazel_version=3.7.2
ARG protobuf_version=3.12.4
ARG tensorflow_commit=v2.5.0
ARG compile_jobs=32

WORKDIR /tensorflow-test

# Install build dependencies
RUN apt-get update && \
        DEBIAN_FRONTEND=noninteractive apt-get install -y \
                build-essential \
                autoconf \
                libtool-bin \
                zlib1g-dev \
                unzip \
                wget \
                git \
                openjdk-8-jdk-headless \
                python-is-python3 \
                python3-all-dev \
                python3-setuptools \
                python3-pip \
                python3-six \
                python3-numpy && \
        rm -rf /var/lib/apt/lists/*

# Install Bazel
RUN wget https://storage.googleapis.com/bazel-apt/pool/jdk1.8/b/bazel-${bazel_version}/bazel-${bazel_version}_${bazel_version}_amd64.deb && \
        dpkg -i bazel-*.deb

# Compile and install protobuf
RUN wget -O protobuf-${protobuf_version}.tar.gz \
                https://github.com/protocolbuffers/protobuf/archive/v${protobuf_version}.tar.gz && \
        tar xvf protobuf-${protobuf_version}.tar.gz && \
        cd protobuf-${protobuf_version} && \
        ./autogen.sh && \
        ./configure --prefix=/usr && \
        make -j${compile_jobs} install && \
        ldconfig && \
        cd python && \
        python3 setup.py install --cpp_implementation

# Install tensorflow python dependencies
RUN pip3 install \
                absl-py \
                astunparse \
                flatbuffers \
                gast \
                google-pasta \
                keras-preprocessing \
                opt-einsum \
                wrapt \
                termcolor

# Compile and install tensorflow
RUN git clone https://github.com/tensorflow/tensorflow && \
        cd tensorflow && \
        git checkout ${tensorflow_commit} && \
        echo ""build --action_env PYTHON_BIN_PATH=\""/usr/bin/python3.8\"""" >> .tf_configure.bazelrc && \
        echo ""build --action_env PYTHON_LIB_PATH=\""/usr/lib/python3/dist-packages\"""" >> .tf_configure.bazelrc && \
        echo ""build --python_path=\""/usr/bin/python3.8\"""" >> .tf_configure.bazelrc && \
        echo ""build --action_env TF_SYSTEM_LIBS=\""com_google_protobuf\"""" >> .tf_configure.bazelrc && \
        sed -i -e '/\/\/third_party\/systemlibs:protobuf.bzl/a\ \ \ \ \ \ \ \ \ \ \ \ ""//third_party/systemlibs:protobuf_deps.bzl"": ""protobuf_deps.bzl"",' tensorflow/workspace2.bzl && \
        echo ""def protobuf_deps():"" > third_party/systemlibs/protobuf_deps.bzl && \
        echo ""    pass"" >> third_party/systemlibs/protobuf_deps.bzl && \
        bazel-${bazel_version} build --jobs=${compile_jobs} //tensorflow/tools/pip_package:build_pip_package && \
        ./bazel-bin/tensorflow/tools/pip_package/build_pip_package .. && \
        pip3 install --no-deps ../tensorflow-*.whl


```

You can then observe the error by running
`python3 -c ""import tensorflow; tensorflow.keras.models.Sequential()""`

Swap the two lines in `tensorflow/python/__init__.py` as described in https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-872229474 and the error does not occur.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-872307752,sclarkson,2021-07-01 14:45:02,50545,[51450],Code bug,0,"@tilakrayal Needs this patch to compile with a local protobuf [url] which I very hackily applied in the Dockerfile below. ``[code]`[code]python3 -c ""import tensorflow; tensorflow.keras.models.Sequential()""[code]tensorflow/python/__init__.py` as described in [url]#issuecomment-872229474 and the error does not occur.",0
"@Saduf2019  ,
I was able to execute the code without any isssues in tf [v2.4](https://colab.research.google.com/gist/tilakrayal/41207bef2b66eb3f236089521bdbb8c7/2-4-50545.ipynb) and [v2.5](https://colab.research.google.com/gist/tilakrayal/4c8ea2462baf883bc635544e24aef422/classification.ipynb).Please find the gist here.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-872905847,tilakrayal,2021-07-02 10:48:20,50545,[51450],Code bug,0,"@Saduf2019 , I was able to execute the code without any isssues in tf [v2.4]([url] and [v2.5]([url] find the gist here.",5
"Tagging @jzhoulon who re-introduced the bug, and @annarev who fixed this last time. It looks like there was some discussion about this reordering in PR #43610.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-873334136,sclarkson,2021-07-03 03:02:15,50545,[51450],Code bug,0,"Tagging @jzhoulon who re-introduced the bug, and @annarev who fixed this last time. It looks like there was some discussion about this reordering in PR #43610.",0
"@Sur3 
Is this still an issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-883420158,Saduf2019,2021-07-20 14:03:29,50545,[51450],Code bug,0,@Sur3 Is this still an issue.,0
@Saduf2019 Yes it is.,IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-883432011,Sur3,2021-07-20 14:18:24,50545,[51450],Code bug,0,@Saduf2019 Yes it is.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50545"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50545"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-901086641,google-ml-butler[bot],2021-08-18 12:48:37,50545,[51450],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"> I'm able to reproduce this. I suspect it came from this commit [f599aed](https://github.com/tensorflow/tensorflow/commit/f599aed5d8d73d45991f74ba4c62db92bf716eba), as when I reorder the lines
> 
> ```
> from tensorflow.python.eager import context
> from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
> ```
> 
> to
> 
> ```
> from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
> from tensorflow.python.eager import context
> ```
> 
> the problem goes away.
> 
> Working on testing this in a docker container for reproducibility.

I got the same issue as reported on TF 2.6.0 on my Apple M1 when trying executing the code 

`from tensorflow.keras import layers`

`text_vectorizer = layers.TextVectorization(
    max_tokens=max_vocab_length, # how many different words
    standardize='lower_and_strip_punctuation',
    split='whitespace',
    ngrams=None,
    output_mode='int',
    output_sequence_length=max_length, # none means = padding each sequence to the longest sequence
)`

`text_vectorizer.adapt(X_train)`

Indeed switching the two imports in my _tensorflow/python/__init__.py_ as mentioned above solves the issue. 
For conda users: Find that __init__.py file in your virtual environment directory under _/Users/username/miniforge3/envs/venv_nlp/lib/python3.9/site-packages/tensorflow/python/_.

Thanks for the solution.",IssueComment,https://github.com/tensorflow/tensorflow/issues/50545#issuecomment-975178763,johanneseder711,2021-11-22 06:45:36,50545,[51450],Code bug,0,"> I'm able to reproduce this. I suspect it came from this commit [f599aed]([url] as when I reorder the lines > > ``[code]`[code]`[code]`[code]from tensorflow.keras import layers[code]text_vectorizer = layers.TextVectorization( max_tokens=max_vocab_length, # how many different words standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=max_length, # none means = padding each sequence to the longest sequence )[code]text_vectorizer.adapt(X_train)` Indeed switching the two imports in my _tensorflow/python/__init__.py_ as mentioned above solves the issue. For conda users: Find that __init__.py file in your virtual environment directory under _/Users/username/miniforge3/envs/venv_nlp/lib/python3.9/site-packages/tensorflow/python/_. Thanks for the solution.",2
@sclarkson The issue will move to closed status once the PR is merged.Thank you!,IssueComment,https://github.com/tensorflow/tensorflow/issues/51451#issuecomment-898259422,sushreebarsa,2021-08-13 07:46:11,51451,[51452],Version compatibility bug,0,@sclarkson The issue will move to closed status once the PR is merged.Thank you!,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51451"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51451"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51451#issuecomment-901312673,google-ml-butler[bot],2021-08-18 17:53:25,51451,[51452],Version compatibility bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/d0a9213b5a7d785b1aa18665710c18e8/46929.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46914#issuecomment-773444981,amahendrakar,2021-02-04 16:41:05,46914,[51497],Algorithm design bug,1,"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here]([url] Thanks!",1
Colab crashes till in TF 2.6 Nightly as well. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/2904b0ac3ee60c44defe00f3f2f5e72d/untitled93.ipynb).Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/46914#issuecomment-850771746,saikumarchalla,2021-05-29 05:09:32,46914,[51497],Algorithm design bug,1,Colab crashes till in TF 2.6 Nightly as well. Please find the gist [here]([url],-2
Added a PR #51497 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46914#issuecomment-898993501,yongtang,2021-08-15 04:25:18,46914,[51497],Algorithm design bug,1,Added a PR #51497 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46914"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46914"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46914#issuecomment-900717801,google-ml-butler[bot],2021-08-18 00:21:16,46914,[51497],Algorithm design bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I also observed the following API aliases or similar APIs can cause the same issue in older versions of tensorflow.
Users should be cautious when using them on both CPU and GPU up to tensorflow 2.6.0 (v2.6.0-rc2-32-g919f693420e).

- `(tf.keras.layers.UpSampling2D)`, `tf.compat.v1.keras.layers.UpSampling2D`
- `tf.keras.layers.UpSampling1D`, `tf.compat.v1.keras.layers.UpSampling1D`
- `tf.keras.layers.UpSampling3D`, `tf.compat.v1.keras.layers.UpSampling3D`

<details>
  <summary>Code to reproduce the issue for above APIs in older versions</summary>

- <code>(tf.keras.layers.UpSampling2D)</code>, <code>tf.compat.v1.keras.layers.UpSampling2D</code>

```python
import numpy as np
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION, flush=True)
print(tf.config.list_physical_devices(), flush=True)


try:
    # tf.keras.layers.UpSampling2D(size=1610637938, data_format='channels_first', interpolation='bilinear')(np.ones((5,1,1,1)))
    tf.compat.v1.keras.layers.UpSampling2D(size=1610637938, data_format='channels_first', interpolation='bilinear')(np.ones((5,1,1,1)))
except Exception as e:
    print(""Error:"", str(e), flush=True)
print(""Success!"", flush=True)
```

- <code>tf.keras.layers.UpSampling1D</code>, <code>tf.compat.v1.keras.layers.UpSampling1D</code>

```python
import numpy as np
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION, flush=True)
print(tf.config.list_physical_devices(), flush=True)


try:
    tf.keras.layers.UpSampling1D(size=1610637938)(np.ones((5, 1, 1)))
    # tf.compat.v1.keras.layers.UpSampling1D(size=1610637938)(np.ones((5, 1, 1)))
except Exception as e:
    print(""Error:"", str(e), flush=True)
print(""Success!"", flush=True)
```

- <code>tf.keras.layers.UpSampling3D</code>, <code>tf.compat.v1.keras.layers.UpSampling3D</code>

```python
import numpy as np
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION, flush=True)
print(tf.config.list_physical_devices(), flush=True)


try:
    tf.keras.layers.UpSampling3D(size=1610637938, data_format='channels_first')(np.ones((5, 1, 1, 1, 1)))
    # tf.compat.v1.keras.layers.UpSampling3D(size=1610637938, data_format='channels_first')(np.ones((5, 1, 1, 1, 1)))
except Exception as e:
    print(""Error:"", str(e), flush=True)
print(""Success!"", flush=True)
```

The above code will cause the process to be aborted on both CPU and GPU, which is unexpected.

The following are the outputs of the above code on my GPU machine:

```text
v2.6.0-rc2-32-g919f693420e 2.6.0
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2023-09-08 09:24:30.615084: F tensorflow/core/framework/tensor_shape.cc:187] Non-OK-status: InitDims(dim_sizes) status: Internal: Encountered overflow when multiplying 8053189690 with 1610637938, result: -5475971237085092396
Aborted (core dumped)
```

On CPU:

```text
v2.6.0-rc2-32-g919f693420e 2.6.0
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
2023-09-08 09:24:18.882704: F tensorflow/core/framework/tensor_shape.cc:187] Non-OK-status: InitDims(dim_sizes) status: Internal: Encountered overflow when multiplying 8053189690 with 1610637938, result: -5475971237085092396
Aborted (core dumped)
```
</details>

It seems to be fixed in tensorflow 2.6.1 (v2.6.0-101-g3aa40c3ce9d) and later versions.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46914#issuecomment-1715347080,oawxkw,2023-09-12 09:25:26,46914,[51497],Algorithm design bug,1,"I also observed the following API aliases or similar APIs can cause the same issue in older versions of tensorflow. Users should be cautious when using them on both CPU and GPU up to tensorflow 2.6.0 (v2.6.0-rc2-32-g919f693420e). - [code], [code] - [code], [code] - [code], [code] <details> <summary>Code to reproduce the issue for above APIs in older versions</summary> - <code>(tf.keras.layers.UpSampling2D)</code>, <code>tf.compat.v1.keras.layers.UpSampling2D</code> ``[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`[code]`` </details> It seems to be fixed in tensorflow 2.6.1 (v2.6.0-101-g3aa40c3ce9d) and later versions.",0
"Happy to add the `app.log` from Google Colab executing above snippet for the latest version `2.6.0`.

Seems to me like the call of `CHECK_LT()` in `tensorflow/core/framework/tensor_shape.cc:569` defined at `tensorflow/core/platform/default/logging.h:413` causes that issue.

However, I am not a C++ expert, so I don't get any much further than that for now.

<html><body>
<!--StartFragment-->

Timestamp | Level | Message
-- | -- | --
Aug 22, 2021, 12:34:44 AM | WARNING | WARNING:root:kernel 8e337399-7e5c-4782-aaa6-34f661e5c692 restarted
Aug 22, 2021, 12:34:44 AM | INFO | KernelRestarter: restarting kernel (1/5), keep random ports
Aug 22, 2021, 12:34:44 AM | WARNING | 2021-08-21 22:34:44.441658: F tensorflow/core/framework/tensor_shape.cc:569] Check failed: size >= 0 (-63 vs. 0)
Aug 22, 2021, 12:34:44 AM | WARNING | 2021-08-21  22:34:44.376372: I  tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver  does not appear to be running on this host (c679a9bf8bfa):  /proc/driver/nvidia/version does not exist
Aug 22, 2021, 12:34:44 AM | WARNING | 2021-08-21  22:34:44.375437: E tensorflow/stream_executor/cuda/cuda_driver.cc:271]  failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is  detected
Aug 22, 2021, 12:34:37 AM | INFO | Adapting to protocol v5.1 for kernel 8e337399-7e5c-4782-aaa6-34f661e5c692
Aug 22, 2021, 12:34:35 AM | INFO | Kernel started: 8e337399-7e5c-4782-aaa6-34f661e5c692
Aug 22, 2021, 12:33:19 AM | INFO | Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
Aug 22, 2021, 12:33:19 AM | INFO | http://172.28.0.12:9000/
Aug 22, 2021, 12:33:19 AM | INFO | The Jupyter Notebook is running at:
Aug 22, 2021, 12:33:19 AM | INFO | Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
Aug 22, 2021, 12:33:19 AM | INFO | http://172.28.0.2:9000/
Aug 22, 2021, 12:33:19 AM | INFO | The Jupyter Notebook is running at:
Aug 22, 2021, 12:33:19 AM | INFO | 0 active kernels
Aug 22, 2021, 12:33:19 AM | INFO | Serving notebooks from local directory: /
Aug 22, 2021, 12:33:19 AM | INFO | 0 active kernels
Aug 22, 2021, 12:33:19 AM | INFO | Serving notebooks from local directory: /
Aug 22, 2021, 12:33:19 AM | INFO | google.colab serverextension initialized.
Aug 22, 2021, 12:33:19 AM | INFO | google.colab serverextension initialized.
Aug 22, 2021, 12:33:19 AM | INFO | Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
Aug 22, 2021, 12:33:19 AM | INFO | Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret

<!--EndFragment-->
</body>
</html>",IssueComment,https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-903185385,LudwigStumpp,2021-08-21 22:50:55,51618,[51658],Data bug,1,"Happy to add the [code] from Google Colab executing above snippet for the latest version [code]. Seems to me like the call of [code] in [code] defined at [code] causes that issue. However, I am not a C++ expert, so I don't get any much further than that for now. <html><body> <!--StartFragment--> Timestamp | Level | Message -- | -- | -- Aug 22, 2021, 12:34:44 AM | WARNING | WARNING:root:kernel 8e337399-7e5c-4782-aaa6-34f661e5c692 restarted Aug 22, 2021, 12:34:44 AM | INFO | KernelRestarter: restarting kernel (1/5), keep random ports Aug 22, 2021, 12:34:44 AM | WARNING | 2021-08-21 22:34:44.441658: F tensorflow/core/framework/tensor_shape.cc:569] Check failed: size >= 0 (-63 vs. 0) Aug 22, 2021, 12:34:44 AM | WARNING | 2021-08-21 22:34:44.376372: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c679a9bf8bfa): /proc/driver/nvidia/version does not exist Aug 22, 2021, 12:34:44 AM | WARNING | 2021-08-21 22:34:44.375437: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected Aug 22, 2021, 12:34:37 AM | INFO | Adapting to protocol v5.1 for kernel 8e337399-7e5c-4782-aaa6-34f661e5c692 Aug 22, 2021, 12:34:35 AM | INFO | Kernel started: 8e337399-7e5c-4782-aaa6-34f661e5c692 Aug 22, 2021, 12:33:19 AM | INFO | Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). Aug 22, 2021, 12:33:19 AM | INFO | [url] Aug 22, 2021, 12:33:19 AM | INFO | The Jupyter Notebook is running at: Aug 22, 2021, 12:33:19 AM | INFO | Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). Aug 22, 2021, 12:33:19 AM | INFO | [url] Aug 22, 2021, 12:33:19 AM | INFO | The Jupyter Notebook is running at: Aug 22, 2021, 12:33:19 AM | INFO | 0 active kernels Aug 22, 2021, 12:33:19 AM | INFO | Serving notebooks from local directory: / Aug 22, 2021, 12:33:19 AM | INFO | 0 active kernels Aug 22, 2021, 12:33:19 AM | INFO | Serving notebooks from local directory: / Aug 22, 2021, 12:33:19 AM | INFO | google.colab serverextension initialized. Aug 22, 2021, 12:33:19 AM | INFO | google.colab serverextension initialized. Aug 22, 2021, 12:33:19 AM | INFO | Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret Aug 22, 2021, 12:33:19 AM | INFO | Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret <!--EndFragment--> </body> </html>",0
@lugalUrim Could you please refer to the [link](https://www.tensorflow.org/api_docs/python/tf/image/extract_glimpse) . Please try to upgrade the TF version 2.4 to 2.6.0 and refer to the above [comment](https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-903185385).Please let us know if it helps ?,IssueComment,https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-903485593,sushreebarsa,2021-08-23 06:38:41,51618,[51658],Data bug,1,@lugalUrim Could you please refer to the [link]([url] . Please try to upgrade the TF version 2.4 to 2.6.0 and refer to the above [comment]([url]#issuecomment-903185385).Please let us know if it helps ?,0
Added a PR #51618 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-904888403,yongtang,2021-08-24 18:48:13,51618,[51658],Data bug,1,Added a PR #51618 for the fix.,0
@lugalUrim This issue will be closed once the PR is merged! Thanks! ,IssueComment,https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-908842052,sushreebarsa,2021-08-31 02:16:14,51618,[51658],Data bug,1,@lugalUrim This issue will be closed once the PR is merged! Thanks!,3
"This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-913955610,google-ml-butler[bot],2021-09-07 03:05:57,51618,[51658],Data bug,1,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,0
"Closing as stale. Please reopen if you'd like to work on this further.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-918772162,google-ml-butler[bot],2021-09-14 03:42:13,51618,[51658],Data bug,1,Closing as stale. Please reopen if you'd like to work on this further.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51618"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51618"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-918772185,google-ml-butler[bot],2021-09-14 03:42:16,51618,[51658],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I also observed the following API aliases or similar APIs can cause the same issue in older versions of tensorflow.
Users should be cautious when using them on both CPU and GPU up to tensorflow 2.7.4 (v2.7.3-139-ga73cc22ba39) except for tensorflow 2.6.1 (v2.6.0-101-g3aa40c3ce9d).

- `(tf.image.extract_glimpse)`, `tf.compat.v1.image.extract_glimpse`

<details>
  <summary>Code to reproduce the issue in <code>tf.compat.v1.image.extract_glimpse</code> in older versions</summary>

```python
import numpy as np
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION, flush=True)
print(tf.config.list_physical_devices(), flush=True)


try:
    x = np.arange(9).reshape([1,3,3,1])
    res = tf.compat.v1.image.extract_glimpse(x, size=[1023, -63], offsets=[1023, 63], centered=False, normalized=False) # Crash
except Exception as e:
    print(""Error:"", str(e), flush=True)
print(""Success!"", flush=True)
```

On GPU, the Check failed error occurs:

```text
v2.7.3-139-ga73cc22ba39 2.7.4
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2023-09-08 02:15:16.158398: F tensorflow/core/framework/tensor_shape.cc:573] Check failed: size >= 0 (0 vs. -63)
Aborted (core dumped)
```

This behavior is also reproducible on my CPU machine:

```text
v2.7.3-139-ga73cc22ba39 2.7.4
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
2023-09-08 02:15:10.646207: F tensorflow/core/framework/tensor_shape.cc:573] Check failed: size >= 0 (0 vs. -63)
Aborted (core dumped)
```
</details>

It seems to be fixed in tensorflow 2.8.0 (v2.8.0-rc1-32-g3f878cff5b6) and later versions.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51618#issuecomment-1715344439,oawxkw,2023-09-12 09:23:39,51618,[51658],Data bug,1,"I also observed the following API aliases or similar APIs can cause the same issue in older versions of tensorflow. Users should be cautious when using them on both CPU and GPU up to tensorflow 2.7.4 (v2.7.3-139-ga73cc22ba39) except for tensorflow 2.6.1 (v2.6.0-101-g3aa40c3ce9d). - [code], [code] <details> <summary>Code to reproduce the issue in <code>tf.compat.v1.image.extract_glimpse</code> in older versions</summary> ``[code]`[code]`[code]`[code]`[code]`` </details> It seems to be fixed in tensorflow 2.8.0 (v2.8.0-rc1-32-g3f878cff5b6) and later versions.",0
"I have tried in colab with TF versions 2.1,2.4,nightly versions(`2.5.0-dev20210203`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/9329366f22f1d5559d31065583e6f21e/untitled656.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46909#issuecomment-773149177,ravikyram,2021-02-04 09:05:39,46909,[51715],Visualization bug,1,"I have tried in colab with TF versions 2.1,2.4,nightly versions([code]) and was able to reproduce the issue.Please, find the gist [here]([url] Thanks!",1
Colab is still crashing in TF 2.6 when I executed the code. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/4d07531868b085424317d42652909927/untitled92.ipynb#scrollTo=RvUKM453ViFa).Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/46909#issuecomment-850766270,saikumarchalla,2021-05-29 04:17:42,46909,[51715],Visualization bug,1,Colab is still crashing in TF 2.6 when I executed the code. Please find the gist [here]([url]#scrollTo=RvUKM453ViFa).Thanks!,-2
Created a PR #51715 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46909#issuecomment-907319377,yongtang,2021-08-27 16:19:12,46909,[51715],Visualization bug,1,Created a PR #51715 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46909"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46909"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46909#issuecomment-909741631,google-ml-butler[bot],2021-08-31 23:59:30,46909,[51715],Visualization bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/26149c9c28de86ef49b179c9ce6425a0/46888.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46888#issuecomment-773087743,amahendrakar,2021-02-04 07:13:02,46888,[51733],Data bug,1,"Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here]([url] Thanks!",0
"Was able to reproduce this issue in TF 2.6.0-dev20210528,please find the gist [here ](https://colab.research.google.com/gist/sushreebarsa/380145e341cb9341b9af8743ad359a46/untitled43.ipynb#scrollTo=fX4HwL-Fxk0D)..Thanks !",IssueComment,https://github.com/tensorflow/tensorflow/issues/46888#issuecomment-850361680,sushreebarsa,2021-05-28 11:47:12,46888,[51733],Data bug,1,"Was able to reproduce this issue in TF 2.6.0-dev20210528,please find the gist [here ]([url]#scrollTo=fX4HwL-Fxk0D)..Thanks !",0
Added a PR #51733 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46888#issuecomment-907657211,yongtang,2021-08-28 17:18:07,46888,[51733],Data bug,1,Added a PR #51733 for the fix.,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46888"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46888"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46888#issuecomment-953409158,google-ml-butler[bot],2021-10-28 00:38:22,46888,[51733],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Hi @eli-osherovich !You should provide only positive weights  in w , Here 0's are not positive weights.
Reference -https://www.tensorflow.org/api_docs/python/tf/nn/weighted_moments#args",IssueComment,https://github.com/tensorflow/tensorflow/issues/51792#issuecomment-911354605,mohantym,2021-09-02 08:09:08,51792,[51966],Data bug,0,"Hi @eli-osherovich !You should provide only positive weights in w , Here 0's are not positive weights. Reference -[url]#args",0
"I understand the rationale, yet, I believe that all-zeros is still a valid case.  Obviously, the weights are expected to be non-negative.",IssueComment,https://github.com/tensorflow/tensorflow/issues/51792#issuecomment-911395764,eli-osherovich,2021-09-02 08:40:36,51792,[51966],Data bug,0,"I understand the rationale, yet, I believe that all-zeros is still a valid case. Obviously, the weights are expected to be non-negative.",0
"Hi @Saduf2019 , Could you look into this please . providing[ gist](https://colab.research.google.com/gist/mohantym/bfc557013a0db04183e0c2d2ba4cec79/github_51792.ipynb) for reference . issue is replicating in 2.5 ,2.6 and nightly",IssueComment,https://github.com/tensorflow/tensorflow/issues/51792#issuecomment-912359166,mohantym,2021-09-03 08:27:17,51792,[51966],Data bug,0,"Hi @Saduf2019 , Could you look into this please . providing[ gist]([url] for reference . issue is replicating in 2.5 ,2.6 and nightly",0
"@eli-osherovich 
The weighted_moments function sums your weights with zero vector and  then determines the divisor by taking a reciprocal of the broadcasted vector. In this case, your sum will be zero and since the reciprocal of zero is infinity, nans are appearing.
Don't use zero weights, logically it makes no sense, instead 1's weight every element equally.
For any further queries i suggest to open an issue at tf [discussion forum](https://discuss.tensorflow.org/) as there is a larger community to support/respond.",IssueComment,https://github.com/tensorflow/tensorflow/issues/51792#issuecomment-913395438,Saduf2019,2021-09-06 07:02:51,51792,[51966],Data bug,0,"@eli-osherovich The weighted_moments function sums your weights with zero vector and then determines the divisor by taking a reciprocal of the broadcasted vector. In this case, your sum will be zero and since the reciprocal of zero is infinity, nans are appearing. Don't use zero weights, logically it makes no sense, instead 1's weight every element equally. For any further queries i suggest to open an issue at tf [discussion forum]([url] as there is a larger community to support/respond.",0
"@Saduf2019 
I know why it happens. Let me assure you zeroes are perfectly logical. I do not see why zeros should be replaced with ones....

P. S. 
It is a bit difficult to understand is this the TF team answer or a recommendation from a fellow user....",IssueComment,https://github.com/tensorflow/tensorflow/issues/51792#issuecomment-913419688,eli-osherovich,2021-09-06 07:40:57,51792,[51966],Data bug,0,@Saduf2019 I know why it happens. Let me assure you zeroes are perfectly logical. I do not see why zeros should be replaced with ones.... P. S. It is a bit difficult to understand is this the TF team answer or a recommendation from a fellow user....,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51792"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51792"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51792#issuecomment-936464626,google-ml-butler[bot],2021-10-06 15:09:48,51792,[51966],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
The PR was reverted :( The issue still exists.,IssueComment,https://github.com/tensorflow/tensorflow/issues/51792#issuecomment-954753853,eli-osherovich,2021-10-29 13:40:59,51792,[51966],Data bug,0,The PR was reverted :( The issue still exists.,-3
/cc @mdanatg ,IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-842052010,bhack,2021-05-17 06:48:43,49225,[51972],Code bug,0,/cc @mdanatg,0
"Looks most likely like a bug in the deprecation API: https://github.com/tensorflow/tensorflow/blob/5fca930c7fb1b302c6d7f1d05a80724028764480/tensorflow/python/util/deprecation.py#L101 

It should be straightforward to add a test an an extra check.",IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-842277289,mdanatg,2021-05-17 12:16:42,49225,[51972],Code bug,0,Looks most likely like a bug in the deprecation API: [url]#L101 It should be straightforward to add a test an an extra check.,0
@lostmsu Do you want to contribute a PR?,IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-842468931,bhack,2021-05-17 16:36:34,49225,[51972],Code bug,0,@lostmsu Do you want to contribute a PR?,1
"I would like to contribute. This might be my first contribution for tensorflow! So, just a check for `f == None` right?",IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-917720944,AdeshChoudhar,2021-09-12 22:20:31,49225,[51972],Code bug,0,"I would like to contribute. This might be my first contribution for tensorflow! So, just a check for [code] right?",3
I have made a pull request. Can you please review it and let me know if this was the expected thing?,IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-917725377,AdeshChoudhar,2021-09-12 22:53:15,49225,[51972],Code bug,0,I have made a pull request. Can you please review it and let me know if this was the expected thing?,2
I hope we can close this issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-919385533,AdeshChoudhar,2021-09-14 17:56:57,49225,[51972],Code bug,0,I hope we can close this issue.,0
@mdanatg Can you close this?,IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-919471720,bhack,2021-09-14 20:01:28,49225,[51972],Code bug,0,@mdanatg Can you close this?,0
"Sure. BTW, if you add ""Fixed <issue number>"" to your PR then it gets closed automatically.",IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-919475097,mdanatg,2021-09-14 20:06:11,49225,[51972],Code bug,0,"Sure. BTW, if you add ""Fixed <issue number>"" to your PR then it gets closed automatically.",2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49225"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49225"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-919475114,google-ml-butler[bot],2021-09-14 20:06:13,49225,[51972],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"> if you add ""Fixed "" to your PR then it gets closed automatically.

Thanks, It is what I suggest also to the triage and review teams.  To check if the submitted PR is linked or not the issue as they have the permission to link it. Sometimes contributors don't put the auto-connection string in the PR description.",IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-919479772,bhack,2021-09-14 20:13:34,49225,[51972],Code bug,0,"> if you add ""Fixed "" to your PR then it gets closed automatically. Thanks, It is what I suggest also to the triage and review teams. To check if the submitted PR is linked or not the issue as they have the permission to link it. Sometimes contributors don't put the auto-connection string in the PR description.",1
@bhack What is an auto-connection string?,IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-919538178,AdeshChoudhar,2021-09-14 21:51:09,49225,[51972],Code bug,0,@bhack What is an auto-connection string?,0
"> @bhack What is an auto-connection string?

You need to use [one of these keywords](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-919539157,bhack,2021-09-14 21:53:03,49225,[51972],Code bug,0,> @bhack What is an auto-connection string? You need to use [one of these keywords]([url]#linking-a-pull-request-to-an-issue-using-a-keyword),0
"Oh great, I didn't know about that! Thank you for sharing! I will definitely use that from next time.",IssueComment,https://github.com/tensorflow/tensorflow/issues/49225#issuecomment-919541027,AdeshChoudhar,2021-09-14 21:56:42,49225,[51972],Code bug,0,"Oh great, I didn't know about that! Thank you for sharing! I will definitely use that from next time.",5
It turns out that `tf.keras.layers.AveragePooling3D` also crashes when `pool_size` contains `0`.,IssueComment,https://github.com/tensorflow/tensorflow/issues/51936#issuecomment-917517712,lugalUrim,2021-09-12 01:06:46,51936,[51975],Algorithm design bug,1,It turns out that [code] also crashes when [code] contains [code].,-3
"@lugalUrim Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)
To know more see;
[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)
Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/51936#issuecomment-917565455,sushreebarsa,2021-09-12 06:16:13,51936,[51975],Algorithm design bug,1,@lugalUrim Please post this issue on [keras-team/keras repo.]([url] To know more see; [[url] Thank you!,0
"Hi, I have created a [PR](https://github.com/keras-team/keras/pull/15356) for Keras to solve this issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/51936#issuecomment-917632579,WingsBrokenAngel,2021-09-12 13:04:31,51936,[51975],Algorithm design bug,1,"Hi, I have created a [PR]([url] for Keras to solve this issue.",3
"While the original issue is coming from tf.keras.layers.MaxPooling3D, the issue is triggered when max_pool3d is called directly with tensorflow itself. For that PR #51975 has been created to fix the issue inside tensorflow.",IssueComment,https://github.com/tensorflow/tensorflow/issues/51936#issuecomment-917761242,yongtang,2021-09-13 01:19:14,51936,[51975],Algorithm design bug,1,"While the original issue is coming from tf.keras.layers.MaxPooling3D, the issue is triggered when max_pool3d is called directly with tensorflow itself. For that PR #51975 has been created to fix the issue inside tensorflow.",0
"Thanks for the information @sushreebarsa, I will post new issues in the keras repo, but I guess we can keep this issue in tensorflow, as mentioned by @yongtang there are related bugs in the tensorflow operator implementations as well.",IssueComment,https://github.com/tensorflow/tensorflow/issues/51936#issuecomment-919647961,lugalUrim,2021-09-15 02:26:58,51936,[51975],Algorithm design bug,1,"Thanks for the information @sushreebarsa, I will post new issues in the keras repo, but I guess we can keep this issue in tensorflow, as mentioned by @yongtang there are related bugs in the tensorflow operator implementations as well.",1
"Thank you @WingsBrokenAngel and @yongtang for your PRs! Actually here are more crash bugs I find when `pool_size`/`k_size` <= 0, so we may want to fix all of these in the codebase and also cover them in the unit tests.
- `tf.keras.layers.AveragePooling1D`, `tf.keras.layers.AveragePooling2D`, `tf.keras.layers.AveragePooling3D`
- `tf.keras.layers.MaxPooling1D`, `tf.keras.layers.MaxPooling2D`, `tf.keras.layers.MaxPooling3D`
- `tf.nn.avg_pool1d`, `tf.nn.avg_pool2d`, `tf.nn.avg_pool3d`
- `tf.nn.max_pool1d`, `tf.nn.max_pool2d`, `tf.nn.max_pool3d`
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51936#issuecomment-919651602,lugalUrim,2021-09-15 02:36:55,51936,[51975],Algorithm design bug,1,"Thank you @WingsBrokenAngel and @yongtang for your PRs! Actually here are more crash bugs I find when [code]/[code] <= 0, so we may want to fix all of these in the codebase and also cover them in the unit tests. - [code], [code], [code] - [code], [code], [code] - [code], [code], [code] - [code], [code], [code]",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51936"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51936"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51936#issuecomment-936475762,google-ml-butler[bot],2021-10-06 15:15:57,51936,[51975],Algorithm design bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I also observed the following API aliases or similar APIs can cause the same issue in some older versions of tensorflow.
Users should be cautious when using them on CPU up to tensorflow 2.6.0 (v2.6.0-rc2-32-g919f693420e).

> Besides, in tensorflow 2.6.0 (v2.6.0-rc2-32-g919f693420e) and previous versions, it throws the InternalError Exception on GPU, which is acceptable.

- `(tf.keras.layers.MaxPooling3D)`, `tf.keras.layers.MaxPool3D`, `tf.compat.v1.keras.layers.MaxPooling3D`, `tf.compat.v1.keras.layers.MaxPool3D`
- `tf.keras.layers.AveragePooling3D`, `tf.keras.layers.AvgPool3D`, `tf.compat.v1.keras.layers.AveragePooling3D`, `tf.compat.v1.keras.layers.AvgPool3D`

<details>
  <summary>Code to reproduce the issue for the above APIs in older versions</summary>

- `(tf.keras.layers.MaxPooling3D)`, `tf.keras.layers.MaxPool3D`, `tf.compat.v1.keras.layers.MaxPooling3D`, `tf.compat.v1.keras.layers.MaxPool3D`
- `tf.keras.layers.AveragePooling3D`, `tf.keras.layers.AvgPool3D`, `tf.compat.v1.keras.layers.AveragePooling3D`, `tf.compat.v1.keras.layers.AvgPool3D`

```python
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION, flush=True)
print(tf.config.list_physical_devices(), flush=True)


pool_size = [2, 2, 0]
# layer = tf.keras.layers.MaxPooling3D(strides=1, pool_size=pool_size)
layer = tf.keras.layers.MaxPool3D(strides=1, pool_size=pool_size)
# layer = tf.compat.v1.keras.layers.MaxPooling3D(strides=1, pool_size=pool_size)
# layer = tf.compat.v1.keras.layers.MaxPool3D(strides=1, pool_size=pool_size)
# layer = tf.keras.layers.AveragePooling3D(strides=1, pool_size=pool_size)
# layer = tf.keras.layers.AvgPool3D(strides=1, pool_size=pool_size)
# layer = tf.compat.v1.keras.layers.AveragePooling3D(strides=1, pool_size=pool_size)
# layer = tf.compat.v1.keras.layers.AvgPool3D(strides=1, pool_size=pool_size)
input_tensor = tf.random.uniform([3, 4, 10, 11, 12], dtype=tf.float32)
res = layer(input_tensor) # crash
print(res)
```

On CPU, the process aborts with a Floating point exception(core dumped), which is not expected.

```text
v2.6.0-rc2-32-g919f693420e 2.6.0
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Floating point exception(core dumped)
```

While on GPU, it throws the InternalError Exception:

```text
v2.6.0-rc2-32-g919f693420e 2.6.0
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Traceback (most recent call last):
  File ""51936-6-s/tf.keras.layers.MaxPool3D.py"", line 8, in <module>
    res = layer(input_tensor) # crash
  File ""/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py"", line 1037, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py"", line 700, in call
    padding=self.padding.upper())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py"", line 206, in wrapper
    return target(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py"", line 4935, in max_pool3d
    name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 5430, in max_pool3d
    _ops.raise_from_not_ok_status(e, name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 6941, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: dnn PoolForward launch failed [Op:MaxPool3D]
```
</details>

It seems to be fixed in tensorflow 2.6.1 (v2.6.0-101-g3aa40c3ce9d) and later versions.
Note that, in tensorflow 2.6.1 (v2.6.0-101-g3aa40c3ce9d), it throws the InvalidArgumentError Exception, and in later versions, it throws the ValueError Exception, which is expected.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/51936#issuecomment-1715343444,oawxkw,2023-09-12 09:23:02,51936,[51975],Algorithm design bug,1,"I also observed the following API aliases or similar APIs can cause the same issue in some older versions of tensorflow. Users should be cautious when using them on CPU up to tensorflow 2.6.0 (v2.6.0-rc2-32-g919f693420e). > Besides, in tensorflow 2.6.0 (v2.6.0-rc2-32-g919f693420e) and previous versions, it throws the InternalError Exception on GPU, which is acceptable. - [code], [code], [code], [code] - [code], [code], [code], [code] <details> <summary>Code to reproduce the issue for the above APIs in older versions</summary> - [code], [code], [code], [code] - [code], [code], [code], [code] ``[code]`[code]`[code]`[code]`[code]`` </details> It seems to be fixed in tensorflow 2.6.1 (v2.6.0-101-g3aa40c3ce9d) and later versions. Note that, in tensorflow 2.6.1 (v2.6.0-101-g3aa40c3ce9d), it throws the InvalidArgumentError Exception, and in later versions, it throws the ValueError Exception, which is expected.",0
Hi @Saduf2019 ! Could you please look at this bug ?,IssueComment,https://github.com/tensorflow/tensorflow/issues/52355#issuecomment-942855687,mohantym,2021-10-14 01:25:56,52355,[52521],Documentation bug,0,Hi @Saduf2019 ! Could you please look at this bug ?,0
"@mahozad 
Pr has been created once its merged this issue will move to closed status.",IssueComment,https://github.com/tensorflow/tensorflow/issues/52355#issuecomment-944492589,Saduf2019,2021-10-15 18:00:48,52355,[52521],Documentation bug,0,@mahozad Pr has been created once its merged this issue will move to closed status.,0
@Saduf2019 The new logo is still a PNG. Could you please use the SVG format instead?,IssueComment,https://github.com/tensorflow/tensorflow/issues/52355#issuecomment-944511990,mahozad,2021-10-15 18:32:38,52355,[52521],Documentation bug,0,@Saduf2019 The new logo is still a PNG. Could you please use the SVG format instead?,0
"@mahozad 
It is as per the guidelines hence its been approved. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/52355#issuecomment-946819430,Saduf2019,2021-10-19 15:06:23,52355,[52521],Documentation bug,0,@mahozad It is as per the guidelines hence its been approved.,3
@cfRod @nSircombe ,IssueComment,https://github.com/tensorflow/tensorflow/issues/52676#issuecomment-951848165,elfringham,2021-10-26 11:38:28,52676,[52707],Test bug,1,@cfRod @nSircombe,0
@elfringham This issue will be closed once the PR is merged. Thank you!,IssueComment,https://github.com/tensorflow/tensorflow/issues/52676#issuecomment-954450347,sushreebarsa,2021-10-29 05:54:37,52676,[52707],Test bug,1,@elfringham This issue will be closed once the PR is merged. Thank you!,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52676"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52676"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/52676#issuecomment-996407947,google-ml-butler[bot],2021-12-17 03:28:10,52676,[52707],Test bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@cfRod
@nSircombe",IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-922979899,elfringham,2021-09-20 14:27:20,52069,[52966],Test bug,0,@cfRod @nSircombe,0
"> _Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template_
> 
> **System information**
> 
> * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
> * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
> * TensorFlow installed from (source or binary): source
> * TensorFlow version (use command below): git HEAD
> * Python version: 3.8.10
> * Bazel version (if compiling from source): 3.7.2
> * GCC/Compiler version (if compiling from source): 10.3.0
> * CUDA/cuDNN version: n/a
> * GPU model and memory: n/a
> 
> You can collect some of this information using our environment capture
> [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
> You can also obtain the TensorFlow version with:
> 
> 1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
> 2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
> 
> **Describe the current behavior**
> 
> Test fails
> 
> **Describe the expected behavior**
> 
> Test passes
> 
> **[Contributing](https://www.tensorflow.org/community/contribute)**
> 
> * Do you want to contribute a PR? (yes/no): no
> * Briefly describe your candidate solution(if contributing): I think the test needs to be relaxed slightly to accept the values produced by AARCH64 CPUs.
> 
> **Standalone code to reproduce the issue**
> Provide a reproducible test case that is the bare minimum necessary to generate
> the problem. If possible, please share a link to Colab/Jupyter/any notebook.
> 
> bazel test //tensorflow/tools/docs:tf_doctest
> 
> **Other info / logs** Include any logs or source code that would be helpful to
> diagnose the problem. If including tracebacks, please include the full
> traceback. Large logs and files should be attached.
> 
> ## ======================================================================
> FAIL: Tanh (tensorflow.python.ops.gen_math_ops)
> Doctest: tensorflow.python.ops.gen_math_ops.Tanh
> Traceback (most recent call last):
> File ""/usr/lib/python3.8/doctest.py"", line 2204, in runTest
> raise self.failureException(self.format_failure(new.getvalue()))
> AssertionError: Failed doctest test for tensorflow.python.ops.gen_math_ops.Tanh
> File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py"", line 408, in Tanh
> 
> File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py"", line 416, in tensorflow.python.ops.gen_math_ops.Tanh
> Failed example:
> tf.math.tanh(x)
> Expected:
> <tf.Tensor: shape=(8,), dtype=float32, numpy=
> array([-1. , -0.99990916, -0.46211717, 0.7615942 , 0.8336547 ,
> 0.9640276 , 0.9950547 , 1. ], dtype=float32)>
> Got:
> <tf.Tensor: shape=(8,), dtype=float32, numpy=
> array([-0.99999976, -0.99990916, -0.46211717, 0.7615942 , 0.8336546 ,
> 0.9640276 , 0.9950547 , 0.99999976], dtype=float32)>
> 
> ```
> #############################################################
> Check the documentation
> (https://www.tensorflow.org/community/contribute/docs_ref) on how to write testable docstrings.
> #############################################################
> ```
> 
> ## ======================================================================
> FAIL: tanh (tensorflow.python.ops.gen_math_ops)
> Doctest: tensorflow.python.ops.gen_math_ops.tanh
> Traceback (most recent call last):
> File ""/usr/lib/python3.8/doctest.py"", line 2204, in runTest
> raise self.failureException(self.format_failure(new.getvalue()))
> AssertionError: Failed doctest test for tensorflow.python.ops.gen_math_ops.tanh
> File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py"", line 11336, in tanh
> 
> File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py"", line 11344, in tensorflow.python.ops.gen_math_ops.tanh
> Failed example:
> tf.math.tanh(x)
> Expected:
> <tf.Tensor: shape=(8,), dtype=float32, numpy=
> array([-1. , -0.99990916, -0.46211717, 0.7615942 , 0.8336547 ,
> 0.9640276 , 0.9950547 , 1. ], dtype=float32)>
> Got:
> <tf.Tensor: shape=(8,), dtype=float32, numpy=
> array([-0.99999976, -0.99990916, -0.46211717, 0.7615942 , 0.8336546 ,
> 0.9640276 , 0.9950547 , 0.99999976], dtype=float32)>
> 
> ```
> #############################################################
> Check the documentation
> (https://www.tensorflow.org/community/contribute/docs_ref) on how to write testable docstrings.
> #############################################################
> ```
> 
> ## ======================================================================
> FAIL: sigmoid (tensorflow.python.ops.math_ops)
> Doctest: tensorflow.python.ops.math_ops.sigmoid
> Traceback (most recent call last):
> File ""/usr/lib/python3.8/doctest.py"", line 2204, in runTest
> raise self.failureException(self.format_failure(new.getvalue()))
> AssertionError: Failed doctest test for tensorflow.python.ops.math_ops.sigmoid
> File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py"", line 174, in sigmoid
> 
> File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py"", line 187, in tensorflow.python.ops.math_ops.sigmoid
> Failed example:
> tf.math.sigmoid(x)
> Expected:
> <tf.Tensor: shape=(4,), dtype=float32,
> numpy=array([0.5 , 0.7310586, 1. , 1. ], dtype=float32)>
> Got:
> <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5 , 0.7310586, 0.9999998, 0.9999998], dtype=float32)>

",IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-923701240,soffieswan041,2021-09-21 07:08:27,52069,[52966],Test bug,0,"> _Please make sure that this is a bug. As per our [GitHub Policy]([url] we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template_ > > **System information** > > * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no > * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04 > * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a > * TensorFlow installed from (source or binary): source > * TensorFlow version (use command below): git HEAD > * Python version: 3.8.10 > * Bazel version (if compiling from source): 3.7.2 > * GCC/Compiler version (if compiling from source): 10.3.0 > * CUDA/cuDNN version: n/a > * GPU model and memory: n/a > > You can collect some of this information using our environment capture > [script]([url] > You can also obtain the TensorFlow version with: > > 1. TF 1.0: [code] > 2. TF 2.0: [code] > > **Describe the current behavior** > > Test fails > > **Describe the expected behavior** > > Test passes > > **[Contributing]([url] > > * Do you want to contribute a PR? (yes/no): no > * Briefly describe your candidate solution(if contributing): I think the test needs to be relaxed slightly to accept the values produced by AARCH64 CPUs. > > **Standalone code to reproduce the issue** > Provide a reproducible test case that is the bare minimum necessary to generate > the problem. If possible, please share a link to Colab/Jupyter/any notebook. > > bazel test //tensorflow/tools/docs:tf_doctest > > **Other info / logs** Include any logs or source code that would be helpful to > diagnose the problem. If including tracebacks, please include the full > traceback. Large logs and files should be attached. > > ## ====================================================================== > FAIL: Tanh (tensorflow.python.ops.gen_math_ops) > Doctest: tensorflow.python.ops.gen_math_ops.Tanh > Traceback (most recent call last): > File ""/usr/lib/python3.8/doctest.py"", line 2204, in runTest > raise self.failureException(self.format_failure(new.getvalue())) > AssertionError: Failed doctest test for tensorflow.python.ops.gen_math_ops.Tanh > File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py"", line 408, in Tanh > > File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py"", line 416, in tensorflow.python.ops.gen_math_ops.Tanh > Failed example: > tf.math.tanh(x) > Expected: > <tf.Tensor: shape=(8,), dtype=float32, numpy= > array([-1. , -0.99990916, -0.46211717, 0.7615942 , 0.8336547 , > 0.9640276 , 0.9950547 , 1. ], dtype=float32)> > Got: > <tf.Tensor: shape=(8,), dtype=float32, numpy= > array([-0.99999976, -0.99990916, -0.46211717, 0.7615942 , 0.8336546 , > 0.9640276 , 0.9950547 , 0.99999976], dtype=float32)> > > ``[code]`[code]`[code]`` > > ## ====================================================================== > FAIL: sigmoid (tensorflow.python.ops.math_ops) > Doctest: tensorflow.python.ops.math_ops.sigmoid > Traceback (most recent call last): > File ""/usr/lib/python3.8/doctest.py"", line 2204, in runTest > raise self.failureException(self.format_failure(new.getvalue())) > AssertionError: Failed doctest test for tensorflow.python.ops.math_ops.sigmoid > File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py"", line 174, in sigmoid > > File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py"", line 187, in tensorflow.python.ops.math_ops.sigmoid > Failed example: > tf.math.sigmoid(x) > Expected: > <tf.Tensor: shape=(4,), dtype=float32, > numpy=array([0.5 , 0.7310586, 1. , 1. ], dtype=float32)> > Got: > <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5 , 0.7310586, 0.9999998, 0.9999998], dtype=float32)>",-1
"> @cfRod
> @nSircombe

",IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-923701404,soffieswan041,2021-09-21 07:08:42,52069,[52966],Test bug,0,> @cfRod > @nSircombe,0
"Hi @Saduf2019 ,Could you please look  at this issue!",IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-924595401,mohantym,2021-09-22 05:19:33,52069,[52966],Test bug,0,"Hi @Saduf2019 ,Could you please look at this issue!",0
"non-critical failure if it only fails on aarch64, marking contributions welcome!",IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-926049152,kkimdev,2021-09-23 18:20:40,52069,[52966],Test bug,0,"non-critical failure if it only fails on aarch64, marking contributions welcome!",1
It turns out that the doctest was overly strict on the output and this is not a numerical accuracy issue at all. Relax the test by removing the unneeded white space allows the test to pass. See the attached PR.,IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-962087047,elfringham,2021-11-05 17:36:37,52069,[52966],Test bug,0,It turns out that the doctest was overly strict on the output and this is not a numerical accuracy issue at all. Relax the test by removing the unneeded white space allows the test to pass. See the attached PR.,2
"Doesn't seem to be caused by spacing, the error message has very different numbers

```
Expected:
<tf.Tensor: shape=(8,), dtype=float32, numpy=
array([-1. , -0.99990916, -0.46211717, 0.7615942 , 0.8336547 ,
0.9640276 , 0.9950547 , 1. ], dtype=float32)>
Got:
<tf.Tensor: shape=(8,), dtype=float32, numpy=
array([-0.99999976, -0.99990916, -0.46211717, 0.7615942 , 0.8336546 ,
0.9640276 , 0.9950547 , 0.99999976], dtype=float32)>
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-962706622,mihaimaruseac,2021-11-08 00:00:55,52069,[52966],Test bug,0,"Doesn't seem to be caused by spacing, the error message has very different numbers ``[code]``",0
"The tolerance is 1e-03. The numbers are close enough to match. It is the spaces that cause the string comparison to fail.
https://github.com/tensorflow/tensorflow/blob/c1ddc3f097997094d0e045bd81502805a169937c/tensorflow/tools/docs/tf_doctest_lib.py#L117",IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-962984320,elfringham,2021-11-08 09:54:52,52069,[52966],Test bug,0,The tolerance is 1e-03. The numbers are close enough to match. It is the spaces that cause the string comparison to fail. [url]#L117,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52069"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52069"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/52069#issuecomment-964364650,google-ml-butler[bot],2021-11-09 17:20:10,52069,[52966],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@cfRod @nSircombe ,IssueComment,https://github.com/tensorflow/tensorflow/issues/53067#issuecomment-968964471,elfringham,2021-11-15 14:28:17,53067,[53068],Test bug,0,@cfRod @nSircombe,0
Hi @elfringham! This issue will be closed once PR #53068 is merged. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/53067#issuecomment-969872298,mohantym,2021-11-16 05:25:43,53067,[53068],Test bug,0,Hi @elfringham! This issue will be closed once PR #53068 is merged. Thanks!,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53067"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53067"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/53067#issuecomment-996173931,google-ml-butler[bot],2021-12-16 20:33:24,53067,[53068],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Hi @Nyrio ! This issue will be closed once the PR #53158  is merged. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/53157#issuecomment-976163902,mohantym,2021-11-23 04:40:49,53157,[53158],Documentation bug,0,Hi @Nyrio ! This issue will be closed once the PR #53158 is merged. Thanks!,3
Hi @Nyrio ! Is this issue good to close now ? As the above PR seems to be merged now . Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/53157#issuecomment-989600800,mohantym,2021-12-09 07:56:37,53157,[53158],Documentation bug,0,Hi @Nyrio ! Is this issue good to close now ? As the above PR seems to be merged now . Thanks!,2
"@mohantym No, that's a different PR. #53158 is the one that closes this issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/53157#issuecomment-989692908,Nyrio,2021-12-09 10:00:03,53157,[53158],Documentation bug,0,"@mohantym No, that's a different PR. #53158 is the one that closes this issue.",0
Ok @Nyrio! Thanks for the confirmation! ,IssueComment,https://github.com/tensorflow/tensorflow/issues/53157#issuecomment-991917225,mohantym,2021-12-12 15:22:38,53157,[53158],Documentation bug,0,Ok @Nyrio! Thanks for the confirmation!,3
@cfRod @nSircombe ,IssueComment,https://github.com/tensorflow/tensorflow/issues/53166#issuecomment-976446132,elfringham,2021-11-23 12:03:28,53166,[53167],Test bug,0,@cfRod @nSircombe,0
"@elfringham ,
The issue will move to closed status once the PR is merged.",IssueComment,https://github.com/tensorflow/tensorflow/issues/53166#issuecomment-977447541,tilakrayal,2021-11-24 02:44:52,53166,[53167],Test bug,0,"@elfringham , The issue will move to closed status once the PR is merged.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53166"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53166"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/53166#issuecomment-999840789,google-ml-butler[bot],2021-12-22 20:21:55,53166,[53167],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@cfRod @nSircombe ,IssueComment,https://github.com/tensorflow/tensorflow/issues/53189#issuecomment-978074603,elfringham,2021-11-24 17:16:01,53189,[53274],Test bug,0,@cfRod @nSircombe,0
Hi @sanatmpa1! Could you please look at this issue?,IssueComment,https://github.com/tensorflow/tensorflow/issues/53189#issuecomment-978812451,mohantym,2021-11-25 04:08:27,53189,[53274],Test bug,0,Hi @sanatmpa1! Could you please look at this issue?,0
Reading the documentation at https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/arm64/cpu-feature-registers.rst?h=v5.16-rc2 it seems that it is not possible for a user space application like TensorFlow to read the performance counters directly on AARCH64 Linux.,IssueComment,https://github.com/tensorflow/tensorflow/issues/53189#issuecomment-979002501,elfringham,2021-11-25 09:17:29,53189,[53274],Test bug,0,Reading the documentation at [url] it seems that it is not possible for a user space application like TensorFlow to read the performance counters directly on AARCH64 Linux.,0
It seems like the use of llvm::Intrinsic::readcyclecounter at https://github.com/tensorflow/tensorflow/blob/f37b7b1f619a424b420fcaebb7826c76a6eb9627/tensorflow/compiler/xla/service/cpu/ir_emitter.cc#L2939 is not going to work on AARCH64 Linux.,IssueComment,https://github.com/tensorflow/tensorflow/issues/53189#issuecomment-979138299,elfringham,2021-11-25 11:49:45,53189,[53274],Test bug,0,It seems like the use of llvm::Intrinsic::readcyclecounter at [url]#L2939 is not going to work on AARCH64 Linux.,-1
"XLA's profiling feature is not going to work on ARM/AArch64 unless the system is configured to set `PMUSERENR.EN`. I think the only reasonable thing we can do for now is disabling that test on ARM.

Do you want to send a PR for that? Otherwise I can take a look.",IssueComment,https://github.com/tensorflow/tensorflow/issues/53189#issuecomment-983650389,d0k,2021-12-01 13:38:43,53189,[53274],Test bug,0,XLA's profiling feature is not going to work on ARM/AArch64 unless the system is configured to set [code]. I think the only reasonable thing we can do for now is disabling that test on ARM. Do you want to send a PR for that? Otherwise I can take a look.,0
"I propose to add the same tag as suggested in #53068 to exclude the test. I will add a PR for this shortly.

This does only deal with the unit tests however. It still leaves the feature in TF and if ever anyone attempts to make use of it on AARCH64, it will fail with SIGILL which is not really that nice for the unlucky user. So if you have some idea of how best to avoid that situation, that would be great, thanks @d0k .",IssueComment,https://github.com/tensorflow/tensorflow/issues/53189#issuecomment-983703105,elfringham,2021-12-01 14:36:23,53189,[53274],Test bug,0,"I propose to add the same tag as suggested in #53068 to exclude the test. I will add a PR for this shortly. This does only deal with the unit tests however. It still leaves the feature in TF and if ever anyone attempts to make use of it on AARCH64, it will fail with SIGILL which is not really that nice for the unlucky user. So if you have some idea of how best to avoid that situation, that would be great, thanks @d0k .",1
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53189"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53189"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/53189#issuecomment-988385516,google-ml-butler[bot],2021-12-08 00:45:59,53189,[53274],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@cfRod @nSircombe ,IssueComment,https://github.com/tensorflow/tensorflow/issues/53322#issuecomment-986979511,elfringham,2021-12-06 17:13:22,53322,[53323],Test bug,0,@cfRod @nSircombe,0
@elfringham This issue will be closed once the [PR](https://github.com/tensorflow/tensorflow/pull/53323) is merged. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/53322#issuecomment-998950354,sushreebarsa,2021-12-21 17:09:06,53322,[53323],Test bug,0,@elfringham This issue will be closed once the [PR]([url] is merged. Thanks!,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53322"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53322"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/53322#issuecomment-1011292842,google-ml-butler[bot],2022-01-12 17:38:06,53322,[53323],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@anhappdev This issue will be closed once the [PR](https://github.com/tensorflow/tensorflow/pull/53468) is merged.Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/53461#issuecomment-998581810,sushreebarsa,2021-12-21 08:44:25,53461,[53468],Deployment bug,0,@anhappdev This issue will be closed once the [PR]([url] is merged.Thanks!,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53461"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53461"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/53461#issuecomment-1006966010,google-ml-butler[bot],2022-01-06 22:01:40,53461,[53468],Deployment bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added PR #53694 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/53653#issuecomment-1007637604,yongtang,2022-01-07 18:29:44,53653,[53694],Data bug,1,Added PR #53694 for the fix.,0
"Hi @Saduf2019 ! Could you please look at this issue? It's replicating in [2.7](https://colab.sandbox.google.com/gist/mohantym/599ed1f5134314a960fff561fc369737/github_53660.ipynb) ,[2.6 ](https://colab.sandbox.google.com/gist/mohantym/98348f4572ffac7b91f30d94f930644d/github_53660.ipynb#scrollTo=qjuBqEkMup9X)and [nightly](https://colab.sandbox.google.com/gist/mohantym/fec4b007291137635e74b18b70423929/github_53660.ipynb#scrollTo=qjuBqEkMup9X) .Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/53660#issuecomment-1007197298,mohantym,2022-01-07 07:28:52,53660,[53695],Data bug,1,"Hi @Saduf2019 ! Could you please look at this issue? It's replicating in [2.7]([url] ,[2.6 ]([url]#scrollTo=qjuBqEkMup9X)and [nightly]([url]#scrollTo=qjuBqEkMup9X) .Thank you!",2
Added a PR #53695 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/53660#issuecomment-1007644055,yongtang,2022-01-07 18:39:13,53660,[53695],Data bug,1,Added a PR #53695 for the fix.,0
"Hi @sachinprasadhs ! Could you please look at this issue?  Attaching gist in [2.6](https://colab.sandbox.google.com/gist/mohantym/38dd66c557d5f77993144919b11f653b/github_54125.ipynb#scrollTo=fxuWOtXR_aPE) and [2.7](https://colab.sandbox.google.com/gist/mohantym/6942139dfd2218e14af74cccea8db259/github_54125.ipynb) , [2.8](https://colab.sandbox.google.com/gist/mohantym/17c5b2aa7cbf28f9b59de73a92ec858e/github_54125.ipynb#scrollTo=fxuWOtXR_aPE) for reference.


",IssueComment,https://github.com/tensorflow/tensorflow/issues/54125#issuecomment-1023389190,mohantym,2022-01-27 16:13:09,54125,[54191],Data bug,0,"Hi @sachinprasadhs ! Could you please look at this issue? Attaching gist in [2.6]([url]#scrollTo=fxuWOtXR_aPE) and [2.7]([url] , [2.8]([url]#scrollTo=fxuWOtXR_aPE) for reference.",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54125"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54125"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/54125#issuecomment-1034084128,google-ml-butler[bot],2022-02-09 18:48:23,54125,[54191],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@chunduriv ,
I was able to reproduce the issue in tf v2.7, v2.8 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/e984b885c1efc3c9cc06b3659914c4da/54317.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/54317#issuecomment-1035004869,tilakrayal,2022-02-10 14:45:04,54317,[54356],Data bug,1,"@chunduriv , I was able to reproduce the issue in tf v2.7, v2.8 and nightly.Please find the gist of it [here]([url]",0
Added a PR #54356 for the complex support of tf.math.asin.,IssueComment,https://github.com/tensorflow/tensorflow/issues/54317#issuecomment-1036984633,yongtang,2022-02-12 04:17:26,54317,[54356],Data bug,1,Added a PR #54356 for the complex support of tf.math.asin.,0
"@ArrowIntoTheSky, The issue will move to closed status once the https://github.com/tensorflow/tensorflow/pull/54356 is merged. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/54317#issuecomment-1038833770,chunduriv,2022-02-14 09:11:28,54317,[54356],Data bug,1,"@ArrowIntoTheSky, The issue will move to closed status once the [url] is merged. Thanks!",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54317"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54317"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/54317#issuecomment-1041918177,google-ml-butler[bot],2022-02-16 17:36:41,54317,[54356],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
we've also raised a PR for the keras one [upstream](https://github.com/keras-team/keras/issues/16072),IssueComment,https://github.com/tensorflow/tensorflow/issues/54392#issuecomment-1040593231,code-review-doctor,2022-02-15 17:52:22,54392,[54395],Test bug,0,we've also raised a PR for the keras one [upstream]([url],0
Thank you created a PR https://github.com/tensorflow/tensorflow/pull/54395 for the same.,IssueComment,https://github.com/tensorflow/tensorflow/issues/54392#issuecomment-1040818863,rthadur,2022-02-15 21:37:09,54392,[54395],Test bug,0,Thank you created a PR [url] for the same.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54392"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54392"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/54392#issuecomment-1042362753,google-ml-butler[bot],2022-02-16 22:14:44,54392,[54395],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Hi @chunduriv ! Could you please look at this issue? It is replicating  in TF 2.7 and 2.8. Attaching gist in [2.8 ](https://colab.sandbox.google.com/gist/mohantym/422bcc9269550d072870afe4f0b3c578/github_54415_2-8.ipynb#scrollTo=7AJOJUOiT-Gu) and [2.7](https://colab.sandbox.google.com/gist/mohantym/c3e643aa8b2ac6ec0ae83b37b25c5465/github_54415_2-8.ipynb#scrollTo=Fhee8nopUdjy)  for reference. Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/54415#issuecomment-1042613618,mohantym,2022-02-17 06:21:22,54415,[54429],Data bug,0,Hi @chunduriv ! Could you please look at this issue? It is replicating in TF 2.7 and 2.8. Attaching gist in [2.8 ]([url]#scrollTo=7AJOJUOiT-Gu) and [2.7]([url]#scrollTo=Fhee8nopUdjy) for reference. Thanks!,2
Added a PR #54429 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/54415#issuecomment-1043609432,yongtang,2022-02-17 23:21:47,54415,[54429],Data bug,0,Added a PR #54429 for the fix.,0
"@ArrowIntoTheSky, The issue will move to closed status once the https://github.com/tensorflow/tensorflow/pull/54429 is merged. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/54415#issuecomment-1043884303,chunduriv,2022-02-18 04:52:13,54415,[54429],Data bug,0,"@ArrowIntoTheSky, The issue will move to closed status once the [url] is merged. Thanks!",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54415"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54415"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/54415#issuecomment-1047995218,google-ml-butler[bot],2022-02-22 16:44:10,54415,[54429],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added a PR #54412 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/54412#issuecomment-1043661574,yongtang,2022-02-18 00:06:15,54412,[54432],Data bug,0,Added a PR #54412 for the fix.,0
"@ArrowIntoTheSky, The issue will move to closed status once the https://github.com/tensorflow/tensorflow/pull/54432 is merged. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/54412#issuecomment-1043889525,chunduriv,2022-02-18 04:56:48,54412,[54432],Data bug,0,"@ArrowIntoTheSky, The issue will move to closed status once the [url] is merged. Thanks!",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54412"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54412"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/54412#issuecomment-1060973414,google-ml-butler[bot],2022-03-07 18:04:24,54412,[54432],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@ArrowIntoTheSky ,
Please find the difference between tf.compat.as_text and tf.compat.as_bytes.
tf.compat.as_text:Converts any string-like python input types to unicode.
tf.compat.as_bytes:Converts bytearray, bytes, or unicode python input types to bytes",IssueComment,https://github.com/tensorflow/tensorflow/issues/54413#issuecomment-1042903225,tilakrayal,2022-02-17 12:33:11,54413,[54503],Data bug,0,"@ArrowIntoTheSky , Please find the difference between tf.compat.as_text and tf.compat.as_bytes. tf.compat.as_text:Converts any string-like python input types to unicode. tf.compat.as_bytes:Converts bytearray, bytes, or unicode python input types to bytes",0
"@tilakrayal 
Yes, they are different APIs. I just use `tf.compat.as_bytes` to show the correct error handling of a **wrong** encoding string. It is obvious that `encoding` cannot be `valid` or `hi` as in the following example:
```
import tensorflow as tf
bytes_or_text = ""hello""
encoding = ""hi""
t1 = tf.compat.as_text(bytes_or_text, encoding=encoding) # This pass! But it should not.
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/54413#issuecomment-1043179198,ArrowIntoTheSky,2022-02-17 16:51:56,54413,[54503],Data bug,0,"@tilakrayal Yes, they are different APIs. I just use [code] to show the correct error handling of a **wrong** encoding string. It is obvious that [code] cannot be [code] or [code] as in the following example: ``[code]``",0
"@gadagashwini ,
I was able to reproduce the issue in tf v2.7, v2.8 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/00dfd63ad2db6914065b7d00893cfc41/54413.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/54413#issuecomment-1044235053,tilakrayal,2022-02-18 09:48:11,54413,[54503],Data bug,0,"@gadagashwini , I was able to reproduce the issue in tf v2.7, v2.8 and nightly.Please find the gist of it [here]([url]",0
Added a PR #54503 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/54413#issuecomment-1049206302,yongtang,2022-02-23 20:53:11,54413,[54503],Data bug,0,Added a PR #54503 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54413"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54413"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/54413#issuecomment-1054711877,google-ml-butler[bot],2022-02-28 22:10:34,54413,[54503],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@chunduriv Was able to replicate the issue on colab using TF v2.8.0 and tf-nightly(2.9.0.dev20220303), please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/edac82db0255229e1a8a06989716e6d9/54855.ipynb#scrollTo=BxmihNCvCOid).Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/54855#issuecomment-1058062762,sushreebarsa,2022-03-03 13:53:02,54855,[54972],Data bug,1,"@chunduriv Was able to replicate the issue on colab using TF v2.8.0 and tf-nightly(2.9.0.dev20220303), please find the gist [here]([url]#scrollTo=BxmihNCvCOid).Thanks!",2
Added a PR #54972 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/54855#issuecomment-1058886561,yongtang,2022-03-04 06:53:44,54855,[54972],Data bug,1,Added a PR #54972 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54855"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54855"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/54855#issuecomment-1060989086,google-ml-butler[bot],2022-03-07 18:20:12,54855,[54972],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Added PR #55274 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/55263#issuecomment-1071236514,yongtang,2022-03-17 19:13:17,55263,[55274],Data bug,1,Added PR #55274 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55263"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55263"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/55263#issuecomment-1076515771,google-ml-butler[bot],2022-03-23 16:05:25,55263,[55274],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
Sofware updating ,IssueComment,https://github.com/tensorflow/tensorflow/issues/55290#issuecomment-1072973767,roniesha1994,2022-03-19 09:07:53,55290,[55365],Documentation bug,0,Sofware updating,0
"@kanghj ,
I have tried in colab with v 2.8 version and noticed that session is being crashed. Please, find the gist [here](https://colab.research.google.com/gist/tilakrayal/39587d8c4222dbbb35d876cb316973be/untitled255.ipynb). Also please find the errorlog of the crashed colab which stated as below.
`Check failed: ndims_byte() < MaxDimensions() (unsigned char value 254 vs. 254)Too many dimensions in tensor`",IssueComment,https://github.com/tensorflow/tensorflow/issues/55292#issuecomment-1073529368,tilakrayal,2022-03-21 06:45:48,55292,[55430],Data bug,0,"@kanghj , I have tried in colab with v 2.8 version and noticed that session is being crashed. Please, find the gist [here]([url] Also please find the errorlog of the crashed colab which stated as below. [code]",-2
"Thanks for checking. 

Yes, indeed it crashes, which I am reporting as a bug. The expected, correct behavior is that`tf.experimental.numpy.array` should throw an exception (perhaps a `ValueError`, same as numpy.array), and not crash. Crashing is an unexpected, wrong behavior. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/55292#issuecomment-1073555035,kanghj,2022-03-21 07:33:27,55292,[55430],Data bug,0,"Thanks for checking. Yes, indeed it crashes, which I am reporting as a bug. The expected, correct behavior is that[code] should throw an exception (perhaps a [code], same as numpy.array), and not crash. Crashing is an unexpected, wrong behavior.",-2
"@chunduriv ,
I have tried in colab with tf v2.8, v2.7, nightly and noticed that session is being crashed. Please, find the gist [here](https://colab.research.google.com/gist/tilakrayal/a0505cddfd9e7663e5c56e945b74b912/55292.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/55292#issuecomment-1076087398,tilakrayal,2022-03-23 08:36:47,55292,[55430],Data bug,0,"@chunduriv , I have tried in colab with tf v2.8, v2.7, nightly and noticed that session is being crashed. Please, find the gist [here]([url] Thanks!",-2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55292"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55292"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/55292#issuecomment-1085648661,google-ml-butler[bot],2022-04-01 09:06:18,55292,[55430],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@code-review-doctor ,
The respective PR has been assigned for reviewing and once it is merged this issue will move to closed status.Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/55723#issuecomment-1108327837,tilakrayal,2022-04-25 09:35:44,55723,[55726],Documentation bug,0,"@code-review-doctor , The respective PR has been assigned for reviewing and once it is merged this issue will move to closed status.Thanks!",3
"Update: 
test still fails on commit `55645ca964508507890529a71591f51a344a6356` April 9

test passes with ``--config=opt``",IssueComment,https://github.com/tensorflow/tensorflow/issues/55530#issuecomment-1094062446,awf,2022-04-09 15:05:37,55530,[55730],Test bug,0,Update: test still fails on commit [code] April 9 test passes with `[code]`,0
"@awf
Please let us know if this issue is resolved for you in a recent commit ?Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/55530#issuecomment-1094674598,sushreebarsa,2022-04-11 08:00:08,55530,[55730],Test bug,0,@awf Please let us know if this issue is resolved for you in a recent commit ?Thanks!,2
"Still present in 55645c from 2 days ago.
I'll take a look, but I don't see anything more recent that might have fixed it.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/55530#issuecomment-1095023202,awf,2022-04-11 13:03:04,55530,[55730],Test bug,0,"Still present in 55645c from 2 days ago. I'll take a look, but I don't see anything more recent that might have fixed it.",0
"Confirmed on
```
commit c44d14f2194cf4c4b4060fd4141194ee62792ca8 (HEAD -> master, upstream/master, origin/master, origin/HEAD)
Date:   Mon Apr 11 05:36:24 2022 -0700
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/55530#issuecomment-1095183150,awf,2022-04-11 15:16:18,55530,[55730],Test bug,0,Confirmed on ``[code]``,0
"Note I'm happy to submit a PR, but there are a few options, as listed above, so seeking guidance on which one to implement.",IssueComment,https://github.com/tensorflow/tensorflow/issues/55530#issuecomment-1096458487,awf,2022-04-12 09:41:40,55530,[55730],Test bug,0,"Note I'm happy to submit a PR, but there are a few options, as listed above, so seeking guidance on which one to implement.",3
PR fixing this issue is #55730 ,IssueComment,https://github.com/tensorflow/tensorflow/issues/55530#issuecomment-1109688299,awf,2022-04-26 11:37:16,55530,[55730],Test bug,0,PR fixing this issue is #55730,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55530"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55530"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/55530#issuecomment-1112679906,google-ml-butler[bot],2022-04-28 21:42:10,55530,[55730],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Thanks for the bug, I have created a PR for the same.",IssueComment,https://github.com/tensorflow/tensorflow/issues/55795#issuecomment-1115317878,sachinprasadhs,2022-05-02 20:13:12,55795,[55831],Build bug,0,"Thanks for the bug, I have created a PR for the same.",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55795"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55795"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/55795#issuecomment-1117420626,google-ml-butler[bot],2022-05-04 14:51:29,55795,[55831],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Hello @dev0x13 ,
The PR has been assigned for reviewing and once it is merged this issue will move to closed status.Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/56134#issuecomment-1131089637,tilakrayal,2022-05-19 03:06:51,56134,[56136],Processor bug,0,"Hello @dev0x13 , The PR has been assigned for reviewing and once it is merged this issue will move to closed status.Thank you!",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56134"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56134"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/56134#issuecomment-1201734327,google-ml-butler[bot],2022-08-01 21:20:32,56134,[56136],Processor bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@namrata-ibm 
In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/56046#issuecomment-1122250435,sushreebarsa,2022-05-10 11:11:17,56046,[56167],Test bug,0,"@namrata-ibm In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thank you!",2
"@sushreebarsa below is the reduced test case which can be used to reproduce the failure on s390x:
```
#include ""tensorflow/core/platform/ctstring.h""

#include <memory>
#include <string>

#include ""tensorflow/core/platform/ctstring_internal.h""
#include ""tensorflow/core/platform/test.h""

TEST(TF_CTStringTest, OffsetType) {
  {
    TF_TString s71;

    TF_TString_Init(&s71);
    size_t header_length = 24;
    size_t size = 8;
    TF_TString_ResizeUninitialized(&s71, header_length + size);
    uint32_t save_size = s71.u.offset.size;
    uint32_t save_offset = s71.u.offset.offset;
    uint32_t save_count = s71.u.offset.count;

    s71.u.offset.size = TF_TString_ToInternalSizeT(size, TF_TSTR_OFFSET);
    s71.u.offset.offset = header_length;
    s71.u.offset.count = 0;
    EXPECT_EQ(size, TF_TString_GetSize(&s71));
    EXPECT_EQ(TF_TSTR_OFFSET, TF_TString_GetType(&s71));

    // restore state so string can be deallocated
    s71.u.offset.size = save_size;
    s71.u.offset.offset = save_offset;
    s71.u.offset.count = save_count;
    TF_TString_Dealloc(&s71);
  }
}
```
The corresponding failure is mentioned in issue description under `Relevant log output`. 
Please let me know if anything more is needed.


",IssueComment,https://github.com/tensorflow/tensorflow/issues/56046#issuecomment-1122493161,namrata-ibm,2022-05-10 14:44:55,56046,[56167],Test bug,0,@sushreebarsa below is the reduced test case which can be used to reproduce the failure on s390x: ``[code]`[code]Relevant log output`. Please let me know if anything more is needed.,0
"Some more analysis: The `TF_TString_ToInternalSizeT` is also used in other functions like [TF_TString_AssignView](https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/core/platform/ctstring_test.cc#L313) which are part of other tests within `TF_CTStringTest`.  These do pass on s390x, where the type is `TF_TSTR_SMALL/LARGE`. Issue is only seen for the `offset type` added recently.

[This ](https://github.com/tensorflow/tensorflow/commit/206dc37a33bf34a1a79dd56e19fb7b1c6cdf5dc6) had resolved a bug in those functions last time, however looks like something more is amiss. @gharibian any pointers would be helpful!",IssueComment,https://github.com/tensorflow/tensorflow/issues/56046#issuecomment-1122507967,namrata-ibm,2022-05-10 14:56:59,56046,[56167],Test bug,0,"Some more analysis: The [code] is also used in other functions like [TF_TString_AssignView]([url]#L313) which are part of other tests within [code]. These do pass on s390x, where the type is [code]. Issue is only seen for the [code] added recently. [This ]([url] had resolved a bug in those functions last time, however looks like something more is amiss. @gharibian any pointers would be helpful!",0
@gadagashwini could you please check?,IssueComment,https://github.com/tensorflow/tensorflow/issues/56046#issuecomment-1125213506,namrata-ibm,2022-05-12 16:47:48,56046,[56167],Test bug,0,@gadagashwini could you please check?,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56046"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56046"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/56046#issuecomment-1202421433,google-ml-butler[bot],2022-08-02 12:26:46,56046,[56167],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Abort is caused by the following code in label_image.
https://github.com/tensorflow/tensorflow/blob/v2.9.1/tensorflow/lite/examples/label_image/label_image.cc#L129

The correct type of num_threads is i`nt32_t`, not `bool`.
https://github.com/tensorflow/tensorflow/blob/v2.9.1/tensorflow/lite/tools/delegates/default_execution_provider.cc#L30

This error occurs on Raspberry Pi OS 64bit (bullseye) and Fedora 36.
On Ubuntu 22.04, the process is completed without Abort. For unknown reasons, xnnpack delegate does not take effect. It may be one of the possibilities of #55476.",IssueComment,https://github.com/tensorflow/tensorflow/issues/56367#issuecomment-1147391577,NobuoTsukamoto,2022-06-06 12:25:14,56367,[56369],Build bug,0,"Abort is caused by the following code in label_image. [url]#L129 The correct type of num_threads is i[code], not [code]. [url]#L30 This error occurs on Raspberry Pi OS 64bit (bullseye) and Fedora 36. On Ubuntu 22.04, the process is completed without Abort. For unknown reasons, xnnpack delegate does not take effect. It may be one of the possibilities of #55476.",-2
Hi @NobuoTsukamoto ! Thanks for reporting this bug. This issue will be closed once PR #56369 is merged. ,IssueComment,https://github.com/tensorflow/tensorflow/issues/56367#issuecomment-1147419136,mohantym,2022-06-06 12:58:58,56367,[56369],Build bug,0,Hi @NobuoTsukamoto ! Thanks for reporting this bug. This issue will be closed once PR #56369 is merged.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56367"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56367"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/56367#issuecomment-1153309314,google-ml-butler[bot],2022-06-12 22:30:33,56367,[56369],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@Flamefire,
Can you please elaborate about your issue so that everyone could understand what the issue exactly is? Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-850351105,rmothukuru,2021-05-28 11:26:31,49833,[56633],Processor bug,0,"@Flamefire, Can you please elaborate about your issue so that everyone could understand what the issue exactly is? Thanks!",1
"Sure:
The call at https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/core/platform/default/port.cc#L75 only works for systems with at most 1024 cores
This is due to the usage of the default `cpu_set_t` at https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/core/platform/default/port.cc#L74 which has only enough space for 1024 cores.

Hence: When using TF on a system with more than 1024 cores the call to `sched_getaffinity` will fail and TF will fallback to using only 4 cores as indicated by the warning.

The solution is to use the macros `CPU_ALLOC_SIZE` and `CPU_ALLOC` provided by glibc to dynamically increase the size of the struct passed to `sched_getaffinity` until there is enough space for all CPUs. See e.g. https://github.com/python/cpython/blob/0fa282c55f1a45765340cb24ed65c90ffe2aa405/Modules/posixmodule.c#L7129",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-850355351,Flamefire,2021-05-28 11:34:51,49833,[56633],Processor bug,0,Sure: The call at [url]#L75 only works for systems with at most 1024 cores This is due to the usage of the default [code] at [url]#L74 which has only enough space for 1024 cores. Hence: When using TF on a system with more than 1024 cores the call to [code] will fail and TF will fallback to using only 4 cores as indicated by the warning. The solution is to use the macros [code] and [code] provided by glibc to dynamically increase the size of the struct passed to [code] until there is enough space for all CPUs. See e.g. [url]#L7129,0
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-854652361,google-ml-butler[bot],2021-06-04 12:01:04,49833,[56633],Processor bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
This issue is not stale!,IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-854653069,Flamefire,2021-06-04 12:02:27,49833,[56633],Processor bug,0,This issue is not stale!,0
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-859556795,google-ml-butler[bot],2021-06-11 12:46:55,49833,[56633],Processor bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
This issue is not stale!,IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-859566352,Flamefire,2021-06-11 13:03:09,49833,[56633],Processor bug,0,This issue is not stale!,0
"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-864031317,google-ml-butler[bot],2021-06-18 13:15:50,49833,[56633],Processor bug,0,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.,0
This issue is not stale!,IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-864786070,Flamefire,2021-06-21 07:08:35,49833,[56633],Processor bug,0,This issue is not stale!,0
"@Flamefire,
Sorry for the inconvenience caused by the Stale Bot. It doesn't bother you anymore. Thanks! ",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-864928055,rmothukuru,2021-06-21 10:37:42,49833,[56633],Processor bug,0,"@Flamefire, Sorry for the inconvenience caused by the Stale Bot. It doesn't bother you anymore. Thanks!",3
"@Flamefire 
please confirm if this is still an issue in latest tf version.",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-948477372,Saduf2019,2021-10-21 10:33:17,49833,[56633],Processor bug,0,@Flamefire please confirm if this is still an issue in latest tf version.,0
"@Saduf2019 as the problematic code linked at https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-850355351 is still current, yes the issue still persists",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-948544221,Flamefire,2021-10-21 12:03:31,49833,[56633],Processor bug,0,"@Saduf2019 as the problematic code linked at [url]#issuecomment-850355351 is still current, yes the issue still persists",-2
I opened a PR with an implementation based on CPythons `os.sched_getaffinity` and used as a patch for building TF with EasyBuild for a while now: #56633,IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-1171014596,Flamefire,2022-06-30 09:58:15,49833,[56633],Processor bug,0,I opened a PR with an implementation based on CPythons [code] and used as a patch for building TF with EasyBuild for a while now: #56633,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49833"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49833"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/49833#issuecomment-1202643166,google-ml-butler[bot],2022-08-02 14:03:59,49833,[56633],Processor bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@cfRod @nSircombe ,IssueComment,https://github.com/tensorflow/tensorflow/issues/56713#issuecomment-1178879984,elfringham,2022-07-08 11:30:31,56713,[56714],Test bug,0,@cfRod @nSircombe,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56713"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56713"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/56713#issuecomment-1190853802,google-ml-butler[bot],2022-07-20 23:06:18,56713,[56714],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
@cfRod @nSircombe ,IssueComment,https://github.com/tensorflow/tensorflow/issues/56840#issuecomment-1190310522,elfringham,2022-07-20 13:47:46,56840,[56841],Test bug,0,@cfRod @nSircombe,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56840"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56840"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/56840#issuecomment-1192892273,google-ml-butler[bot],2022-07-22 19:57:05,56840,[56841],Test bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"Hi @Wanzizhu !
Could you please share your code and results with a gist . I could not find any issue while doing unit test of this op. Attached [gist ](https://colab.sandbox.google.com/gist/mohantym/0ccc54941f7f0c784cc0da5389e540b8/tensorflow-ranking.ipynb#scrollTo=tlf7PgzQ2JtS)for reference. 

Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/56906#issuecomment-1196178467,mohantym,2022-07-27 01:53:05,56906,[56939],Data bug,0,Hi @Wanzizhu ! Could you please share your code and results with a gist . I could not find any issue while doing unit test of this op. Attached [gist ]([url]#scrollTo=tlf7PgzQ2JtS)for reference. Thank you!,2
"hi, @mohantym , current uint test doesn't cover the issue case, so no issue for current unit test. I added below test and tested on my local machine. Below are the added test and failed result. 

- Test

```
TEST(OpsTest, ShapeInferenceMultiInput) {
  NodeDef def;
  shape_inference::InferenceContext c(
      0, def, MakeOpDef(1, 0), {S({10, 20, 30, 40, 50}), S({10})}, {}, {}, {});
  ASSERT_EQ(""[10]"", c.DebugString(c.input(1)));

  TF_ShapeHandle* handle = TF_NewShapeHandle();
  TF_Status* status = TF_NewStatus();
  TF_ShapeInferenceContextGetInput(C_CTX(&c), 1, handle, status);
  ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);
  ASSERT_EQ(
      ""[10]"",
      c.DebugString(*reinterpret_cast<shape_inference::ShapeHandle*>(handle)));
  TF_DeleteStatus(status);
  TF_DeleteShapeHandle(handle);
}

void multi_output_shape_fn(TF_ShapeInferenceContext* ctx, TF_Status* status) {
  TF_ShapeHandle* handle = TF_NewShapeHandle();
  TF_ShapeInferenceContextGetInput(ctx, 0, handle, status);
  ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);

  TF_ShapeInferenceContextSetOutput(ctx, 0, handle, status);
  ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);
  TF_ShapeInferenceContextSetOutput(ctx, 1, handle, status);
  ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);
  TF_DeleteShapeHandle(handle);
}

TEST(OpsTest, TestShapeInference_MultiOutput) {
  ShapeInferenceTestOp op(""MultioutputTestOp"");

  TF_OpDefinitionBuilder* builder =
      TF_NewOpDefinitionBuilder(""MultioutputTestOp"");
  TF_OpDefinitionBuilderAddInput(builder, ""input1: uint8"");
  TF_OpDefinitionBuilderAddOutput(builder, ""output1: uint8"");
  TF_OpDefinitionBuilderAddOutput(builder, ""output2: uint8"");

  TF_OpDefinitionBuilderSetShapeInferenceFunction(builder, &multi_output_shape_fn);  
  
  TF_Status* status = TF_NewStatus();
  TF_RegisterOpDefinition(builder, status);  
  ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);
  TF_ASSERT_OK(
      shape_inference::ShapeInferenceTestutil::InferShapes(op, ""[1,2]"", ""in0;in0""));  
  TF_DeleteStatus(status);
}
```
- Result
```
[ RUN      ] OpsTest.TestShapeInference_MultiOutput
tensorflow/c/ops_test.cc:92: Failure
Expected equality of these values:
  TF_OK
    Which is: 0
  TF_GetCode(status)
    Which is: 3
output index out of range
tensorflow/c/ops_test.cc:110: Failure
Expected equality of these values:
  ::tensorflow::Status::OK()
    Which is: OK
  (shape_inference::ShapeInferenceTestutil::InferShapes(op, ""[1,2]"", ""in0;in0""))
    Which is: INVALID_ARGUMENT: output index out of range for '{{node }} = []()' with input shapes: [1,2].
[  FAILED  ] OpsTest.TestShapeInference_MultiOutput (0 ms)
[ RUN      ] OpsTest.ShapeInferenceMultiInput
tensorflow/c/ops_test.cc:369: Failure
Expected equality of these values:
  TF_OK
    Which is: 0
  TF_GetCode(status)
    Which is: 3
input index out of range
[  FAILED  ] OpsTest.ShapeInferenceMultiInput (0 ms)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/56906#issuecomment-1197602546,Wanzizhu,2022-07-28 03:09:19,56906,[56939],Data bug,0,"hi, @mohantym , current uint test doesn't cover the issue case, so no issue for current unit test. I added below test and tested on my local machine. Below are the added test and failed result. - Test ``[code]`[code]`[code]``",0
"@mohantym, maybe it 's a typo in source code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/ops.cc#L146) and [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/ops.cc#L166)",IssueComment,https://github.com/tensorflow/tensorflow/issues/56906#issuecomment-1197611171,Wanzizhu,2022-07-28 03:25:50,56906,[56939],Data bug,0,"@mohantym, maybe it 's a typo in source code [here]([url]#L146) and [here]([url]#L166)",0
"Ok @Wanzizhu !
Thanks for the update. @sachinprasadhs ! Could you please look at this issue.
Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/56906#issuecomment-1197706185,mohantym,2022-07-28 06:09:12,56906,[56939],Data bug,0,Ok @Wanzizhu ! Thanks for the update. @sachinprasadhs ! Could you please look at this issue. Thank you!,3
Are you suggesting the existing condition to change it to `0 <= i || i >= cc_ctx->num_inputs()` for your tests to pass?,IssueComment,https://github.com/tensorflow/tensorflow/issues/56906#issuecomment-1198634973,sachinprasadhs,2022-07-28 21:11:04,56906,[56939],Data bug,0,Are you suggesting the existing condition to change it to [code] for your tests to pass?,0
"@sachinprasadhs , i am suggesting to change ` 0 < i` to`i < 0` in both `TF_ShapeInferenceContextGetInput` and `TF_ShapeInferenceContextSetOutput`, as `0 < i` is not out of range.",IssueComment,https://github.com/tensorflow/tensorflow/issues/56906#issuecomment-1198682336,Wanzizhu,2022-07-28 22:14:02,56906,[56939],Data bug,0,"@sachinprasadhs , i am suggesting to change [code] to[code] in both [code] and [code], as [code] is not out of range.",0
"Thanks for the clarification, I will create a PR for the above mentioned changes.",IssueComment,https://github.com/tensorflow/tensorflow/issues/56906#issuecomment-1198696029,sachinprasadhs,2022-07-28 22:38:01,56906,[56939],Data bug,0,"Thanks for the clarification, I will create a PR for the above mentioned changes.",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56906"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/56906"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/56906#issuecomment-1206762657,google-ml-butler[bot],2022-08-05 18:55:45,56906,[56939],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@kcoul,
This issue will move to closed status once the respected PR is merged. Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/57133#issuecomment-1216220959,tilakrayal,2022-08-16 06:53:39,57133,[57134],Build bug,0,"@kcoul, This issue will move to closed status once the respected PR is merged. Thank you!",3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/57133"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/57133"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/57133#issuecomment-1225030226,google-ml-butler[bot],2022-08-24 00:39:11,57133,[57134],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"This bug was introduced by me when rewriting the prod gradient to deal with zeros in the input.
The code doesn't handle the case where `reduction_indices` is a scalar.

To fix this we should
- Add a line to the gradient that reshapes the `reduction_indices` to a rank 1 tensor: `tf.reshape(reduction_indices, [-1])`
- Add a test case that computes the gradient with a scalar reduction index parameter.
- Maybe add a bit of text to the documentation of the reduction ops that mentions that both scalars and rank tensors can be passed in? I couldn't find any mention of this being possible except for the examples.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/3815#issuecomment-239878316,ibab,2016-08-15 18:03:29,3815,[3858],Build bug,0,This bug was introduced by me when rewriting the prod gradient to deal with zeros in the input. The code doesn't handle the case where [code] is a scalar. To fix this we should - Add a line to the gradient that reshapes the [code] to a rank 1 tensor: [code] - Add a test case that computes the gradient with a scalar reduction index parameter. - Maybe add a bit of text to the documentation of the reduction ops that mentions that both scalars and rank tensors can be passed in? I couldn't find any mention of this being possible except for the examples.,0
"@ibab, do you plan to submit a PR? Thanks.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/3815#issuecomment-240206589,sherrym,2016-08-16 19:11:04,3815,[3858],Build bug,0,"@ibab, do you plan to submit a PR? Thanks.",0
"I've just pushed #3858 with a fix.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/3815#issuecomment-240247177,ibab,2016-08-16 21:36:38,3815,[3858],Build bug,0,I've just pushed #3858 with a fix.,2
"Thanks much, @ibab!
",IssueComment,https://github.com/tensorflow/tensorflow/issues/3815#issuecomment-240248303,sherrym,2016-08-16 21:40:52,3815,[3858],Build bug,0,"Thanks much, @ibab!",5
Created a PR #12129 to address the int64 support for `tf.unique`.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12113#issuecomment-321148973,yongtang,2017-08-09 04:23:34,12113,[12129],Data bug,1,Created a PR #12129 to address the int64 support for [code].,3
Thanks @yongtang for the quick PR!  Marking this as community support; it'll get closed when the PR gets merged.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12113#issuecomment-321313530,tatatodd,2017-08-09 16:47:02,12113,[12129],Data bug,1,Thanks @yongtang for the quick PR! Marking this as community support; it'll get closed when the PR gets merged.,3
I think the fix is correct. Created a PR #12562,IssueComment,https://github.com/tensorflow/tensorflow/issues/12525#issuecomment-324713067,yongtang,2017-08-24 18:08:32,12525,[12562],Data bug,0,I think the fix is correct. Created a PR #12562,3
@jhseu Can you close this when PR #12562 is merged?,IssueComment,https://github.com/tensorflow/tensorflow/issues/12525#issuecomment-324790121,andydavis1,2017-08-25 00:09:24,12525,[12562],Data bug,0,@jhseu Can you close this when PR #12562 is merged?,0
@jhseu please close this once #12584 and #12558 are merged...,IssueComment,https://github.com/tensorflow/tensorflow/issues/12583#issuecomment-325016744,andydavis1,2017-08-25 19:36:35,12583,[12584],Data bug,0,@jhseu please close this once #12584 and #12558 are merged...,0
"Hi, the out-of-bounds bug in `tf.contrib.layers.feature_column` is fixed in #12584, and `tf.feature_columns` is fixed in #12638. Please close this once they are both accepted and merged. Thanks.",IssueComment,https://github.com/tensorflow/tensorflow/issues/12583#issuecomment-325244832,facaiy,2017-08-28 02:20:13,12583,[12584],Data bug,0,"Hi, the out-of-bounds bug in [code] is fixed in #12584, and [code] is fixed in #12638. Please close this once they are both accepted and merged. Thanks.",2
"@caisq I think this change may relates to the problem: https://github.com/tensorflow/tensorflow/commit/41803db36d4f4a3239bd81e5d460eb0e6e2eea88

That changes #if defined(PLATFORM_GOOGLE) to #ifndef PLATFORM_WINDOWS, which essentially allows it to #include ""tensorflow/core/debug/debug_service.grpc.pb.h"" on Linux but that file does not exist on the master branch.

Could you help taking a look?",IssueComment,https://github.com/tensorflow/tensorflow/issues/12018#issuecomment-320084932,rlegithub,2017-08-03 20:44:47,12018,[13145],Build bug,0,"@caisq I think this change may relates to the problem: [url] That changes #if defined(PLATFORM_GOOGLE) to #ifndef PLATFORM_WINDOWS, which essentially allows it to #include ""tensorflow/core/debug/debug_service.grpc.pb.h"" on Linux but that file does not exist on the master branch. Could you help taking a look?",0
"`debug_service_grpc.pb.h` is an automatically generated file from this bazel BUILD rule:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/debug/BUILD#L45

So there should be no problem building TF is you are using bazel. What build tool are you using?",IssueComment,https://github.com/tensorflow/tensorflow/issues/12018#issuecomment-320086199,caisq,2017-08-03 20:49:54,12018,[13145],Build bug,0,[code] is an automatically generated file from this bazel BUILD rule: [url]#L45 So there should be no problem building TF is you are using bazel. What build tool are you using?,0
I used Linux Continuous Integration Build steps from this link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md,IssueComment,https://github.com/tensorflow/tensorflow/issues/12018#issuecomment-320086528,rlegithub,2017-08-03 20:51:20,12018,[13145],Build bug,0,I used Linux Continuous Integration Build steps from this link: [url],0
"So I see that you are running cmake build on Linux. This is our nightly build:
http://ci.tensorflow.org/view/Nightly/job/nightly-cmake-cpu/

It seems to be okay. You can look at the log to see what commands / configuration it uses:
http://ci.tensorflow.org/view/Nightly/job/nightly-cmake-cpu/368/consoleFull",IssueComment,https://github.com/tensorflow/tensorflow/issues/12018#issuecomment-320147110,caisq,2017-08-04 03:29:56,12018,[13145],Build bug,0,So I see that you are running cmake build on Linux. This is our nightly build: [url] It seems to be okay. You can look at the log to see what commands / configuration it uses: [url],0
"On Ubuntu 16 with anaconda 2.7, when running 

cmake -DCMAKE_BUILD_TYPE=Release ../tensorflow/contrib/cmake
make -j6 all

I get the error: fatal error: tensorflow/core/debug/debug_service.grpc.pb.h: No such file or directory

Any ideas how to resolve this?",IssueComment,https://github.com/tensorflow/tensorflow/issues/12018#issuecomment-321672690,gmaher,2017-08-10 21:03:22,12018,[13145],Build bug,0,"On Ubuntu 16 with anaconda 2.7, when running cmake -DCMAKE_BUILD_TYPE=Release ../tensorflow/contrib/cmake make -j6 all I get the error: fatal error: tensorflow/core/debug/debug_service.grpc.pb.h: No such file or directory Any ideas how to resolve this?",-1
"Encountered the similar issue. The 
```
tensorflow/core/debug/debug_service.pb.h
```
was generated but not
```
tensorflow/core/debug/debug_service.grpc.pb.h
```
so the make fails.

I assume `*.grpc.pb.h` might be generated with grpc plugins though I am not familiar with cmake so not sure how to fix it.",IssueComment,https://github.com/tensorflow/tensorflow/issues/12018#issuecomment-322020757,yongtang,2017-08-13 04:13:07,12018,[13145],Build bug,0,Encountered the similar issue. The ``[code]`[code]`[code]`[code]*.grpc.pb.h` might be generated with grpc plugins though I am not familiar with cmake so not sure how to fix it.,0
Confirmed on macOS 10.12.4 using TensorFlow 1.3.0 and CMake 3.7.2.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12018#issuecomment-323036565,kaspermarstal,2017-08-17 10:55:36,12018,[13145],Build bug,0,Confirmed on macOS 10.12.4 using TensorFlow 1.3.0 and CMake 3.7.2.,0
Created a PR #13145 that should fix the cmake issue on Linux.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12018#issuecomment-330428637,yongtang,2017-09-19 04:50:16,12018,[13145],Build bug,0,Created a PR #13145 that should fix the cmake issue on Linux.,2
Added a PR #13301 for that.,IssueComment,https://github.com/tensorflow/tensorflow/issues/13293#issuecomment-332058428,yongtang,2017-09-26 01:22:15,13293,[13301],Processor bug,1,Added a PR #13301 for that.,0
Added a PR #14967 to fix the crash.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14959#issuecomment-347791647,yongtang,2017-11-29 08:46:53,14959,[14967],Code bug,1,Added a PR #14967 to fix the crash.,3
Thanks @yongtang!  I'll close this out once your PR gets merged.,IssueComment,https://github.com/tensorflow/tensorflow/issues/14959#issuecomment-348059390,tatatodd,2017-11-30 02:04:43,14959,[14967],Code bug,1,Thanks @yongtang! I'll close this out once your PR gets merged.,3
Duplicate of #,IssueComment,https://github.com/tensorflow/tensorflow/issues/14959#issuecomment-590111173,Deydeq,2020-02-23 20:16:43,14959,[14967],Code bug,1,Duplicate of #,0
"When using `REGISTER_KERNEL_BUILDER`, he name `""BytesInUse""` does not match the op `MaxBytesInUseOp`. This may be a typo.
https://github.com/tensorflow/tensorflow/blob/e210cb140a60a74d5e9ce3bf9ebedb21b4910f1c/tensorflow/contrib/memory_stats/kernels/memory_stats_ops.cc#L60-L63

I will make a PR to fix this.",IssueComment,https://github.com/tensorflow/tensorflow/issues/15477#issuecomment-352720767,qmick,2017-12-19 11:23:14,15477,[15479],Build bug,0,"When using [code], he name [code] does not match the op [code]. This may be a typo. [url]#L60-L63 I will make a PR to fix this.",1
"I think the issue is that, when sample_distorted_bounding_box switched to V2, min_object_covered has been changed form an attr to an input. As input could not have a default value like attr, min_object_covered=None will result in an error. Created a PR #15531 for the fix.",IssueComment,https://github.com/tensorflow/tensorflow/issues/15529#issuecomment-353197396,yongtang,2017-12-20 22:11:10,15529,[15531],Data bug,0,"I think the issue is that, when sample_distorted_bounding_box switched to V2, min_object_covered has been changed form an attr to an input. As input could not have a default value like attr, min_object_covered=None will result in an error. Created a PR #15531 for the fix.",2
Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/15529#issuecomment-357324287,tensorflowbutler,2018-01-12 18:58:59,15529,[15531],Data bug,0,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the [code] label was assigned. Please update the label and/or status accordingly.,-3
"Was able to reproduce this issue... actually if y is double, we also have a problem... I tried passing in 1.2 and that didn't work. 

TypeError: Expected int32 passed to parameter 'y' of op 'Pow', got [1.2] of type 'list' instead.

The documentation (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/math_ops.cc#L656) seems to suggest that y can be int32 or double etc. So either we should fix the documentation or increase the capability.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/12156#issuecomment-321370674,rohan100jain,2017-08-09 20:22:37,12156,[15607],Documentation bug,1,"Was able to reproduce this issue... actually if y is double, we also have a problem... I tried passing in 1.2 and that didn't work. TypeError: Expected int32 passed to parameter 'y' of op 'Pow', got [1.2] of type 'list' instead. The documentation ([url]#L656) seems to suggest that y can be int32 or double etc. So either we should fix the documentation or increase the capability.",-1
"Hi, I found the doc of `gen_math_ops._pow` is:
```python
    y: A `Tensor`. Must have the same type as `x`.
```
Hence, if both `x` and `y` are double, it works well.

```python
In [4]: sess.run(tf.pow(5.0, 1.2))
Out[4]: 6.8986487
```

So for double, there are two solution in my option:

1. cast `x` or `y` automatically when dtypes are different.
2. or fix the document: `y` must be the same type as `x`.

I prefer to the first one, and I can work on the double issue.

As for negative value, it indeed hangs out. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/12156#issuecomment-321975041,facaiy,2017-08-12 11:20:09,12156,[15607],Documentation bug,1,"Hi, I found the doc of [code] is: ``[code]Tensor[code]x[code]`[code]x[code]y[code]`[code]`[code]x[code]y[code]y[code]x`. I prefer to the first one, and I can work on the double issue. As for negative value, it indeed hangs out.",0
I am interested in working on this.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12156#issuecomment-338561998,sayak119,2017-10-23 06:42:35,12156,[15607],Documentation bug,1,I am interested in working on this.,3
It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12156#issuecomment-352935785,tensorflowbutler,2017-12-20 01:15:02,12156,[15607],Documentation bug,1,It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.,0
Added a PR #15607 to try to address the issue. It follows a similar approach as safe_mod/safe_div. Please take a look if interested.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12156#issuecomment-353759140,yongtang,2017-12-24 01:21:50,12156,[15607],Documentation bug,1,Added a PR #15607 to try to address the issue. It follows a similar approach as safe_mod/safe_div. Please take a look if interested.,3
Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/12156#issuecomment-355843657,tensorflowbutler,2018-01-07 18:54:40,12156,[15607],Documentation bug,1,Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
Added a PR #20768 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/20751#issuecomment-404735839,yongtang,2018-07-13 06:08:50,20751,[20768],Data bug,0,Added a PR #20768 for the fix.,0
Nagging Assignee @poxvoculi: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/20751#issuecomment-408696739,tensorflowbutler,2018-07-29 18:35:45,20751,[20768],Data bug,0,Nagging Assignee @poxvoculi: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-2
"Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Have I written custom code
OS Platform and Distribution
TensorFlow installed from
TensorFlow version
Bazel version
CUDA/cuDNN version
GPU model and memory
Exact command to reproduce",IssueComment,https://github.com/tensorflow/tensorflow/issues/20776#issuecomment-404922923,tensorflowbutler,2018-07-13 18:56:46,20776,[20807],Version compatibility bug,0,"Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks. Have I written custom code OS Platform and Distribution TensorFlow installed from TensorFlow version Bazel version CUDA/cuDNN version GPU model and memory Exact command to reproduce",0
Added a PR #20807 for the fix in boston.py.,IssueComment,https://github.com/tensorflow/tensorflow/issues/20776#issuecomment-405057292,yongtang,2018-07-14 23:59:52,20776,[20807],Version compatibility bug,0,Added a PR #20807 for the fix in boston.py.,0
Added PR #21533 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/21525#issuecomment-411971345,yongtang,2018-08-10 04:24:52,21525,[21533],Documentation bug,0,Added PR #21533 for the fix.,0
"Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Bazel version
Exact command to reproduce
Mobile device",IssueComment,https://github.com/tensorflow/tensorflow/issues/22110#issuecomment-419290647,tensorflowbutler,2018-09-07 01:21:55,22110,[22139],Algorithm design bug,0,"Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks. Bazel version Exact command to reproduce Mobile device",0
Added a PR #22139 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/22110#issuecomment-419314046,yongtang,2018-09-07 03:48:57,22110,[22139],Algorithm design bug,0,Added a PR #22139 for the fix.,0
"As requested, system information with all fields filled out.

### System information
- **Have I written custom code**: yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **Mobile device**: N/A
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: v1.10.1-0-g4dcfddc5d1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0/7.1.4
- **GPU model and memory**: GTX 1070
- **Exact command to reproduce**: N/A
",IssueComment,https://github.com/tensorflow/tensorflow/issues/22110#issuecomment-419351032,manu291,2018-09-07 07:36:46,22110,[22139],Algorithm design bug,0,"As requested, system information with all fields filled out. ### System information - **Have I written custom code**: yes - **OS Platform and Distribution**: Linux Ubuntu 16.04 - **Mobile device**: N/A - **TensorFlow installed from (source or binary)**: binary - **TensorFlow version**: v1.10.1-0-g4dcfddc5d1 - **Python version**: 2.7.12 - **Bazel version (if compiling from source)**: N/A - **GCC/Compiler version (if compiling from source)**: N/A - **CUDA/cuDNN version**: 9.0/7.1.4 - **GPU model and memory**: GTX 1070 - **Exact command to reproduce**: N/A",0
Added PR #23658 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/23654#issuecomment-437619359,yongtang,2018-11-10 20:35:16,23654,[23658],Version compatibility bug,0,Added PR #23658 for the fix.,0
Nagging Assignee @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,IssueComment,https://github.com/tensorflow/tensorflow/issues/23654#issuecomment-442564721,tensorflowbutler,2018-11-28 19:00:56,23654,[23658],Version compatibility bug,0,Nagging Assignee @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.,-3
This issue happens only when we turn on VLOG with `TF_CPP_MIN_VLOG_LEVEL=1`,IssueComment,https://github.com/tensorflow/tensorflow/issues/25674#issuecomment-462969986,rahul003,2019-02-12 22:48:12,25674,[25726],Code bug,0,This issue happens only when we turn on VLOG with [code],0
"@rahul003 The is not an MKL issue per say. `options.graph` in `optimization_registry.cc` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/optimization_registry.cc#L44) could be invalid depending on the phase of the graph pass. So dumping it could cause a problem.

I have a fix for this issue. Let me submit a PR.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25674#issuecomment-462984634,nhasabni,2019-02-12 23:29:51,25674,[25726],Code bug,0,@rahul003 The is not an MKL issue per say. [code] in [code] [here]([url]#L44) could be invalid depending on the phase of the graph pass. So dumping it could cause a problem. I have a fix for this issue. Let me submit a PR.,2
"Thanks @nhasabni , look forward to the fix!",IssueComment,https://github.com/tensorflow/tensorflow/issues/25674#issuecomment-462986699,rahul003,2019-02-12 23:35:47,25674,[25726],Code bug,0,"Thanks @nhasabni , look forward to the fix!",3
The PR for fix is out for review.,IssueComment,https://github.com/tensorflow/tensorflow/issues/25674#issuecomment-463326241,nhasabni,2019-02-13 19:07:58,25674,[25726],Code bug,0,The PR for fix is out for review.,0
Added a PR #27301 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/27276#issuecomment-478120790,yongtang,2019-03-29 19:24:36,27276,[28006],Version compatibility bug,0,Added a PR #27301 for the fix.,0
"As I wrote comments on https://github.com/tensorflow/tensorflow/pull/27301#discussion_r275780277, this issue should be opened again. 
@ymodak, Could you re-open this issue? ",IssueComment,https://github.com/tensorflow/tensorflow/issues/27276#issuecomment-483975063,Corea,2019-04-17 07:43:54,27276,[28006],Version compatibility bug,0,"As I wrote comments on [url]#discussion_r275780277, this issue should be opened again. @ymodak, Could you re-open this issue?",0
Reopened and add a follow up PR #28006 to fix the issue.,IssueComment,https://github.com/tensorflow/tensorflow/issues/27276#issuecomment-485146943,yongtang,2019-04-20 17:52:43,27276,[28006],Version compatibility bug,0,Reopened and add a follow up PR #28006 to fix the issue.,0
"Also @shlens in case he knows.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1123#issuecomment-184959088,vrv,2016-02-17 01:10:05,1123,[29807],Build bug,0,Also @shlens in case he knows.,0
"Having the same issue. And the training command hangs. In fact, even the mnist example on setup page hangs too.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1123#issuecomment-185035228,ZhengBitFusion,2016-02-17 05:36:35,1123,[29807],Build bug,0,"Having the same issue. And the training command hangs. In fact, even the mnist example on setup page hangs too.",-3
"Thanks for pointing out this warning! It's benign (for the training process), but unfortunate to have this in an example model. I have a patch in the pipeline that will fix the root cause for the warning.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1123#issuecomment-185323605,mrry,2016-02-17 17:51:12,1123,[29807],Build bug,0,"Thanks for pointing out this warning! It's benign (for the training process), but unfortunate to have this in an example model. I have a patch in the pipeline that will fix the root cause for the warning.",2
"Issue Cleanup
",IssueComment,https://github.com/tensorflow/tensorflow/issues/1123#issuecomment-244551987,trinity77,2016-09-03 15:14:55,1123,[29807],Build bug,0,Issue Cleanup,0
"I tried on Google colab but it is working as expected.Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/4e8b0ca20a27ab518f6329aaf5479dd6/untitled127.ipynb).
And, I could replicate the issue on my system by running it on terminal. Please see the screenshot below.
![Screenshot from 2019-09-09 11-22-50](https://user-images.githubusercontent.com/48476109/64506178-3421e300-d2f4-11e9-852a-9d1a6d1e64ac.png)
 Thnaks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-529310415,gadagashwini-zz,2019-09-09 05:53:36,32320,[33921],Code bug,0,"I tried on Google colab but it is working as expected.Please see the gist [here]([url] And, I could replicate the issue on my system by running it on terminal. Please see the screenshot below. ![Screenshot from 2019-09-09 11-22-50]([url] Thnaks!",1
"Same problem here.

Code:
```python
import tensorflow as tf
from tensorflow import keras
print('Version of TensorFlow:', tf.__version__)
print('Version of tf.keras:', tf.keras.__version__)

# Import dataset
fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# Build and Compile the model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy']
             )

# Train the model
print('Training')
model.fit(train_images, train_labels, epochs=5)

# Evaluate the model
print('Evaluating')
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1)
print('\nTest accuracy:', test_acc)
```

Output:
![image](https://user-images.githubusercontent.com/14865017/64515840-a7742680-d2ed-11e9-973f-488e72f1c440.png)
Notice how short the slider is. It is all filled with ""="" signs.",IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-529359571,nofreewill42,2019-09-09 08:38:13,32320,[33921],Code bug,0,"Same problem here. Code: ``[code]`` Output: ![image]([url] Notice how short the slider is. It is all filled with ""="" signs.",-2
"I confirm I am seeing the issue too. The eval progress bar seems to be broken. Adding a batch size and a number of steps does not change the erroneous behavior:

model.evaluate(test_images, test_labels, verbose=1, batch_size=1000, steps=10)
Expecting exactly 10 progress steps with an eval dataset of 10,000 elements
Getting many many steps....",IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-529673106,martin-gorner,2019-09-09 21:24:35,32320,[33921],Code bug,0,"I confirm I am seeing the issue too. The eval progress bar seems to be broken. Adding a batch size and a number of steps does not change the erroneous behavior: model.evaluate(test_images, test_labels, verbose=1, batch_size=1000, steps=10) Expecting exactly 10 progress steps with an eval dataset of 10,000 elements Getting many many steps....",-3
"Same issue here. Even on the official tutorial page, the progress bar is extremely long. 
[https://www.tensorflow.org/tutorials/keras/classification](url)",IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-536851665,XingyuChen01,2019-10-01 03:59:30,32320,[33921],Code bug,0,"Same issue here. Even on the official tutorial page, the progress bar is extremely long. [[url]",-2
@qlzh727 Could this be related to the training_v2 loop?,IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-537174467,omalleyt12,2019-10-01 18:44:02,32320,[33921],Code bug,0,@qlzh727 Could this be related to the training_v2 loop?,0
Very likely.,IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-537180985,qlzh727,2019-10-01 18:59:24,32320,[33921],Code bug,0,Very likely.,0
"https://github.com/tensorflow/tensorflow/blob/f9ad945a479caccca9002dcfe0e9623e3b753360/tensorflow/python/keras/engine/training_v2.py#L448
`samples=use_sample` should be `samples=total_samples`",IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-548883188,djshen,2019-11-01 17:42:12,32320,[33921],Code bug,0,[url]#L448 [code] should be [code],0
"@djshen Thanks for the find! Agreed, would you please submit a PR to fix this? You can add me as a reviewer, I will approve",IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-548899482,omalleyt12,2019-11-01 18:26:53,32320,[33921],Code bug,0,"@djshen Thanks for the find! Agreed, would you please submit a PR to fix this? You can add me as a reviewer, I will approve",4
@omalleyt12 I created a PR https://github.com/tensorflow/tensorflow/pull/33921,IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-548924151,djshen,2019-11-01 19:38:46,32320,[33921],Code bug,0,@omalleyt12 I created a PR [url],0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32320"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32320"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-548960251,tensorflow-bot[bot],2019-11-01 21:39:50,32320,[33921],Code bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"same here, is going to be merged in 2.1?",IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-569439654,myhyper,2019-12-28 18:14:22,32320,[33921],Code bug,0,"same here, is going to be merged in 2.1?",0
Yes this should be fixed in 2.1,IssueComment,https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-570301292,omalleyt12,2020-01-02 18:41:43,32320,[33921],Code bug,0,Yes this should be fixed in 2.1,1
"Since the actual model implementation, including parameters, returns, and errors, is in `keras_applications` (https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet_v2.py), I have a few questions: 
* What would be the best approach to reference this in TF docs?
* Is it still worth pointing the definition link to `__init__.py` in `python/keras/applications`? 
* Is there already a plan for replicating/sharing documentation between Keras and tf.keras?
",IssueComment,https://github.com/tensorflow/tensorflow/issues/25988#issuecomment-466423876,JTunis,2019-02-22 14:55:04,25988,[36951],Documentation bug,0,"Since the actual model implementation, including parameters, returns, and errors, is in [code] ([url] I have a few questions: * What would be the best approach to reference this in TF docs? * Is it still worth pointing the definition link to [code] in [code]? * Is there already a plan for replicating/sharing documentation between Keras and tf.keras?",0
"@JTunis Thanks so much for the interest in contributing to TF 2.0 API documentation! We appreciate it, and these are excellent questions. I believe the best approach for modifying this endpoint in TF 2.0 docs would be to modify the docstrings for the [`mobilenet_v2.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/mobilenet_v2.py) file in `tensorflow/tensorflow`. 

All of the documentation for the models listed in [`tf.keras.applications`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications) (VGG16, Xception, etc.) is currently pointing at the [`__init__.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/__init__.py) file; we'll want to make similar changes for each of them, as well, or confirm that we can safely point to the [documentation you referenced](https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet_v2.py) in the Keras project. There is no current plan to migrate documentation from Keras endpoints to their matching `tf.keras` symbols, but we would love to have help!

**Note**: these models are currently in the process of being migrated to TF 2.0: (https://github.com/tensorflow/tensorflow/issues/25341).

cc: @MarkDaoust @lamberta to make sure that I'm pointing you in the right direction. ðŸ™‚ ",IssueComment,https://github.com/tensorflow/tensorflow/issues/25988#issuecomment-466740682,dynamicwebpaige,2019-02-24 07:06:30,25988,[36951],Documentation bug,0,"@JTunis Thanks so much for the interest in contributing to TF 2.0 API documentation! We appreciate it, and these are excellent questions. I believe the best approach for modifying this endpoint in TF 2.0 docs would be to modify the docstrings for the [[code]]([url] file in [code]. All of the documentation for the models listed in [[code]]([url] (VGG16, Xception, etc.) is currently pointing at the [[code]]([url] file; we'll want to make similar changes for each of them, as well, or confirm that we can safely point to the [documentation you referenced]([url] in the Keras project. There is no current plan to migrate documentation from Keras endpoints to their matching [code] symbols, but we would love to have help! **Note**: these models are currently in the process of being migrated to TF 2.0: ([url] cc: @MarkDaoust @lamberta to make sure that I'm pointing you in the right direction. ðŸ™‚",5
"Happy to take over the documentation of all `tf.keras.applications`. I do think I'd like to play with pointing to `keras-applications`, so that changes are reflected in the TF2.0 docs, or, minimally, adding a link to the actual implementations.

Maybe I'll start with migrating documentation from `keras-applications` to `tf.keras.applications` manually so that there's some useful documentation for users, then depending on the progress of #25341, work on either pointing to `tf.keras` implementations or `keras-applications` implementations.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25988#issuecomment-467595417,JTunis,2019-02-26 20:14:14,25988,[36951],Documentation bug,0,"Happy to take over the documentation of all [code]. I do think I'd like to play with pointing to [code], so that changes are reflected in the TF2.0 docs, or, minimally, adding a link to the actual implementations. Maybe I'll start with migrating documentation from [code] to [code] manually so that there's some useful documentation for users, then depending on the progress of #25341, work on either pointing to [code] implementations or [code] implementations.",4
@JTunis would love to help as well! Need help with anything?,IssueComment,https://github.com/tensorflow/tensorflow/issues/25988#issuecomment-470193757,Sri-vatsa,2019-03-06 17:13:36,25988,[36951],Documentation bug,0,@JTunis would love to help as well! Need help with anything?,5
"@Sri-vatsa Totally! I've been struggling to figure out how to point the docs generator to the appropriate file to generate the markdown docs. Some things that I've poked:
* `generate2.py` located [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docs/generate2.py). As it's looping through the results of the parser, it seems to be generating the doc from the markdown from the first appearance of the MobileNetV2 API that it encounters, which seems to be from `python/keras/api/_v2/keras/applications/mobilenet_v2/__init__.py`. Unfortunately, we can't change the docs there because the file is auto-generated from [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/tools/api/generator)
* Maybe I'm making this harder than it has to be, but simply changing docstrings in `mobilenet_v2.py` doesn't change the generated markdown files.

Let me know if you can figure out how to resolve this, then it should be pretty easy to start banging out the docs for all of `tf.keras.applications`",IssueComment,https://github.com/tensorflow/tensorflow/issues/25988#issuecomment-470227716,JTunis,2019-03-06 18:47:50,25988,[36951],Documentation bug,0,"@Sri-vatsa Totally! I've been struggling to figure out how to point the docs generator to the appropriate file to generate the markdown docs. Some things that I've poked: * [code] located [here]([url] As it's looping through the results of the parser, it seems to be generating the doc from the markdown from the first appearance of the MobileNetV2 API that it encounters, which seems to be from [code]. Unfortunately, we can't change the docs there because the file is auto-generated from [here]([url] * Maybe I'm making this harder than it has to be, but simply changing docstrings in [code] doesn't change the generated markdown files. Let me know if you can figure out how to resolve this, then it should be pretty easy to start banging out the docs for all of [code]",-1
"@JTunis I haven't had a lot of time to look at it yet but from an initial examination, it seems like the docstrings for Keras files have a different format than what is used in Tensorflow. 
Take a look at the corresponding docstring [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py) for `tf.data.dataset` api [here](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset). 

For Keras, the modules are injected from `keras.applications.MobileNetV2` [here](https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet_v2.py). So, I believe that your approach of modifying the`mobilenet_v2.py` might be the solution. Can I check what you have tried changing in `mobilenet_v2.py`?",IssueComment,https://github.com/tensorflow/tensorflow/issues/25988#issuecomment-471583685,Sri-vatsa,2019-03-11 15:20:10,25988,[36951],Documentation bug,0,"@JTunis I haven't had a lot of time to look at it yet but from an initial examination, it seems like the docstrings for Keras files have a different format than what is used in Tensorflow. Take a look at the corresponding docstring [here]([url] for [code] api [here]([url] For Keras, the modules are injected from [code] [here]([url] So, I believe that your approach of modifying the[code] might be the solution. Can I check what you have tried changing in [code]?",0
"@JTunis Figured out how to fix the issue. It is an issue with docstrings within Python Decorators. I have tested the fix locally by checking the readme files generated through `generate2.py`. It is a simple fix by wrapping the Keras functions using the `wraps` decorator from Python's `functools` library.  

1) Modify `tensorflow/tensorflow/python/keras/applications/__init__.py` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/__init__.py). Import `wraps` from `functools` by adding `from functools import wraps` to the top of the file. Add `@wraps(base_fun)` to the function `keras_modules_injection(base_fun)` 

2) Add docstrings to `mobilenet_v2.py` or any other models in `tf.keras.applications`.

@dynamicwebpaige Regarding the documentation for `tf.keras.applications`, what is the best way to update the documentation? For now, I am thinking of copying the relevant docstrings from `keras_applications`. Would that be alright?

I will clean things up locally and make a PR over this weekend.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25988#issuecomment-473319088,Sri-vatsa,2019-03-15 14:58:42,25988,[36951],Documentation bug,0,"@JTunis Figured out how to fix the issue. It is an issue with docstrings within Python Decorators. I have tested the fix locally by checking the readme files generated through [code]. It is a simple fix by wrapping the Keras functions using the [code] decorator from Python's [code] library. 1) Modify [code] [here]([url] Import [code] from [code] by adding [code] to the top of the file. Add [code] to the function [code] 2) Add docstrings to [code] or any other models in [code]. @dynamicwebpaige Regarding the documentation for [code], what is the best way to update the documentation? For now, I am thinking of copying the relevant docstrings from [code]. Would that be alright? I will clean things up locally and make a PR over this weekend.",3
"@Sri-vatsa Awesome, once your PR is in we can work to divvy up the rest of the the `tf.keras.application` models. 

As far as the docs for each model, I was also thinking of mostly copying relevant docstrings from `keras_applications` and maybe also linking to the implementation (at least until the `tf.keras` implementations are done). There was also a good transfer learning with `tf.keras.applications` models example that I wanted to link to, but I can't seem to find it right now.

Also not sure if it's worth editing the models' arguments to match those of `keras_applications` rather than just taking `*args` and `**kwargs`.",IssueComment,https://github.com/tensorflow/tensorflow/issues/25988#issuecomment-473344195,JTunis,2019-03-15 16:03:08,25988,[36951],Documentation bug,0,"@Sri-vatsa Awesome, once your PR is in we can work to divvy up the rest of the the [code] models. As far as the docs for each model, I was also thinking of mostly copying relevant docstrings from [code] and maybe also linking to the implementation (at least until the [code] implementations are done). There was also a good transfer learning with [code] models example that I wanted to link to, but I can't seem to find it right now. Also not sure if it's worth editing the models' arguments to match those of [code] rather than just taking [code] and [code].",3
"@nscotto , You can convert tensor into numpy array using `tensor.numpy()`, But you can't do the same in case of `MapDataset`. In the example code you have given,  the `x` in the transformer function is `MapDataset` and not `Tensor`.
I have seen similar issue [#30035](https://github.com/tensorflow/tensorflow/issues/30035) and also you can refer to [this function](https://www.tensorflow.org/api_docs/python/tf/numpy_function?version=nightly) which I think will solve your problem. 
Also, if you have any doubts regarding `from_tensors` and `from_tensor_slices`, then please review the official docs [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#from_tensor_slices). Also, take a look at these example which I recently Added through my PR #36989.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36979#issuecomment-590066285,ashutosh1919,2020-02-23 12:59:24,36979,[37853],Data bug,0,"@nscotto , You can convert tensor into numpy array using [code], But you can't do the same in case of [code]. In the example code you have given, the [code] in the transformer function is [code] and not [code]. I have seen similar issue [#30035]([url] and also you can refer to [this function]([url] which I think will solve your problem. Also, if you have any doubts regarding [code] and [code], then please review the official docs [here]([url]#from_tensor_slices). Also, take a look at these example which I recently Added through my PR #36989.",0
"@nscotto 

Any update on this issue please. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/36979#issuecomment-593904983,ravikyram,2020-03-03 11:30:06,36979,[37853],Data bug,0,@nscotto Any update on this issue please. Thanks!,0
"@ravikyram 
Yes, ashutosh1919 is right, it's because `Dataset.map` passes `Tensor` instead of `EagerTensor`, thus I need to wrap my code inside a `tf.py_function` if I need to convert to numpy (and obviously reducing the performances).
As a suggestion I think the documentation could make this information more visible.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36979#issuecomment-594100272,nscotto,2020-03-03 18:33:03,36979,[37853],Data bug,0,"@ravikyram Yes, ashutosh1919 is right, it's because [code] passes [code] instead of [code], thus I need to wrap my code inside a [code] if I need to convert to numpy (and obviously reducing the performances). As a suggestion I think the documentation could make this information more visible.",-1
"@ashutosh1919  @ravikyram @nscotto 
I am trying to address the problem by making a numpy() function in the Tensor class. But I am facing a problem. Can anyone tell me from which attribute of Tensor class I can find the data.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/36979#issuecomment-595589895,ghosalsattam,2020-03-06 04:04:51,36979,[37853],Data bug,0,@ashutosh1919 @ravikyram @nscotto I am trying to address the problem by making a numpy() function in the Tensor class. But I am facing a problem. Can anyone tell me from which attribute of Tensor class I can find the data.,0
@ashutosh1919 I went through all the codes. From the codes it seems that internally the map() function iterates through all the tensors(for each function call). So what x sees from inside the function in map() is the single tensor passed to it at that very time. So using .numpy() inside the function called through map() is pointless. ,IssueComment,https://github.com/tensorflow/tensorflow/issues/36979#issuecomment-602760594,ghosalsattam,2020-03-23 17:55:37,36979,[37853],Data bug,0,@ashutosh1919 I went through all the codes. From the codes it seems that internally the map() function iterates through all the tensors(for each function call). So what x sees from inside the function in map() is the single tensor passed to it at that very time. So using .numpy() inside the function called through map() is pointless.,-1
"@nscotto , @ravikyram and @ghosalsattam , I have raised PR #37853 to add an example on `tf.numpy_function` and how it is different from `tf.py_function`. Now, 2nd and 3rd point [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#map) about `py_function` and `numpy_function` clearly explains the difference. Note that you won't be able to see 3rd point until my PR is merged. See PR changes to see example. 
Please give your suggestions if anything else is required.",IssueComment,https://github.com/tensorflow/tensorflow/issues/36979#issuecomment-603006216,ashutosh1919,2020-03-24 04:22:25,36979,[37853],Data bug,0,"@nscotto , @ravikyram and @ghosalsattam , I have raised PR #37853 to add an example on [code] and how it is different from [code]. Now, 2nd and 3rd point [here]([url]#map) about [code] and [code] clearly explains the difference. Note that you won't be able to see 3rd point until my PR is merged. See PR changes to see example. Please give your suggestions if anything else is required.",2
"@bas-aarts,
Could you please provide the platform details and the TensorFlow version you're trying to build.

Also, please provide the exact sequence of commands / steps that you executed before running into this error. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/39280#issuecomment-625806293,amahendrakar,2020-05-08 13:06:35,39280,[39281],Build bug,0,"@bas-aarts, Could you please provide the platform details and the TensorFlow version you're trying to build. Also, please provide the exact sequence of commands / steps that you executed before running into this error. Thanks!",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39280"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39280"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/39280#issuecomment-628249358,google-ml-butler[bot],2020-05-13 21:14:45,39280,[39281],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@Leslie-Fang 
could you please downgrade the GCC/Compiler version to 7.x and build.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37498#issuecomment-597569840,Saduf2019,2020-03-11 11:03:05,37498,[42743],Build bug,0,@Leslie-Fang could you please downgrade the GCC/Compiler version to 7.x and build.,0
"Thanks @Saduf2019 Since I don't have GCC7.x available. I have tried GCC63 which gives the same error.
Is GCC7.x specifically required to build the debug version?",IssueComment,https://github.com/tensorflow/tensorflow/issues/37498#issuecomment-597582464,Leslie-Fang,2020-03-11 11:34:20,37498,[42743],Build bug,0,Thanks @Saduf2019 Since I don't have GCC7.x available. I have tried GCC63 which gives the same error. Is GCC7.x specifically required to build the debug version?,0
"Hi @Saduf2019, I'm using `gcc==7.5.0` to build with the above command in debug mode, it raises the same issue. ",IssueComment,https://github.com/tensorflow/tensorflow/issues/37498#issuecomment-600858775,pengwu22,2020-03-18 21:07:31,37498,[42743],Build bug,0,"Hi @Saduf2019, I'm using [code] to build with the above command in debug mode, it raises the same issue.",0
"i'm running into this on gcc 7.5.0 as well. i was able to work around this by adding a small change in here https://github.com/tensorflow/tensorflow/blob/master/third_party/aws/aws-checksums.bazel#L24. below the various options that are already there, i added
```
    defines = [                                                                                                                                                                                                    
        ""DEBUG_BUILD""                                                                                                                                                                                              
    ]                                                                                                                                                                                                              
```
that seemed to do the trick. the advice came from this comment https://github.com/awslabs/aws-checksums/issues/8#issuecomment-440027793.

hope this helps someone else. i'm happy to help try to figure out or test a fix for this issue.",IssueComment,https://github.com/tensorflow/tensorflow/issues/37498#issuecomment-612538952,mikeurbach,2020-04-12 00:00:24,37498,[42743],Build bug,0,"i'm running into this on gcc 7.5.0 as well. i was able to work around this by adding a small change in here [url]#L24. below the various options that are already there, i added ``[code]`` that seemed to do the trick. the advice came from this comment [url]#issuecomment-440027793. hope this helps someone else. i'm happy to help try to figure out or test a fix for this issue.",3
"I still experience this issue with fa0721cfbd93a1506d39735296a260a877354e6c (May 21). The real issue here is that the inline asm code in question isn't meant to compile with debug build flags (-c dbg), but only with -O3/-O2/-O1 specified. So, aws-checksums uses DEBUG_BUILD to avoid that inline asm and use an alternative slow implementation for debug builds. As such, for TensorFlow's debug builds, one should pass -DDEBUG_BUILD to aws-checksums so that the inline asm code path is avoided (it has hardcoded register constraints). For more information:
https://github.com/awslabs/aws-checksums/issues/8
The workaround suggested in the post above works, but that would use the slow implementation even under release builds. Instead, DEBUG_BUILD for aws-checksums should be defined only under bazel debug build config. fastbuild and opt conf should be fine without that.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37498#issuecomment-636490796,bondhugula,2020-05-31 16:02:29,37498,[42743],Build bug,0,"I still experience this issue with fa0721cfbd93a1506d39735296a260a877354e6c (May 21). The real issue here is that the inline asm code in question isn't meant to compile with debug build flags (-c dbg), but only with -O3/-O2/-O1 specified. So, aws-checksums uses DEBUG_BUILD to avoid that inline asm and use an alternative slow implementation for debug builds. As such, for TensorFlow's debug builds, one should pass -DDEBUG_BUILD to aws-checksums so that the inline asm code path is avoided (it has hardcoded register constraints). For more information: [url] The workaround suggested in the post above works, but that would use the slow implementation even under release builds. Instead, DEBUG_BUILD for aws-checksums should be defined only under bazel debug build config. fastbuild and opt conf should be fine without that.",0
I provided a fix in PR #42743 which adds DEBUG_BUILD only for linux debug builds,IssueComment,https://github.com/tensorflow/tensorflow/issues/37498#issuecomment-682842980,jgehw,2020-08-28 16:35:18,37498,[42743],Build bug,0,I provided a fix in PR #42743 which adds DEBUG_BUILD only for linux debug builds,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37498"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37498"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/37498#issuecomment-684120153,google-ml-butler[bot],2020-09-01 00:32:08,37498,[42743],Build bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@DNXie @ravikyram I have created a pull request to solve this issue , which will help raise `FloatingPoitnError`  when `ksize = 0`",IssueComment,https://github.com/tensorflow/tensorflow/issues/46834#issuecomment-771150733,around-star,2021-02-01 20:54:05,46834,[46838],Algorithm design bug,0,"@DNXie @ravikyram I have created a pull request to solve this issue , which will help raise [code] when [code]",3
"I have tried in colab with TF version 2.4, nightly version(`2.5.0-dev20210201`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/96c0b6fc38409baaca216bdb942a228a/untitled650.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46834#issuecomment-771365672,ravikyram,2021-02-02 05:09:15,46834,[46838],Algorithm design bug,0,"I have tried in colab with TF version 2.4, nightly version([code]) and was able to reproduce the issue.Please, find the gist [here]([url] Thanks!",0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46834"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46834"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46834#issuecomment-777652458,google-ml-butler[bot],2021-02-11 17:15:33,46834,[46838],Algorithm design bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@SamuelMarks ,
Please feel free to submit a PR for the requested change or share the link where requested change is to be made",IssueComment,https://github.com/tensorflow/tensorflow/issues/53566#issuecomment-1002462530,tilakrayal,2021-12-29 08:42:10,53566,[53576],Code bug,0,"@SamuelMarks , Please feel free to submit a PR for the requested change or share the link where requested change is to be made",3
Opened PR,IssueComment,https://github.com/tensorflow/tensorflow/issues/53566#issuecomment-1002662358,SamuelMarks,2021-12-29 15:57:41,53566,[53576],Code bug,0,Opened PR,0
"@SamuelMarks 
The related PR has been assigned for reviewing and once it is merged this issue will move to closed status.",IssueComment,https://github.com/tensorflow/tensorflow/issues/53566#issuecomment-1002863957,tilakrayal,2021-12-30 04:08:05,53566,[53576],Code bug,0,@SamuelMarks The related PR has been assigned for reviewing and once it is merged this issue will move to closed status.,2
"This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.
",IssueComment,https://github.com/tensorflow/tensorflow/issues/53657#issuecomment-1011970496,google-ml-butler[bot],2022-01-13 09:51:27,53657,[53741],Data bug,1,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,0
"@ArrowIntoTheSky ,
The issue will move to closed status once the PR is merged.",IssueComment,https://github.com/tensorflow/tensorflow/issues/53657#issuecomment-1029905377,tilakrayal,2022-02-04 11:31:57,53657,[53741],Data bug,1,"@ArrowIntoTheSky , The issue will move to closed status once the PR is merged.",0
Was able to reproduce the issue with `tf-nightly-2.11.0-dev20220829` . Please find the gist [here](https://colab.research.google.com/drive/1MYXLhHnH2NoX9ktS4FtAc-jnznNtPRQj?usp=sharing). Thank you!,IssueComment,https://github.com/tensorflow/tensorflow/issues/53657#issuecomment-1231176182,gadagashwini,2022-08-30 05:52:41,53657,[53741],Data bug,1,Was able to reproduce the issue with [code] . Please find the gist [here]([url] Thank you!,2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53657"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53657"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/53657#issuecomment-1256605586,google-ml-butler[bot],2022-09-23 19:40:31,53657,[53741],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@ArrowIntoTheSky ,
Can you please share a reproducible code that supports your statement so that the issue can be easily understood? Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/54545#issuecomment-1050638571,tilakrayal,2022-02-25 08:26:44,54545,[54740],Documentation bug,0,"@ArrowIntoTheSky , Can you please share a reproducible code that supports your statement so that the issue can be easily understood? Thanks!",2
Was able to reproduce the issue with `tf-2.11.0-dev20220915`. Please find the [gist](https://colab.research.google.com/drive/1-PXHtwdjtwfjJGL0XckX-auzdBBDBWXF?usp=sharing) here. Thank you!,IssueComment,https://github.com/tensorflow/tensorflow/issues/57716#issuecomment-1249013451,gadagashwini,2022-09-16 07:23:42,57716,[57785],Data bug,1,Was able to reproduce the issue with [code]. Please find the [gist]([url] here. Thank you!,2
Could you please refer the comment [here](https://github.com/tensorflow/tensorflow/issues/57711#issuecomment-1249679156) which explains about OOM/Resource exhausted issue. Thanks! ,IssueComment,https://github.com/tensorflow/tensorflow/issues/57716#issuecomment-1249717034,sachinprasadhs,2022-09-16 19:15:13,57716,[57785],Data bug,1,Could you please refer the comment [here]([url]#issuecomment-1249679156) which explains about OOM/Resource exhausted issue. Thanks!,0
"@sachinprasadhs  Hi, Thanks for looking into this. With the input I provided, I see a crash (abortion) instead of an OOM error.
As public APIs, it would be great to have the functions kindly throw exceptions for these cases instead of crashing. Also replied in #57711. Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/57716#issuecomment-1251681239,DNXie,2022-09-19 23:41:31,57716,[57785],Data bug,1,"@sachinprasadhs Hi, Thanks for looking into this. With the input I provided, I see a crash (abortion) instead of an OOM error. As public APIs, it would be great to have the functions kindly throw exceptions for these cases instead of crashing. Also replied in #57711. Thank you!",2
Created a PR #57785 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/57716#issuecomment-1254286912,yongtang,2022-09-21 22:16:40,57716,[57785],Data bug,1,Created a PR #57785 for the fix.,3
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/57716"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/57716"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/57716#issuecomment-1258605238,google-ml-butler[bot],2022-09-26 20:36:51,57716,[57785],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@VictoriaGriffith,
Could you please provide any reference link or the documentation link which mentioned that **tf.sparse.to_dense** supports the **qint**. Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/57489#issuecomment-1230108237,tilakrayal,2022-08-29 10:38:30,57489,[57793],Data bug,1,"@VictoriaGriffith, Could you please provide any reference link or the documentation link which mentioned that **tf.sparse.to_dense** supports the **qint**. Thank you!",0
"Hi @tilakrayal , the document does not make it clear whether this API or the `tf.sparse.*` APIs supports the qint (and could be improved by including this information). 
However, I believe that this should be consistent across `SparseTensor`: if users are allowed to create such a sparse tensor with qint, we expect the **basic support like `sparse.to_dense/from_dense`**. For example, I tried a few APIs that supports `qint`.
```
import tensorflow as tf
dtype = tf.qint16
x = tf.sparse.eye(3, num_columns=3, dtype=dtype, )
x = tf.sparse.expand_dims(x, -1) # Pass
```
While some others does not:
```
import tensorflow as tf
dtype = tf.qint16
x = tf.random.uniform([2, 2], minval=0, maxval=5, dtype=tf.int32)
x = tf.cast(x, tf.qint16)
y = tf.sparse.from_dense(x) # NotFoundError
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/57489#issuecomment-1230203680,VictoriaGriffith,2022-08-29 12:13:39,57489,[57793],Data bug,1,"Hi @tilakrayal , the document does not make it clear whether this API or the [code] APIs supports the qint (and could be improved by including this information). However, I believe that this should be consistent across [code]: if users are allowed to create such a sparse tensor with qint, we expect the **basic support like [code]**. For example, I tried a few APIs that supports [code]. ``[code]`[code]`[code]``",0
"@gadagashwini,
I was able to reproduce the issue on tensorflow v2.8, v2.9 and nightly. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/a2d2250bc9ad1c071939b80b5cf508a3/untitled551.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/57489#issuecomment-1235034389,tilakrayal,2022-09-02 03:40:56,57489,[57793],Data bug,1,"@gadagashwini, I was able to reproduce the issue on tensorflow v2.8, v2.9 and nightly. Kindly find the gist of it [here]([url]",0
"Feel free to submit a PR to add support.

Not all ops are registered for all types.  They are typically registered as they are needed.  This helps us keep the TensorFlow binary size lower.",IssueComment,https://github.com/tensorflow/tensorflow/issues/57489#issuecomment-1246270459,cantonios,2022-09-14 05:46:59,57489,[57793],Data bug,1,Feel free to submit a PR to add support. Not all ops are registered for all types. They are typically registered as they are needed. This helps us keep the TensorFlow binary size lower.,1
Added a PR #57793 for qint support.,IssueComment,https://github.com/tensorflow/tensorflow/issues/57489#issuecomment-1254415375,yongtang,2022-09-22 01:58:12,57489,[57793],Data bug,1,Added a PR #57793 for qint support.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/57489"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/57489"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/57489#issuecomment-1263852008,google-ml-butler[bot],2022-09-30 17:49:56,57489,[57793],Data bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@DNXie,
Could you please refer to the comment https://github.com/tensorflow/tensorflow/issues/57711#issuecomment-1249679156 which explains about the OOM/Resource exhausted issue. Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/57728#issuecomment-1251194989,tilakrayal,2022-09-19 15:39:56,57728,[57852],Data bug,0,"@DNXie, Could you please refer to the comment [url]#issuecomment-1249679156 which explains about the OOM/Resource exhausted issue. Thanks!",0
"@tilakrayal Thanks for looking into this. With the input I provided, I see a crash (abortion) instead of an OOM error.
As public APIs, it would be great to have the functions kindly throw exceptions for these cases instead of crashing. Also replied in #57711. Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/57728#issuecomment-1251681441,DNXie,2022-09-19 23:41:54,57728,[57852],Data bug,0,"@tilakrayal Thanks for looking into this. With the input I provided, I see a crash (abortion) instead of an OOM error. As public APIs, it would be great to have the functions kindly throw exceptions for these cases instead of crashing. Also replied in #57711. Thank you!",2
"@sachinprasadhs,
I was able to reproduce the issue on tensorflow v2.8, v2.9 and nightly. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/5b51e660cd19f9634949649af9eb0ea5/untitled605.ipynb).",IssueComment,https://github.com/tensorflow/tensorflow/issues/57728#issuecomment-1251922207,tilakrayal,2022-09-20 06:58:34,57728,[57852],Data bug,0,"@sachinprasadhs, I was able to reproduce the issue on tensorflow v2.8, v2.9 and nightly. Kindly find the gist of it [here]([url]",0
Added a PR #57852 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/57728#issuecomment-1258934067,yongtang,2022-09-27 03:51:42,57728,[57852],Data bug,0,Added a PR #57852 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/57728"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/57728"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/57728#issuecomment-1263873119,google-ml-butler[bot],2022-09-30 18:11:31,57728,[57852],Data bug,0,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"I have tried in colab with TF versions 2.1, 2.4, nightly versions (`2.5.0-dev20210203`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/1fda44be7360e4382bedf8f9c6c8dfb9/untitled658.ipynb). Thanks!",IssueComment,https://github.com/tensorflow/tensorflow/issues/46915#issuecomment-773158505,ravikyram,2021-02-04 09:20:03,46915,[57854],Algorithm design bug,1,"I have tried in colab with TF versions 2.1, 2.4, nightly versions ([code]) and was able to reproduce the issue. Please, find the gist [here]([url] Thanks!",0
"BTW, `tf.nn.atrous_conv2d_transpose` has similar crash which is due to large `rate`.

~~~python
import tensorflow as tf
import numpy as np
tf.nn.atrous_conv2d_transpose(value=np.ones((10,1,1,1)), filters=np.ones((1,1,1,1)), rate=1356819205, padding='SAME', output_shape=[1,1,1,1])
~~~

Error Message:
~~~python
2021-04-15 00:08:19.741409: F tensorflow/core/framework/tensor_shape.cc:397] Check failed: size >= 0 (-37160523141231366 vs. 0)
Aborted (core dumped)
~~~",IssueComment,https://github.com/tensorflow/tensorflow/issues/46915#issuecomment-819927920,DNXie,2021-04-15 00:09:40,46915,[57854],Algorithm design bug,1,"BTW, [code] has similar crash which is due to large [code]. ~~~python import tensorflow as tf import numpy as np tf.nn.atrous_conv2d_transpose(value=np.ones((10,1,1,1)), filters=np.ones((1,1,1,1)), rate=1356819205, padding='SAME', output_shape=[1,1,1,1]) ~~~ Error Message: ~~~python 2021-04-15 00:08:19.741409: F tensorflow/core/framework/tensor_shape.cc:397] Check failed: size >= 0 (-37160523141231366 vs. 0) Aborted (core dumped) ~~~",-2
Colab crashes in TF Nightly 2.6 as well.Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/b44477be4d8ec2fdc1028f4684ec4cdf/untitled92.ipynb).Thanks!,IssueComment,https://github.com/tensorflow/tensorflow/issues/46915#issuecomment-850772127,saikumarchalla,2021-05-29 05:12:57,46915,[57854],Algorithm design bug,1,Colab crashes in TF Nightly 2.6 as well.Please find the gist [here]([url],-2
"I was able to reproduce the issue on tf-nightly 2.10.0-dev20220719. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/1b101bc302a95283ff9ba66e46d1cb4d/untitled46915.ipynb). Thank you!

",IssueComment,https://github.com/tensorflow/tensorflow/issues/46915#issuecomment-1188880636,tilakrayal,2022-07-19 10:25:02,46915,[57854],Algorithm design bug,1,I was able to reproduce the issue on tf-nightly 2.10.0-dev20220719. Kindly find the gist of it [here]([url] Thank you!,2
Added a PR #57854 for the fix.,IssueComment,https://github.com/tensorflow/tensorflow/issues/46915#issuecomment-1258979239,yongtang,2022-09-27 04:58:00,46915,[57854],Algorithm design bug,1,Added a PR #57854 for the fix.,0
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46915"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46915"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/46915#issuecomment-1263870703,google-ml-butler[bot],2022-09-30 18:09:11,46915,[57854],Algorithm design bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"@benbarsdell, do you know why the kernels had to be disabled on Windows, and how hard it would be to enable them for Windows?

/CC @duncanriach",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1030491872,reedwm,2022-02-05 01:41:56,54276,[57855],Processor bug,1,"@benbarsdell, do you know why the kernels had to be disabled on Windows, and how hard it would be to enable them for Windows? /CC @duncanriach",0
"Hi @bersbersbers ! Did not get any error either in [Colab ](https://colab.sandbox.google.com/gist/mohantym/1989e72f47d012c552fc953e0912c019/github_54276.ipynb#scrollTo=koYvPob1U-i9) or Windows 20H2 for 2.8.0. Could you try again with following code in Windows 21H2 and let us know?  Thanks!
```
import tensorflow as tf
print(tf.__version__)
tf.keras.utils.set_random_seed(1)
tf.config.experimental.enable_op_determinism()
data = tf.ones((1, 1))
layer = tf.keras.layers.Input(shape=[1])
model = tf.keras.models.Model(inputs=layer, outputs=layer)
model.compile(loss=""CategoricalCrossentropy"", metrics=""AUC"")
model.fit(x=data, y=data)
```",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1031062978,mohantym,2022-02-07 04:28:35,54276,[57855],Processor bug,1,Hi @bersbersbers ! Did not get any error either in [Colab ]([url]#scrollTo=koYvPob1U-i9) or Windows 20H2 for 2.8.0. Could you try again with following code in Windows 21H2 and let us know? Thanks! ``[code]``,3
"Colab is running on Linux, I guess, in which case it won't reproduce there because it doesn't reproduce on Linux.

When you try to reproduce on Windows, are you sure you are using GPU acceleration? Because it doesn't reproduce on a CPU.

*Edit*: for the record:

<details>

```
>python
Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> print(tf.__version__)
2.8.0
>>> tf.keras.utils.set_random_seed(1)
>>> tf.config.experimental.enable_op_determinism()
>>> data = tf.ones((1, 1))
2022-02-07 06:55:55.047679: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-02-07 06:55:56.218623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3969 MB memory:  -> device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5
>>> layer = tf.keras.layers.Input(shape=[1])
>>> model = tf.keras.models.Model(inputs=layer, outputs=layer)
>>> model.compile(loss=""CategoricalCrossentropy"", metrics=""AUC"")
>>> model.fit(x=data, y=data)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""Python310\lib\site-packages\keras\utils\traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""Python310\lib\site-packages\tensorflow\python\eager\execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnimplementedError: Graph execution error:

Detected at node 'UnsortedSegmentSum_1' defined at (most recent call last):
    File ""<stdin>"", line 1, in <module>
    File ""Python310\lib\site-packages\keras\utils\traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""Python310\lib\site-packages\keras\engine\training.py"", line 1384, in fit
      tmp_logs = self.train_function(iterator)
    File ""Python310\lib\site-packages\keras\engine\training.py"", line 1021, in train_function
      return step_function(self, iterator)
    File ""Python310\lib\site-packages\keras\engine\training.py"", line 1010, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""Python310\lib\site-packages\keras\engine\training.py"", line 1000, in run_step
      outputs = model.train_step(data)
    File ""Python310\lib\site-packages\keras\engine\training.py"", line 864, in train_step
      return self.compute_metrics(x, y, y_pred, sample_weight)
    File ""Python310\lib\site-packages\keras\engine\training.py"", line 957, in compute_metrics
      self.compiled_metrics.update_state(y, y_pred, sample_weight)
    File ""Python310\lib\site-packages\keras\engine\compile_utils.py"", line 459, in update_state
      metric_obj.update_state(y_t, y_p, sample_weight=mask)
    File ""Python310\lib\site-packages\keras\utils\metrics_utils.py"", line 70, in decorated
      update_op = update_state_fn(*args, **kwargs)
    File ""Python310\lib\site-packages\keras\metrics.py"", line 178, in update_state_fn
      return ag_update_state(*args, **kwargs)
    File ""Python310\lib\site-packages\keras\metrics.py"", line 2347, in update_state
      return metrics_utils.update_confusion_matrix_variables(
    File ""Python310\lib\site-packages\keras\utils\metrics_utils.py"", line 628, in update_confusion_matrix_variables
      return _update_confusion_matrix_variables_optimized(
    File ""Python310\lib\site-packages\keras\utils\metrics_utils.py"", line 429, in _update_confusion_matrix_variables_optimized
      fp_bucket_v = tf.math.unsorted_segment_sum(
Node: 'UnsortedSegmentSum_1'
Deterministic GPU implementation of unsorted segment reduction op not available.
         [[{{node UnsortedSegmentSum_1}}]] [Op:__inference_train_function_517]
>>>
```
</details>",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1031080703,bersbersbers,2022-02-07 05:10:50,54276,[57855],Processor bug,1,"Colab is running on Linux, I guess, in which case it won't reproduce there because it doesn't reproduce on Linux. When you try to reproduce on Windows, are you sure you are using GPU acceleration? Because it doesn't reproduce on a CPU. *Edit*: for the record: <details> ``[code]`` </details>",0
"The issue we ran into is described here:
https://github.com/tensorflow/tensorflow/blob/92b294f/tensorflow/core/kernels/segment_reduction_ops_gpu_0.cu.cc#L97-L103",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1031088587,benbarsdell,2022-02-07 05:25:57,54276,[57855],Processor bug,1,The issue we ran into is described here: [url]#L97-L103,0
"I can reproduce on a Windows VM, where I can edit and quickly get a build error. The error is:

```
C:\Users\kbuilder\AppData\Local\Temp\nvcc_inter_files_tmp_dir\tmpmapuno6t\segment_reduction_ops_gpu_0.cu.cudafe1.stub.c(4558): error C2719: 'unnamed-parameter': formal parameter with requested alignment of 128 won't be aligned
C:\Users\kbuilder\AppData\Local\Temp\nvcc_inter_files_tmp_dir\tmpmapuno6t\segment_reduction_ops_gpu_0.cu.cudafe1.stub.c(5323): error C2719: 'unnamed-parameter': formal parameter with requested alignment of 128 won't be aligned
C:\Users\kbuilder\AppData\Local\Temp\nvcc_inter_files_tmp_dir\tmpmapuno6t\segment_reduction_ops_gpu_0.cu.cudafe1.stub.c(5428): error C2719: 'unnamed-parameter': formal parameter with requested alignment of 128 won't be aligned
C:\Users\kbuilder\AppData\Local\Temp\nvcc_inter_files_tmp_dir\tmpmapuno6t\segment_reduction_ops_gpu_0.cu.cudafe1.stub.c(5525): error C2719: 'unnamed-parameter': formal parameter with requested alignment of 128 won't be aligned
C:\Users\kbuilder\AppData\Local\Temp\nvcc_inter_files_tmp_dir\tmpmapuno6t\segment_reduction_ops_gpu_0.cu.cudafe1.stub.c(5530): error C2719: 'unnamed-parameter': formal parameter with requested alignment of 128 won't be aligned
C:\Users\kbuilder\AppData\Local\Temp\nvcc_inter_files_tmp_dir\tmpmapuno6t\segment_reduction_ops_gpu_0.cu.cudafe1.stub.c(5567): error C2719: 'unnamed-parameter': formal parameter with requested alignment of 128 won't be aligned
```

Opening the file on the first file, the specified line, 4558, is:

```
__cudaLaunch(((char *)((void ( *)(_ZN10tensorflow12CastIteratorINS_13AlignedVectorIdLi16EEES2_idE10IteratorTyE,  _ZN10tensorflow13AlignedVectorIdLi16EEE *, const int *, const int *, int,  _ZN10tensorflow7functor3SumE, _ZN3cub2IfILb0EN10tensorflow13AlignedVectorIdLi16EEES3_E4TypeE))cub::DeviceSegmentedReduceKernel< ::cub::DeviceReducePolicy< ::tensorflow::AlignedVector<double, (int)16> ,  ::tensorflow::AlignedVector<double, (int)16> , int,  ::tensorflow::functor::Sum> ::Policy600,  ::cub::TransformInputIterator< ::tensorflow::AlignedVector<double, (int)16> ,  ::tensorflow::LookupAndScaleAndCastInputsFunctor< ::tensorflow::AlignedVector<double, (int)16> ,  ::tensorflow::AlignedVector<double, (int)16> , int, double> ,  ::cub::CountingInputIterator<int, long long> , long long> ,  ::tensorflow::AlignedVector<double, (int)16>  *, const int *, int,  ::tensorflow::functor::Sum,  ::tensorflow::AlignedVector<double, (int)16> > )));
```

Looks like your comment is correct: the line above references both AlignedVector and cub. Any advice on how to fix? I don't have time to spend very long on this unfortunately, so we may have to leave this unfixed.",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1032051015,reedwm,2022-02-07 23:40:00,54276,[57855],Processor bug,1,"I can reproduce on a Windows VM, where I can edit and quickly get a build error. The error is: ``[code]`[code]`[code]`` Looks like your comment is correct: the line above references both AlignedVector and cub. Any advice on how to fix? I don't have time to spend very long on this unfortunately, so we may have to leave this unfixed.",-2
"So I was able to fix the error by changing [this line](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/util/gpu_kernel_helper.h;l=329;drc=0d53fe6214d99fc8ab85cfc45bb02b8d1fbf3411) to not instantiate `Functor<16>`, giving a max value of 8 on Windows. But I got several other errors, such as:

```
.\tensorflow/core/util/gpu_kernel_helper.h(259): error: more than one operator ""*="" matches these operands:
            function ""Eigen::complex_operator_detail::operator*=(std::complex<float> &, const std::complex<float> &)""
            function ""std::complex<float>::operator*=(const std::complex<float> &)""
            operand types are: tensorflow::complex64 *= const tensorflow::complex64
          detected during:
            instantiation of ""tensorflow::AlignedVector<T, N> &tensorflow::AlignedVector<T, N>::operator*=(const tensorflow::AlignedVector<T, N> &) [with T=tensorflow::complex64, N=8]""
.\tensorflow/core/kernels/segment_reduction_ops_gpu.cu.h(460): here
```

and

```
.\tensorflow/core/util/gpu_kernel_helper.h(288): error: no instance of overloaded function ""tensorflow::max"" matches the argument list
            argument types are: (const int, const int)
          detected during instantiation of class ""tensorflow::AlignedVector<T, N> [with T=int, N=8]""
```

The first seems like a legitimate error: I don't why why eigen is redefining `operator*=` on complex numbers. I'm confused by the second, as I cannot find any `tensorflow::max` function at all, so I'm not sure why it's not simply using the CUDA max function.

Unfortunately, I don't have more time to work on this.",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1032186006,reedwm,2022-02-08 03:50:43,54276,[57855],Processor bug,1,"So I was able to fix the error by changing [this line]([url] to not instantiate [code], giving a max value of 8 on Windows. But I got several other errors, such as: ``[code]`[code]`[code]`[code]operator*=[code]tensorflow::max` function at all, so I'm not sure why it's not simply using the CUDA max function. Unfortunately, I don't have more time to work on this.",-2
"@reedwm @benbarsdell I don't have context for this problem.

Is `SparseSegmentReductionFunctor` only used after `tf.config.experimental.enable_op_determinism()` is called?",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1061350864,wangpengmit,2022-03-08 02:48:16,54276,[57855],Processor bug,1,@reedwm @benbarsdell I don't have context for this problem. Is [code] only used after [code] is called?,0
"Hi @benbarsdell, Can we move this issue to closed state, If it was  resolved. Thank you!",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1231241221,gadagashwini,2022-08-30 07:09:55,54276,[57855],Processor bug,1,"Hi @benbarsdell, Can we move this issue to closed state, If it was resolved. Thank you!",3
"> Hi @benbarsdell, Can we move this issue to closed state, If it was resolved. Thank you!

@gadagashwini I don't think it was resolved. I am experiencing the same issue on Windows with TensorFlow 2.10.0. Works fine on CPU though, but same issue on GPU as described above. Any simple fix for this?",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1257047957,andreped,2022-09-24 19:14:03,54276,[57855],Processor bug,1,"> Hi @benbarsdell, Can we move this issue to closed state, If it was resolved. Thank you! @gadagashwini I don't think it was resolved. I am experiencing the same issue on Windows with TensorFlow 2.10.0. Works fine on CPU though, but same issue on GPU as described above. Any simple fix for this?",-2
"Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54276"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54276"">No</a>
",IssueComment,https://github.com/tensorflow/tensorflow/issues/54276#issuecomment-1261672277,google-ml-butler[bot],2022-09-29 02:45:46,54276,[57855],Processor bug,1,"Are you satisfied with the resolution of your issue? <a href=""[url]"">Yes</a> <a href=""[url]"">No</a>",0
"you need to send metrics to call_model_fn, right?
could you please add a test which catches this error?",PrComment,https://github.com/tensorflow/tensorflow/pull/12206#discussion_r132721763,ispirmustafa,2017-08-11 15:58:34,12205,12206,Code bug,0,"you need to send metrics to call_model_fn, right? could you please add a test which catches this error?",0
"Thanks for your review. 

Now `feature_engineerng_fn(features, label)` is called by `Estimator.eval()` twice. See code [here](https://github.com/facaiy/tensorflow/blob/c7b80d51da4fb6d51ea54a0bdf2601afa379d60c/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L1095) and [there](https://github.com/facaiy/tensorflow/blob/c7b80d51da4fb6d51ea54a0bdf2601afa379d60c/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L1165).
Because `features` can be a `dict` which is passed by pointer for function, hence `features` will be converted by `feature_engineering_fn` twice. It's dangerous and might get in trouble.

So we should assure that `feature_engineering_fn` only be called once for `train`, `eval` and `predict`. That's why I send metrics to `call_model_fn`. 

In fact, I have added an unit test below to catch the error. 
 
",PrComment,https://github.com/tensorflow/tensorflow/pull/12206#discussion_r132803953,facaiy,2017-08-12 00:15:55,12205,12206,Code bug,0,"Thanks for your review. Now [code] is called by [code] twice. See code [here]([url]#L1095) and [there]([url]#L1165). Because [code] can be a [code] which is passed by pointer for function, hence [code] will be converted by [code] twice. It's dangerous and might get in trouble. So we should assure that [code] only be called once for [code], [code] and [code]. That's why I send metrics to [code]. In fact, I have added an unit test below to catch the error.",0
"Hi, @ispirmustafa . In the `feature_engineering_fn`, it converts string tensor to float tensor. So if it's be called twice, TypeError will be raised because `features[""x""]` has been converted to float tensor, which is unsupported by string_op.",PrComment,https://github.com/tensorflow/tensorflow/pull/12206#discussion_r132804127,facaiy,2017-08-12 00:19:05,12205,12206,Code bug,0,"Hi, @ispirmustafa . In the [code], it converts string tensor to float tensor. So if it's be called twice, TypeError will be raised because [code] has been converted to float tensor, which is unsupported by string_op.",-2
"Hi Yan,
I understand the reason of change. 
It seems there is a bug in current code: you forgot to send metrics to call_model_fn in Eval mode. Could you please check that?
otherwise LGTM
",PrComment,https://github.com/tensorflow/tensorflow/pull/12206#discussion_r132804628,ispirmustafa,2017-08-12 00:29:57,12205,12206,Code bug,0,"Hi Yan, I understand the reason of change. It seems there is a bug in current code: you forgot to send metrics to call_model_fn in Eval mode. Could you please check that? otherwise LGTM",1
"Oh, my fault! I have corrected it. Thanks for your comment, ispirmustafa!",PrComment,https://github.com/tensorflow/tensorflow/pull/12206#discussion_r132808054,facaiy,2017-08-12 02:36:34,12205,12206,Code bug,0,"Oh, my fault! I have corrected it. Thanks for your comment, ispirmustafa!",3
"If you unwrap it, it won't be the outermost object. I.e. if I have a decorator modifying the arguments, we should return the arguments directly, without unwrapping.",PrComment,https://github.com/tensorflow/tensorflow/pull/12276#discussion_r133091536,martinwicke,2017-08-15 00:02:31,12249,12276,Version compatibility bug,0,"If you unwrap it, it won't be the outermost object. I.e. if I have a decorator modifying the arguments, we should return the arguments directly, without unwrapping.",0
"Please name this something else, not ""object"", which is a reserved word.",PrComment,https://github.com/tensorflow/tensorflow/pull/12276#discussion_r133091647,martinwicke,2017-08-15 00:03:23,12249,12276,Version compatibility bug,0,"Please name this something else, not ""object"", which is a reserved word.",-1
Are these classes compatible enough that all downstream code can use them interchangeably? I.e. is FullArgSpec backwards compatible with ArgSpec?,PrComment,https://github.com/tensorflow/tensorflow/pull/12276#discussion_r133091740,martinwicke,2017-08-15 00:04:10,12249,12276,Version compatibility bug,0,Are these classes compatible enough that all downstream code can use them interchangeably? I.e. is FullArgSpec backwards compatible with ArgSpec?,0
"@martinwicke They are not truly compatible as FullArgSpec has `varkw` while ArgSpec has `keywords`. For example, if `getfullargspec` is used, then in `tensorflow/python/util/deprecation.py`:

https://github.com/tensorflow/tensorflow/blob/325fc2330f4e527b394456ce1d821f2c73b1e7a2/tensorflow/python/util/deprecation.py#L224-L229

The following has to be used:
```
# Cannot use arg_spec.keywords directory
getattr(arg_spec, ""keywords"", getattr(arg_spec, ""varkw""))
```

For that I try to use `util.getfullargspec` only for `estimator.Estimator`. For everything else, the original `util.getargspec` would be used.",PrComment,https://github.com/tensorflow/tensorflow/pull/12276#discussion_r133297410,yongtang,2017-08-15 20:39:58,12249,12276,Version compatibility bug,0,"@martinwicke They are not truly compatible as FullArgSpec has [code] while ArgSpec has [code]. For example, if [code] is used, then in [code]: [url]#L224-L229 The following has to be used: ``[code]`[code]util.getfullargspec[code]estimator.Estimator[code]util.getargspec` would be used.",0
@martinwicke The unwrap was done previously so the implementation before PR might have already been problematic. Let me take a look and update the PR accordingly.,PrComment,https://github.com/tensorflow/tensorflow/pull/12276#discussion_r133321183,yongtang,2017-08-15 22:36:13,12249,12276,Version compatibility bug,0,@martinwicke The unwrap was done previously so the implementation before PR might have already been problematic. Let me take a look and update the PR accordingly.,1
"Use TF_RETURN_IF_ERROR(GetFileSize(src, &size)); instead. Here and elsewhere...",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r137834731,rohan100jain,2017-09-08 16:33:09,12641,12658,Memory bug,0,"Use TF_RETURN_IF_ERROR(GetFileSize(src, &size)); instead. Here and elsewhere...",0
Name this bytes_to_read?,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r137835042,rohan100jain,2017-09-08 16:34:50,12641,12658,Memory bug,0,Name this bytes_to_read?,0
"In this case, we'll end up copying something into target_file. Do those semantics make sense? Or should we delete target_file? What are the semantics in Unix for instance? Either way, can we document this in the header file?",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r137835789,rohan100jain,2017-09-08 16:38:27,12641,12658,Memory bug,0,"In this case, we'll end up copying something into target_file. Do those semantics make sense? Or should we delete target_file? What are the semantics in Unix for instance? Either way, can we document this in the header file?",0
"the logic for the same FS and different FS seem very similar... would it make sense to create a utility method that takes in FileSystem* src_fs and FileSystem* target_fs and does the copy. For the Filesystem::CopyFile method pass in this, this to that method?",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r137836253,rohan100jain,2017-09-08 16:40:48,12641,12658,Memory bug,0,"the logic for the same FS and different FS seem very similar... would it make sense to create a utility method that takes in FileSystem* src_fs and FileSystem* target_fs and does the copy. For the Filesystem::CopyFile method pass in this, this to that method?",0
I don't see where this is implemented?,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r137836448,rohan100jain,2017-09-08 16:41:57,12641,12658,Memory bug,0,I don't see where this is implemented?,0
Why do you need to handle this case? From what I understand this case should be handled by platform/windows/windows_file_system,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r137836923,rohan100jain,2017-09-08 16:44:08,12641,12658,Memory bug,0,Why do you need to handle this case? From what I understand this case should be handled by platform/windows/windows_file_system,0
Add a comment here explaining all the flags turned on.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r137837092,rohan100jain,2017-09-08 16:45:02,12641,12658,Memory bug,0,Add a comment here explaining all the flags turned on.,0
"Thanks @rohan100jain, done.",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r139276047,yongtang,2017-09-16 02:20:20,12641,12658,Memory bug,0,"Thanks @rohan100jain, done.",3
Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r139276049,yongtang,2017-09-16 02:20:29,12641,12658,Memory bug,0,Done.,0
"@rohan100jain That was to follow the old semantics (where no partial copy in memory). Now as we use streaming, it is not possible to rollback any way. The `cp` in Linux is not impacted by the file change so I just removed the check at the end.",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r139276117,yongtang,2017-09-16 02:23:43,12641,12658,Memory bug,0,"@rohan100jain That was to follow the old semantics (where no partial copy in memory). Now as we use streaming, it is not possible to rollback any way. The [code] in Linux is not impacted by the file change so I just removed the check at the end.",0
Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r139276122,yongtang,2017-09-16 02:23:51,12641,12658,Memory bug,0,Done.,0
"Sorry, that was left over when check in. It has been cleaned.",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r139276132,yongtang,2017-09-16 02:24:33,12641,12658,Memory bug,0,"Sorry, that was left over when check in. It has been cleaned.",1
Removed. Thanks.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r139276135,yongtang,2017-09-16 02:24:42,12641,12658,Memory bug,0,Removed. Thanks.,2
Done. Thanks.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r139276143,yongtang,2017-09-16 02:24:53,12641,12658,Memory bug,0,Done. Thanks.,3
One fabulous fact about Google is stacks are 64kB and individual frames can't exceed 16kB. Please use heap memory here.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150377573,jart,2017-11-11 07:44:40,12641,12658,Memory bug,0,One fabulous fact about Google is stacks are 64kB and individual frames can't exceed 16kB. Please use heap memory here.,3
"From `RandomAccessFile`:

```c
  /// Returns `OUT_OF_RANGE` if fewer than n bytes were stored in `*result`
  /// because of EOF.
```

So you could possibly be able to avoid the round trip of fetching the length, if you check the status returned by `Read`.",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150377870,jart,2017-11-11 08:02:05,12641,12658,Memory bug,0,From [code]: ``[code]OUT_OF_RANGE[code]*result[code]`[code]Read`.,0
"Do we want copies to be atomic? I just noticed our GCS RandomAccessFile impl doesn't lock-in the [generation](https://cloud.google.com/storage/docs/generations-preconditions). Can we do that @dbcode? If that can happen soon, I don't see any reason to block this PR.",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150378392,jart,2017-11-11 08:24:26,12641,12658,Memory bug,0,"Do we want copies to be atomic? I just noticed our GCS RandomAccessFile impl doesn't lock-in the [generation]([url] Can we do that @dbcode? If that can happen soon, I don't see any reason to block this PR.",1
How about 0644?,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150378574,jart,2017-11-11 08:30:43,12641,12658,Memory bug,0,How about 0644?,0
"This is fine, but can we have an if statement instead? I always get scared when I have to search Google to make sure unsafe code is correct. Same goes for that other ternary.",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150378724,jart,2017-11-11 08:36:19,12641,12658,Memory bug,0,"This is fine, but can we have an if statement instead? I always get scared when I have to search Google to make sure unsafe code is correct. Same goes for that other ternary.",-1
128kB is the optimal according to this guy: https://eklitzke.org/efficient-file-copying-on-linux,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150378926,jart,2017-11-11 08:44:21,12641,12658,Memory bug,0,128kB is the optimal according to this guy: [url],0
Please check for `close` errors.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150379064,jart,2017-11-11 08:48:50,12641,12658,Memory bug,0,Please check for [code] errors.,0
kernelspace! :D,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150379074,jart,2017-11-11 08:49:16,12641,12658,Memory bug,0,kernelspace! :D,3
Ditto on heap memory.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150379140,jart,2017-11-11 08:52:39,12641,12658,Memory bug,0,Ditto on heap memory.,0
Mixing signed and unsigned with integer limits like this scares me a little bit because I can't tell if the code is correct. Would it be possible to write this in a way there the code is obviously correct? Even if it results in a ton of static_cast<> boilerplate? I'll also note that I would personally feel completely fine if sendfile() context-switched back into userspace every 128kB. What matters IIRC is that the memory itself isn't being copied between the two.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150379342,jart,2017-11-11 08:59:45,12641,12658,Memory bug,0,Mixing signed and unsigned with integer limits like this scares me a little bit because I can't tell if the code is correct. Would it be possible to write this in a way there the code is obviously correct? Even if it results in a ton of static_cast<> boilerplate? I'll also note that I would personally feel completely fine if sendfile() context-switched back into userspace every 128kB. What matters IIRC is that the memory itself isn't being copied between the two.,-1
"Having done more homework, I would say change this to `#if defined(__linux__) && !defined(__ANDROID__)` because it won't work on FreeBSD and you never know with Android. I've confirmed it will work on Linux kernels â‰¥2.6.33 (published in 2010.) TensorFlow supports as far back as CentOS 7, which uses Linux 3.10.0, so this should be fine. If we want to be even more conservative, we could use the [splice](https://en.wikipedia.org/wiki/Splice_(system_call)) system call instead, which became available in 2.6.17 in 2006. It's Linux-only, but we've constrained ourselves to Linux anyway.",PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150396025,jart,2017-11-11 23:18:52,12641,12658,Memory bug,0,"Having done more homework, I would say change this to [code] because it won't work on FreeBSD and you never know with Android. I've confirmed it will work on Linux kernels â‰¥2.6.33 (published in 2010.) TensorFlow supports as far back as CentOS 7, which uses Linux 3.10.0, so this should be fine. If we want to be even more conservative, we could use the [splice]([url] system call instead, which became available in 2.6.17 in 2006. It's Linux-only, but we've constrained ourselves to Linux anyway.",0
Thanks @jart. Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150423097,yongtang,2017-11-12 20:53:33,12641,12658,Memory bug,0,Thanks @jart. Done.,3
Thanks. The PR has been updated and size has been removed.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150423113,yongtang,2017-11-12 20:53:54,12641,12658,Memory bug,0,Thanks. The PR has been updated and size has been removed.,3
Updated. Thanks.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150423122,yongtang,2017-11-12 20:54:10,12641,12658,Memory bug,0,Updated. Thanks.,3
Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150423135,yongtang,2017-11-12 20:54:23,12641,12658,Memory bug,0,Done.,0
Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/12658#discussion_r150423155,yongtang,2017-11-12 20:54:37,12641,12658,Memory bug,0,Updated.,0
Do I make a mistake?  [`path repository_ctx.which()`](https://docs.bazel.build/versions/master/skylark/lib/repository_ctx.html#which) doesn't receive any argument.,PrComment,https://github.com/tensorflow/tensorflow/pull/12839#discussion_r137176593,facaiy,2017-09-06 05:56:13,12821,12839,Code bug,0,Do I make a mistake? [[code]]([url]#which) doesn't receive any argument.,0
Looks good to me.,PrComment,https://github.com/tensorflow/tensorflow/pull/12839#discussion_r137349129,yifeif,2017-09-06 18:17:30,12821,12839,Code bug,0,Looks good to me.,3
please fix the alignment of the \ at the end of the line to match the other lines,PrComment,https://github.com/tensorflow/tensorflow/pull/13517#discussion_r143886708,rryan,2017-10-11 00:26:21,13506,13517,Data bug,1,please fix the alignment of the \ at the end of the line to match the other lines,0
please fix the alignment of the \ at the end of the line to match the other lines,PrComment,https://github.com/tensorflow/tensorflow/pull/13517#discussion_r143886748,rryan,2017-10-11 00:26:37,13506,13517,Data bug,1,please fix the alignment of the \ at the end of the line to match the other lines,0
Thanks @rryan. The alignment has been fixed.,PrComment,https://github.com/tensorflow/tensorflow/pull/13517#discussion_r143915565,yongtang,2017-10-11 05:33:21,13506,13517,Data bug,1,Thanks @rryan. The alignment has been fixed.,5
Thanks. Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/13517#discussion_r143915579,yongtang,2017-10-11 05:33:29,13506,13517,Data bug,1,Thanks. Done.,3
Looks good. How about inserting a comment here ? `# Github issue: 14819`,PrComment,https://github.com/tensorflow/tensorflow/pull/14831#discussion_r152769134,facaiy,2017-11-23 10:46:06,14819,14831,Algorithm design bug,0,Looks good. How about inserting a comment here ? [code],2
Fine . I'd like to do it.,PrComment,https://github.com/tensorflow/tensorflow/pull/14831#discussion_r152773725,ZhengshengWei,2017-11-23 11:09:12,14819,14831,Algorithm design bug,0,Fine . I'd like to do it.,2
Small nit: Prefer to avoid making unrelated formatting changes.,PrComment,https://github.com/tensorflow/tensorflow/pull/14872#discussion_r170094867,josh11b,2018-02-22 21:13:41,14871,14872,Processor bug,1,Small nit: Prefer to avoid making unrelated formatting changes.,-1
Thanks @josh11b. The unrelated formatting changes in those two files have been removed.,PrComment,https://github.com/tensorflow/tensorflow/pull/14872#discussion_r170101315,yongtang,2018-02-22 21:38:43,14871,14872,Processor bug,1,Thanks @josh11b. The unrelated formatting changes in those two files have been removed.,3
"normally when we talk about ""squared difference"" we are referring to the L2 metric in a vector space. Therefore, this function should compute conj(x-y)*(x-y). In other words, you need to modify the implementation as well by adding a conjugation to the first input for complex types.",PrComment,https://github.com/tensorflow/tensorflow/pull/14939#discussion_r222860700,rmlarsen,2018-10-04 23:54:46,14932,14939,Data bug,1,"normally when we talk about ""squared difference"" we are referring to the L2 metric in a vector space. Therefore, this function should compute conj(x-y)*(x-y). In other words, you need to modify the implementation as well by adding a conjugation to the first input for complex types.",0
missing colon at the end,PrComment,https://github.com/tensorflow/tensorflow/pull/18052#discussion_r177896678,rmlarsen,2018-03-28 21:30:46,7404,18052,Documentation bug,0,missing colon at the end,-1
linter will complain if lines are >80 chars.,PrComment,https://github.com/tensorflow/tensorflow/pull/18052#discussion_r177896775,rmlarsen,2018-03-28 21:31:05,7404,18052,Documentation bug,0,linter will complain if lines are >80 chars.,-1
Hmmm so the semantics of GetChildren are not clear when PERMISSION_DENIED is returned. Should we try to process the children in the vector? Might be better to bail if we hit PERMISSION_DENIED?,PrComment,https://github.com/tensorflow/tensorflow/pull/19307#discussion_r209071971,rohan100jain,2018-08-09 20:41:46,19274,19307,Code bug,1,Hmmm so the semantics of GetChildren are not clear when PERMISSION_DENIED is returned. Should we try to process the children in the vector? Might be better to bail if we hit PERMISSION_DENIED?,0
Remove this comment line,PrComment,https://github.com/tensorflow/tensorflow/pull/19307#discussion_r211369700,rohan100jain,2018-08-20 18:50:45,19274,19307,Code bug,1,Remove this comment line,0
"why use gen_io_ops.matching_files.. why not file_io.get_matching_files instead? In fact try looking for .../test_dir/*/file*.txt and expect to only find file1.txt, file2.txt and file3.txt",PrComment,https://github.com/tensorflow/tensorflow/pull/19307#discussion_r211370229,rohan100jain,2018-08-20 18:52:20,19274,19307,Code bug,1,"why use gen_io_ops.matching_files.. why not file_io.get_matching_files instead? In fact try looking for .../test_dir/*/file*.txt and expect to only find file1.txt, file2.txt and file3.txt",0
"Thanks for the fix!
I think we might also be leaking `ctarget`, perhaps we can move the block that calls `GetStringUTFChars` to fill in `ctarget` after this `if (config != nullptr)` block so that we don't leak it?",PrComment,https://github.com/tensorflow/tensorflow/pull/20558#discussion_r200815431,asimshankar,2018-07-07 15:39:47,17698,20558,Memory bug,0,"Thanks for the fix! I think we might also be leaking [code], perhaps we can move the block that calls [code] to fill in [code] after this [code] block so that we don't leak it?",2
"Thanks for your reminder, this may be the better way. I'll update this commit.",PrComment,https://github.com/tensorflow/tensorflow/pull/20558#discussion_r200816711,weberxie,2018-07-07 16:31:52,17698,20558,Memory bug,0,"Thanks for your reminder, this may be the better way. I'll update this commit.",3
"It would be great to put the comments alongside the change in the code. Same for the change below.
Thanks for the catch.",PrComment,https://github.com/tensorflow/tensorflow/pull/21677#discussion_r228681938,protoget,2018-10-26 22:33:26,21676,21677,Test bug,0,It would be great to put the comments alongside the change in the code. Same for the change below. Thanks for the catch.,3
@protoget Thanks for the review.  I've added an explanatory comment to each of the changes.,PrComment,https://github.com/tensorflow/tensorflow/pull/21677#discussion_r228909737,markdryan,2018-10-29 12:47:15,21676,21677,Test bug,0,@protoget Thanks for the review. I've added an explanatory comment to each of the changes.,3
"I'd probaby put details about the ""AVX512 builds as the
embedding operation makes use of Eigen's fast vectorized square root
algorithm for doubles"" etc.",PrComment,https://github.com/tensorflow/tensorflow/pull/21677#discussion_r229122356,protoget,2018-10-29 22:33:11,21676,21677,Test bug,0,"I'd probaby put details about the ""AVX512 builds as the embedding operation makes use of Eigen's fast vectorized square root algorithm for doubles"" etc.",0
@protoget I've updated the comments to explicitly mention the AVX512 builds.,PrComment,https://github.com/tensorflow/tensorflow/pull/21677#discussion_r229233101,markdryan,2018-10-30 09:36:53,21676,21677,Test bug,0,@protoget I've updated the comments to explicitly mention the AVX512 builds.,0
"@protoget Does the updated comment read okay to you now?  If not, I'm happy to change it.",PrComment,https://github.com/tensorflow/tensorflow/pull/21677#discussion_r231296008,markdryan,2018-11-06 21:17:19,21676,21677,Test bug,0,"@protoget Does the updated comment read okay to you now? If not, I'm happy to change it.",3
"Thanks for the PR! But can't we do something even more direct here?

This code already assumes that shape.ndims is not None, and that dim is a Python integer. So I don't think we need to do this test as part of the graph â€”Â we can do it in Python instead, which is simpler and easier to understand. i.e., I think you can just write:

```python
if dim < -shape.ndims or dim >= shape.ndims:
  raise ... etc.
```

This would also give the caller a more usable backtrace from Python, rather than a somewhat more cryptic error when running the graph.",PrComment,https://github.com/tensorflow/tensorflow/pull/22849#discussion_r224214267,hawkinsp,2018-10-10 19:38:27,22793,22849,Algorithm design bug,0,"Thanks for the PR! But can't we do something even more direct here? This code already assumes that shape.ndims is not None, and that dim is a Python integer. So I don't think we need to do this test as part of the graph â€” we can do it in Python instead, which is simpler and easier to understand. i.e., I think you can just write: ``[code]`` This would also give the caller a more usable backtrace from Python, rather than a somewhat more cryptic error when running the graph.",2
"In this case we should set an error to avoid accidentally returning an invalid value:

```suggestion
    OP_REQUIRES(ctx, !already_cancelled, errors::Cancelled(""Loop execution was cancelled.""));
```",PrComment,https://github.com/tensorflow/tensorflow/pull/23811#discussion_r234661301,mrry,2018-11-19 15:25:26,22217,23811,Code bug,1,In this case we should set an error to avoid accidentally returning an invalid value: ``[code]``,0
I agree with your suggestion. It is better to raise an error for this case. Will change it.,PrComment,https://github.com/tensorflow/tensorflow/pull/23811#discussion_r234858202,feihugis,2018-11-20 03:23:00,22217,23811,Code bug,1,I agree with your suggestion. It is better to raise an error for this case. Will change it.,3
"After changing it to be as follows, the `errors::Cancelled(""Loop execution was cancelled."")` did not arise as expected. I attach the log of the test case here.

```C++
void LoopCondOp::Compute(OpKernelContext* context) {
  CancellationManager* cm = context->cancellation_manager();
  bool already_cancelled = cm->IsCancelled();
  OP_REQUIRES(context, !already_cancelled,
              errors::Cancelled(""Loop execution was cancelled.""));

  context->set_output(0, context->input(0));
}
```
```
.......ERROR:tensorflow:Timed out waiting for notification
E..ERROR:tensorflow:Attempting to use uninitialized value Variable
	 [[{{node _retval_Variable_0_0}}]]
..
======================================================================
ERROR: testWhileTimeOutWithControlFlowV2 (__main__.ControlFlowTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.DeadlineExceededError: Timed out waiting for notification

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 412, in wrapper
    fn(*args, **kwargs)
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/control_flow_ops_py_test.py"", line 1986, in testWhileTimeOut
    sess.run(r, options=run_options)
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1056, in run
    return super(ErrorLoggingSession, self).run(*args, **kwargs)
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/kernel_tests/control_flow_ops_py_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.DeadlineExceededError: Timed out waiting for notification

----------------------------------------------------------------------
Ran 20 tests in 4.698s

FAILED (errors=1)
```",PrComment,https://github.com/tensorflow/tensorflow/pull/23811#discussion_r234868570,feihugis,2018-11-20 04:51:50,22217,23811,Code bug,1,"After changing it to be as follows, the [code] did not arise as expected. I attach the log of the test case here. ``[code]`[code]`[code]``",0
"That's working as expected. The external error is first set [here](https://github.com/tensorflow/tensorflow/blob/f25493f9c0ae0dec6db31dfe7fd19ed01b57c23d/tensorflow/core/common_runtime/direct_session.cc#L1699-L1700) before ongoing execution is cancelled, so the `CancelledError` won't bubble up to the client code. However, it's still important to set it to some kind of error, to prevent additional ops from executing (and potentially mutating state based on an incorrect value).",PrComment,https://github.com/tensorflow/tensorflow/pull/23811#discussion_r235060504,mrry,2018-11-20 15:55:01,22217,23811,Code bug,1,"That's working as expected. The external error is first set [here]([url]#L1699-L1700) before ongoing execution is cancelled, so the [code] won't bubble up to the client code. However, it's still important to set it to some kind of error, to prevent additional ops from executing (and potentially mutating state based on an incorrect value).",0
Thanks for your explanation! Got better understanding. It makes sense. Will submit the change tonight (only have limited time to access the laptop this week),PrComment,https://github.com/tensorflow/tensorflow/pull/23811#discussion_r235073341,feihugis,2018-11-20 16:24:34,22217,23811,Code bug,1,Thanks for your explanation! Got better understanding. It makes sense. Will submit the change tonight (only have limited time to access the laptop this week),4
I think output_shape is supposed to be a tensor and not a tensorshape,PrComment,https://github.com/tensorflow/tensorflow/pull/24018#discussion_r284924514,alextp,2019-05-16 22:41:47,21964,24018,Data bug,0,I think output_shape is supposed to be a tensor and not a tensorshape,0
"```suggestion
          raise IndexError('Row key {} out of bounds'.format(row_key))
```",PrComment,https://github.com/tensorflow/tensorflow/pull/24723#discussion_r246511062,penpornk,2019-01-09 19:32:34,24679,24723,Data bug,0,``[code]``,0
Can we just use `value[i]` and skip using `value`?,PrComment,https://github.com/tensorflow/tensorflow/pull/24723#discussion_r246511547,penpornk,2019-01-09 19:34:08,24679,24723,Data bug,0,Can we just use [code] and skip using [code]?,0
No control dependencies in tfv2,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r271957704,alextp,2019-04-03 22:30:27,27478,27479,Documentation bug,0,No control dependencies in tfv2,-1
tf.function exists so no need to import from contrib which doesn't exist in tf2,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r271957783,alextp,2019-04-03 22:30:48,27478,27479,Documentation bug,0,tf.function exists so no need to import from contrib which doesn't exist in tf2,0
The deprecation message I think is fine using a tf.Session; it's giving directions to 1.x users about how to switch within 1.x. ,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r271958313,allenlavoie,2019-04-03 22:32:51,27478,27479,Documentation bug,0,The deprecation message I think is fine using a tf.Session; it's giving directions to 1.x users about how to switch within 1.x.,2
"The best thing to do with 1.x vs. 2.x docstrings is to make a new symbol which is v2-only with the new docstring (no need to mention control dependencies at all there, and certainly no need to mention Sessions) and have a v1-only symbol with the same name which has the old docstring. The v1 symbol should call the v2 symbol.

We're still planning on making a couple 1.x releases I believe, so we should preserve the existing information in the v1 docstring.

Example of this kind of transformation (although it's copying a bit more than you'll need to): https://github.com/tensorflow/tensorflow/commit/dd0b3d3d724f13bb99423e92ea3e32601058ff2a

Note the tf_export lines, which control which versions the symbol is exposed in.",PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r271960106,allenlavoie,2019-04-03 22:40:35,27478,27479,Documentation bug,0,"The best thing to do with 1.x vs. 2.x docstrings is to make a new symbol which is v2-only with the new docstring (no need to mention control dependencies at all there, and certainly no need to mention Sessions) and have a v1-only symbol with the same name which has the old docstring. The v1 symbol should call the v2 symbol. We're still planning on making a couple 1.x releases I believe, so we should preserve the existing information in the v1 docstring. Example of this kind of transformation (although it's copying a bit more than you'll need to): [url] Note the tf_export lines, which control which versions the symbol is exposed in.",0
"@allenlavoie I finished the work as [`dd0b3d3`](https://github.com/tensorflow/tensorflow/commit/dd0b3d3d724f13bb99423e92ea3e32601058ff2a), but do you thing is good to double the code is just for documenting?I good I can commit the code. Or should I leave or close this issue, and re-open when release when finalizing tfv2?",PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r272367007,hksonngan,2019-04-04 21:04:01,27478,27479,Documentation bug,0,"@allenlavoie I finished the work as [[code]]([url] but do you thing is good to double the code is just for documenting?I good I can commit the code. Or should I leave or close this issue, and re-open when release when finalizing tfv2?",0
A little duplication is fine. They're giving different information.,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r272369018,allenlavoie,2019-04-04 21:10:44,27478,27479,Documentation bug,0,A little duplication is fine. They're giving different information.,2
"this is document [control_dependencies](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/control_dependencies),
And in [migration guide](https://www.tensorflow.org/alpha/guide/migration_guide) have it.
Also this code works with tfv2 nightly build.",PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r272690922,hksonngan,2019-04-05 18:04:45,27478,27479,Documentation bug,0,this is document [control_dependencies]([url] And in [migration guide]([url] have it. Also this code works with tfv2 nightly build.,0
add comment as [`b38ef23`](https://github.com/tensorflow/tensorflow/pull/27479/commits/b38ef235d56a340cb080da328f47294ce24a92ec),PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r272691817,hksonngan,2019-04-05 18:07:38,27478,27479,Documentation bug,0,add comment as [[code]]([url],0
@allenlavoie  I modify as [`b38ef23`](https://github.com/tensorflow/tensorflow/pull/27479/commits/b38ef235d56a340cb080da328f47294ce24a92ec),PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r272692124,hksonngan,2019-04-05 18:08:38,27478,27479,Documentation bug,0,@allenlavoie I modify as [[code]]([url],0
"`from tensorflow.python.eager import function` is for decorator function.defun.
refer to [`control flow unit test`](https://github.com/tensorflow/tensorflow/blob/1d54cbf4a2252215c5d2ce9accb5e498a7c2a704/tensorflow/python/kernel_tests/control_flow_util_v2_test.py)",PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r272695430,hksonngan,2019-04-05 18:19:09,27478,27479,Documentation bug,0,[code] is for decorator function.defun. refer to [[code]]([url],0
We need to use the public API in our documentation.,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r272699339,allenlavoie,2019-04-05 18:31:22,27478,27479,Documentation bug,0,We need to use the public API in our documentation.,0
"```python
from tensorflow.python.framework import function
@function.Defun()
def f():
  tensor = tf.range(10)
  tf.print(tensor, output_stream=sys.stderr)
  return tensor

range_tensor = f()
```
raise InvalidArgumentError as is expected",PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r272704747,hksonngan,2019-04-05 18:48:33,27478,27479,Documentation bug,0,``[code]`` raise InvalidArgumentError as is expected,0
s/defuns/tf.function,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r293873641,alextp,2019-06-14 16:08:17,27478,27479,Documentation bug,0,s/defuns/tf.function,0
only a concern in legacy v1 graph mode,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r293873746,alextp,2019-06-14 16:08:37,27478,27479,Documentation bug,0,only a concern in legacy v1 graph mode,0
Yes but you don't need the control dependency if inside a tf.function or with eager execution enabled,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r293874110,alextp,2019-06-14 16:09:38,27478,27479,Documentation bug,0,Yes but you don't need the control dependency if inside a tf.function or with eager execution enabled,0
Yes but don't use the deprecated function.Defun in documentation,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r293874290,alextp,2019-06-14 16:10:06,27478,27479,Documentation bug,0,Yes but don't use the deprecated function.Defun in documentation,-1
Remove the TODO,PrComment,https://github.com/tensorflow/tensorflow/pull/27479#discussion_r293874390,alextp,2019-06-14 16:10:27,27478,27479,Documentation bug,0,Remove the TODO,0
"```suggestion
      [Self-Normalizing Neural Networks (Klambauer et al, 2017)]
```",PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r275167263,kyscg,2019-04-14 17:52:41,27657,27837,Documentation bug,0,``[code]``,0
"```suggestion
      (https://arxiv.org/abs/1706.02515)
```",PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r275167271,kyscg,2019-04-14 17:52:51,27657,27837,Documentation bug,0,``[code]``,0
Shouldn't you add `kernel_initializer='lecun_normal'` ?,PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r275433845,ekerazha,2019-04-15 16:03:37,27657,27837,Documentation bug,0,Shouldn't you add [code] ?,0
"Added `kernel_initializer='lecun_normal'`, however note that usually `'glorot_uniform'` is recommended, and `activation='selu'` need not indicate otherwise.",PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r275442153,bharatr21,2019-04-15 16:23:51,27657,27837,Documentation bug,0,"Added [code], however note that usually [code] is recommended, and [code] need not indicate otherwise.",0
"@Bharat123rox SELU needs lecun_normal initialization and, when used, AlphaDropout instead of Dropout ",PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r275668363,ekerazha,2019-04-16 07:47:19,27657,27837,Documentation bug,0,"@Bharat123rox SELU needs lecun_normal initialization and, when used, AlphaDropout instead of Dropout",0
Add kernel_initializer='lecun_normal' here too,PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r276251450,ekerazha,2019-04-17 13:51:22,27657,27837,Documentation bug,0,Add kernel_initializer='lecun_normal' here too,0
Add kernel_initializer='lecun_normal' here too,PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r276251613,ekerazha,2019-04-17 13:51:44,27657,27837,Documentation bug,0,Add kernel_initializer='lecun_normal' here too,0
trim,PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r279043146,tanzhenyu,2019-04-26 17:43:46,27657,27837,Documentation bug,0,trim,0
we really don't need that many digits here.,PrComment,https://github.com/tensorflow/tensorflow/pull/27837#discussion_r279043246,tanzhenyu,2019-04-26 17:44:03,27657,27837,Documentation bug,0,we really don't need that many digits here.,-1
"`batch_util::MaybeMoveSliceToElement` is also missing these cases, I didn't add them here because I haven't verified it's ok",PrComment,https://github.com/tensorflow/tensorflow/pull/28776#discussion_r284851141,BryanCutler,2019-05-16 18:54:38,28775,28776,Data bug,1,"[code] is also missing these cases, I didn't add them here because I haven't verified it's ok",-1
You can go ahead and add them there too. Thanks.,PrComment,https://github.com/tensorflow/tensorflow/pull/28776#discussion_r285778950,jsimsa,2019-05-20 21:40:33,28775,28776,Data bug,1,You can go ahead and add them there too. Thanks.,3
You can verify that this works by adding a test to `unbatch_test.py` that uses uint32 / uint64 elements.,PrComment,https://github.com/tensorflow/tensorflow/pull/28776#discussion_r285779265,jsimsa,2019-05-20 21:41:47,28775,28776,Data bug,1,You can verify that this works by adding a test to [code] that uses uint32 / uint64 elements.,0
"In addition to the test here, could you also add a Python-level test to `from_tensor_slices_test.py`? Thanks.",PrComment,https://github.com/tensorflow/tensorflow/pull/28776#discussion_r285779384,jsimsa,2019-05-20 21:42:19,28775,28776,Data bug,1,"In addition to the test here, could you also add a Python-level test to [code]? Thanks.",2
"sure, will do",PrComment,https://github.com/tensorflow/tensorflow/pull/28776#discussion_r285782191,BryanCutler,2019-05-20 21:53:19,28775,28776,Data bug,1,"sure, will do",2
done,PrComment,https://github.com/tensorflow/tensorflow/pull/28776#discussion_r286822423,BryanCutler,2019-05-23 08:04:50,28775,28776,Data bug,1,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/28776#discussion_r286822467,BryanCutler,2019-05-23 08:04:59,28775,28776,Data bug,1,done,0
"Use array_ops.shape(op.inputs[0], out_type=dtypes.int64) instead of an explicit cast.

Also don't use `ops.dtypes`, just import the dtypes module here (we don't want to depend on what modules are imported by another module).",PrComment,https://github.com/tensorflow/tensorflow/pull/29815#discussion_r294373736,alextp,2019-06-17 16:04:19,11651,29815,Algorithm design bug,0,"Use array_ops.shape(op.inputs[0], out_type=dtypes.int64) instead of an explicit cast. Also don't use [code], just import the dtypes module here (we don't want to depend on what modules are imported by another module).",0
Same shape and dtype commentds apply here,PrComment,https://github.com/tensorflow/tensorflow/pull/29815#discussion_r294373811,alextp,2019-06-17 16:04:31,11651,29815,Algorithm design bug,0,Same shape and dtype commentds apply here,0
Thank you for your comment. I corrected the code as instructed.,PrComment,https://github.com/tensorflow/tensorflow/pull/29815#discussion_r294553881,lioutasb,2019-06-17 23:13:51,11651,29815,Algorithm design bug,0,Thank you for your comment. I corrected the code as instructed.,3
Thank you for your comment. I corrected the code as instructed.,PrComment,https://github.com/tensorflow/tensorflow/pull/29815#discussion_r294553915,lioutasb,2019-06-17 23:13:58,11651,29815,Algorithm design bug,0,Thank you for your comment. I corrected the code as instructed.,3
Please remove debug print,PrComment,https://github.com/tensorflow/tensorflow/pull/29815#discussion_r294999172,alextp,2019-06-18 19:53:33,11651,29815,Algorithm design bug,0,Please remove debug print,0
"I see the same print used earlier [here](https://github.com/tensorflow/tensorflow/blob/e67dc75850fe3a54071fdd9db6ad91906ad51797/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py#L104), should I remove that as well?",PrComment,https://github.com/tensorflow/tensorflow/pull/29815#discussion_r295003548,lioutasb,2019-06-18 20:04:37,11651,29815,Algorithm design bug,0,"I see the same print used earlier [here]([url]#L104), should I remove that as well?",0
Done,PrComment,https://github.com/tensorflow/tensorflow/pull/29815#discussion_r295065545,lioutasb,2019-06-18 23:12:17,11651,29815,Algorithm design bug,0,Done,0
"no reference to internal symbols, just say tf.InvalidArgumentError",PrComment,https://github.com/tensorflow/tensorflow/pull/29985#discussion_r295836219,alextp,2019-06-20 14:34:04,29276,29985,Documentation bug,0,"no reference to internal symbols, just say tf.InvalidArgumentError",0
@alextp Thanks. The PR has been updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/29985#discussion_r295873342,yongtang,2019-06-20 15:47:37,29276,29985,Documentation bug,0,@alextp Thanks. The PR has been updated.,3
"I think it would actually be enough to just to swap `convert_to_tensor` for `cast` (since `cast` first applies `convert_to_tensor` then casts iff necessary):

```python
start = cast(start, dtype=dtype, name=""start"")
limit = cast(start, dtype=dtype, name=""limit"")
delta = cast(start, dtype=dtype, name=""delta"")
```",PrComment,https://github.com/tensorflow/tensorflow/pull/29987#discussion_r296319949,tomhennigan,2019-06-21 17:08:31,29867,29987,Data bug,0,I think it would actually be enough to just to swap [code] for [code] (since [code] first applies [code] then casts iff necessary): ``[code]``,0
@tomhennigan Thanks. The PR has been updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/29987#discussion_r305532059,yongtang,2019-07-19 21:36:21,29867,29987,Data bug,0,@tomhennigan Thanks. The PR has been updated.,3
Please pass a name into these casts too :),PrComment,https://github.com/tensorflow/tensorflow/pull/29987#discussion_r305590588,tomhennigan,2019-07-20 19:35:19,29867,29987,Data bug,0,Please pass a name into these casts too :),2
Can we use assert_is_compatible_with instead of try catch?,PrComment,https://github.com/tensorflow/tensorflow/pull/30053#discussion_r299246043,pavithrasv,2019-07-01 22:52:36,30040,30053,Algorithm design bug,0,Can we use assert_is_compatible_with instead of try catch?,0
Please remove comment.,PrComment,https://github.com/tensorflow/tensorflow/pull/30053#discussion_r299246164,pavithrasv,2019-07-01 22:53:03,30040,30053,Algorithm design bug,0,Please remove comment.,0
Thanks @pavithrasv. The PR has been updated with `assert_is_compatible_with`.,PrComment,https://github.com/tensorflow/tensorflow/pull/30053#discussion_r299286458,yongtang,2019-07-02 02:57:59,30040,30053,Algorithm design bug,0,Thanks @pavithrasv. The PR has been updated with [code].,3
@pavithrasv Update. Thanks.,PrComment,https://github.com/tensorflow/tensorflow/pull/30053#discussion_r299286490,yongtang,2019-07-02 02:58:11,30040,30053,Algorithm design bug,0,@pavithrasv Update. Thanks.,3
What is happening here? I don't understand why cleanup only needs to be called if other resources are not being cleared.,PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297324783,alextp,2019-06-25 18:12:26,29695,30102,Code bug,1,What is happening here? I don't understand why cleanup only needs to be called if other resources are not being cleared.,-1
"@jsimsa Thanks for adding @alextp for the review!

@alextp Yes, multiple resources can be cleaned in parallel by calling  [ResourceMgr::Cleanup()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/resource_mgr.cc#L220), which uses `tf_shared_lock`. The problem is that `ResourceMgr::Clear()` and `ResourceMgr::Cleanup()` can not be called at the same time.

In the above generator_data [case](https://github.com/tensorflow/tensorflow/pull/30102#issue-291325728), `ResourceMgr::Clear()` internally calls `ResourceMgr::Cleanup()` by `GeneratorDatasetOp::Dataset::Iterator::~Iterator()`. As [ResourceMgr::Clear()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/resource_mgr.cc#L110) uses `metex_lock`, it causes the deadlock with `ResourceMgr::Cleanup()`.

The function names in this PR may be confusing. What this PR wants to do is that if `ResourceMgr::Clear()` is running and `ResourceMgr::Cleanup()` is called somehow (e.g. a deconstructor runs some captured instantiated functions, which call `ResourceMgr::Cleanup()` inside), then the call of `ResourceMgr::Cleanup()` will be skipped. In my understanding, when `ResourceMgr::Clear()` is running, the resources can not be added, so it may be ok to skip the call of `ResourceMgr::Cleanup()`.",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297420883,feihugis,2019-06-25 22:34:16,29695,30102,Code bug,1,"@jsimsa Thanks for adding @alextp for the review! @alextp Yes, multiple resources can be cleaned in parallel by calling [ResourceMgr::Cleanup()]([url]#L220), which uses [code]. The problem is that [code] and [code] can not be called at the same time. In the above generator_data [case]([url]#issue-291325728), [code] internally calls [code] by [code]. As [ResourceMgr::Clear()]([url]#L110) uses [code], it causes the deadlock with [code]. The function names in this PR may be confusing. What this PR wants to do is that if [code] is running and [code] is called somehow (e.g. a deconstructor runs some captured instantiated functions, which call [code] inside), then the call of [code] will be skipped. In my understanding, when [code] is running, the resources can not be added, so it may be ok to skip the call of [code].",0
"Ok I think the thing I do not understand is why do we need to call cleanup here at all, instead of just removing a particular resource.",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297713237,alextp,2019-06-26 14:55:39,29695,30102,Code bug,1,"Ok I think the thing I do not understand is why do we need to call cleanup here at all, instead of just removing a particular resource.",0
"@alextp Could you please give more explanation about ""just removing a particular resource""? 

`CleanUp()` is called here to remove the resources used when running the instantiated function. It is necessary to call `CleanUp()` for the normal cases (where the iterator of generator dataset reaches the end of sequence), since `ResourceMgr::Clear()` will not be called. For the special case mentioned above (the iterator does not reach the end of sequence and `ResourceMgr::Clear()` is called by session close()), we do not need to call `ResourceMgr::Cleanup()`. 

Basically, this PR wants to make `InstantiatedCapturedFunction::RunInstantiated()` handle this special case and also work on normal cases. I'm not sure if this kind of deadlock will happen somewhere else. If the change of ResourceMgr here does not make too much sense to other codes, I can try another approach. For example, `InstantiatedCapturedFunction::RunInstantiated(
    const std::vector<Tensor>& args, std::vector<Tensor>* rets)` is only used by `GeneratorDatasetOp::Dataset`, so we can change this function to handle the special case with no need of changing `ResourceMgr`.",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297835632,feihugis,2019-06-26 19:42:57,29695,30102,Code bug,1,"@alextp Could you please give more explanation about ""just removing a particular resource""? [code] is called here to remove the resources used when running the instantiated function. It is necessary to call [code] for the normal cases (where the iterator of generator dataset reaches the end of sequence), since [code] will not be called. For the special case mentioned above (the iterator does not reach the end of sequence and [code] is called by session close()), we do not need to call [code]. Basically, this PR wants to make [code] handle this special case and also work on normal cases. I'm not sure if this kind of deadlock will happen somewhere else. If the change of ResourceMgr here does not make too much sense to other codes, I can try another approach. For example, [code] is only used by [code], so we can change this function to handle the special case with no need of changing [code].",0
"So cleanup takes a container name. Why do we have to clear an entire container instead of deleting a few specific resources?

This is what confuses me here.",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297868920,alextp,2019-06-26 21:12:21,29695,30102,Code bug,1,So cleanup takes a container name. Why do we have to clear an entire container instead of deleting a few specific resources? This is what confuses me here.,-2
"In my understanding, the container (`ScopedStepContainer`) here is used for per-step resources. Once this step finishes, all resources in this step need to be removed.  ",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297877695,feihugis,2019-06-26 21:38:41,29695,30102,Code bug,1,"In my understanding, the container ([code]) here is used for per-step resources. Once this step finishes, all resources in this step need to be removed.",0
Do we still need the per-step container?,PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297881756,alextp,2019-06-26 21:51:27,29695,30102,Code bug,1,Do we still need the per-step container?,0
"If we do, the right fix is to store somewhere that we need to run a cleanup operation and run it after we release the mutex.",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297882011,alextp,2019-06-26 21:52:19,29695,30102,Code bug,1,"If we do, the right fix is to store somewhere that we need to run a cleanup operation and run it after we release the mutex.",0
"@alextp Thanks for the explanation! Got it now and I will try to implement the fix you suggest.
@jsimsa may know whether we need the per-step container here.",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r297890261,feihugis,2019-06-26 22:22:33,29695,30102,Code bug,1,@alextp Thanks for the explanation! Got it now and I will try to implement the fix you suggest. @jsimsa may know whether we need the per-step container here.,3
"Looking at the code base, `ScopedStepContainer` is used by ops that create resources whose life-time is scoped within a step and the method that is passed to the `ScopedStepContainer` constructor is used to cleanup these resources. However, the argument to the cleanup method is that name of the container (so that all resources it contains are cleaned up), not a resource handle.

It seems that the `ResourceMgr::Clear` does not expect that a destructor it triggers could in turn call methods on the `ResourceMgr` object.

I think a better way to fix this problem would be to modify `Clear` to move the contents of `containers_` to a temporary local variable under the mutex (and then perform that actual unref-ing and deallocation without holding the lock).",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r298299873,jsimsa,2019-06-27 17:58:53,29695,30102,Code bug,1,"Looking at the code base, [code] is used by ops that create resources whose life-time is scoped within a step and the method that is passed to the [code] constructor is used to cleanup these resources. However, the argument to the cleanup method is that name of the container (so that all resources it contains are cleaned up), not a resource handle. It seems that the [code] does not expect that a destructor it triggers could in turn call methods on the [code] object. I think a better way to fix this problem would be to modify [code] to move the contents of [code] to a temporary local variable under the mutex (and then perform that actual unref-ing and deallocation without holding the lock).",0
+1. Thanks @jsimsa! Will work it.,PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r298314001,feihugis,2019-06-27 18:34:19,29695,30102,Code bug,1,+1. Thanks @jsimsa! Will work it.,5
"IMHO, comments like this one tend to become obsolete over time at which point they add little value (and potentially cause confusion).

I would simply say here that the we do the deallocation outside of the lock to avoid a potential deadlock in case any of the destructors access the resource manager.",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r298399442,jsimsa,2019-06-27 22:51:36,29695,30102,Code bug,1,"IMHO, comments like this one tend to become obsolete over time at which point they add little value (and potentially cause confusion). I would simply say here that the we do the deallocation outside of the lock to avoid a potential deadlock in case any of the destructors access the resource manager.",0
"Why do you create a copy here? When I suggested you move it, I meant the following:

```
void ResourceMgr::Clear() {
  std::unordered_map<string, Container*> tmp_containers;
  {
    mutex_lock l(mu_);
    tmp_containers = std::move(containers_);
  }
  for (const auto& p : tmp_containers) {
    for (const auto& q : *p.second) {
      q.second->Unref();
    }
    delete p.second;
  }
  tmp_containers.clear();
}
```",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r298400021,jsimsa,2019-06-27 22:54:26,29695,30102,Code bug,1,"Why do you create a copy here? When I suggested you move it, I meant the following: ``[code]``",-1
"Yes, this is better. Will change it. Thanks for the detailed codes!",PrComment,https://github.com/tensorflow/tensorflow/pull/30102#discussion_r298407737,feihugis,2019-06-27 23:33:31,29695,30102,Code bug,1,"Yes, this is better. Will change it. Thanks for the detailed codes!",4
"It looks like we should have also watched complex types here?
(context: https://github.com/tensorflow/tensorflow/issues/32774)",PrComment,https://github.com/tensorflow/tensorflow/pull/30107#discussion_r336323652,rryan,2019-10-18 05:19:16,28248,30107,Data bug,0,It looks like we should have also watched complex types here? (context: [url],0
This had been fixed in 507325c5b3fa5943485f3f994048fe7683e0f95d,PrComment,https://github.com/tensorflow/tensorflow/pull/30107#discussion_r341666972,jaingaurav,2019-11-01 17:11:55,28248,30107,Data bug,0,This had been fixed in 507325c5b3fa5943485f3f994048fe7683e0f95d,0
probably skip the dict check and use nest.flatten(vals)[0].shape[0] here.,PrComment,https://github.com/tensorflow/tensorflow/pull/30258#discussion_r301213747,qlzh727,2019-07-08 17:28:43,30122,30258,Version compatibility bug,0,probably skip the dict check and use nest.flatten(vals)[0].shape[0] here.,0
Should be test_dict_validation_input(),PrComment,https://github.com/tensorflow/tensorflow/pull/30258#discussion_r301213952,qlzh727,2019-07-08 17:29:13,30122,30258,Version compatibility bug,0,Should be test_dict_validation_input(),0
"I don't see the reason to mock the output, are u trying to validate any output here?",PrComment,https://github.com/tensorflow/tensorflow/pull/30258#discussion_r301214362,qlzh727,2019-07-08 17:30:08,30122,30258,Version compatibility bug,0,"I don't see the reason to mock the output, are u trying to validate any output here?",-1
"Thanks @qlzh727, the PR has been updated.",PrComment,https://github.com/tensorflow/tensorflow/pull/30258#discussion_r301823759,yongtang,2019-07-09 22:44:13,30122,30258,Version compatibility bug,0,"Thanks @qlzh727, the PR has been updated.",3
Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/30258#discussion_r301823842,yongtang,2019-07-09 22:44:33,30122,30258,Version compatibility bug,0,Updated.,0
Thanks for the comment. Removed.,PrComment,https://github.com/tensorflow/tensorflow/pull/30258#discussion_r301823926,yongtang,2019-07-09 22:44:53,30122,30258,Version compatibility bug,0,Thanks for the comment. Removed.,2
"The old implementation will break in the following case:
1. Finish the iteration of `FileWriterIterator` and save it using `SaveInternal()`
2. When restoring `FileIterator`, `FileIterator::RestoreInternal()` will create a `FileReaderIterator` instead of `FileWriterIterator`, but it is still restored based on the serialized data at the first step. 
3. Currently, the saving order in `FileWriterIterator::SaveInternal()` does not match with `FileReaderIterator::RestoreInternal()`.

This change makes `cur_index_ ` be saved before other elements in order to be compatible with [FileReaderIterator:: RestoreInternal()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/cache_dataset_ops.cc#L507). ",PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r304674358,feihugis,2019-07-17 22:51:50,28798,30825,Code bug,1,"The old implementation will break in the following case: 1. Finish the iteration of [code] and save it using [code] 2. When restoring [code], [code] will create a [code] instead of [code], but it is still restored based on the serialized data at the first step. 3. Currently, the saving order in [code] does not match with [code]. This change makes [code] be saved before other elements in order to be compatible with [FileReaderIterator:: RestoreInternal()]([url]#L507).",0
can we log a warning if this fails?,PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r304697297,aaudiber,2019-07-18 00:51:35,28798,30825,Code bug,1,can we log a warning if this fails?,0
same here,PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r304697311,aaudiber,2019-07-18 00:51:40,28798,30825,Code bug,1,same here,0
does this not work in graph mode?,PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r304722899,aaudiber,2019-07-18 03:36:39,28798,30825,Code bug,1,does this not work in graph mode?,0
Great find! Can we add a test case to prevent this bug from happening again?,PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r304723386,aaudiber,2019-07-18 03:40:07,28798,30825,Code bug,1,Great find! Can we add a test case to prevent this bug from happening again?,3
"Yeah, the enhanced Roundtrip test ([here](https://github.com/tensorflow/tensorflow/blob/80223ea8a01718df61891fc8a23645fc02829edc/tensorflow/core/kernels/data/cache_dataset_ops_test.cc#L463)) has covered this case now by adding [more breakpoints](https://github.com/tensorflow/tensorflow/pull/30825/files#diff-7def5e1766c22b54ae33c7479b478a9cR105). When `breakpoint` < `cardinality`, the restored iterator will be `FileWriterIterator`; When `breakpoint` > `cardinality`,  the restored iterator will be `FileReaderIterator `. ",PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r305028609,feihugis,2019-07-18 17:17:54,28798,30825,Code bug,1,"Yeah, the enhanced Roundtrip test ([here]([url]#L463)) has covered this case now by adding [more breakpoints]([url]#diff-7def5e1766c22b54ae33c7479b478a9cR105). When [code] < [code], the restored iterator will be [code]; When [code] > [code], the restored iterator will be [code].",2
"This test case does not work in graph mode. If I understand correctly, the failure may be expected, because the iterator resource is still held when the iteration is not finished and the iterator deconstructor can not be triggered. The error message is in below.
```
There appears to be a concurrent caching iterator running - cache lockfile already exists ('/var/folders/44/dzfy03t93h990mbh3qjy3pjm0000gn/T/tmp6bpwffxz/cache_0.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1563470964
``` ",PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r305036490,feihugis,2019-07-18 17:37:45,28798,30825,Code bug,1,"This test case does not work in graph mode. If I understand correctly, the failure may be expected, because the iterator resource is still held when the iteration is not finished and the iterator deconstructor can not be triggered. The error message is in below. ``[code]``",-2
"Sure, will do.",PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r305039797,feihugis,2019-07-18 17:45:57,28798,30825,Code bug,1,"Sure, will do.",2
Can we also add a comment that the output of `FileWriterIterator::SaveInternal` needs to be readable by both `FileWriterIterator::RestoreInternal` as well as `FileReaderIterator::RestoreInternal`?,PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r305145338,aaudiber,2019-07-18 22:52:44,28798,30825,Code bug,1,Can we also add a comment that the output of [code] needs to be readable by both [code] as well as [code]?,0
why do we need this destructor now but we didn't need it before?,PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r305145781,aaudiber,2019-07-18 22:54:40,28798,30825,Code bug,1,why do we need this destructor now but we didn't need it before?,0
"Got it, makes sense. Can we update the check to
```python
if not context.executing_eagerly():
  self.skipTest(""Test requires eager mode for iterators to be deconstructed"")

for i in [0, 3, 10, 12, 15]:
  do_test(i)
```",PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r305147314,aaudiber,2019-07-18 23:01:38,28798,30825,Code bug,1,"Got it, makes sense. Can we update the check to ``[code]``",1
"got it, thanks",PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r305147451,aaudiber,2019-07-18 23:02:12,28798,30825,Code bug,1,"got it, thanks",2
"I did not realize the potential issue before. If we do not delete the cache files for each `TEST_P`, the next `TEST_P` will use the cache files generated by the previous `TEST_P` and then the iterator will be in the `Read` mode. For example, without deleting the cache files, `TEST_P(ParameterizedCacheDatasetOpTest, Roundtrip)` will always run in the `Read` mode as the cache files have already been generated by previous tests. ",PrComment,https://github.com/tensorflow/tensorflow/pull/30825#discussion_r305151991,feihugis,2019-07-18 23:23:24,28798,30825,Code bug,1,"I did not realize the potential issue before. If we do not delete the cache files for each [code], the next [code] will use the cache files generated by the previous [code] and then the iterator will be in the [code] mode. For example, without deleting the cache files, [code] will always run in the [code] mode as the cache files have already been generated by previous tests.",-1
"Since we only use file reading (and not writing) functionality, `file_io_fn` can be a single argument function that takes in just the filename?
`file_io_fn = lambda filename: file_io.FileIO(filename, 'r')` here and
`file_io_fn = lambda filename: gzip.GzipFile(filename, 'rt')`  below?

and in the relevant functions above:
`with file_io_fn(filename) as f:`",PrComment,https://github.com/tensorflow/tensorflow/pull/30867#discussion_r306894485,rachellim,2019-07-24 16:03:49,30849,30867,Data bug,0,"Since we only use file reading (and not writing) functionality, [code] can be a single argument function that takes in just the filename? [code] here and [code] below? and in the relevant functions above: [code]",0
"Thanks @rachellim, PR has been updated.",PrComment,https://github.com/tensorflow/tensorflow/pull/30867#discussion_r306920149,yongtang,2019-07-24 17:02:15,30849,30867,Data bug,0,"Thanks @rachellim, PR has been updated.",3
Wouldn't a simpler fix be just to pass name=name to identity?,PrComment,https://github.com/tensorflow/tensorflow/pull/31145#discussion_r308429985,alextp,2019-07-29 20:47:06,31137,31145,Data bug,0,Wouldn't a simpler fix be just to pass name=name to identity?,0
"Thanks @alextp, indeed that should fix the issue. The PR has been updated.",PrComment,https://github.com/tensorflow/tensorflow/pull/31145#discussion_r308446629,yongtang,2019-07-29 21:31:16,31137,31145,Data bug,0,"Thanks @alextp, indeed that should fix the issue. The PR has been updated.",3
Actually why is this changed?,PrComment,https://github.com/tensorflow/tensorflow/pull/31918#discussion_r339792835,frankchn,2019-10-28 21:06:32,31843,31918,Build bug,0,Actually why is this changed?,0
"If both SDK and NDK are missing, I decided to add just pass statement instead of nothing.
I guess it might not be necessary, and empty function would work too",PrComment,https://github.com/tensorflow/tensorflow/pull/31918#discussion_r339814585,DoumanAsh,2019-10-28 22:06:10,31843,31918,Build bug,0,"If both SDK and NDK are missing, I decided to add just pass statement instead of nothing. I guess it might not be necessary, and empty function would work too",0
"> Here is the internal error we are getting , can you please check this.
/third_party/tensorflow/lite/experimental/micro/memory_planner/greedy_memory_planner.h:19:10: fatal error: 'third_party/tensorflow/lite/experimental/micro/compatibility.h' file not found
#include ""third_party/tensorflow/lite/experimental/micro/compatibility.h""
cc @petewarden @wangtz",PrComment,https://github.com/tensorflow/tensorflow/pull/32417#discussion_r348909766,gbaned,2019-11-21 06:10:38,32416,32417,Memory bug,0,"> Here is the internal error we are getting , can you please check this. /third_party/tensorflow/lite/experimental/micro/memory_planner/greedy_memory_planner.h:19:10: fatal error: 'third_party/tensorflow/lite/experimental/micro/compatibility.h' file not found #include ""third_party/tensorflow/lite/experimental/micro/compatibility.h"" cc @petewarden @wangtz",0
"I believe the fix here should be to replace lines 226-234 with:

```python
if isinstance(loss_config, dict) and 'class_name' in loss_config:
  loss = losses.deserialize(loss_config, custom_objects)
else:
  loss = nest.map_structure(
    lambda obj: losses.deserialize(obj, custom_objects),
    loss_config)

metrics_config = training_config['metrics']
if isinstance(metrics_config, dict) and 'class_name' in metrics_config:
  metrics = metrics.deserialize(metrics_config, custom_objects)
else:
  metrics = nest.map_structure(
    lambda obj: metrics.deserialize(obj, custom_objects)
    metrics_config)

weighted_metrics_config = training_config['weighted_metrics']
if isinstance(weighted_metrics_config, dict) and 'class_name' in weighted_metrics_config:
  weighted_metrics = metrics.deserialize(weighted_metrics_config, custom_objects)
else:
  weighted_metrics = nest.map_structure(
    lambda obj: metrics.deserialize(obj, custom_objects),
    weighted_metrics_config)
```

Could you please make these changes and confirm this works for your use case?",PrComment,https://github.com/tensorflow/tensorflow/pull/33229#discussion_r344871572,omalleyt12,2019-11-11 19:27:29,32612,33229,Deployment bug,0,I believe the fix here should be to replace lines 226-234 with: ``[code]`` Could you please make these changes and confirm this works for your use case?,0
"Please see the below comment, I think this change is not needed",PrComment,https://github.com/tensorflow/tensorflow/pull/33229#discussion_r344871718,omalleyt12,2019-11-11 19:27:45,32612,33229,Deployment bug,0,"Please see the below comment, I think this change is not needed",-1
"thanks @omalleyt12 
will do.",PrComment,https://github.com/tensorflow/tensorflow/pull/33229#discussion_r345009169,thierryherrmann,2019-11-12 04:02:43,32612,33229,Deployment bug,0,thanks @omalleyt12 will do.,3
"`google3.third_party` can be removed.
from tensorflow.python.keras import metrics as metrics_module  # pylint:disable=g-import-not-at-top",PrComment,https://github.com/tensorflow/tensorflow/pull/33229#discussion_r357478703,pavithrasv,2019-12-13 04:10:30,32612,33229,Deployment bug,0,[code] can be removed. from tensorflow.python.keras import metrics as metrics_module # pylint:disable=g-import-not-at-top,0
"`FAIL: Found 1 non-whitelisted pylint errors:
tensorflow/python/keras/engine/training_v2.py:260: [C0301(line-too-long), ] Line too long (86/80)`
can you please check this lint error",PrComment,https://github.com/tensorflow/tensorflow/pull/33610#discussion_r339180789,rthadur,2019-10-25 18:20:44,33216,33610,Algorithm design bug,0,[code] can you please check this lint error,0
"Hi! Sorry for the late reply. Added some line-breaks according to Google Style Guide, hope it's good now. ",PrComment,https://github.com/tensorflow/tensorflow/pull/33610#discussion_r341110877,angeliand,2019-10-31 12:34:16,33216,33610,Algorithm design bug,0,"Hi! Sorry for the late reply. Added some line-breaks according to Google Style Guide, hope it's good now.",3
"`FAIL: Found 1 non-whitelisted pylint errors:
tensorflow/python/kernel_tests/string_split_op_test.py:362: [W0622(redefined-builtin), StringSplitV2OpTest.testSplitV1] Redefining built-in 'input'



=== Sanity check step 3 of 15: do_pylint PYTHON3 (Python 3 pylint) ===`",PrComment,https://github.com/tensorflow/tensorflow/pull/33625#discussion_r346523769,rthadur,2019-11-14 20:13:03,33623,33625,Data bug,0,[code],0
"can you please fix this sanity errors ? 
link: https://source.cloud.google.com/results/invocations/f0c921f7-3aa0-4705-aa15-661c770c53e0/log",PrComment,https://github.com/tensorflow/tensorflow/pull/33625#discussion_r346524044,rthadur,2019-11-14 20:13:43,33623,33625,Data bug,0,can you please fix this sanity errors ? link: [url],-1
Changed.@rthadur,PrComment,https://github.com/tensorflow/tensorflow/pull/33625#discussion_r347119024,fsx950223,2019-11-17 05:47:12,33623,33625,Data bug,0,Changed.@rthadur,0
Can you change the test to `(out_type_ == DT_COMPLEX64) || (out_type_ == DT_COMPLEX128)` in order to avoid the string conversion?,PrComment,https://github.com/tensorflow/tensorflow/pull/33816#discussion_r344930477,jaingaurav,2019-11-11 22:03:31,33496,33816,Test bug,1,Can you change the test to [code] in order to avoid the string conversion?,0
"Corrected, Thank you!",PrComment,https://github.com/tensorflow/tensorflow/pull/33816#discussion_r345124978,namrata-ibm,2019-11-12 10:27:43,33496,33816,Test bug,1,"Corrected, Thank you!",3
This could be `*end_of_sequence |= end_of_sequence_component`,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341224315,jsimsa,2019-10-31 15:59:04,33383,33887,Data bug,1,This could be [code],0
This could be `status.Update(status_component)`.,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341224510,jsimsa,2019-10-31 15:59:23,33383,33887,Data bug,1,This could be [code].,0
nit: rename `end_of_sequence_component` to `component_end_of_sequence`,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341224755,jsimsa,2019-10-31 15:59:47,33383,33887,Data bug,1,nit: rename [code] to [code],0
nit: rename `status_component` to `component_status`,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341224913,jsimsa,2019-10-31 16:00:04,33383,33887,Data bug,1,nit: rename [code] to [code],0
I don't think you need to do the flush for `*end_of_sequence == true`.,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341225742,jsimsa,2019-10-31 16:01:24,33383,33887,Data bug,1,I don't think you need to do the flush for [code].,0
"This comment should be updated to:

```
// Even if an error is encountered for one of the components, we need to make sure
// to advance all components, to keep them in sync.",PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341292016,jsimsa,2019-10-31 18:08:31,33383,33887,Data bug,1,"This comment should be updated to: ``` // Even if an error is encountered for one of the components, we need to make sure // to advance all components, to keep them in sync.",0
Thanks @jsimsa! Yes there is no need to flush the remaining components when EOF is reached.,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341382427,yongtang,2019-10-31 21:55:20,33383,33887,Data bug,1,Thanks @jsimsa! Yes there is no need to flush the remaining components when EOF is reached.,3
You don't need the if statement. `status.Update(component_status)` only updates `status` if it is OK.,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341384938,jsimsa,2019-10-31 22:03:54,33383,33887,Data bug,1,You don't need the if statement. [code] only updates [code] if it is OK.,0
indentation seems off here,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341385018,jsimsa,2019-10-31 22:04:10,33383,33887,Data bug,1,indentation seems off here,-1
@jsimsa Thanks! Didn't know this usage before. Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341389727,yongtang,2019-10-31 22:21:23,33383,33887,Data bug,1,@jsimsa Thanks! Didn't know this usage before. Updated.,3
Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341389775,yongtang,2019-10-31 22:21:35,33383,33887,Data bug,1,Updated.,0
"This could be further simplified to:

```
status.Update(input_impl->GetNext(ctx, &input_tensors, &component_end_of_sequence));
*end_of_sequence |= component_end_of_sequence;
```",PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341396514,jsimsa,2019-10-31 22:48:35,33383,33887,Data bug,1,This could be further simplified to: ``[code]``,0
Thanks @jsimsa! This looks even better.,PrComment,https://github.com/tensorflow/tensorflow/pull/33887#discussion_r341406069,yongtang,2019-10-31 23:33:09,33383,33887,Data bug,1,Thanks @jsimsa! This looks even better.,5
"`FAIL: Found 1 non-whitelisted pylint errors:
tensorflow/python/ops/collective_ops_test.py:359: [C0301(line-too-long), ] Line too long (95/80)`
can you please fix this ?",PrComment,https://github.com/tensorflow/tensorflow/pull/34295#discussion_r347026474,rthadur,2019-11-15 21:53:24,34250,34295,Data bug,1,[code] can you please fix this ?,0
lol cool sorry fixed,PrComment,https://github.com/tensorflow/tensorflow/pull/34295#discussion_r347028680,pengwu22,2019-11-15 22:00:10,34250,34295,Data bug,1,lol cool sorry fixed,3
"nit: can you rename these variables to be more descriptive?  Perhaps `input0, input1, expected_output0, expected_output1`.",PrComment,https://github.com/tensorflow/tensorflow/pull/34295#discussion_r347047772,dubey,2019-11-15 23:13:05,34250,34295,Data bug,1,nit: can you rename these variables to be more descriptive? Perhaps [code].,1
done,PrComment,https://github.com/tensorflow/tensorflow/pull/34295#discussion_r347055984,pengwu22,2019-11-15 23:55:20,34250,34295,Data bug,1,done,0
"I don't think it is great to call `create_autocast_variable()` here, but `self.__class__()`, `AutoCastVariable()` or `super(AutoCastVariable, self).__init__()` would not work for distributed variables since either inheritance is wrong or since `__init__()` would expect different arguments.",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r352953640,lgeiger,2019-12-03 02:08:07,34332,34779,Data bug,0,"I don't think it is great to call [code] here, but [code], [code] or [code] would not work for distributed variables since either inheritance is wrong or since [code] would expect different arguments.",-2
I think subclasses just have to override this. We shouldn't enforce a contract on how to initialize subclasses.,PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353381073,alextp,2019-12-03 19:36:26,34332,34779,Data bug,0,I think subclasses just have to override this. We shouldn't enforce a contract on how to initialize subclasses.,0
"I agree. Thinking about this again, it is not too bad after all :+1:",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353403694,lgeiger,2019-12-03 20:24:53,34332,34779,Data bug,0,"I agree. Thinking about this again, it is not too bad after all :+1:",3
"This will fail with DistributionStrategy with at least two devices. The issue is that `MirroredVariable.assign` will (incorrectly) return a `Mirrored` value instead of a `MirroredVariable`. Following the logic, I think MirroredVariable eventually returns a `Mirrored` [here](https://github.com/tensorflow/tensorflow/blob/147de48ad973a6a05e8113af815988014652caf2/tensorflow/python/distribute/values.py#L1637). I'm guessing that with one device, it simply will return a normal non-mirrored variable.

To reproduce, on [this line](https://github.com/tensorflow/tensorflow/blob/147de48ad973a6a05e8113af815988014652caf2/tensorflow/python/keras/mixed_precision/experimental/autocast_variable_test.py#L64), change `['cpu:0']` to `['cpu:0', 'gpu:0']`. Since you do not have a GPU, also add the following two lines to the top of the file:

```
from tensorflow.python.framework import config
config.set_soft_device_placement(True)
```

Unfortunately, soft placement seems to be broken in Eager mode (I'll ask internally to get this resolved), but the graph test is running first so you'll be able to reproduce the issue. If you can get it to pass in graph mode, chances are it will pass in eager.

I can't think of an elegant way of fixing this, unfortunately. I think for now, you should simply return `assign_op` if it is `Mirrored` (or perhaps if `not resource_variable_ops.is_resource_variable(assign_op)`). This means #34332 won't be fixed in the distributed case for now, but that can be addressed later. Let me know if you can think of a better solution. 

In the long term, we can fix this by having DistributionStrategy return a MirroredVariable instead of Mirrored from MirroredVariable.assign(). @guptapriya can you work on that?",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353481035,reedwm,2019-12-03 23:39:58,34332,34779,Data bug,0,"This will fail with DistributionStrategy with at least two devices. The issue is that [code] will (incorrectly) return a [code] value instead of a [code]. Following the logic, I think MirroredVariable eventually returns a [code] [here]([url]#L1637). I'm guessing that with one device, it simply will return a normal non-mirrored variable. To reproduce, on [this line]([url]#L64), change [code] to [code]. Since you do not have a GPU, also add the following two lines to the top of the file: ``[code]`[code]assign_op[code]Mirrored[code]not resource_variable_ops.is_resource_variable(assign_op)`). This means #34332 won't be fixed in the distributed case for now, but that can be addressed later. Let me know if you can think of a better solution. In the long term, we can fix this by having DistributionStrategy return a MirroredVariable instead of Mirrored from MirroredVariable.assign(). @guptapriya can you work on that?",-1
"You should also test that you can assign the return value of `x.assign(8)`. And that if you pass `read_value=False`, the return value is an Operation or None instead of a variable.

I would move the `assign`, `assign_add`, and `assign_sub` calls to a new test method as well.",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353481496,reedwm,2019-12-03 23:41:39,34332,34779,Data bug,0,"You should also test that you can assign the return value of [code]. And that if you pass [code], the return value is an Operation or None instead of a variable. I would move the [code], [code], and [code] calls to a new test method as well.",0
:+1: I added the tests in c87a0e20d31cccd70a0f1c9687221b45066786fa,PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353495825,lgeiger,2019-12-04 00:33:50,34332,34779,Data bug,0,:+1: I added the tests in c87a0e20d31cccd70a0f1c9687221b45066786fa,5
"I see, thanks for the help debugging this.

> I can't think of an elegant way of fixing this, unfortunately.

Probably a dumb question, but is there a reason why we cannot allow `AutoCastVariable` to also wrap `Mirrored` and loosen the `is_resource_variable` check?",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353505160,lgeiger,2019-12-04 01:11:09,34332,34779,Data bug,0,"I see, thanks for the help debugging this. > I can't think of an elegant way of fixing this, unfortunately. Probably a dumb question, but is there a reason why we cannot allow [code] to also wrap [code] and loosen the [code] check?",1
"The issue is `AutoCastVariable` subclasses from `tf.Variable` so it doesn't make sense to wrap `Mirrored`. It also defines many assignment methods.

We could create a base class, say `AutoCastTensor`, that could wrap Mirrored. `AutoCastVariable` would then subclass `AutoCastTensor` and `tf.Variable`. But this introduces complexity that I'd rather avoid. Fixing this by having MirroredVariable.assign return a MirroredVariable is a better solution.",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353508739,reedwm,2019-12-04 01:26:53,34332,34779,Data bug,0,"The issue is [code] subclasses from [code] so it doesn't make sense to wrap [code]. It also defines many assignment methods. We could create a base class, say [code], that could wrap Mirrored. [code] would then subclass [code] and [code]. But this introduces complexity that I'd rather avoid. Fixing this by having MirroredVariable.assign return a MirroredVariable is a better solution.",1
"Makes sense, thanks for the explanation. I made the changes in 78fbe39329aaf4645c2a308eb805e3661e397bd3 to only wrap it if `is_resource_variable(assign_op) is True`.",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353657296,lgeiger,2019-12-04 10:20:24,34332,34779,Data bug,0,"Makes sense, thanks for the explanation. I made the changes in 78fbe39329aaf4645c2a308eb805e3661e397bd3 to only wrap it if [code].",3
"Move these three lines to a shared function, named something like _maybe_wrap. Also add a comment or docstring why this is necessary.",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r354092211,reedwm,2019-12-05 03:09:00,34332,34779,Data bug,0,"Move these three lines to a shared function, named something like _maybe_wrap. Also add a comment or docstring why this is necessary.",0
"I would also have the logic to not wrap here as well. Even though DistributedVariables currently don't support these scatter methods, they may add it in the future.",PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r354092819,reedwm,2019-12-05 03:12:17,34332,34779,Data bug,0,"I would also have the logic to not wrap here as well. Even though DistributedVariables currently don't support these scatter methods, they may add it in the future.",0
Good point. Made the changes in 109a41e4c324a0ebfb1206979f724d8116f916c1,PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r354474875,lgeiger,2019-12-05 18:25:45,34332,34779,Data bug,0,Good point. Made the changes in 109a41e4c324a0ebfb1206979f724d8116f916c1,2
@reedwm are you saying var.assign(..) should return a variable? that's not what tf.Variable docs say though: https://www.tensorflow.org/api_docs/python/tf/Variable#assign,PrComment,https://github.com/tensorflow/tensorflow/pull/34779#discussion_r354591826,guptapriya,2019-12-05 23:00:55,34332,34779,Data bug,0,@reedwm are you saying var.assign(..) should return a variable? that's not what tf.Variable docs say though: [url]#assign,0
"convert_to_tensor already is a no-op if the input is a tensor, so what is this doing?",PrComment,https://github.com/tensorflow/tensorflow/pull/35821#discussion_r366021255,alextp,2020-01-13 20:51:10,35710,35821,Version compatibility bug,0,"convert_to_tensor already is a no-op if the input is a tensor, so what is this doing?",0
We don't want to do this; TF likes to fail loudly when mixing dtypes as it's not obvious what is the user intent (and casts can always be inserted at the call site),PrComment,https://github.com/tensorflow/tensorflow/pull/35821#discussion_r366021534,alextp,2020-01-13 20:51:45,35710,35821,Version compatibility bug,0,We don't want to do this; TF likes to fail loudly when mixing dtypes as it's not obvious what is the user intent (and casts can always be inserted at the call site),-2
"Thanks @alextp for the review. In #35710 the case was that the `dtype` passed along with `tf.range(start, limit, delta, dtype) ` is different from the tensor of the `start`/`limit`/`delta`. In other words, the following:
```
tf.range(tf.constant(4, dtype=tf.int32), dtype=tf.int64)
```

In that case, `convert_to_tensor` will try to convert `tf.constant(4, dtype=tf.int32)` to `dtype=tf.int64` and that is returning an error. That is the issue from  #35710 .",PrComment,https://github.com/tensorflow/tensorflow/pull/35821#discussion_r366023997,yongtang,2020-01-13 20:57:28,35710,35821,Version compatibility bug,0,"Thanks @alextp for the review. In #35710 the case was that the [code] passed along with [code] is different from the tensor of the [code]/[code]/[code]. In other words, the following: ``[code]`[code]convert_to_tensor[code]tf.constant(4, dtype=tf.int32)[code]dtype=tf.int64` and that is returning an error. That is the issue from #35710 .",0
I believe this would also include quantized types but that is not included in TF_CALL_GPU_ALL_TYPES,PrComment,https://github.com/tensorflow/tensorflow/pull/35962#discussion_r368043494,jaingaurav,2020-01-17 17:09:32,35955,35962,Data bug,1,I believe this would also include quantized types but that is not included in TF_CALL_GPU_ALL_TYPES,0
Please set a non-zero imaginary part for complex data.,PrComment,https://github.com/tensorflow/tensorflow/pull/35962#discussion_r369135938,rmlarsen,2020-01-21 17:20:19,35955,35962,Data bug,1,Please set a non-zero imaginary part for complex data.,0
Thanks @rmlarsen. The PR has been updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/35962#discussion_r369266928,yongtang,2020-01-21 22:01:54,35955,35962,Data bug,1,Thanks @rmlarsen. The PR has been updated.,3
"Thanks for the change, can you move this to the backend_test.py under test_relu()",PrComment,https://github.com/tensorflow/tensorflow/pull/36037#discussion_r369292675,qlzh727,2020-01-21 23:08:26,35430,36037,Deployment bug,0,"Thanks for the change, can you move this to the backend_test.py under test_relu()",2
"The line including the drawing (line 29) needs to link to here: 

https://github.com/tensorflow/tensorflow/tree/3cfbf14e80a4b5feb9e1a786e02ff705b42f83ef/tensorflow/lite/g3doc/r1/images/convert (basically within the r1 directory instead of the main directory)",PrComment,https://github.com/tensorflow/tensorflow/pull/36157#discussion_r370279110,gargn,2020-01-23 18:19:42,36099,36157,Documentation bug,0,The line including the drawing (line 29) needs to link to here: [url] (basically within the r1 directory instead of the main directory),0
Fixed in 994b6defd9778eb1478977b8249a458bc35cb523.,PrComment,https://github.com/tensorflow/tensorflow/pull/36157#discussion_r370492500,z3dm4n,2020-01-24 06:46:23,36099,36157,Documentation bug,0,Fixed in 994b6defd9778eb1478977b8249a458bc35cb523.,0
"@ashutosh1919 can you please check this error 

`AttributeError: 'Tensor' object has no attribute 'numpy'
`",PrComment,https://github.com/tensorflow/tensorflow/pull/36364#discussion_r623194516,rthadur,2021-04-29 16:07:55,36359,36364,Version compatibility bug,0,@ashutosh1919 can you please check this error [code],0
"This is similar to what other modules like `initializers`, `losses`, etc. do.",PrComment,https://github.com/tensorflow/tensorflow/pull/36519#discussion_r375991894,hartikainen,2020-02-06 17:58:15,36518,36519,Deployment bug,0,"This is similar to what other modules like [code], [code], etc. do.",0
"Before you were also checking the error message. I would recommend checking that here too, using method of `tf.TestCase`",PrComment,https://github.com/tensorflow/tensorflow/pull/36597#discussion_r377768881,mihaimaruseac,2020-02-11 17:00:30,34947,36597,Data bug,0,"Before you were also checking the error message. I would recommend checking that here too, using method of [code]",1
"I have added that. Can you review it again, please?",PrComment,https://github.com/tensorflow/tensorflow/pull/36597#discussion_r377825966,rushabh-v,2020-02-11 18:44:43,34947,36597,Data bug,0,"I have added that. Can you review it again, please?",1
This should be sorted in alphabetical order for linter and code-style check.,PrComment,https://github.com/tensorflow/tensorflow/pull/37006#discussion_r383566785,byronyi,2020-02-24 23:03:26,35122,37006,Build bug,0,This should be sorted in alphabetical order for linter and code-style check.,0
Resolved.,PrComment,https://github.com/tensorflow/tensorflow/pull/37006#discussion_r383574553,njzjz,2020-02-24 23:25:38,35122,37006,Build bug,0,Resolved.,3
"Make sure you run pylint, the indentation on these lines looks strange",PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r391760428,mihaimaruseac,2020-03-12 16:58:12,37000,37014,Data bug,0,"Make sure you run pylint, the indentation on these lines looks strange",-1
done,PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r391828116,ashutosh1919,2020-03-12 18:56:41,37000,37014,Data bug,0,done,0
"Make sure you don't mix tabs and spaces here. Visually it looks like it has the proper indentation, but pylint complains asking to insert a few more spaces.",PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r393155920,mihaimaruseac,2020-03-16 16:34:55,37000,37014,Data bug,0,"Make sure you don't mix tabs and spaces here. Visually it looks like it has the proper indentation, but pylint complains asking to insert a few more spaces.",-1
"This should be `math_ops.square`, not `gen_ragged_math_ops.square`.  (Are the tests passing?  I would have expected this to be caught by the tests.)  (Similarly, line 648 below should be changed to `math_ops.square`.)",PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r632625607,edloper,2021-05-14 15:50:25,37000,37014,Data bug,0,"This should be [code], not [code]. (Are the tests passing? I would have expected this to be caught by the tests.) (Similarly, line 648 below should be changed to [code].)",-1
"Suggestion: have this just return `np.var(values)`.  (Your implementation looks right to me, but if we use a standard/reference implementation then it's one less thing to think about.)",PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r632628037,edloper,2021-05-14 15:54:17,37000,37014,Data bug,0,"Suggestion: have this just return [code]. (Your implementation looks right to me, but if we use a standard/reference implementation then it's one less thing to think about.)",2
done,PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r632897931,ashutosh1919,2021-05-15 05:19:50,37000,37014,Data bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r632897940,ashutosh1919,2021-05-15 05:19:58,37000,37014,Data bug,0,done,0
"Using `gen_math_ops.square` works here, but it's preferable to just use `math_ops.square`.  (`gen_math_ops.py` is the generated python stub file, and all of its symbols are imported into `math_ops.py`.)",PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r633628316,edloper,2021-05-17 15:21:32,37000,37014,Data bug,0,"Using [code] works here, but it's preferable to just use [code]. ([code] is the generated python stub file, and all of its symbols are imported into [code].)",0
done the change,PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r633640313,ashutosh1919,2021-05-17 15:35:13,37000,37014,Data bug,0,done the change,0
The lint checker may complain that this import is now unused.,PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r633649361,edloper,2021-05-17 15:46:26,37000,37014,Data bug,0,The lint checker may complain that this import is now unused.,0
Removed. Can you please approve again @edloper ?,PrComment,https://github.com/tensorflow/tensorflow/pull/37014#discussion_r633672408,ashutosh1919,2021-05-17 16:15:59,37000,37014,Data bug,0,Removed. Can you please approve again @edloper ?,0
Don't add new exports under `v1`,PrComment,https://github.com/tensorflow/tensorflow/pull/37174#discussion_r386041925,mihaimaruseac,2020-02-29 17:18:31,37168,37174,Code bug,0,Don't add new exports under [code],-1
"From internal review (CC @shuharsh)

> This is not true, it is optional. it is only necessary if INT8 is the only support builtin ops in target ops.",PrComment,https://github.com/tensorflow/tensorflow/pull/37192#discussion_r389102742,mihaimaruseac,2020-03-06 19:38:26,37111,37192,Documentation bug,0,"From internal review (CC @shuharsh) > This is not true, it is optional. it is only necessary if INT8 is the only support builtin ops in target ops.",0
CC @suharshs ,PrComment,https://github.com/tensorflow/tensorflow/pull/37192#discussion_r389103070,mihaimaruseac,2020-03-06 19:38:48,37111,37192,Documentation bug,0,CC @suharshs,0
"This isn't completely true, this only opts you into int8 post-training quantization. Int8 quantization of weights should still happen without this flag.",PrComment,https://github.com/tensorflow/tensorflow/pull/37192#discussion_r389103178,suharshs,2020-03-06 19:38:57,37111,37192,Documentation bug,0,"This isn't completely true, this only opts you into int8 post-training quantization. Int8 quantization of weights should still happen without this flag.",-1
"Could u add the keyword argument name in this example? 0 and 1 without the param name is hard to parse in the context. Also the value should be float, so 1.0 should be prefered.",PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r387823268,qlzh727,2020-03-04 17:34:42,31277,37281,Documentation bug,0,"Could u add the keyword argument name in this example? 0 and 1 without the param name is hard to parse in the context. Also the value should be float, so 1.0 should be prefered.",1
Same.,PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r387823464,qlzh727,2020-03-04 17:35:03,31277,37281,Documentation bug,0,Same.,0
"For better readability, kvar is not very meaningful, and also somehow indicates its a variable (but actually a tensor). How about change it ""random_normal_tensor""?",PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r387824683,qlzh727,2020-03-04 17:37:09,31277,37281,Documentation bug,0,"For better readability, kvar is not very meaningful, and also somehow indicates its a variable (but actually a tensor). How about change it ""random_normal_tensor""?",1
"I think this only verified the shape of the tensor, is it possible to test the content with a fixed seed?",PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r387825125,qlzh727,2020-03-04 17:38:00,31277,37281,Documentation bug,0,"I think this only verified the shape of the tensor, is it possible to test the content with a fixed seed?",0
same.,PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r387825235,qlzh727,2020-03-04 17:38:12,31277,37281,Documentation bug,0,same.,0
"Hi, when testing locally, I noticed that even if I specify a fixed seed, the  result still varies from time to time.
Also, the examples in `random_normal_variable` and `random_uniform_variable` checked only the shape and type of the result as well.",PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r388247984,Ir1d,2020-03-05 11:56:31,31277,37281,Documentation bug,0,"Hi, when testing locally, I noticed that even if I specify a fixed seed, the result still varies from time to time. Also, the examples in [code] and [code] checked only the shape and type of the result as well.",-1
I think this is breaking tf_docstring test. You shouldn't wrap the line here.,PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r395181099,qlzh727,2020-03-19 17:02:33,31277,37281,Documentation bug,0,I think this is breaking tf_docstring test. You shouldn't wrap the line here.,-2
same.,PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r395181174,qlzh727,2020-03-19 17:02:40,31277,37281,Documentation bug,0,same.,0
"Hi, I've added prepending `... ` so that doctest could recognize it.",PrComment,https://github.com/tensorflow/tensorflow/pull/37281#discussion_r395402812,Ir1d,2020-03-20 01:27:03,31277,37281,Documentation bug,0,"Hi, I've added prepending [code] so that doctest could recognize it.",3
Is this intended to be used with tf.data.Dataset? IIUC it should be the layers under tensorflow/python/keras/layers/preprocessing,PrComment,https://github.com/tensorflow/tensorflow/pull/37520#discussion_r391505889,tanzhenyu,2020-03-12 09:50:02,37445,37520,Documentation bug,0,Is this intended to be used with tf.data.Dataset? IIUC it should be the layers under tensorflow/python/keras/layers/preprocessing,0
"```suggestion
""""""Provides keras data preprocessing utils to pre-process data fed to the keras layers.""""""
```
Will this be okay? ",PrComment,https://github.com/tensorflow/tensorflow/pull/37520#discussion_r391601112,ManishAradwad,2020-03-12 12:55:56,37445,37520,Documentation bug,0,``[code]`` Will this be okay?,0
@tanzhenyu Can you please take a look on the above comment from @ManishAradwad. Thank you!,PrComment,https://github.com/tensorflow/tensorflow/pull/37520#discussion_r393688524,gbaned,2020-03-17 13:43:54,37445,37520,Documentation bug,0,@tanzhenyu Can you please take a look on the above comment from @ManishAradwad. Thank you!,0
@tanzhenyu Any update on this PR? Please. Thanks!,PrComment,https://github.com/tensorflow/tensorflow/pull/37520#discussion_r446302516,gbaned,2020-06-26 16:59:34,37445,37520,Documentation bug,0,@tanzhenyu Any update on this PR? Please. Thanks!,1
@tanzhenyu Any update on this PR? Please. Thanks!,PrComment,https://github.com/tensorflow/tensorflow/pull/37520#discussion_r460219418,gbaned,2020-07-24 18:27:29,37445,37520,Documentation bug,0,@tanzhenyu Any update on this PR? Please. Thanks!,1
top_k=4,PrComment,https://github.com/tensorflow/tensorflow/pull/37528#discussion_r391779762,pavithrasv,2020-03-12 17:30:09,37416,37528,Documentation bug,0,top_k=4,0
nit: Can you add a line break after this?,PrComment,https://github.com/tensorflow/tensorflow/pull/37528#discussion_r391854967,pavithrasv,2020-03-12 19:52:04,37416,37528,Documentation bug,0,nit: Can you add a line break after this?,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/37528#discussion_r392018784,ashutosh1919,2020-03-13 03:54:28,37416,37528,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/37528#discussion_r392018814,ashutosh1919,2020-03-13 03:54:38,37416,37528,Documentation bug,0,done,0
Please add an empty line before every doctest to not break formatting on the website,PrComment,https://github.com/tensorflow/tensorflow/pull/37538#discussion_r391764618,mihaimaruseac,2020-03-12 17:04:56,37240,37538,Documentation bug,0,Please add an empty line before every doctest to not break formatting on the website,0
"nit: I'd combine these examples e.g. 
```
The identifier may be the string name of a loss function or `Loss` class.

>>...
```",PrComment,https://github.com/tensorflow/tensorflow/pull/37538#discussion_r391778877,k-w-w,2020-03-12 17:28:41,37240,37538,Documentation bug,0,nit: I'd combine these examples e.g. ``[code]Loss[code]``,0
Also note that the class name must map to a `Loss` class,PrComment,https://github.com/tensorflow/tensorflow/pull/37538#discussion_r391779703,k-w-w,2020-03-12 17:30:02,37240,37538,Documentation bug,0,Also note that the class name must map to a [code] class,0
Done,PrComment,https://github.com/tensorflow/tensorflow/pull/37538#discussion_r391787098,ashutosh1919,2020-03-12 17:42:01,37240,37538,Documentation bug,0,Done,0
Done,PrComment,https://github.com/tensorflow/tensorflow/pull/37538#discussion_r391787190,ashutosh1919,2020-03-12 17:42:12,37240,37538,Documentation bug,0,Done,0
"Inside Google the class is different (has a prefix). Let's replace with `<class '...tensorflow.python.keras.losses.CategoricalCrossentropy'>`

(hopefully this works, if it doesn't we'll have to rewrite the test somehow",PrComment,https://github.com/tensorflow/tensorflow/pull/37538#discussion_r391979553,mihaimaruseac,2020-03-13 01:02:07,37240,37538,Documentation bug,0,"Inside Google the class is different (has a prefix). Let's replace with [code] (hopefully this works, if it doesn't we'll have to rewrite the test somehow",0
Also here,PrComment,https://github.com/tensorflow/tensorflow/pull/37538#discussion_r391979586,mihaimaruseac,2020-03-13 01:02:19,37240,37538,Documentation bug,0,Also here,0
"Let keep first line as it is. The [PEP rules for docstrings](https://www.python.org/dev/peps/pep-0257/) say that first line should be a short phrase, followed by an empty line and then a longer description.

Then, let's move the discussion about `kwargs` not being used to the documentation for `kwargs`

Then, the notes here can be a different paragraph, just above documenting the arguments",PrComment,https://github.com/tensorflow/tensorflow/pull/37574#discussion_r392342548,mihaimaruseac,2020-03-13 16:39:20,36757,37574,Documentation bug,0,"Let keep first line as it is. The [PEP rules for docstrings]([url] say that first line should be a short phrase, followed by an empty line and then a longer description. Then, let's move the discussion about [code] not being used to the documentation for [code] Then, the notes here can be a different paragraph, just above documenting the arguments",0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/37574#discussion_r392352597,ashutosh1919,2020-03-13 16:55:20,36757,37574,Documentation bug,0,done,0
"Sorry, I meant this should go bellow under `Arugments:`

```
  ** kwargs: Additional keyword arguments. Currently unused
```",PrComment,https://github.com/tensorflow/tensorflow/pull/37574#discussion_r392354908,mihaimaruseac,2020-03-13 16:59:21,36757,37574,Documentation bug,0,"Sorry, I meant this should go bellow under [code] ``[code]``",0
Check plz. Is it okay now?,PrComment,https://github.com/tensorflow/tensorflow/pull/37574#discussion_r392360782,ashutosh1919,2020-03-13 17:10:31,36757,37574,Documentation bug,0,Check plz. Is it okay now?,0
I would also suggest to add descriptions here about when it will raise `No concrete func` and when it will raise `multiple concrete func`.,PrComment,https://github.com/tensorflow/tensorflow/pull/37798#discussion_r396228221,ashutosh1919,2020-03-23 06:05:06,37086,37798,Deployment bug,0,I would also suggest to add descriptions here about when it will raise [code] and when it will raise [code].,0
"nit:
1) Can you remove the dashes (""-"")
2) Can you change the text to be simpler (you don't need to specify the text of the error in the docstring, just when the error can occur since the text can change over time):
```
No concrete functions is specified.
Multiple concrete functions are specified.
Input shape is not specified.
Invalid quantization parameters.
```",PrComment,https://github.com/tensorflow/tensorflow/pull/37798#discussion_r413122560,gargn,2020-04-22 16:17:30,37086,37798,Deployment bug,0,"nit: 1) Can you remove the dashes (""-"") 2) Can you change the text to be simpler (you don't need to specify the text of the error in the docstring, just when the error can occur since the text can change over time): ``[code]``",0
I have made that change.,PrComment,https://github.com/tensorflow/tensorflow/pull/37798#discussion_r413136427,rushabh-v,2020-04-22 16:35:56,37086,37798,Deployment bug,0,I have made that change.,0
"`The values closer to 1 indicate greater dissimilarity.`
This statement isn't right??",PrComment,https://github.com/tensorflow/tensorflow/pull/37905#discussion_r399435831,ManishAradwad,2020-03-27 17:42:27,37896,37905,Documentation bug,0,[code] This statement isn't right??,-2
"Why?

If the data is `[1, 1]` and `[1, 1]` the vectors are completely similar, the cosine similarity is -1 (dot product is 1, we have a - in front).

If the data is `[1, 1]` and `[-1, -1]` the vectors are opposite each other, the dot product is -1, but due to the `-` in front the metric becomes 1.

If the data is `[0, 1]` and `[1, 0]`, the vectors are orthogonal, and both the dot product as well as the metric value are 0.",PrComment,https://github.com/tensorflow/tensorflow/pull/37905#discussion_r399453435,mihaimaruseac,2020-03-27 18:12:35,37896,37905,Documentation bug,0,"Why? If the data is [code] and [code] the vectors are completely similar, the cosine similarity is -1 (dot product is 1, we have a - in front). If the data is [code] and [code] the vectors are opposite each other, the dot product is -1, but due to the [code] in front the metric becomes 1. If the data is [code] and [code], the vectors are orthogonal, and both the dot product as well as the metric value are 0.",0
"@mihaimaruseac I'm sorry, I'm a little bit confused.
In the previous comment, I meant doesn't that statement(`The values closer to 1 indicate greater dissimilarity.`) include a case where output gets closer to 1?",PrComment,https://github.com/tensorflow/tensorflow/pull/37905#discussion_r399627679,ManishAradwad,2020-03-28 06:36:45,37896,37905,Documentation bug,0,"@mihaimaruseac I'm sorry, I'm a little bit confused. In the previous comment, I meant doesn't that statement([code]) include a case where output gets closer to 1?",0
I meant that you should include the case where output gets closer to 1 in the doctest example below. The docstring header is good.,PrComment,https://github.com/tensorflow/tensorflow/pull/37905#discussion_r399686499,mihaimaruseac,2020-03-28 17:18:29,37896,37905,Documentation bug,0,I meant that you should include the case where output gets closer to 1 in the doctest example below. The docstring header is good.,2
"@mihaimaruseac I've edited the `y_true` and `y_pred` but i couldn't get above lines. I tried getting l2_norms of `y_true` and `y_pred` using `nn.l2_normalize(y_true, axis=1)` and `nn.l2_normalize(y_pred, axis=1)`. I got following output: 
```
tf.Tensor(
[[0.         1.        ]
 [0.70710677 0.70710677]
 [0.70710677 0.70710677]], shape=(3, 2), dtype=float32) tf.Tensor(
[[ 1.          0.        ]
 [ 0.70710677  0.70710677]
 [-0.70710677 -0.70710677]], shape=(3, 2), dtype=float32)
```",PrComment,https://github.com/tensorflow/tensorflow/pull/37905#discussion_r399746702,ManishAradwad,2020-03-29 05:12:21,37896,37905,Documentation bug,0,@mihaimaruseac I've edited the [code] and [code] but i couldn't get above lines. I tried getting l2_norms of [code] and [code] using [code] and [code]. I got following output: ``[code]``,0
"1/1.414 is 1/sqrt(2) is 0.707

I would remove the comment lines",PrComment,https://github.com/tensorflow/tensorflow/pull/37905#discussion_r399840129,mihaimaruseac,2020-03-29 19:12:58,37896,37905,Documentation bug,0,1/1.414 is 1/sqrt(2) is 0.707 I would remove the comment lines,0
"I think this decorator was meant to annotate whole classes - I'm not sure it will work. Anyway, if it doesn't, it's always an option to actually create a tf.function and call that instead, something like this:

def testShape(self):
  @def_function.function
  def test_fn():
    tensor = ...
    tensor = ...
    self.assertEqual(tensor.shape.rank, 2)
  test_fn()",PrComment,https://github.com/tensorflow/tensorflow/pull/38142#discussion_r401909149,mdanatg,2020-04-01 21:05:44,37638,38142,Data bug,0,"I think this decorator was meant to annotate whole classes - I'm not sure it will work. Anyway, if it doesn't, it's always an option to actually create a tf.function and call that instead, something like this: def testShape(self): @def_function.function def test_fn(): tensor = ... tensor = ... self.assertEqual(tensor.shape.rank, 2) test_fn()",1
Please use self.assertEqual here.,PrComment,https://github.com/tensorflow/tensorflow/pull/38142#discussion_r401909279,mdanatg,2020-04-01 21:05:59,37638,38142,Data bug,0,Please use self.assertEqual here.,0
"Ah that works. Thanks!
",PrComment,https://github.com/tensorflow/tensorflow/pull/38142#discussion_r401918132,yongtang,2020-04-01 21:23:45,37638,38142,Data bug,0,Ah that works. Thanks!,3
Updated. Thanks!,PrComment,https://github.com/tensorflow/tensorflow/pull/38142#discussion_r401918216,yongtang,2020-04-01 21:23:53,37638,38142,Data bug,0,Updated. Thanks!,3
Can you test for negative scalar axes too (like axes=-1)?,PrComment,https://github.com/tensorflow/tensorflow/pull/38209#discussion_r404210477,alextp,2020-04-06 16:06:26,38172,38209,Data bug,0,Can you test for negative scalar axes too (like axes=-1)?,0
@alextp Thanks. The PR has been updated with additional test cases added.,PrComment,https://github.com/tensorflow/tensorflow/pull/38209#discussion_r404224102,yongtang,2020-04-06 16:26:01,38172,38209,Data bug,0,@alextp Thanks. The PR has been updated with additional test cases added.,3
Please use backticks for code formatting.,PrComment,https://github.com/tensorflow/tensorflow/pull/38214#discussion_r522324808,fchollet,2020-11-12 18:29:45,38199,38214,Documentation bug,0,Please use backticks for code formatting.,0
"@fchollet,
Done ",PrComment,https://github.com/tensorflow/tensorflow/pull/38214#discussion_r559620297,rmothukuru,2021-01-18 14:52:50,38199,38214,Documentation bug,0,"@fchollet, Done",0
This should stay as a doctest format (with `>>> `),PrComment,https://github.com/tensorflow/tensorflow/pull/38214#discussion_r562073906,mihaimaruseac,2021-01-21 17:41:14,38199,38214,Documentation bug,0,This should stay as a doctest format (with [code]),0
"```suggestion
    either `{-1, +1}` or `{0, 1}` (i.e. a one-hot-encoded tensor).
```",PrComment,https://github.com/tensorflow/tensorflow/pull/38214#discussion_r562074158,mihaimaruseac,2021-01-21 17:41:41,38199,38214,Documentation bug,0,"``[code]{-1, +1}[code]{0, 1}[code]``",0
Replaced Backticks (```) with >>>,PrComment,https://github.com/tensorflow/tensorflow/pull/38214#discussion_r562388459,rmothukuru,2021-01-22 04:57:57,38199,38214,Documentation bug,0,Replaced Backticks (```) with >>>,0
Done Mihai,PrComment,https://github.com/tensorflow/tensorflow/pull/38214#discussion_r562389514,rmothukuru,2021-01-22 05:02:06,38199,38214,Documentation bug,0,Done Mihai,0
"```suggestion
      callbacks.on_train_end(logs=training_logs)
```

This way even reordering the arguments will keep the semantics",PrComment,https://github.com/tensorflow/tensorflow/pull/38499#discussion_r408287183,mihaimaruseac,2020-04-14 16:51:12,38498,38499,Code bug,0,``[code]`` This way even reordering the arguments will keep the semantics,0
"```suggestion
      callbacks.on_test_end(logs=logs)
```",PrComment,https://github.com/tensorflow/tensorflow/pull/38499#discussion_r408287332,mihaimaruseac,2020-04-14 16:51:28,38498,38499,Code bug,0,``[code]``,0
"I think we need to escape this backslash, otherwise Python will complain that ""\c"" is an invalid escape sequence.",PrComment,https://github.com/tensorflow/tensorflow/pull/39029#discussion_r417554087,mdanatg,2020-04-29 19:21:02,39019,39029,Code bug,0,"I think we need to escape this backslash, otherwise Python will complain that ""\c"" is an invalid escape sequence.",0
Please also include a string that contains a dash character (adding it to the tests below is fine).,PrComment,https://github.com/tensorflow/tensorflow/pull/39029#discussion_r417554794,mdanatg,2020-04-29 19:22:18,39019,39029,Code bug,0,Please also include a string that contains a dash character (adding it to the tests below is fine).,0
"Thanks @mdanatg, updated.",PrComment,https://github.com/tensorflow/tensorflow/pull/39029#discussion_r417559403,yongtang,2020-04-29 19:30:34,39019,39029,Code bug,0,"Thanks @mdanatg, updated.",3
"Thanks @mdanatg, added `-` into part of the tested string.",PrComment,https://github.com/tensorflow/tensorflow/pull/39029#discussion_r417559603,yongtang,2020-04-29 19:30:56,39019,39029,Code bug,0,"Thanks @mdanatg, added [code] into part of the tested string.",3
"Let's rename the test name since ""all_correct"" seems to be too generic. How about test_loss_with_non_default_dtype?",PrComment,https://github.com/tensorflow/tensorflow/pull/39123#discussion_r419539232,qlzh727,2020-05-04 15:52:18,39004,39123,Algorithm design bug,0,"Let's rename the test name since ""all_correct"" seems to be too generic. How about test_loss_with_non_default_dtype?",1
Let's replace this with a URL.,PrComment,https://github.com/tensorflow/tensorflow/pull/39123#discussion_r419539426,qlzh727,2020-05-04 15:52:34,39004,39123,Algorithm design bug,0,Let's replace this with a URL.,0
@qlzh727 Thanks. Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/39123#discussion_r419558030,yongtang,2020-05-04 16:19:12,39004,39123,Algorithm design bug,0,@qlzh727 Thanks. Updated.,3
"Thanks, Done.",PrComment,https://github.com/tensorflow/tensorflow/pull/39123#discussion_r419558121,yongtang,2020-05-04 16:19:20,39004,39123,Algorithm design bug,0,"Thanks, Done.",3
"This is not super safe as it can generate more than one -1.

Isn't it better to use tf.shape instead?",PrComment,https://github.com/tensorflow/tensorflow/pull/39131#discussion_r419496157,alextp,2020-05-04 14:52:04,32380,39131,Algorithm design bug,0,This is not super safe as it can generate more than one -1. Isn't it better to use tf.shape instead?,-1
Could we change other places float32 is used in this function as well?,PrComment,https://github.com/tensorflow/tensorflow/pull/39134#discussion_r430655524,pavithrasv,2020-05-26 19:31:10,36790,39134,Data bug,0,Could we change other places float32 is used in this function as well?,0
"combine the two `if` clauses:
```
if (known_batch_size_ < 0 && shape.dim_size(0) >= 0) {
  ...
}
```",PrComment,https://github.com/tensorflow/tensorflow/pull/39137#discussion_r419780441,aaudiber,2020-05-04 23:08:19,39136,39137,Data bug,1,combine the two [code] clauses: ``[code]``,0
"can we call this just `batch_size_`? Then add a comment that it may or may not be known, with -1 representing unknown.",PrComment,https://github.com/tensorflow/tensorflow/pull/39137#discussion_r419780878,aaudiber,2020-05-04 23:09:33,39136,39137,Data bug,1,"can we call this just [code]? Then add a comment that it may or may not be known, with -1 representing unknown.",0
"Add test with 2 components, where only the second component's batch size is known:
```
lambda: dataset_ops.Dataset.zip(
  dataset_ops.Dataset.range(4).batch(2, drop_remainder=False),
  dataset_ops.Dataset.range(5).batch(2, drop_remainder=True))
```",PrComment,https://github.com/tensorflow/tensorflow/pull/39137#discussion_r419782728,aaudiber,2020-05-04 23:15:05,39136,39137,Data bug,1,"Add test with 2 components, where only the second component's batch size is known: ``[code]``",0
"Thanks @aaudiber, done.",PrComment,https://github.com/tensorflow/tensorflow/pull/39137#discussion_r420229725,yongtang,2020-05-05 16:10:00,39136,39137,Data bug,1,"Thanks @aaudiber, done.",3
"Thanks @aaudiber, updated.",PrComment,https://github.com/tensorflow/tensorflow/pull/39137#discussion_r420229830,yongtang,2020-05-05 16:10:11,39136,39137,Data bug,1,"Thanks @aaudiber, updated.",3
Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/39137#discussion_r420229898,yongtang,2020-05-05 16:10:16,39136,39137,Data bug,1,Done.,0
"I looks like the common confusion here is that people expect that when `map_fn` is applied to a list, that it will map over that list.  To help steer them in the right direction, let's make this message a little more verbose.  How about something along the lines of:

```
raise ValueError(
    ""elems must be a Tensor or (possibly nested) sequence of Tensors. ""
    ""Got {}, which does not contain any Tensors."".format(elems))
```",PrComment,https://github.com/tensorflow/tensorflow/pull/39241#discussion_r421487639,edloper,2020-05-07 13:05:44,39229,39241,Data bug,0,"I looks like the common confusion here is that people expect that when [code] is applied to a list, that it will map over that list. To help steer them in the right direction, let's make this message a little more verbose. How about something along the lines of: ``[code]``",1
container -> contain,PrComment,https://github.com/tensorflow/tensorflow/pull/39241#discussion_r421876063,terrytangyuan,2020-05-08 00:54:03,39229,39241,Data bug,0,container -> contain,0
@terrytangyuan Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/39241#discussion_r421889089,yongtang,2020-05-08 01:41:46,39229,39241,Data bug,0,@terrytangyuan Updated.,0
Consists -> consist,PrComment,https://github.com/tensorflow/tensorflow/pull/39241#discussion_r436892090,edloper,2020-06-08 17:58:51,39229,39241,Data bug,0,Consists -> consist,0
The `...` line might not be needed. Same below,PrComment,https://github.com/tensorflow/tensorflow/pull/39461#discussion_r424082238,mihaimaruseac,2020-05-12 23:02:43,39454,39461,Documentation bug,0,The [code] line might not be needed. Same below,0
Let's replace `num_split` with `num_or_size_splits` everywhere instead of introducing a new term,PrComment,https://github.com/tensorflow/tensorflow/pull/39461#discussion_r424082536,mihaimaruseac,2020-05-12 23:03:39,39454,39461,Documentation bug,0,Let's replace [code] with [code] everywhere instead of introducing a new term,0
Thanks @mihaimaruseac Removed. ,PrComment,https://github.com/tensorflow/tensorflow/pull/39461#discussion_r424085252,yongtang,2020-05-12 23:11:26,39454,39461,Documentation bug,0,Thanks @mihaimaruseac Removed.,3
@mihaimaruseac  Updated. Thanks.,PrComment,https://github.com/tensorflow/tensorflow/pull/39461#discussion_r424085306,yongtang,2020-05-12 23:11:37,39454,39461,Documentation bug,0,@mihaimaruseac Updated. Thanks.,3
Nit: please fix double whitespace,PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424192964,jaingaurav,2020-05-13 06:09:08,39475,39481,Data bug,0,Nit: please fix double whitespace,0
Nit: please fix double whitespace,PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424193035,jaingaurav,2020-05-13 06:09:18,39475,39481,Data bug,0,Nit: please fix double whitespace,0
Nit: remove extra blank line,PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424193580,jaingaurav,2020-05-13 06:10:49,39475,39481,Data bug,0,Nit: remove extra blank line,0
Please keep blank line,PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424194390,jaingaurav,2020-05-13 06:13:04,39475,39481,Data bug,0,Please keep blank line,0
"I'm sorry, I may be missing something here, but is the logic above saying that we'll just use `_truediv_python` for non-tensor inputs? If so, then the test case shouldn't pass, since we should get a python value back.

I'm probably misreading the code. If so, please document or restructure to help clarify.",PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424196637,jaingaurav,2020-05-13 06:19:15,39475,39481,Data bug,0,"I'm sorry, I may be missing something here, but is the logic above saying that we'll just use [code] for non-tensor inputs? If so, then the test case shouldn't pass, since we should get a python value back. I'm probably misreading the code. If so, please document or restructure to help clarify.",-1
"Okay I think I understand this PR better, I was misreading the if condition.

Wouldn't it be simpler to simply call convert to tensor on `x` and then let the operator overloads kick in? That's basically what each of those function do in the first place.",PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424582937,jaingaurav,2020-05-13 16:45:32,39475,39481,Data bug,0,"Okay I think I understand this PR better, I was misreading the if condition. Wouldn't it be simpler to simply call convert to tensor on [code] and then let the operator overloads kick in? That's basically what each of those function do in the first place.",0
"Please remove the comment or simply to simple say we do the convert in order always return a Tensor. Also, I think the code should be:
```
if not tensor_util.is_tensor(x):
  x = ops.convert_to_tensor(x)
```",PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424685615,jaingaurav,2020-05-13 19:39:34,39475,39481,Data bug,0,"Please remove the comment or simply to simple say we do the convert in order always return a Tensor. Also, I think the code should be: ``[code]``",0
Why do you need to check `tensor_util.is_tensor(y)`?,PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424691986,jaingaurav,2020-05-13 19:51:32,39475,39481,Data bug,0,Why do you need to check [code]?,0
"@jaingaurav I saw the logic in `_OverrideBinaryOperatorHelper` will try both `__truediv__` and rtruediv__` (LHS or RHS). I was overly concerned about if convert x may cause issues when y is a different dtype. So initially tried to test both.

But now I give it try with always convert x. Looks like all tests pass so it should be fine. Thanks for the help!",PrComment,https://github.com/tensorflow/tensorflow/pull/39481#discussion_r424700291,yongtang,2020-05-13 20:06:55,39475,39481,Data bug,0,@jaingaurav I saw the logic in [code] will try both [code] and rtruediv__` (LHS or RHS). I was overly concerned about if convert x may cause issues when y is a different dtype. So initially tried to test both. But now I give it try with always convert x. Looks like all tests pass so it should be fine. Thanks for the help!,4
@chisgg Just to be clear `ToString(res)` as it was designed it will be always classify also this case as `Unkown Error` for the LOG string but we really know that we are in `cudaErrorSharedObjectInitFailed = 303 This indicates that initialization of a shared object failed. `,PrComment,https://github.com/tensorflow/tensorflow/pull/39956#discussion_r434446946,bhack,2020-06-03 09:50:49,37689,39956,Code bug,0,@chisgg Just to be clear [code] as it was designed it will be always classify also this case as [code] for the LOG string but we really know that we are in [code],0
"Looks like Eigen is abused here :) This can be written with a `std::for_all` over ""pointer-range"".

```
Tidx* indices = indices_tensor.data() // is it available?
or
Tidx* indices = indices_tensor.scalar<Tidx>().data() // or this, don't remember the details.

bool check = std::for_all(indices, indicex + size, [&](Tidx index) { return index < dims_prod; })
```",PrComment,https://github.com/tensorflow/tensorflow/pull/40214#discussion_r436299228,ezhulenev,2020-06-06 20:42:52,40204,40214,Data bug,1,"Looks like Eigen is abused here :) This can be written with a [code] over ""pointer-range"". ``[code]``",0
c-style casts are against style guide (https://google.github.io/styleguide/cppguide.html#Casting). Is this cast required to remove `const`? I think `const Tidx* indices` should also work just fine with `std:all_of`.,PrComment,https://github.com/tensorflow/tensorflow/pull/40214#discussion_r436893539,ezhulenev,2020-06-08 18:01:10,40204,40214,Data bug,1,c-style casts are against style guide ([url]#Casting). Is this cast required to remove [code]? I think [code] should also work just fine with [code].,0
@ezhulenev Thanks. The PR has been updated with C cast removed. Please take a look.,PrComment,https://github.com/tensorflow/tensorflow/pull/40214#discussion_r436900609,yongtang,2020-06-08 18:14:04,40204,40214,Data bug,1,@ezhulenev Thanks. The PR has been updated with C cast removed. Please take a look.,3
"Since the fix itself is not directly related to autograph, it would be best to have this test somewhere in a location that's closer to the `tf.equal` op.

I think `math_ops_test.cc` is a good place to verify this logic, since it already includes a basic test. Consider adding a second test which has a more complex shape, like the ones tested here. Feel free to add a new test case (e.g. `TEST(MathOpsTest, EqualOp)`).

Optionally, there is also `tensorflow/python/kernel_tests`, which could be expanded by adding an `equal_test.py` to contain a few more test cases, which should include:
 * matching shapes
 * incompatible shapes
 * dynamic, matching shapes
 * dynamic, incompatible shapes (this last one is most important to make sure that op kernels weren't relying on the shape inference to behave correctly)",PrComment,https://github.com/tensorflow/tensorflow/pull/40480#discussion_r440812789,mdanatg,2020-06-16 12:32:25,40471,40480,Version compatibility bug,0,"Since the fix itself is not directly related to autograph, it would be best to have this test somewhere in a location that's closer to the [code] op. I think [code] is a good place to verify this logic, since it already includes a basic test. Consider adding a second test which has a more complex shape, like the ones tested here. Feel free to add a new test case (e.g. [code]). Optionally, there is also [code], which could be expanded by adding an [code] to contain a few more test cases, which should include: * matching shapes * incompatible shapes * dynamic, matching shapes * dynamic, incompatible shapes (this last one is most important to make sure that op kernels weren't relying on the shape inference to behave correctly)",0
(Optional) This attribute should not be necessary - do tests fail without it?,PrComment,https://github.com/tensorflow/tensorflow/pull/40480#discussion_r441753375,mdanatg,2020-06-17 18:43:53,40471,40480,Version compatibility bug,0,(Optional) This attribute should not be necessary - do tests fail without it?,0
"@mdanatg `incompatible_shape_error` Attr is part of the `Equal` op due to the following line, so it is needed.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/math_ops.cc#L718
",PrComment,https://github.com/tensorflow/tensorflow/pull/40480#discussion_r441779357,yongtang,2020-06-17 19:21:18,40471,40480,Version compatibility bug,0,"@mdanatg [code] Attr is part of the [code] op due to the following line, so it is needed. [url]#L718",0
"This causes a test failure internally:

```
Traceback (most recent call last):
  File ""<embedded stdlib>/unittest/case.py"", line 59, in testPartExecutor
    yield
  File ""<embedded stdlib>/unittest/case.py"", line 605, in run
    testMethod()
  File "".../tensorflow/python/ops/image_ops_test.py"", line 1381, in testFlipImageUnknownShape
    image_flipped_via_dataset_map = next(iter(dataset))
  File "".../tensorflow/python/data/ops/dataset_ops.py"", line 2655, in __iter__
    return iter(self._dataset)
  File "".../tensorflow/python/data/ops/dataset_ops.py"", line 417, in __iter__
    raise RuntimeError(""__iter__() is only supported inside of tf.function ""
RuntimeError: __iter__() is only supported inside of tf.function or when eager execution is enabled.
```",PrComment,https://github.com/tensorflow/tensorflow/pull/40626#discussion_r443688765,mihaimaruseac,2020-06-22 16:37:57,40580,40626,Data bug,0,This causes a test failure internally: ``[code]``,-2
"The code on line 1127 multiplies the `sqrt` by `-i`. The expression inside the `sqrt` is also a bit different.
Please eliminate the inconsistencies and move the comment up before the method.",PrComment,https://github.com/tensorflow/tensorflow/pull/41386#discussion_r465017520,thomasjoerg,2020-08-04 12:36:41,41370,41386,Data bug,0,The code on line 1127 multiplies the [code] by [code]. The expression inside the [code] is also a bit different. Please eliminate the inconsistencies and move the comment up before the method.,-1
"It will be good if you can expand the comment with more details. By explaining the requirements, why and how it is done.",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r507844369,karimnosseir,2020-10-19 15:27:14,39572,41790,Deployment bug,1,"It will be good if you can expand the comment with more details. By explaining the requirements, why and how it is done.",1
Add Function comments please.,PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r507845545,karimnosseir,2020-10-19 15:28:35,39572,41790,Deployment bug,1,Add Function comments please.,0
You can remove this line - it is the default. ,PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r507855616,karimnosseir,2020-10-19 15:41:46,39572,41790,Deployment bug,1,You can remove this line - it is the default.,0
"func1/func2/... are very general names. Please use more descriptive names to what it is testing, and add comments in needed parts please.

Thanks",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r507856760,karimnosseir,2020-10-19 15:43:25,39572,41790,Deployment bug,1,"func1/func2/... are very general names. Please use more descriptive names to what it is testing, and add comments in needed parts please. Thanks",1
duplicate and not needed. Remove please,PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r507857129,karimnosseir,2020-10-19 15:43:55,39572,41790,Deployment bug,1,duplicate and not needed. Remove please,-2
"Good catch, this code is still from the time when it wasn't enabled by default.",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r508087819,lgeiger,2020-10-19 22:00:25,39572,41790,Deployment bug,1,"Good catch, this code is still from the time when it wasn't enabled by default.",2
I refactored the tests to make them clearer and expanded the test coverage.,PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r508088017,lgeiger,2020-10-19 22:00:53,39572,41790,Deployment bug,1,I refactored the tests to make them clearer and expanded the test coverage.,3
"Expand comment on why we only fuse in this case.
",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r508677360,karimnosseir,2020-10-20 16:36:50,39572,41790,Deployment bug,1,Expand comment on why we only fuse in this case.,0
"Thanks for the reply, I tried to improve the comment in 2b2b3a9bd817b05e2451b2de03f170b3282d63f5.

The reason for this is that we can only fuse a multiplier in dimensions that are not summed over during the matmul due to:
![Screenshot 2020-10-20 at 18 07 56](https://user-images.githubusercontent.com/13285808/96620765-c40bcc00-12ff-11eb-9869-37f0b691ed16.png)
",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r508702901,lgeiger,2020-10-20 17:16:46,39572,41790,Deployment bug,1,"Thanks for the reply, I tried to improve the comment in 2b2b3a9bd817b05e2451b2de03f170b3282d63f5. The reason for this is that we can only fuse a multiplier in dimensions that are not summed over during the matmul due to: ![Screenshot 2020-10-20 at 18 07 56]([url]",2
"This line should be rewritten in order to access the shape information if available.

For example,

```
if (auto ranked_type = elements.getType().cast<RankedTensorType>()) {
  return IsDimensionsDegenerateExceptLastOne(ranked_type.getShape());
}
```

Otherwise, it will cause crashing when the type is UnrankedTensorType.",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r518004483,abattery,2020-11-05 12:11:19,39572,41790,Deployment bug,1,"This line should be rewritten in order to access the shape information if available. For example, ``[code]`` Otherwise, it will cause crashing when the type is UnrankedTensorType.",-2
"Good catch, I fixed it in 4ebd2633e870dd474fbc9b348d311a4ccdf20158",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r518015160,lgeiger,2020-11-05 12:30:59,39572,41790,Deployment bug,1,"Good catch, I fixed it in 4ebd2633e870dd474fbc9b348d311a4ccdf20158",3
"Sorry for my bad. Let's use dyn_cast to make sure avoid crashing on UnrankedTensorType.

```
if (auto ranked_type = val.getType().dyn_cast<RankedTensorType>()) {
    return IsDimensionsDegenerateExceptLastOne(ranked_type.getShape());
}
```",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r518395727,abattery,2020-11-05 22:00:30,39572,41790,Deployment bug,1,Sorry for my bad. Let's use dyn_cast to make sure avoid crashing on UnrankedTensorType. ``[code]``,1
"zero valued size_t type minus - 1 is problematic and it is causing test failures.

Let's use the ArrayRef member methods as much as possible to avoid unexpected crashing due to the type conversion:

```
  if (elements_shape.empty()) return true;

  for (auto dim : elements_shape.drop_back(1)) {
    if (dim != ShapedType::kDynamicSize) return false;
  }
  return true;
```",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r518396543,abattery,2020-11-05 22:02:12,39572,41790,Deployment bug,1,zero valued size_t type minus - 1 is problematic and it is causing test failures. Let's use the ArrayRef member methods as much as possible to avoid unexpected crashing due to the type conversion: ``[code]``,-2
"Comparing size() with zero can be easily replaced with empty().

```
    int64_t element_size = shape.empty() ? 1 : shape[shape.size() - 1];
```",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r518396925,abattery,2020-11-05 22:02:58,39572,41790,Deployment bug,1,Comparing size() with zero can be easily replaced with empty(). ``[code]``,1
"I confused about 1 and -1. Here is the updated suggestion.

```
  if (elements_shape.empty()) return true;

  for (auto dim : elements_shape.drop_back(1)) {
    if (dim != 1) return false;
  }
  return true;
```",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r518403314,abattery,2020-11-05 22:16:50,39572,41790,Deployment bug,1,I confused about 1 and -1. Here is the updated suggestion. ``[code]``,0
"Thanks for the review. I addressed the comments in ce4e534ad61012b724b80d1aab2f68017d214e76 ~~however I didn't use `kDynamicSize` as it would change behaviour since we need the dimensions to be `1` and not dynamic, or am I missing something?~~",PrComment,https://github.com/tensorflow/tensorflow/pull/41790#discussion_r518404074,lgeiger,2020-11-05 22:18:27,39572,41790,Deployment bug,1,"Thanks for the review. I addressed the comments in ce4e534ad61012b724b80d1aab2f68017d214e76 ~~however I didn't use [code] as it would change behaviour since we need the dimensions to be [code] and not dynamic, or am I missing something?~~",2
"Is it a good idea to do that? Reduction in floating point numbers might yield different numbers.
@sanjoy WDYT?",PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r466743642,cheshire,2020-08-06 23:45:27,41915,41916,Data bug,1,Is it a good idea to do that? Reduction in floating point numbers might yield different numbers. @sanjoy WDYT?,0
Should be called `PreprocessInput` or something like that.  `ProcessData` sounds super generic.,PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r466752170,sanjoy,2020-08-07 00:16:33,41915,41916,Data bug,1,Should be called [code] or something like that. [code] sounds super generic.,-1
"I don't think this is reducing in floating point, it is just doing the final sqrt in floating point.",PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r466752984,sanjoy,2020-08-07 00:19:26,41915,41916,Data bug,1,"I don't think this is reducing in floating point, it is just doing the final sqrt in floating point.",0
"@sanjoy is right, it's the finalizer that processes output of reduction.",PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r467155577,WindQAQ,2020-08-07 16:51:16,41915,41916,Data bug,1,"@sanjoy is right, it's the finalizer that processes output of reduction.",1
The verb here needs to be more specific than `Process`.  `Preprocess` is fine.,PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r467165102,sanjoy,2020-08-07 17:10:13,41915,41916,Data bug,1,The verb here needs to be more specific than [code]. [code] is fine.,0
Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r467178962,WindQAQ,2020-08-07 17:38:45,41915,41916,Data bug,1,Updated.,0
Why did this need to change?  Earlier we were passing in the result of `ConvertElementType` right?,PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r467249902,sanjoy,2020-08-07 20:18:13,41915,41916,Data bug,1,Why did this need to change? Earlier we were passing in the result of [code] right?,0
"You're right. My original thought is to make codes unchanged in this part, so maybe we should do something like
```cpp
  auto input = xla::ConvertElementType(ctx->Input(0), type);
  auto data = PreprocessInput(b, input);
  ...
  auto finalized = BuildFinalizer(b, input, reduce, xla_axes);
```
What do you think about this? Thanks!",PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r467257334,WindQAQ,2020-08-07 20:36:45,41915,41916,Data bug,1,"You're right. My original thought is to make codes unchanged in this part, so maybe we should do something like ``[code]`` What do you think about this? Thanks!",2
"LGTM, except that I'd prefer s/input/converted_input/",PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r467260754,sanjoy,2020-08-07 20:45:38,41915,41916,Data bug,1,"LGTM, except that I'd prefer s/input/converted_input/",2
"Sorry for the miscommunication, I meant:

```
  auto converted_input = xla::ConvertElementType(ctx->Input(0), type);
  auto preprocessed_input = PreprocessInput(b, converted_input);
```",PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r467268235,sanjoy,2020-08-07 21:04:57,41915,41916,Data bug,1,"Sorry for the miscommunication, I meant: ``[code]``",0
No worries ðŸ˜ƒ Thanks for the review BTW.,PrComment,https://github.com/tensorflow/tensorflow/pull/41916#discussion_r467269978,WindQAQ,2020-08-07 21:09:41,41915,41916,Data bug,1,No worries ðŸ˜ƒ Thanks for the review BTW.,4
os.path.join can take multiple paths. You can just join all the parts you need in one line.,PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468865221,qlzh727,2020-08-11 21:07:01,41874,42074,Deployment bug,0,os.path.join can take multiple paths. You can just join all the parts you need in one line.,0
any reason to have atol here? I think the out and out2 should be identical.,PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468866247,qlzh727,2020-08-11 21:09:18,41874,42074,Deployment bug,0,any reason to have atol here? I think the out and out2 should be identical.,0
what's the error message we are expecting here?,PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468866725,qlzh727,2020-08-11 21:10:15,41874,42074,Deployment bug,0,what's the error message we are expecting here?,0
The existing tests have this atol. I assumed it is there in case there is any inaccuracy when saving/loading?  So I just did the same thing as the others. ,PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468899426,yixingfu,2020-08-11 22:26:59,41874,42074,Deployment bug,0,The existing tests have this atol. I assumed it is there in case there is any inaccuracy when saving/loading? So I just did the same thing as the others.,0
Thanks for the comments!,PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468905296,yixingfu,2020-08-11 22:43:01,41874,42074,Deployment bug,0,Thanks for the comments!,3
Expecting `Unable to create file`. I'm changing this to `assertRaisesRegex`.,PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468906158,yixingfu,2020-08-11 22:45:32,41874,42074,Deployment bug,0,Expecting [code]. I'm changing this to [code].,0
"Its bit weird that the file object created is not used at all here, is this h5 file context needed?",PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468975434,qlzh727,2020-08-12 02:54:36,41874,42074,Deployment bug,0,"Its bit weird that the file object created is not used at all here, is this h5 file context needed?",-1
"This object keeps the file open, so that model saving on the same path will error out, in order to test the exception is thrown. Should I add a comment to explain?",PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468982450,yixingfu,2020-08-12 03:23:53,41874,42074,Deployment bug,0,"This object keeps the file open, so that model saving on the same path will error out, in order to test the exception is thrown. Should I add a comment to explain?",0
"oh, that's fine.",PrComment,https://github.com/tensorflow/tensorflow/pull/42074#discussion_r468985439,qlzh727,2020-08-12 03:35:55,41874,42074,Deployment bug,0,"oh, that's fine.",0
"```suggestion
```",PrComment,https://github.com/tensorflow/tensorflow/pull/42143#discussion_r467521205,mihaimaruseac,2020-08-09 01:09:05,42129,42143,Data bug,1,``[code]``,0
"```suggestion
```",PrComment,https://github.com/tensorflow/tensorflow/pull/42143#discussion_r478623136,mihaimaruseac,2020-08-27 18:44:37,42129,42143,Data bug,1,``[code]``,0
Shouldn't we use non_zero_data here? Or only divide gathered_prod by data when either gathered_prod or data is nonzero?,PrComment,https://github.com/tensorflow/tensorflow/pull/42237#discussion_r489524930,alextp,2020-09-16 15:24:06,41090,42237,Algorithm design bug,0,Shouldn't we use non_zero_data here? Or only divide gathered_prod by data when either gathered_prod or data is nonzero?,0
"Good point! I think it doesn't really matter as we have use `where` to select the finite parts, but the change indeed makes the codes clearer. I'll update accordingly. Thank you!",PrComment,https://github.com/tensorflow/tensorflow/pull/42237#discussion_r490415011,WindQAQ,2020-09-17 16:55:09,41090,42237,Algorithm design bug,0,"Good point! I think it doesn't really matter as we have use [code] to select the finite parts, but the change indeed makes the codes clearer. I'll update accordingly. Thank you!",4
"This got flagged by internal tests: in graph mode, attempting to `bool()` cast a Tensor raises a specific error instead (`OperatorNotAllowedInGraphError`, a subclass of `TypeError`). I think the easiest way is to test that either ValueError os TypeError is raised.",PrComment,https://github.com/tensorflow/tensorflow/pull/42397#discussion_r473268921,mdanatg,2020-08-19 19:28:50,42329,42397,Data bug,0,"This got flagged by internal tests: in graph mode, attempting to [code] cast a Tensor raises a specific error instead ([code], a subclass of [code]). I think the easiest way is to test that either ValueError os TypeError is raised.",0
Is this necessary?  `check_numerics_op` does not need this.,PrComment,https://github.com/tensorflow/tensorflow/pull/42615#discussion_r475763854,sanjoy,2020-08-24 17:05:14,42500,42615,Processor bug,1,Is this necessary? [code] does not need this.,-2
"No, I have removed the header that was requiring that, and forgot to remove this.",PrComment,https://github.com/tensorflow/tensorflow/pull/42615#discussion_r475792944,drebain,2020-08-24 17:53:47,42500,42615,Processor bug,1,"No, I have removed the header that was requiring that, and forgot to remove this.",0
do you think we could we make this more specific? maybe have the check be EXPECT_EQ based on what we expect from the simple mock model?,PrComment,https://github.com/tensorflow/tensorflow/pull/43109#discussion_r486472544,advaitjain,2020-09-10 16:21:23,42964,43109,Data bug,0,do you think we could we make this more specific? maybe have the check be EXPECT_EQ based on what we expect from the simple mock model?,1
Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/43109#discussion_r486499145,nkreeger,2020-09-10 17:04:20,42964,43109,Data bug,0,Done.,0
"Removing the macro will slightly increase the mem footprint for this CMSIS-NN kernel. But since dilation support will be available soon, this is only a temporary issue.",PrComment,https://github.com/tensorflow/tensorflow/pull/43484#discussion_r494103465,freddan80,2020-09-24 07:41:07,42951,43484,Processor bug,0,"Removing the macro will slightly increase the mem footprint for this CMSIS-NN kernel. But since dilation support will be available soon, this is only a temporary issue.",1
let's move this comment close to where the reference implementation is being used. Feels a bit out of place here.,PrComment,https://github.com/tensorflow/tensorflow/pull/43484#discussion_r494520264,advaitjain,2020-09-24 18:21:35,42951,43484,Processor bug,0,let's move this comment close to where the reference implementation is being used. Feels a bit out of place here.,0
"in google code, we avoid using yoda-style comparisons. Would be great if the cmsis kernels could follow that convention too.

```cc
if (conv_params.dilation.h == 1 && conv_params.dilation.w == 1)
```",PrComment,https://github.com/tensorflow/tensorflow/pull/43484#discussion_r494521728,advaitjain,2020-09-24 18:23:33,42951,43484,Processor bug,0,"in google code, we avoid using yoda-style comparisons. Would be great if the cmsis kernels could follow that convention too. ``[code]``",1
"can we make a github issue for supporting dilation in the cmsis kernels? and add a TODO(#link to issue): remove calls to reference kernels once dilation is supported with optimized code.
",PrComment,https://github.com/tensorflow/tensorflow/pull/43484#discussion_r494522600,advaitjain,2020-09-24 18:24:51,42951,43484,Processor bug,0,can we make a github issue for supporting dilation in the cmsis kernels? and add a TODO(#link to issue): remove calls to reference kernels once dilation is supported with optimized code.,0
I'll remove this comment and replace it with the TODO instead. ,PrComment,https://github.com/tensorflow/tensorflow/pull/43484#discussion_r494806341,felix-johnny,2020-09-25 07:42:36,42951,43484,Processor bug,0,I'll remove this comment and replace it with the TODO instead.,0
"@felix-johnny can you please remove TODO , this is blocking internal checks",PrComment,https://github.com/tensorflow/tensorflow/pull/43484#discussion_r496220532,rthadur,2020-09-28 20:43:13,42951,43484,Processor bug,0,"@felix-johnny can you please remove TODO , this is blocking internal checks",-2
"> @felix-johnny can you please remove TODO , this is blocking internal checks

I'll take care of this. The todo is useful and I'll modify the internal checks to accept todos in this format as well.",PrComment,https://github.com/tensorflow/tensorflow/pull/43484#discussion_r496251094,advaitjain,2020-09-28 21:44:46,42951,43484,Processor bug,0,"> @felix-johnny can you please remove TODO , this is blocking internal checks I'll take care of this. The todo is useful and I'll modify the internal checks to accept todos in this format as well.",2
I have done this internally to accept todos.,PrComment,https://github.com/tensorflow/tensorflow/pull/43484#discussion_r496343469,rthadur,2020-09-29 02:35:22,42951,43484,Processor bug,0,I have done this internally to accept todos.,0
"the referenced issue doesn't really talk about the bug in kernel_utils.cc

If you could make a separate issue for just that, we can figure out if if can be fixed quickly. And referencing this PR from the newly created issue would also be nice so that we can remember to add the appropriate if check here.",PrComment,https://github.com/tensorflow/tensorflow/pull/43486#discussion_r494529523,advaitjain,2020-09-24 18:32:19,42748,43486,Algorithm design bug,0,"the referenced issue doesn't really talk about the bug in kernel_utils.cc If you could make a separate issue for just that, we can figure out if if can be fixed quickly. And referencing this PR from the newly created issue would also be nice so that we can remember to add the appropriate if check here.",2
nit: prefer static_cast,PrComment,https://github.com/tensorflow/tensorflow/pull/43486#discussion_r494531127,advaitjain,2020-09-24 18:34:37,42748,43486,Algorithm design bug,0,nit: prefer static_cast,0
nit: prefer static_cast,PrComment,https://github.com/tensorflow/tensorflow/pull/43486#discussion_r494531223,advaitjain,2020-09-24 18:34:48,42748,43486,Algorithm design bug,0,nit: prefer static_cast,0
Ah.. wrote the wrong ticket number here. It is https://github.com/tensorflow/tensorflow/issues/42883 . I'll fix that. I've made a reference in the issue as well about this PR.,PrComment,https://github.com/tensorflow/tensorflow/pull/43486#discussion_r494780094,felix-johnny,2020-09-25 06:44:24,42748,43486,Algorithm design bug,0,Ah.. wrote the wrong ticket number here. It is [url] . I'll fix that. I've made a reference in the issue as well about this PR.,1
The if check and the subsequent memory save would be applicable for the reference implementations of conv and DW conv as well. ,PrComment,https://github.com/tensorflow/tensorflow/pull/43486#discussion_r494787991,felix-johnny,2020-09-25 07:03:02,42748,43486,Algorithm design bug,0,The if check and the subsequent memory save would be applicable for the reference implementations of conv and DW conv as well.,0
sure. I've fixed it for the reference implementation as well.,PrComment,https://github.com/tensorflow/tensorflow/pull/43486#discussion_r494792283,felix-johnny,2020-09-25 07:13:02,42748,43486,Algorithm design bug,0,sure. I've fixed it for the reference implementation as well.,3
Lets use an explicit array (or couple of arrays) here instead,PrComment,https://github.com/tensorflow/tensorflow/pull/45280#discussion_r538685946,jpienaar,2020-12-08 18:17:17,44788,45280,Data bug,1,Lets use an explicit array (or couple of arrays) here instead,0
Shall we remove the else and just have this the final statement?,PrComment,https://github.com/tensorflow/tensorflow/pull/45280#discussion_r538703292,jpienaar,2020-12-08 18:33:58,44788,45280,Data bug,1,Shall we remove the else and just have this the final statement?,0
Is this path tested?,PrComment,https://github.com/tensorflow/tensorflow/pull/45280#discussion_r538707076,jpienaar,2020-12-08 18:37:35,44788,45280,Data bug,1,Is this path tested?,0
"Updated to `np.arange(6).reshape(3, 2, 1)`",PrComment,https://github.com/tensorflow/tensorflow/pull/45280#discussion_r539007660,WindQAQ,2020-12-09 05:02:26,44788,45280,Data bug,1,Updated to [code],0
Updated,PrComment,https://github.com/tensorflow/tensorflow/pull/45280#discussion_r539007695,WindQAQ,2020-12-09 05:02:32,44788,45280,Data bug,1,Updated,0
Updated. See https://github.com/tensorflow/tensorflow/pull/45280/files#diff-726ba0e315de050c5239e934b36007b491757737d48f1308551d8e17beedb4ddR126,PrComment,https://github.com/tensorflow/tensorflow/pull/45280#discussion_r539007840,WindQAQ,2020-12-09 05:03:01,44788,45280,Data bug,1,Updated. See [url]#diff-726ba0e315de050c5239e934b36007b491757737d48f1308551d8e17beedb4ddR126,0
"```suggestion
```

This is no longer needed",PrComment,https://github.com/tensorflow/tensorflow/pull/45675#discussion_r549135101,mihaimaruseac,2020-12-27 16:46:11,45392,45675,Data bug,1,``[code]`` This is no longer needed,0
Let's add comments here for why we are using the iterator based versions instead of the constructors that take a single argument.,PrComment,https://github.com/tensorflow/tensorflow/pull/45675#discussion_r549135198,mihaimaruseac,2020-12-27 16:46:49,45392,45675,Data bug,1,Let's add comments here for why we are using the iterator based versions instead of the constructors that take a single argument.,0
@mihaimaruseac Thanks. The extraneous include has been removed.,PrComment,https://github.com/tensorflow/tensorflow/pull/45675#discussion_r549357080,yongtang,2020-12-28 13:58:06,45392,45675,Data bug,1,@mihaimaruseac Thanks. The extraneous include has been removed.,3
"Thanks @mihaimaruseac. I checked again, as `std_order` is actually initialized through the following line `std::iota(...)`, `std_order` only needs to be initialized with appropriate size (no need to get the copy of the shape). For that I have replace the initialization of `std_order` with `gtl::InlinedVector<int64, 8> std_order(input_shape.size())`.",PrComment,https://github.com/tensorflow/tensorflow/pull/45675#discussion_r549358096,yongtang,2020-12-28 14:01:20,45392,45675,Data bug,1,"Thanks @mihaimaruseac. I checked again, as [code] is actually initialized through the following line [code], [code] only needs to be initialized with appropriate size (no need to get the copy of the shape). For that I have replace the initialization of [code] with [code].",3
Let's replace the number with the URL so it's easy to get to the issue.,PrComment,https://github.com/tensorflow/tensorflow/pull/46013#discussion_r549785984,mihaimaruseac,2020-12-29 17:25:12,45975,46013,Data bug,0,Let's replace the number with the URL so it's easy to get to the issue.,2
@mihaimaruseac The PR has been updated. ,PrComment,https://github.com/tensorflow/tensorflow/pull/46013#discussion_r549796861,yongtang,2020-12-29 18:01:12,45975,46013,Data bug,0,@mihaimaruseac The PR has been updated.,0
"nit, you can reduce those two returns with only one at the end.",PrComment,https://github.com/tensorflow/tensorflow/pull/46150#discussion_r557732165,haozha111,2021-01-14 22:12:47,38638,46150,Deployment bug,0,"nit, you can reduce those two returns with only one at the end.",0
Will do!,PrComment,https://github.com/tensorflow/tensorflow/pull/46150#discussion_r557744941,WindQAQ,2021-01-14 22:39:06,38638,46150,Deployment bug,0,Will do!,3
Updated. Please see if this is better.,PrComment,https://github.com/tensorflow/tensorflow/pull/46150#discussion_r557750638,WindQAQ,2021-01-14 22:52:33,38638,46150,Deployment bug,0,Updated. Please see if this is better.,1
Yeap! It looks better. ,PrComment,https://github.com/tensorflow/tensorflow/pull/46150#discussion_r557751587,haozha111,2021-01-14 22:54:56,38638,46150,Deployment bug,0,Yeap! It looks better.,3
Looks like we're weren't passing TARGET in before. I'm confused how this worked previously.,PrComment,https://github.com/tensorflow/tensorflow/pull/46187#discussion_r552265468,njeffrie,2021-01-05 23:45:53,46186,46187,Test bug,0,Looks like we're weren't passing TARGET in before. I'm confused how this worked previously.,-1
"It worked for everything but running tests with renode (which is the only place where we need `TARGET`.

Even with renode, it works when we call `make test` which is what is part of our CI since that uses a different test rule which does pass in the target:
https://github.com/tensorflow/tensorflow/blob/d9841dfd9689f9c4e0bc4e1229dbc354f01ebc1b/tensorflow/lite/micro/tools/make/targets/bluepill_makefile.inc#L69-L71

This common code in helper_functions.inc is only used when we do:
```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill test_kernel_add_test
```

which is what this change is fixing.",PrComment,https://github.com/tensorflow/tensorflow/pull/46187#discussion_r552287641,advaitjain,2021-01-06 00:29:09,46186,46187,Test bug,0,"It worked for everything but running tests with renode (which is the only place where we need [code]. Even with renode, it works when we call [code] which is what is part of our CI since that uses a different test rule which does pass in the target: [url]#L69-L71 This common code in helper_functions.inc is only used when we do: ``[code]`` which is what this change is fixing.",0
Can you explain why the neg op help here?,PrComment,https://github.com/tensorflow/tensorflow/pull/46749#discussion_r565882421,thaink,2021-01-28 07:52:59,46724,46749,Deployment bug,0,Can you explain why the neg op help here?,0
"It's somehow tricky. When there is no following ops (not limited to neg), temporary allocation with `kTfLiteArenaRw` type tends to re-claim the same memory across each evaluation and no other ops will modify values at that memory address (cause no other memory allocations take place). Therefore, the values of rhs are not polluted without neg op, and next evaluation can also get the same piece of memory, so the results are correct.

https://colab.research.google.com/drive/1eFVszZZN-NcR64X_VHns0w-l3Vwci0CY?usp=sharing

Here is the colab link from original post. Values of last tensor (temp tensor, transposed rhs) become

```
[[-51. -84.]
 [  3.   6.]
 [  7.   9.]]
```

where -51, -84 are the last two elements of `Identity` (output of neg op). While without neg op, everything works smoothly.",PrComment,https://github.com/tensorflow/tensorflow/pull/46749#discussion_r565893196,WindQAQ,2021-01-28 08:13:25,46724,46749,Deployment bug,0,"It's somehow tricky. When there is no following ops (not limited to neg), temporary allocation with [code] type tends to re-claim the same memory across each evaluation and no other ops will modify values at that memory address (cause no other memory allocations take place). Therefore, the values of rhs are not polluted without neg op, and next evaluation can also get the same piece of memory, so the results are correct. [url] Here is the colab link from original post. Values of last tensor (temp tensor, transposed rhs) become ``[code]`[code]Identity` (output of neg op). While without neg op, everything works smoothly.",0
Acked. Thanks for explanation.  May be it worths a comment then.,PrComment,https://github.com/tensorflow/tensorflow/pull/46749#discussion_r566174985,thaink,2021-01-28 15:18:15,46724,46749,Deployment bug,0,Acked. Thanks for explanation. May be it worths a comment then.,2
Updated comments. See if it's better! Thanks!,PrComment,https://github.com/tensorflow/tensorflow/pull/46749#discussion_r566323346,WindQAQ,2021-01-28 18:39:54,46724,46749,Deployment bug,0,Updated comments. See if it's better! Thanks!,3
AreCastCompatible is used for shape verification. I think you want to verify that source element type of operand and result are the same.,PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r567159414,smit-hinsu,2021-01-30 00:11:01,46656,46798,Deployment bug,0,AreCastCompatible is used for shape verification. I think you want to verify that source element type of operand and result are the same.,0
"Thanks for review! I think it checks both element type and shape and is used in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tensorflow/ir/tf_ops_a_m.cc#L792 to verfiy IfOp/WhileOp. Maybe checking element type only is too strict?

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tensorflow/ir/tf_types.cc#L251-L268",PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r567161568,WindQAQ,2021-01-30 00:20:07,46656,46798,Deployment bug,0,Thanks for review! I think it checks both element type and shape and is used in [url]#L792 to verfiy IfOp/WhileOp. Maybe checking element type only is too strict? [url]#L251-L268,1
We can expect all legal tensorflow tf.Cast ops to have the same operand and result shape at runtime. We don't have a verifier for this but we should add one.,PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r567168418,smit-hinsu,2021-01-30 00:53:07,46656,46798,Deployment bug,0,We can expect all legal tensorflow tf.Cast ops to have the same operand and result shape at runtime. We don't have a verifier for this but we should add one.,0
Should we also check cast_op.Truncate()?,PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r567173861,jurahul,2021-01-30 01:21:41,46656,46798,Deployment bug,0,Should we also check cast_op.Truncate()?,0
"Not sure if this test is actually testing the changed code. We look through casts inside the IfRegion body, but the cast here is outside.",PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r567174073,jurahul,2021-01-30 01:22:57,46656,46798,Deployment bug,0,"Not sure if this test is actually testing the changed code. We look through casts inside the IfRegion body, but the cast here is outside.",-1
Got it!,PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r567179205,WindQAQ,2021-01-30 01:56:34,46656,46798,Deployment bug,0,Got it!,2
"Thanks for review! This testcase is exactly the one in the original issue. MatchCallArgs does not limit to ops inside the region, that is, it keeps tracking back the definingOp until it is not a cast op.",PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r567179866,WindQAQ,2021-01-30 02:00:24,46656,46798,Deployment bug,0,"Thanks for review! This testcase is exactly the one in the original issue. MatchCallArgs does not limit to ops inside the region, that is, it keeps tracking back the definingOp until it is not a cast op.",3
Updated description: Two testcases for IfOp are trivial transforms but one with extern incompatible cast and the other has non-extern incompatible cast.,PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r567182598,WindQAQ,2021-01-30 02:22:18,46656,46798,Deployment bug,0,Updated description: Two testcases for IfOp are trivial transforms but one with extern incompatible cast and the other has non-extern incompatible cast.,0
"if src and dest type are same, then I'd assume Truncate = false, so no need to check that. Otherwise this looks good. ",PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r568065864,jurahul,2021-02-01 18:59:20,46656,46798,Deployment bug,0,"if src and dest type are same, then I'd assume Truncate = false, so no need to check that. Otherwise this looks good.",2
Updated!,PrComment,https://github.com/tensorflow/tensorflow/pull/46798#discussion_r568110256,WindQAQ,2021-02-01 20:14:54,46656,46798,Deployment bug,0,Updated!,0
I hope you don't need this decorator. Can you remove it and see if the tests pass?,PrComment,https://github.com/tensorflow/tensorflow/pull/46973#discussion_r602671890,rohan100jain,2021-03-27 05:11:02,46891,46973,Data bug,1,I hope you don't need this decorator. Can you remove it and see if the tests pass?,0
nit: s/Scaler/Scalar,PrComment,https://github.com/tensorflow/tensorflow/pull/46973#discussion_r602671910,rohan100jain,2021-03-27 05:11:14,46891,46973,Data bug,1,nit: s/Scaler/Scalar,0
ditto,PrComment,https://github.com/tensorflow/tensorflow/pull/46973#discussion_r602671933,rohan100jain,2021-03-27 05:11:20,46891,46973,Data bug,1,ditto,0
"Thanks @rohan100jain, Updated.",PrComment,https://github.com/tensorflow/tensorflow/pull/46973#discussion_r602911365,yongtang,2021-03-28 18:07:58,46891,46973,Data bug,1,"Thanks @rohan100jain, Updated.",3
Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/46973#discussion_r602911379,yongtang,2021-03-28 18:08:03,46891,46973,Data bug,1,Updated.,0
Updated.,PrComment,https://github.com/tensorflow/tensorflow/pull/46973#discussion_r602911406,yongtang,2021-03-28 18:08:09,46891,46973,Data bug,1,Updated.,0
nit: put these above the others so they test in increasing rank order.,PrComment,https://github.com/tensorflow/tensorflow/pull/46973#discussion_r607953152,cantonios,2021-04-06 15:27:16,46891,46973,Data bug,1,nit: put these above the others so they test in increasing rank order.,0
Thanks @cantonios. Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/46973#discussion_r607965621,yongtang,2021-04-06 15:42:01,46891,46973,Data bug,1,Thanks @cantonios. Done.,3
"Thanks for the update. The output tensor shape and value need to be updated as well.

>>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')
>>> max_pool_2d(x)
<tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=
array([[[[6.],
         [8.]]]], dtype=float32)>
",PrComment,https://github.com/tensorflow/tensorflow/pull/47003#discussion_r573269689,qlzh727,2021-02-09 21:54:37,46998,47003,Documentation bug,0,"Thanks for the update. The output tensor shape and value need to be updated as well. >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid') >>> max_pool_2d(x) <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy= array([[[[6.], [8.]]]], dtype=float32)>",0
Updated the shape and output. Thanks for pointing it out.,PrComment,https://github.com/tensorflow/tensorflow/pull/47003#discussion_r573472520,amahendrakar,2021-02-10 06:10:59,46998,47003,Documentation bug,0,Updated the shape and output. Thanks for pointing it out.,3
I think you can skip axis since its never changed by the caller.,PrComment,https://github.com/tensorflow/tensorflow/pull/47012#discussion_r585093342,qlzh727,2021-03-01 22:23:57,35199,47012,Deployment bug,0,I think you can skip axis since its never changed by the caller.,1
Sure let me modify it real quick.,PrComment,https://github.com/tensorflow/tensorflow/pull/47012#discussion_r585094704,WindQAQ,2021-03-01 22:26:18,35199,47012,Deployment bug,0,Sure let me modify it real quick.,3
Done ðŸ˜ƒ ,PrComment,https://github.com/tensorflow/tensorflow/pull/47012#discussion_r585096539,WindQAQ,2021-03-01 22:29:26,35199,47012,Deployment bug,0,Done ðŸ˜ƒ,5
Could you add a test case where the given batch dim is dynamic only to verify the inference result?,PrComment,https://github.com/tensorflow/tensorflow/pull/47060#discussion_r573660226,abattery,2021-02-10 11:41:13,47057,47060,Deployment bug,0,Could you add a test case where the given batch dim is dynamic only to verify the inference result?,0
Thanks for the review. See `testDynamicBatchConv2D`.,PrComment,https://github.com/tensorflow/tensorflow/pull/47060#discussion_r573955189,WindQAQ,2021-02-10 18:05:01,47057,47060,Deployment bug,0,Thanks for the review. See [code].,2
How about moving these new tests under shape inference test if it is available?,PrComment,https://github.com/tensorflow/tensorflow/pull/47060#discussion_r574131964,abattery,2021-02-10 22:45:03,47057,47060,Deployment bug,0,How about moving these new tests under shape inference test if it is available?,0
"For example, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tensorflow/tests/shape_inference.mlir",PrComment,https://github.com/tensorflow/tensorflow/pull/47060#discussion_r574187885,abattery,2021-02-11 00:48:44,47057,47060,Deployment bug,0,"For example, [url]",0
Thanks for pointing out :) Let me try it real quick.,PrComment,https://github.com/tensorflow/tensorflow/pull/47060#discussion_r574216348,WindQAQ,2021-02-11 02:24:04,47057,47060,Deployment bug,0,Thanks for pointing out :) Let me try it real quick.,3
Updated ðŸ˜ƒ ,PrComment,https://github.com/tensorflow/tensorflow/pull/47060#discussion_r574234448,WindQAQ,2021-02-11 03:37:12,47057,47060,Deployment bug,0,Updated ðŸ˜ƒ,3
Nit: Could you modify this sentence to make a complete sentence?,PrComment,https://github.com/tensorflow/tensorflow/pull/47060#discussion_r574236274,abattery,2021-02-11 03:45:13,47057,47060,Deployment bug,0,Nit: Could you modify this sentence to make a complete sentence?,0
See if this is better ðŸ˜ƒ ,PrComment,https://github.com/tensorflow/tensorflow/pull/47060#discussion_r574239464,WindQAQ,2021-02-11 03:58:13,47057,47060,Deployment bug,0,See if this is better ðŸ˜ƒ,3
"Actually, in certain conditions we will stick a dtype into the config, causing this to fail. Could you update this to 

config['config']['bias_initializer']['class_name'], 'Zeros'

That should be more robust and allow us to merge this.",PrComment,https://github.com/tensorflow/tensorflow/pull/47128#discussion_r589738647,mattdangerw,2021-03-08 20:50:22,47054,47128,Deployment bug,0,"Actually, in certain conditions we will stick a dtype into the config, causing this to fail. Could you update this to config['config']['bias_initializer']['class_name'], 'Zeros' That should be more robust and allow us to merge this.",2
Here too,PrComment,https://github.com/tensorflow/tensorflow/pull/47128#discussion_r589738760,mattdangerw,2021-03-08 20:50:35,47054,47128,Deployment bug,0,Here too,0
Done,PrComment,https://github.com/tensorflow/tensorflow/pull/47128#discussion_r590354932,mishc9,2021-03-09 13:10:44,47054,47128,Deployment bug,0,Done,0
"Not sure if you agree, but I think making the env for user to over the top_k value is more flexible. If that is what we will do, this code will look like this:
```
std::optional<int64> user_request_top_k = read from env
if (user_request_top_k) {
    if (top_k <= user_request_top_k.value()) {
           issue a VLOG message saying the user request is not used because it is bigger than the natural top_k.
    } else {
          issue a VLOG to tell the ""natural top_k"" and user requested top_k values, and the use requested one is use
          top_k = user_requested_top_k.value();
          keep_top_k = min(top_k, keep_top_k)
    }
}
if (top_k > 4096)
   return errors::InvalidaArgument(...)
```
",PrComment,https://github.com/tensorflow/tensorflow/pull/47698#discussion_r591685176,bixia1,2021-03-10 16:41:12,46453,47698,Deployment bug,1,"Not sure if you agree, but I think making the env for user to over the top_k value is more flexible. If that is what we will do, this code will look like this: ``[code]``",1
"I believe what we need here is a way for the user to opt-in for a conversion in case the TRT converted op is not strictly equivalent with the TF op. While your suggestion can be used to reach the same goal, I do not see the need for flexibly overriding top_k, and therefore I would choose the current simpler solution.

Why would the user want to override top_k with a concrete value? More importantly, how would he/she decide what value to use? The TF-TRT converter does this job: it sets a value for top_k based on the input parameters. If that value is not compatible with TRT, then we either skip conversion, or not (this case only with the users consent). If we do not skip conversion, then the next best thing (in terms of correctness of the results) is to set the max value allowed by the plugin.
",PrComment,https://github.com/tensorflow/tensorflow/pull/47698#discussion_r591728865,tfeher,2021-03-10 17:34:55,46453,47698,Deployment bug,1,"I believe what we need here is a way for the user to opt-in for a conversion in case the TRT converted op is not strictly equivalent with the TF op. While your suggestion can be used to reach the same goal, I do not see the need for flexibly overriding top_k, and therefore I would choose the current simpler solution. Why would the user want to override top_k with a concrete value? More importantly, how would he/she decide what value to use? The TF-TRT converter does this job: it sets a value for top_k based on the input parameters. If that value is not compatible with TRT, then we either skip conversion, or not (this case only with the users consent). If we do not skip conversion, then the next best thing (in terms of correctness of the results) is to set the max value allowed by the plugin.",0
"See [this comment](https://github.com/tensorflow/tensorflow/issues/46453#issuecomment-774227477).
Can this value affect performance? That is the only reason I can think of to allow users change the value.
",PrComment,https://github.com/tensorflow/tensorflow/pull/47698#discussion_r591741329,bixia1,2021-03-10 17:51:56,46453,47698,Deployment bug,1,See [this comment]([url]#issuecomment-774227477). Can this value affect performance? That is the only reason I can think of to allow users change the value.,0
"This is already what `super(Lambda, self).compute_output_shape(input_shape)` is supposed to do (`compute_output_shape` method of `Layer` base class). Why can't we leverage it, instead of duplicating the functionality?",PrComment,https://github.com/tensorflow/tensorflow/pull/48207#discussion_r614281429,fchollet,2021-04-15 17:58:45,44906,48207,Algorithm design bug,0,"This is already what [code] is supposed to do ([code] method of [code] base class). Why can't we leverage it, instead of duplicating the functionality?",-2
"```_functional_construction_call``` under ```__call__``` raises RecusionError bug.
I use call instead in order to fix it.",PrComment,https://github.com/tensorflow/tensorflow/pull/48207#discussion_r615273442,fsx950223,2021-04-17 16:20:30,44906,48207,Algorithm design bug,0,``[code]`[code]`[code]`` raises RecusionError bug. I use call instead in order to fix it.,0
"I would recommend modifying the line `outputs = self(inputs, training=False)` to use `call` in `compute_output_shape` in `Layer`. That should be more generic, and it will avoid reimplementing functionality twice.",PrComment,https://github.com/tensorflow/tensorflow/pull/48207#discussion_r616044272,fchollet,2021-04-19 17:33:35,44906,48207,Algorithm design bug,0,"I would recommend modifying the line [code] to use [code] in [code] in [code]. That should be more generic, and it will avoid reimplementing functionality twice.",2
Done,PrComment,https://github.com/tensorflow/tensorflow/pull/48207#discussion_r616442018,fsx950223,2021-04-20 08:02:13,44906,48207,Algorithm design bug,0,Done,0
"I'm not sure what ""course assignments, templates"" you're referring to here. The link goes to the lite directory.

Can you clarify? Maybe: ""For the Udacity course notebooks see  [this directory](https://github.com/tensorflow/examples/tree/master/courses)""

",PrComment,https://github.com/tensorflow/tensorflow/pull/48398#discussion_r609660537,MarkDaoust,2021-04-08 12:47:35,48394,48398,Documentation bug,0,"I'm not sure what ""course assignments, templates"" you're referring to here. The link goes to the lite directory. Can you clarify? Maybe: ""For the Udacity course notebooks see [this directory]([url]""",0
"Hmm alright. I thought it was assignments ðŸ˜… coz the heading mentioned so! Anyway, updating this and yes, it redirects to lite directory",PrComment,https://github.com/tensorflow/tensorflow/pull/48398#discussion_r609702197,alphaX86,2021-04-08 13:30:08,48394,48398,Documentation bug,0,"Hmm alright. I thought it was assignments ðŸ˜… coz the heading mentioned so! Anyway, updating this and yes, it redirects to lite directory",1
"I've updated it, please check ðŸ‘ ",PrComment,https://github.com/tensorflow/tensorflow/pull/48398#discussion_r609706008,alphaX86,2021-04-08 13:33:37,48394,48398,Documentation bug,0,"I've updated it, please check ðŸ‘",3
"Let's make the ""magic"" explicit

`# Trim the output. Will do nothing if _output_sequence_length is None.`

Or something like that",PrComment,https://github.com/tensorflow/tensorflow/pull/48434#discussion_r621755532,mattdangerw,2021-04-28 02:08:35,47954,48434,Data bug,0,"Let's make the ""magic"" explicit [code] Or something like that",1
"Thanks, @mattdangerw 
WE added some unit tests ;)",PrComment,https://github.com/tensorflow/tensorflow/pull/48434#discussion_r625774650,eli-osherovich,2021-05-04 13:20:25,47954,48434,Data bug,0,"Thanks, @mattdangerw WE added some unit tests ;)",5
"""The value of the `filters` argument should not be zero.""",PrComment,https://github.com/tensorflow/tensorflow/pull/48566#discussion_r616087766,fchollet,2021-04-19 18:41:43,48470,48566,Algorithm design bug,0,"""The value of the [code] argument should not be zero.""",0
"In all tests, please use `assertRaisesRegex` to check the error message.",PrComment,https://github.com/tensorflow/tensorflow/pull/48566#discussion_r616088036,fchollet,2021-04-19 18:42:09,48470,48566,Algorithm design bug,0,"In all tests, please use [code] to check the error message.",0
@fchollet Made the necessary changes. Thank you for reviewing .,PrComment,https://github.com/tensorflow/tensorflow/pull/48566#discussion_r616103182,around-star,2021-04-19 19:02:56,48470,48566,Algorithm design bug,0,@fchollet Made the necessary changes. Thank you for reviewing .,3
"It has two params  `self.assertRaisesRegex(ValueError, <str>):`",PrComment,https://github.com/tensorflow/tensorflow/pull/48566#discussion_r616276874,bhack,2021-04-20 01:18:16,48470,48566,Algorithm design bug,0,It has two params [code],0
@bhack sorry about that. I fixed it.,PrComment,https://github.com/tensorflow/tensorflow/pull/48566#discussion_r616280626,around-star,2021-04-20 01:29:44,48470,48566,Algorithm design bug,0,@bhack sorry about that. I fixed it.,2
"we are incrementally moving away from TF_LITE_ERROR_REPORTER in favor of using MicroPrintf:
https://github.com/tensorflow/tensorflow/blob/282fa073abc720a3b668c0aebe607c4105c3effe/tensorflow/lite/micro/micro_error_reporter.h#L26

Can you switch this over to
```cc
MicroPrintf(""%s (id=%d): size=%d, offset=%d, first_used=%d last_used=%d"", s, i, requirements_[i].size, buffer_offsets_[i],requirements_[i].first_time_used, requirements_[i].last_time_used);
```",PrComment,https://github.com/tensorflow/tensorflow/pull/48595#discussion_r620435268,advaitjain,2021-04-26 16:00:23,48606,48595,Visualization bug,0,we are incrementally moving away from TF_LITE_ERROR_REPORTER in favor of using MicroPrintf: [url]#L26 Can you switch this over to ``[code]``,0
"use MicroPrintf instead.

and I believe that the error_reporter param can be dropped from PrintMemoryPlan with this change.",PrComment,https://github.com/tensorflow/tensorflow/pull/48595#discussion_r620435679,advaitjain,2021-04-26 16:00:52,48606,48595,Visualization bug,0,use MicroPrintf instead. and I believe that the error_reporter param can be dropped from PrintMemoryPlan with this change.,0
"I'm wondering if we can somehow mentioned on why there's changes on the implementation on the PR's description, previously we're using `backend` instead of `array_ops`.",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r617359251,irvifa,2021-04-21 09:33:09,48589,48610,Algorithm design bug,0,"I'm wondering if we can somehow mentioned on why there's changes on the implementation on the PR's description, previously we're using [code] instead of [code].",0
"@irvifa 
Can you please elaborate on that?",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r617360905,AdityaKane2001,2021-04-21 09:35:23,48589,48610,Algorithm design bug,0,@irvifa Can you please elaborate on that?,0
"Actually in the issue the user pointed out that some of the calls were deprecated. Also, backend also calls `array_ops` methods, so I called them directly.",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r617362051,AdityaKane2001,2021-04-21 09:37:02,48589,48610,Algorithm design bug,0,"Actually in the issue the user pointed out that some of the calls were deprecated. Also, backend also calls [code] methods, so I called them directly.",0
Please change to singular form: output_shapes => output_shape,PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r618655650,chenmoneygithub,2021-04-22 18:47:03,48589,48610,Algorithm design bug,0,Please change to singular form: output_shapes => output_shape,0
"all() operator here is a bit unclear, please change to 0 in output_shapes, or do specific checks on the dimension.",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r618656401,chenmoneygithub,2021-04-22 18:48:07,48589,48610,Algorithm design bug,0,"all() operator here is a bit unclear, please change to 0 in output_shapes, or do specific checks on the dimension.",-1
"Is it an invalid shape? If true, consider changing the test name to test_conv1d_invalid_output_shapes()?",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r618656741,chenmoneygithub,2021-04-22 18:48:39,48589,48610,Algorithm design bug,0,"Is it an invalid shape? If true, consider changing the test name to test_conv1d_invalid_output_shapes()?",0
Same as above,PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r618656839,chenmoneygithub,2021-04-22 18:48:48,48589,48610,Algorithm design bug,0,Same as above,0
Could you explain why we need to skip checks on the channel axis? Also please consider putting a comment before the if check.,PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r624038148,chenmoneygithub,2021-04-30 17:17:41,48589,48610,Algorithm design bug,0,Could you explain why we need to skip checks on the channel axis? Also please consider putting a comment before the if check.,0
"The code chunk under if and else are basically same, usually we discourage duplicated code. Could you create a small helper function to wrap the code? Thx!",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r624039075,chenmoneygithub,2021-04-30 17:19:20,48589,48610,Algorithm design bug,0,"The code chunk under if and else are basically same, usually we discourage duplicated code. Could you create a small helper function to wrap the code? Thx!",2
"Sure, I'll add one",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r624042883,AdityaKane2001,2021-04-30 17:25:57,48589,48610,Algorithm design bug,0,"Sure, I'll add one",3
"@chenmoneygithub 
The channel axis is dependent on no. of filters, which are checked by the additions made in #48566 . ",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r624043183,AdityaKane2001,2021-04-30 17:26:26,48589,48610,Algorithm design bug,0,"@chenmoneygithub The channel axis is dependent on no. of filters, which are checked by the additions made in #48566 .",0
Also the rest of the arguments for `conv_utils.conv_output_length` don't consider channels and batch size.,PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r624054448,AdityaKane2001,2021-04-30 17:44:15,48589,48610,Algorithm design bug,0,Also the rest of the arguments for [code] don't consider channels and batch size.,-1
"Nit: delete the space after 'filters': 2. 'filters': 2 , => 'filters': 2,",PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r625968278,chenmoneygithub,2021-05-04 17:24:32,48589,48610,Algorithm design bug,0,"Nit: delete the space after 'filters': 2. 'filters': 2 , => 'filters': 2,",0
Same here,PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r625968381,chenmoneygithub,2021-05-04 17:24:42,48589,48610,Algorithm design bug,0,Same here,0
Same here,PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r625968580,chenmoneygithub,2021-05-04 17:25:00,48589,48610,Algorithm design bug,0,Same here,0
Same here,PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r625968652,chenmoneygithub,2021-05-04 17:25:07,48589,48610,Algorithm design bug,0,Same here,0
Nit: space between var and operator: output_dimension<=0 => output_dimension <= 0,PrComment,https://github.com/tensorflow/tensorflow/pull/48610#discussion_r625969069,chenmoneygithub,2021-05-04 17:25:50,48589,48610,Algorithm design bug,0,Nit: space between var and operator: output_dimension<=0 => output_dimension <= 0,0
"I did not notice this earlier, but a setter for an immutable property seems like a code smell to me.  Have you tried passing in the stream via the constructor somehow?

(Does not need to be addressed in this PR.)",PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r634058763,sanjoy,2021-05-18 05:43:21,48869,49173,Processor bug,0,"I did not notice this earlier, but a setter for an immutable property seems like a code smell to me. Have you tried passing in the stream via the constructor somehow? (Does not need to be addressed in this PR.)",-1
"Mostly, the GpuDevice need the gpu_allocator. But the gpu_allocator need the stream created by the GpuDevice.
Fixing this would request a refactoring that will break existing API and I wasn't sure if those API was part of the public API or not. As I wanted this to get in TF2.5, I prefered to stay away from this refactoring.
Relevant code:
https://github.com/tensorflow/tensorflow/blob/aa08697dcb98135ee39ba00ee08b5c1a28cfde61/tensorflow/core/common_runtime/gpu/gpu_device.cc#L1414-L1422

(I also updated the PR description)
(I amended the test commit to remove a commented left over line)",PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r634364987,nouiz,2021-05-18 13:13:52,48869,49173,Processor bug,0,"Mostly, the GpuDevice need the gpu_allocator. But the gpu_allocator need the stream created by the GpuDevice. Fixing this would request a refactoring that will break existing API and I wasn't sure if those API was part of the public API or not. As I wanted this to get in TF2.5, I prefered to stay away from this refactoring. Relevant code: [url]#L1414-L1422 (I also updated the PR description) (I amended the test commit to remove a commented left over line)",0
"s/instanciated/instantiated/ everywhere.

Also s/nb/number",PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r640299607,sanjoy,2021-05-27 05:34:24,48869,49173,Processor bug,0,s/instanciated/instantiated/ everywhere. Also s/nb/number,0
Does this need to be an `std::atomic`?,PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r640299941,sanjoy,2021-05-27 05:35:15,48869,49173,Processor bug,0,Does this need to be an [code]?,0
Maybe call this `GetInstantiatedCountTestOnly`?,PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r640300086,sanjoy,2021-05-27 05:35:38,48869,49173,Processor bug,0,Maybe call this [code]?,0
Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r640639895,nouiz,2021-05-27 13:46:35,48869,49173,Processor bug,0,Done.,3
Done.,PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r640639964,nouiz,2021-05-27 13:46:41,48869,49173,Processor bug,0,Done.,0
Implemented. Note the current TF GpuDevice create them serially. But having it atomic is more future proof.,PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r640640481,nouiz,2021-05-27 13:47:13,48869,49173,Processor bug,0,Implemented. Note the current TF GpuDevice create them serially. But having it atomic is more future proof.,2
Could you please use `DCHECK` instead? We don't use `CHECK` in new code anymore. Sorry we didn't notice this earlier!,PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r647784441,penpornk,2021-06-08 20:51:31,48869,49173,Processor bug,0,Could you please use [code] instead? We don't use [code] in new code anymore. Sorry we didn't notice this earlier!,-1
"This is a test. I really want a crash even in no-debug mode.
So I pushed a change to use an EXPECT instead.",PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r647800021,nouiz,2021-06-08 21:17:36,48869,49173,Processor bug,0,This is a test. I really want a crash even in no-debug mode. So I pushed a change to use an EXPECT instead.,0
Is this correct? Assigning an integer constant to a bool seems wrong. ,PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r649680757,ruler501,2021-06-11 04:25:15,48869,49173,Processor bug,0,Is this correct? Assigning an integer constant to a bool seems wrong.,-1
"This is not assigning a value, but assigning an ID. So this is fine.",PrComment,https://github.com/tensorflow/tensorflow/pull/49173#discussion_r649709837,akuegel,2021-06-11 05:56:56,48869,49173,Processor bug,0,"This is not assigning a value, but assigning an ID. So this is fine.",2
"Consider rephrasing, something like:

The examples above illustrate how to specify custom gradients for functions which do not read from variables. The following example uses variables, which require special handling because they are effectively inputs of the forward function:",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638336864,allenlavoie,2021-05-24 22:44:53,26270,49488,Documentation bug,0,"Consider rephrasing, something like: The examples above illustrate how to specify custom gradients for functions which do not read from variables. The following example uses variables, which require special handling because they are effectively inputs of the forward function:",0
Re-creating a variable every time `linear_poly` is called is pretty weird. The common case would be a variable created outside the function and captured. Can the example do that instead?,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638338031,allenlavoie,2021-05-24 22:48:24,26270,49488,Documentation bug,0,Re-creating a variable every time [code] is called is pretty weird. The common case would be a variable created outside the function and captured. Can the example do that instead?,-1
"In this example the variable is used in the forward pass, so `variables` had better not be None, right? Maybe just assert instead and leave a comment / describe after the example what to do if you don't know which variables were accessed in the forward pass (or just leave that bit out).",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638340095,allenlavoie,2021-05-24 22:50:51,26270,49488,Documentation bug,0,"In this example the variable is used in the forward pass, so [code] had better not be None, right? Maybe just assert instead and leave a comment / describe after the example what to do if you don't know which variables were accessed in the forward pass (or just leave that bit out).",0
"I don't think this should be a variable just because it's computing the gradient of a variable. Then you can pass just the list to concat, which looks like it's instead un-packing the value read from the variable and re-concatting things right now.",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638341127,allenlavoie,2021-05-24 22:53:33,26270,49488,Documentation bug,0,"I don't think this should be a variable just because it's computing the gradient of a variable. Then you can pass just the list to concat, which looks like it's instead un-packing the value read from the variable and re-concatting things right now.",-1
"This just gets read before it goes into the custom_gradient, right? So I don't think it's involved much, and confuses the example a bit.

Maybe `x = tf.constant([1., 2., 3.])` here, and you'll want to watch it on the tape explicitly.",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638343271,allenlavoie,2021-05-24 22:59:52,26270,49488,Documentation bug,0,"This just gets read before it goes into the custom_gradient, right? So I don't think it's involved much, and confuses the example a bit. Maybe [code] here, and you'll want to watch it on the tape explicitly.",-1
"Not sure what ""Computing gradient in case of batches"" means.

Maybe just delete this bit, but otherwise as a nit s/""computing it's gradient""/""computing its gradient""/",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638344197,allenlavoie,2021-05-24 23:02:24,26270,49488,Documentation bug,0,"Not sure what ""Computing gradient in case of batches"" means. Maybe just delete this bit, but otherwise as a nit s/""computing it's gradient""/""computing its gradient""/",0
"grammar/style nits: ""In the example, the inner `grad_fn` accepts an extra `variables` input parameter and also returns an extra `grad_vars` output."" (I'd leave off the ""scalar gradient functions"" bit, since it's stateless vs. stateful more than scalar vs. non-scalar)",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638344460,allenlavoie,2021-05-24 23:03:18,26270,49488,Documentation bug,0,"grammar/style nits: ""In the example, the inner [code] accepts an extra [code] input parameter and also returns an extra [code] output."" (I'd leave off the ""scalar gradient functions"" bit, since it's stateless vs. stateful more than scalar vs. non-scalar)",0
"""That extra argument is passed if you have any trainable parameters in your model. You need to compute the gradient w.r.t. each of those variables and output it as a list of `grad_vars`. Note here that default value of `variables` is set to `None` when no variables are used in the forward function.""",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638346048,allenlavoie,2021-05-24 23:08:15,26270,49488,Documentation bug,0,"""That extra argument is passed if you have any trainable parameters in your model. You need to compute the gradient w.r.t. each of those variables and output it as a list of [code]. Note here that default value of [code] is set to [code] when no variables are used in the forward function.""",0
"Is this paragraph relevant to `tf.custom_gradient`? The docstring is already quite long, if we can cut this it would be helpful.",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638346708,allenlavoie,2021-05-24 23:10:08,26270,49488,Documentation bug,0,"Is this paragraph relevant to [code]? The docstring is already quite long, if we can cut this it would be helpful.",1
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638459908,ashutosh1919,2021-05-25 05:15:48,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638459972,ashutosh1919,2021-05-25 05:15:55,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638460052,ashutosh1919,2021-05-25 05:16:08,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638460092,ashutosh1919,2021-05-25 05:16:14,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638460137,ashutosh1919,2021-05-25 05:16:23,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638460177,ashutosh1919,2021-05-25 05:16:29,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638460228,ashutosh1919,2021-05-25 05:16:36,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r638460476,ashutosh1919,2021-05-25 05:17:22,26270,49488,Documentation bug,0,done,0
"I would just take this summary out, I don't think it's adding much.",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639011190,allenlavoie,2021-05-25 17:25:36,26270,49488,Documentation bug,0,"I would just take this summary out, I don't think it's adding much.",-1
"Missed this the first time, but I'd replace ""if you have any trainable parameters in your model."" with ""if the forward function reads any variables.""",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639013275,allenlavoie,2021-05-25 17:28:33,26270,49488,Documentation bug,0,"Missed this the first time, but I'd replace ""if you have any trainable parameters in your model."" with ""if the forward function reads any variables.""",0
"This still looks like it can be simplified: ""assert variables is not None"" and reduce the indent, no loop just ""assert len(variables) == 1 and variables[0] is weights""",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639017364,allenlavoie,2021-05-25 17:33:13,26270,49488,Documentation bug,0,"This still looks like it can be simplified: ""assert variables is not None"" and reduce the indent, no loop just ""assert len(variables) == 1 and variables[0] is weights""",0
Shouldn't this depend on dpoly?,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639018201,allenlavoie,2021-05-25 17:33:55,26270,49488,Documentation bug,0,Shouldn't this depend on dpoly?,0
"Maybe to simplify the example just omit the batching bits and the `else:` and `tf.reduce_sum(tf.reshape(dy_dw, [2, -1]), axis=1)` instead",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639021296,allenlavoie,2021-05-25 17:36:34,26270,49488,Documentation bug,0,Maybe to simplify the example just omit the batching bits and the [code] and [code] instead,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639391592,ashutosh1919,2021-05-26 04:27:25,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639391626,ashutosh1919,2021-05-26 04:27:32,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639391677,ashutosh1919,2021-05-26 04:27:43,26270,49488,Documentation bug,0,done,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639391770,ashutosh1919,2021-05-26 04:28:01,26270,49488,Documentation bug,0,done,0
"Maybe just remove this note? I'm not sure what it's saying. It's returning the correctly sized gradient for the example, so maybe no explanation is needed here.",PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639874132,allenlavoie,2021-05-26 16:01:32,26270,49488,Documentation bug,0,"Maybe just remove this note? I'm not sure what it's saying. It's returning the correctly sized gradient for the example, so maybe no explanation is needed here.",1
done,PrComment,https://github.com/tensorflow/tensorflow/pull/49488#discussion_r639891383,ashutosh1919,2021-05-26 16:23:06,26270,49488,Documentation bug,0,done,0
"It's probably better to put this line inside the scope of the `with ops.name_scope(name)`.  (I.e., move it down one line.)  That way, if you're inspecting the graph produced by this op, it will be clear that the conversion was done as part of the reduce_variance op.",PrComment,https://github.com/tensorflow/tensorflow/pull/49609#discussion_r640618500,edloper,2021-05-27 13:22:37,49606,49609,Data bug,0,"It's probably better to put this line inside the scope of the [code]. (I.e., move it down one line.) That way, if you're inspecting the graph produced by this op, it will be clear that the conversion was done as part of the reduce_variance op.",1
"@edloper, let me do one thing. Let me add test case as well for this. I haven't tested it thoroughly. Let me do that first. re-requesting you again so that ready-to-pull is removed.",PrComment,https://github.com/tensorflow/tensorflow/pull/49609#discussion_r640741566,ashutosh1919,2021-05-27 15:35:48,49606,49609,Data bug,0,"@edloper, let me do one thing. Let me add test case as well for this. I haven't tested it thoroughly. Let me do that first. re-requesting you again so that ready-to-pull is removed.",0
+1 please add a test for this so that we can ensure it fixes the problem!,PrComment,https://github.com/tensorflow/tensorflow/pull/49609#discussion_r641273938,rohan100jain,2021-05-28 05:18:50,49606,49609,Data bug,0,+1 please add a test for this so that we can ensure it fixes the problem!,2
"I think something like this should be done on runtime startup.

We've seen quite a few issues when folks tried to run TF built with CUDA-11.3 on the drivers 460. It does not fail right away, but tends to cause weird issues later one. Some apps work OK, others crash or fail with odd CUDA errors. No idea what exactly triggers the failures.

Checking if the driver is recent enough for the CUDA version we build with, and issuing a warning if it's not, would be very useful. CUDA-11 was supposed to be driver-agnostic, but while it removed the strict checks for the driver version, it did not quite remove the dependency on recent enough driver versions.",PrComment,https://github.com/tensorflow/tensorflow/pull/50961#discussion_r696148902,Artem-B,2021-08-25 22:11:39,50669,50961,Processor bug,0,"I think something like this should be done on runtime startup. We've seen quite a few issues when folks tried to run TF built with CUDA-11.3 on the drivers 460. It does not fail right away, but tends to cause weird issues later one. Some apps work OK, others crash or fail with odd CUDA errors. No idea what exactly triggers the failures. Checking if the driver is recent enough for the CUDA version we build with, and issuing a warning if it's not, would be very useful. CUDA-11 was supposed to be driver-agnostic, but while it removed the strict checks for the driver version, it did not quite remove the dependency on recent enough driver versions.",-1
"Do you have example of problems that this cause?
If a new 11.X version introduce new features, then some of those features need new feature inside the driver. Like cudaMallocAsync. In that case, I think it is impossible to backport this to older 11.X. 
To my knowledge, the compatibility between 11.X driver is only if you limit yourself to features in 11.0. If you use the new feature, then you are bumping the minimum driver requirement.

So you only need to take care about new features that need new drivers.

Personally, I think it is useful for TF user that those new features are enabled only when a recent enough driver is installed. So those feature should detect the version and be enabled only when they are available.

I think that crashing as you suggest is too strong.",PrComment,https://github.com/tensorflow/tensorflow/pull/50961#discussion_r696617088,nouiz,2021-08-26 13:14:39,50669,50961,Processor bug,0,"Do you have example of problems that this cause? If a new 11.X version introduce new features, then some of those features need new feature inside the driver. Like cudaMallocAsync. In that case, I think it is impossible to backport this to older 11.X. To my knowledge, the compatibility between 11.X driver is only if you limit yourself to features in 11.0. If you use the new feature, then you are bumping the minimum driver requirement. So you only need to take care about new features that need new drivers. Personally, I think it is useful for TF user that those new features are enabled only when a recent enough driver is installed. So those feature should detect the version and be enabled only when they are available. I think that crashing as you suggest is too strong.",0
"Let's instead change this to use [`AddDimWithStatus`](https://github.com/tensorflow/tensorflow/blob/51d911b4661b290f0e207fc7cf1ec79b9e411a58/tensorflow/core/framework/tensor_shape.h#L208-L210) and wrap that in `OP_REQUIRES_OK`.

Also, if we want to display a shape in an error message, `shape.DebugString()` is the best API to use.",PrComment,https://github.com/tensorflow/tensorflow/pull/51138#discussion_r682808547,mihaimaruseac,2021-08-04 17:14:26,46911,51138,Data bug,1,"Let's instead change this to use [[code]]([url]#L208-L210) and wrap that in [code]. Also, if we want to display a shape in an error message, [code] is the best API to use.",0
Let's separate each branch to a separate expression to ease in readability.,PrComment,https://github.com/tensorflow/tensorflow/pull/51359#discussion_r685272958,mihaimaruseac,2021-08-09 15:01:14,46913,51359,Data bug,1,Let's separate each branch to a separate expression to ease in readability.,2
"Why doesn't the 

```
    OP_REQUIRES(context, output_rows >= 0,
                errors::InvalidArgument(""segment ids must be >= 0""));
```

check above catch this?",PrComment,https://github.com/tensorflow/tensorflow/pull/51733#discussion_r698959176,sanjoy,2021-08-31 03:42:09,46888,51733,Data bug,1,Why doesn't the ``[code]`` check above catch this?,-2
What error is this catching?,PrComment,https://github.com/tensorflow/tensorflow/pull/51733#discussion_r698959322,sanjoy,2021-08-31 03:42:29,46888,51733,Data bug,1,What error is this catching?,0
`SetDim` also checks that the total tensor size does not overflow.,PrComment,https://github.com/tensorflow/tensorflow/pull/51733#discussion_r699474954,mihaimaruseac,2021-08-31 16:09:37,46888,51733,Data bug,1,[code] also checks that the total tensor size does not overflow.,0
"Thanks, maybe add a comment?",PrComment,https://github.com/tensorflow/tensorflow/pull/51733#discussion_r701525916,sanjoy,2021-09-03 01:36:53,46888,51733,Data bug,1,"Thanks, maybe add a comment?",1
Added in the manual import.,PrComment,https://github.com/tensorflow/tensorflow/pull/51733#discussion_r737680024,mihaimaruseac,2021-10-27 17:09:42,46888,51733,Data bug,1,Added in the manual import.,0
I don't think this is needed. Reverted in the local import.,PrComment,https://github.com/tensorflow/tensorflow/pull/51733#discussion_r737681119,mihaimaruseac,2021-10-27 17:10:30,46888,51733,Data bug,1,I don't think this is needed. Reverted in the local import.,-2
"This would change the type of parent. Try this instead:

```
parent = f.f_back if f is not None else None
```",PrComment,https://github.com/tensorflow/tensorflow/pull/51972#discussion_r707313896,mdanatg,2021-09-13 13:04:34,49225,51972,Code bug,0,This would change the type of parent. Try this instead: ``[code]``,0
"@mdanatg Thank you for the feedback. I am using short-circuiting to do the same thing which you mentioned because I thought it would look cleaner. Please check the screenshot below, I know it is a small change, but I'm not sure how it would change the type of `parent`. If `parent` becomes `NoneType` then that check is handled in line 111.
Kindly correct me if I'm going wrong.
![Screenshot from 2021-09-14 01-06-35](https://user-images.githubusercontent.com/60918872/133146114-d073a27d-a440-408c-a148-0855f2a6b8f9.png)
",PrComment,https://github.com/tensorflow/tensorflow/pull/51972#discussion_r707636899,AdeshChoudhar,2021-09-13 19:54:42,49225,51972,Code bug,0,"@mdanatg Thank you for the feedback. I am using short-circuiting to do the same thing which you mentioned because I thought it would look cleaner. Please check the screenshot below, I know it is a small change, but I'm not sure how it would change the type of [code]. If [code] becomes [code] then that check is handled in line 111. Kindly correct me if I'm going wrong. ![Screenshot from 2021-09-14 01-06-35]([url]",2
Ah I forgot about the short circuiting. LGTM then.,PrComment,https://github.com/tensorflow/tensorflow/pull/51972#discussion_r707644056,mdanatg,2021-09-13 20:06:14,49225,51972,Code bug,0,Ah I forgot about the short circuiting. LGTM then.,3
Yes. Thank you!,PrComment,https://github.com/tensorflow/tensorflow/pull/51972#discussion_r707648708,AdeshChoudhar,2021-09-13 20:13:41,49225,51972,Code bug,0,Yes. Thank you!,5
s/a source/source/?,PrComment,https://github.com/tensorflow/tensorflow/pull/53158#discussion_r853299375,bixia1,2022-04-19 17:01:35,53157,53158,Documentation bug,0,s/a source/source/?,0
I'm sorry but I don't understand the suggested change?,PrComment,https://github.com/tensorflow/tensorflow/pull/53158#discussion_r853311857,Nyrio,2022-04-19 17:16:59,53157,53158,Documentation bug,0,I'm sorry but I don't understand the suggested change?,0
"""a source and destination format strings"" doesn't look right to me. Would ""source and destination format strings"" work?",PrComment,https://github.com/tensorflow/tensorflow/pull/53158#discussion_r853321441,bixia1,2022-04-19 17:28:35,53157,53158,Documentation bug,0,"""a source and destination format strings"" doesn't look right to me. Would ""source and destination format strings"" work?",1
"Do you see an issue when running under the ASAN?

I'm wondering since literals, e.g,  ""_mlir_device"" have static storage duration and live the whole duration of the program.
So, taking StringRef from a string literal should be completely safe.

ArrayRef<...> keywords{"".."", ""..""} gets constructed from the initializer_list < llvm::StringRef > (https://llvm.org/doxygen/ArrayRef_8h_source.html#l00114)
which is safe as well, makes copies internally.
 ",PrComment,https://github.com/tensorflow/tensorflow/pull/53167#discussion_r770851138,rdzhabarov,2021-12-16 19:15:42,53166,53167,Test bug,0,"Do you see an issue when running under the ASAN? I'm wondering since literals, e.g, ""_mlir_device"" have static storage duration and live the whole duration of the program. So, taking StringRef from a string literal should be completely safe. ArrayRef<...> keywords{"".."", ""..""} gets constructed from the initializer_list < llvm::StringRef > ([url]#l00114) which is safe as well, makes copies internally.",0
"What I see is that before https://github.com/tensorflow/tensorflow/blob/4a265a6f3a8ea441e6135da03aafa773bbce5505/tensorflow/core/ir/ops.cc#L202 the array that ArrayRef keywords references is OK, but after that line, the first entry in that array has been overwritten. Looking at the assembler I can see the write to the memory location of that array which appears to be being used as temporary storage. So my conclusion was that the storage for the array itself was only temporarily allocated and hence available to the compiler for re-use. Depending on the optimization level in use, this could either lead to a crash or else just incorrect behaviour.
Now it may be overkill to create Strings for the string literals for the StringRefs to refer to, but something certainly needs to be done to extend the life of the array of those StringRefs. The compiler believes that memory is fair game.",PrComment,https://github.com/tensorflow/tensorflow/pull/53167#discussion_r771233426,elfringham,2021-12-17 09:29:59,53166,53167,Test bug,0,"What I see is that before [url]#L202 the array that ArrayRef keywords references is OK, but after that line, the first entry in that array has been overwritten. Looking at the assembler I can see the write to the memory location of that array which appears to be being used as temporary storage. So my conclusion was that the storage for the array itself was only temporarily allocated and hence available to the compiler for re-use. Depending on the optimization level in use, this could either lead to a crash or else just incorrect behaviour. Now it may be overkill to create Strings for the string literals for the StringRefs to refer to, but something certainly needs to be done to extend the life of the array of those StringRefs. The compiler believes that memory is fair game.",-2
"Interesting, I see. Could you check if this is sufficient?
```
  std::array<llvm::StringRef, 3> keywords = {""_mlir_device"", ""_mlir_assigned_device"", ""_mlir_name""};
  ```",PrComment,https://github.com/tensorflow/tensorflow/pull/53167#discussion_r772629684,rdzhabarov,2021-12-20 19:52:20,53166,53167,Test bug,0,"Interesting, I see. Could you check if this is sufficient? ``[code]``",0
Yes that is sufficient.,PrComment,https://github.com/tensorflow/tensorflow/pull/53167#discussion_r773107547,elfringham,2021-12-21 12:47:47,53166,53167,Test bug,0,Yes that is sufficient.,2
Sounds good!,PrComment,https://github.com/tensorflow/tensorflow/pull/53167#discussion_r773513638,rdzhabarov,2021-12-22 00:01:38,53166,53167,Test bug,0,Sounds good!,3
"This sometimes errors with

```
  File "".../tensorflow/python/histogram_ops_test_cpu.runfiles/org_tensorflow/tensorflow/python/ops/histogram_ops.py"", line 144, in histogram_fixed_width
    if nbins < 0:
TypeError: '<' not supported between instances of 'list' and 'int'
```",PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r795849436,mihaimaruseac,2022-01-31 16:33:29,54125,54191,Data bug,0,This sometimes errors with ``[code]``,-2
"This one is handled in the C++ implementation, we don't need it here.",PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r795859341,mihaimaruseac,2022-01-31 16:43:39,54125,54191,Data bug,0,"This one is handled in the C++ implementation, we don't need it here.",1
The C++ implementation return `InvalidArgumentError`.,PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r795859801,mihaimaruseac,2022-01-31 16:44:03,54125,54191,Data bug,0,The C++ implementation return [code].,0
"This does not go to the C++ implementation, so it needs to be handled here,but needs to validate that the argument is either a number (int) or a scalar tensor of integral dtype.",PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r795860683,mihaimaruseac,2022-01-31 16:44:47,54125,54191,Data bug,0,"This does not go to the C++ implementation, so it needs to be handled here,but needs to validate that the argument is either a number (int) or a scalar tensor of integral dtype.",0
"This was throwing error due to the condition at line 144, now I have removed it since it is being handled in C++. 
nbins:  Scalar `int32 Tensor`.  Number of histogram bins.",PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r797005966,sachinprasadhs,2022-02-01 20:49:58,54125,54191,Data bug,0,"This was throwing error due to the condition at line 144, now I have removed it since it is being handled in C++. nbins: Scalar [code]. Number of histogram bins.",0
Removed this condition.,PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r797006297,sachinprasadhs,2022-02-01 20:50:19,54125,54191,Data bug,0,Removed this condition.,0
Changed it to `tf.errors.InvalidArgumentError`,PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r797006710,sachinprasadhs,2022-02-01 20:50:47,54125,54191,Data bug,0,Changed it to [code],0
"This doesn't call the function that includes line 144, so it was not giving an error due to it.",PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r797014312,mihaimaruseac,2022-02-01 20:58:54,54125,54191,Data bug,0,"This doesn't call the function that includes line 144, so it was not giving an error due to it.",0
"Please add another test where `nbins` is given by a 0-D tensor

Ideally, we'd also add a test where multidimensional tensors are used so we'd get that error too.",PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r797014956,mihaimaruseac,2022-02-01 20:59:41,54125,54191,Data bug,0,"Please add another test where [code] is given by a 0-D tensor Ideally, we'd also add a test where multidimensional tensors are used so we'd get that error too.",0
"error says `line 144, in histogram_fixed_width File "".../tensorflow/python/histogram_ops_test_cpu.runfiles/org_tensorflow/tensorflow/python/ops/histogram_ops.py"",`",PrComment,https://github.com/tensorflow/tensorflow/pull/54191#discussion_r797071837,sachinprasadhs,2022-02-01 22:03:02,54125,54191,Data bug,0,error says [code],-2
"Change this to ""On CPU and GPU:  Caller may...""

since (as noted by other commenters) using sparse labels will be significantly faster.",PrComment,https://github.com/tensorflow/tensorflow/pull/55365#discussion_r958681636,cantonios,2022-08-30 16:13:23,55290,55365,Documentation bug,0,"Change this to ""On CPU and GPU: Caller may..."" since (as noted by other commenters) using sparse labels will be significantly faster.",0
"~~this change is not needed - notice the leading `f` on line 196~~ nvm, I was corrected on IRC.",PrComment,https://github.com/tensorflow/tensorflow/pull/55726#discussion_r862081672,ezzieyguywuf,2022-04-29 19:15:25,55723,55726,Documentation bug,0,"~~this change is not needed - notice the leading [code] on line 196~~ nvm, I was corrected on IRC.",0
"~~again, this is a spurious change - perhaps check your checker script so that these multi-line literals are ignored if they already have the leading f?~~ nvm, I was corrected on IRC. I'll leave this here for shamecube purposes.",PrComment,https://github.com/tensorflow/tensorflow/pull/55726#discussion_r862082142,ezzieyguywuf,2022-04-29 19:16:20,55723,55726,Documentation bug,0,"~~again, this is a spurious change - perhaps check your checker script so that these multi-line literals are ignored if they already have the leading f?~~ nvm, I was corrected on IRC. I'll leave this here for shamecube purposes.",-1
"I think we could even remove it, I see error and log don't have one.",PrComment,https://github.com/tensorflow/tensorflow/pull/55831#discussion_r863156963,mdanatg,2022-05-02 20:14:25,55795,55831,Build bug,0,"I think we could even remove it, I see error and log don't have one.",0
"Prefer `static_cast`, it is well-defined here.",PrComment,https://github.com/tensorflow/tensorflow/pull/56136#discussion_r931759941,cantonios,2022-07-28 03:59:00,56134,56136,Processor bug,0,"Prefer [code], it is well-defined here.",1
"Fixed, thanks",PrComment,https://github.com/tensorflow/tensorflow/pull/56136#discussion_r931940093,dev0x13,2022-07-28 08:38:18,56134,56136,Processor bug,0,"Fixed, thanks",3
"This last return seems to be the exact same as the one below, can we remove this one?",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r920263313,cantonios,2022-07-13 16:10:04,56046,56167,Test bug,0,"This last return seems to be the exact same as the one below, can we remove this one?",0
"Judging from the description, this issue is not only present for s390x, we have the same thing for any big-endian system with 64-bit `size_t`.  In the case of big-endian and `TF_TSTR_OFFSET`, instead of putting the type in the MSB byte, we should *always* be putting it in the 4th byte from the right.",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r920512019,cantonios,2022-07-13 21:03:26,56046,56167,Test bug,0,"Judging from the description, this issue is not only present for s390x, we have the same thing for any big-endian system with 64-bit [code]. In the case of big-endian and [code], instead of putting the type in the MSB byte, we should *always* be putting it in the 4th byte from the right.",0
"This doesn't look right... I think the `type` information will be merged with existing (non-masked) bits.

Let's say the`size` is `0x00000000 3FFFFFFF`, and the type is `0x02` (offset)
```
size = 0x00000000 3FFFFFFF
mask = 0xFF000000 00000000

 mask & (size << 2) = 0x00000000 00000000
~mask & (size << 2) = 0x00000000 FFFFFFFC
         type << 24 = 0x00000000 20000000
                   _______________________
or                  = 0x00000000 FFFFFFFC
```
The type information is then corrupted.  I believe you want the mask to always be `0xFF000000` in the case of offset.
",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r920524299,cantonios,2022-07-13 21:21:28,56046,56167,Test bug,0,"This doesn't look right... I think the [code] information will be merged with existing (non-masked) bits. Let's say the[code] is [code], and the type is [code] (offset) ``[code]`[code]0xFF000000` in the case of offset.",-2
Shouldn't this be some kind of `TF_TString_ToActualSize_T`?,PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r920527015,cantonios,2022-07-13 21:25:39,56046,56167,Test bug,0,Shouldn't this be some kind of [code]?,0
"Thank you for finding and reporting this bug!
My current understanding is that `TF_TString_ToInternalSizeT` should only be used with ""large"" and ""view"" representations that use `size_t size`. The ""offset"" representation uses ""uint32_t size"". My thought is that the issue should be solved by creating a `TF_TString_ToInternalUint32T` function (which uses `uint32_t` and not `size_t`) and have the test use this new function.",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r921426372,SeeForTwo,2022-07-14 17:51:28,56046,56167,Test bug,0,"Thank you for finding and reporting this bug! My current understanding is that [code] should only be used with ""large"" and ""view"" representations that use [code]. The ""offset"" representation uses ""uint32_t size"". My thought is that the issue should be solved by creating a [code] function (which uses [code] and not [code]) and have the test use this new function.",3
"Sure, sounds good to me.",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r921514319,cantonios,2022-07-14 19:46:28,56046,56167,Test bug,0,"Sure, sounds good to me.",3
"To clarify, the bug here is in the test; ctstring_test.cc is the only user of `TF_TString_ToInternalSizeT(..., TF_TSTR_OFFSET);` which as @SeeForTwo  mentioned is an invalid use.  This test was added after the original implementation.

The test should not be using internal functions for generating offset types.  Offset types were written as a placeholder for a future potential need for memory map-able tstrings, and as such, generation of offset types was not implemented, as they would need to be done with a series of tstrings in mind in order to generate an offset table and its associated packed contiguous data segement.  Generating a single OFFSET type doesn't have much use.

To resolve this either: 1) remove the test, or since OFFSET types are expected to be little-endian u32, 2) construct a byte sequence by hand for size and offset.",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r921541203,gharibian,2022-07-14 20:23:20,56046,56167,Test bug,0,"To clarify, the bug here is in the test; ctstring_test.cc is the only user of [code] which as @SeeForTwo mentioned is an invalid use. This test was added after the original implementation. The test should not be using internal functions for generating offset types. Offset types were written as a placeholder for a future potential need for memory map-able tstrings, and as such, generation of offset types was not implemented, as they would need to be done with a series of tstrings in mind in order to generate an offset table and its associated packed contiguous data segement. Generating a single OFFSET type doesn't have much use. To resolve this either: 1) remove the test, or since OFFSET types are expected to be little-endian u32, 2) construct a byte sequence by hand for size and offset.",0
"Good summary.

> 2) construct a byte sequence by hand for size and offset.

This seems reasonable. While Offset types are currently a placeholder, some code for them exists and at can be exercised, so I see advantage in keeping and fixing the test.

Any other thoughts?",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r921549103,SeeForTwo,2022-07-14 20:34:49,56046,56167,Test bug,0,"Good summary. > 2) construct a byte sequence by hand for size and offset. This seems reasonable. While Offset types are currently a placeholder, some code for them exists and at can be exercised, so I see advantage in keeping and fixing the test. Any other thoughts?",3
I have no preference.,PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r921549457,cantonios,2022-07-14 20:35:24,56046,56167,Test bug,0,I have no preference.,0
"Looking closer at the existing test, there are several issues with it. @namrata-ibm please replace the OffsetType test with the following and try it out on your big-endian arch.   If there are no issues, please update your pull request to include:

```
 TEST(TF_CTStringTest, OffsetType) {
    {
      uint8_t str[] = ""test"";
      constexpr size_t str_size = sizeof(str) / sizeof(str[0]);
   
      uint8_t buf[sizeof(TF_TString) + str_size];
   
      memcpy(buf + sizeof(TF_TString), str, str_size);
   
      TF_TString *offsets = (TF_TString *)buf;
      TF_TString_Init(offsets);
   
      offsets[0].u.offset.size = TF_le32toh(str_size << 2 | TF_TSTR_OFFSET);
      offsets[0].u.offset.offset = TF_le32toh(sizeof(TF_TString));
      offsets[0].u.offset.count = TF_le32toh(1);
                                                                                                                                                                                                                   
      EXPECT_EQ(str_size, TF_TString_GetSize(offsets));
      EXPECT_EQ(TF_TSTR_OFFSET, TF_TString_GetType(offsets));
      EXPECT_EQ(0, ::memcmp(str, TF_TString_GetDataPointer(offsets), str_size));
    }
  }
```",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r921579383,gharibian,2022-07-14 21:17:20,56046,56167,Test bug,0,"Looking closer at the existing test, there are several issues with it. @namrata-ibm please replace the OffsetType test with the following and try it out on your big-endian arch. If there are no issues, please update your pull request to include: ``[code]``",0
"Note that we are 'technically' doing 'TF_htole32', but a macro with that name doesn't currently exist.  It would be the same exact function though. Feel free to add one in ctstring_internal.h or keep as is (and maybe make a comment)",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r921585268,gharibian,2022-07-14 21:27:04,56046,56167,Test bug,0,"Note that we are 'technically' doing 'TF_htole32', but a macro with that name doesn't currently exist. It would be the same exact function though. Feel free to add one in ctstring_internal.h or keep as is (and maybe make a comment)",0
"Thank you @cantonios @SeeForTwo @gharibian for your valuable comments. 

@gharibian I tried above test on BE, however `EXPECT_EQ(0, ::memcmp(str, TF_TString_GetDataPointer(offsets), str_size));` this check produces a crash on BE. Particularly `TF_TString_GetDataPointer(offsets)` is problematic.",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r922230890,namrata-ibm,2022-07-15 14:37:46,56046,56167,Test bug,0,"Thank you @cantonios @SeeForTwo @gharibian for your valuable comments. @gharibian I tried above test on BE, however [code] this check produces a crash on BE. Particularly [code] is problematic.",-1
"@namrata-ibm, thank you for your patience! I would defer to @gharibian, but I think that in TF_TString_GetDataPointer the current:
```
    case TF_TSTR_OFFSET:
      return (const char *)str + str->u.offset.offset;  // NOLINT
```

should be changed to use TF_le32toh:

```
    case TF_TSTR_OFFSET:
      return (const char *)str + TF_le32toh(str->u.offset.offset);  // NOLINT
```",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r922328698,SeeForTwo,2022-07-15 16:32:21,56046,56167,Test bug,0,"@namrata-ibm, thank you for your patience! I would defer to @gharibian, but I think that in TF_TString_GetDataPointer the current: ``[code]`[code]`[code]``",2
"@SeeForTwo Yes, that works on LE and BE.",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r922669261,namrata-ibm,2022-07-16 11:21:30,56046,56167,Test bug,0,"@SeeForTwo Yes, that works on LE and BE.",3
"That looks good, thanks for catching that @SeeForTwo ",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r923598660,gharibian,2022-07-18 16:52:17,56046,56167,Test bug,0,"That looks good, thanks for catching that @SeeForTwo",3
"> Yes, that works on LE and BE.

@namrata-ibm, wonderful! If you are happy with the working software that you have, could you please update the PR when you have time?  (My apologies if you've already updated and I'm just confused by how to see it in github.) ",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r923878539,SeeForTwo,2022-07-18 21:33:10,56046,56167,Test bug,0,"> Yes, that works on LE and BE. @namrata-ibm, wonderful! If you are happy with the working software that you have, could you please update the PR when you have time? (My apologies if you've already updated and I'm just confused by how to see it in github.)",3
"@SeeForTwo Updated the PR, Thank you!",PrComment,https://github.com/tensorflow/tensorflow/pull/56167#discussion_r924140830,namrata-ibm,2022-07-19 07:13:56,56046,56167,Test bug,0,"@SeeForTwo Updated the PR, Thank you!",3
So it interfered xnnpack delegate option?,PrComment,https://github.com/tensorflow/tensorflow/pull/56369#discussion_r890456850,terryheo,2022-06-06 19:09:12,56367,56369,Build bug,0,So it interfered xnnpack delegate option?,-2
"Yes. Cannot be executed with the xnnpack delegate option.
```
Type mismatch while accessing parameter.
Abort
```


When specifying the xnnpack delegate option, the specification in `Interpreter::SetNumThreads` does not work. Must be specified in `DelegateProviders`.",PrComment,https://github.com/tensorflow/tensorflow/pull/56369#discussion_r890615581,NobuoTsukamoto,2022-06-06 22:24:43,56367,56369,Build bug,0,Yes. Cannot be executed with the xnnpack delegate option. ``[code]`[code]Interpreter::SetNumThreads[code]DelegateProviders`.,-2
Got it. Thanks for the confirmation.,PrComment,https://github.com/tensorflow/tensorflow/pull/56369#discussion_r890617142,terryheo,2022-06-06 22:28:04,56367,56369,Build bug,0,Got it. Thanks for the confirmation.,2
Could you add a comment for what this means? Thank you.,PrComment,https://github.com/tensorflow/tensorflow/pull/56841#discussion_r926116798,yangustc07,2022-07-20 22:57:03,56840,56841,Test bug,0,Could you add a comment for what this means? Thank you.,2
Comment added.,PrComment,https://github.com/tensorflow/tensorflow/pull/56841#discussion_r926406889,elfringham,2022-07-21 08:34:29,56840,56841,Test bug,0,Comment added.,0
"You should update the default value instead, although that will require an API review, I believe.",PrComment,https://github.com/tensorflow/tensorflow/pull/15531#discussion_r163362958,rmlarsen,2018-01-23 20:10:16,15529,15531,Data bug,0,"You should update the default value instead, although that will require an API review, I believe.",0
"The documentation already states that the default is 0.1, so I think it would be fine to change it.",PrComment,https://github.com/tensorflow/tensorflow/pull/15531#discussion_r163365283,rmlarsen,2018-01-23 20:20:08,15529,15531,Data bug,0,"The documentation already states that the default is 0.1, so I think it would be fine to change it.",2
"`tf.numpy_function` only accepts numpu arrays and only returns numpy arrays

https://www.tensorflow.org/api_docs/python/tf/numpy_function",PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r397271563,mihaimaruseac,2020-03-24 16:04:23,36979,37853,Data bug,0,[code] only accepts numpu arrays and only returns numpy arrays [url],0
"```suggestion
    3) Use `tf.numpy_function`, which also allows you to write arbitrary Python
```",PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r397271693,mihaimaruseac,2020-03-24 16:04:33,36979,37853,Data bug,0,``[code]tf.numpy_function[code]``,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r397597978,ashutosh1919,2020-03-25 04:03:29,36979,37853,Data bug,0,done,0
Done,PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r397598017,ashutosh1919,2020-03-25 04:03:38,36979,37853,Data bug,0,Done,0
Please add information about that fact the the use of `tf.numpy_function` and `tf.py_function` in general precludes the possibility of executing user-defined transformations in parallel (because of Python GIL).,PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r400289492,jsimsa,2020-03-30 15:35:45,36979,37853,Data bug,0,Please add information about that fact the the use of [code] and [code] in general precludes the possibility of executing user-defined transformations in parallel (because of Python GIL).,0
Done,PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r401566347,ashutosh1919,2020-04-01 12:10:55,36979,37853,Data bug,0,Done,0
"thank you, please remove ""the fact"" ... so this should start with ""Note that the use of ...""",PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r401742854,jsimsa,2020-04-01 16:21:26,36979,37853,Data bug,0,"thank you, please remove ""the fact"" ... so this should start with ""Note that the use of ...""",2
"```suggestion
    Note that the use of `tf.numpy_function` and `tf.py_function`
```",PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r402012644,mihaimaruseac,2020-04-02 02:10:41,36979,37853,Data bug,0,``[code]tf.numpy_function[code]tf.py_function[code]``,0
done,PrComment,https://github.com/tensorflow/tensorflow/pull/37853#discussion_r402096812,ashutosh1919,2020-04-02 07:11:14,36979,37853,Data bug,0,done,0
return type should be char,PrComment,https://github.com/tensorflow/tensorflow/pull/39281#discussion_r421960955,yifeif,2020-05-08 06:18:23,39280,39281,Build bug,0,return type should be char,0
"same here, but I'm not sure what char to return if not found. @chsigg ",PrComment,https://github.com/tensorflow/tensorflow/pull/39281#discussion_r421961249,yifeif,2020-05-08 06:19:12,39280,39281,Build bug,0,"same here, but I'm not sure what char to return if not found. @chsigg",0
"0, 1, or Ï€
;-)

It's not documented, but probably Bastiaan has access to the implementation.",PrComment,https://github.com/tensorflow/tensorflow/pull/39281#discussion_r421984683,chsigg,2020-05-08 07:17:07,39280,39281,Build bug,0,"0, 1, or Ï€ ;-) It's not documented, but probably Bastiaan has access to the implementation.",0
done. too eager with copy-paste,PrComment,https://github.com/tensorflow/tensorflow/pull/39281#discussion_r422193381,bas-aarts,2020-05-08 14:59:27,39280,39281,Build bug,0,done. too eager with copy-paste,-1
"done. too eager with copy-paste.
0 on failure",PrComment,https://github.com/tensorflow/tensorflow/pull/39281#discussion_r422193531,bas-aarts,2020-05-08 14:59:43,39280,39281,Build bug,0,done. too eager with copy-paste. 0 on failure,-1
I thought that might have been the case :). LG!,PrComment,https://github.com/tensorflow/tensorflow/pull/39281#discussion_r422256199,yifeif,2020-05-08 16:58:56,39280,39281,Build bug,0,I thought that might have been the case :). LG!,3
Thanks @bas-aarts and @chsigg!,PrComment,https://github.com/tensorflow/tensorflow/pull/39281#discussion_r422256278,yifeif,2020-05-08 16:59:05,39280,39281,Build bug,0,Thanks @bas-aarts and @chsigg!,5
Does this needed the `run_deprecated_v1` and `with self.session()`?  We're trying to slowly update all these tests to run in V2 mode.,PrComment,https://github.com/tensorflow/tensorflow/pull/57854#discussion_r981401016,cantonios,2022-09-27 15:31:45,46915,57854,Algorithm design bug,1,Does this needed the [code] and [code]? We're trying to slowly update all these tests to run in V2 mode.,0
